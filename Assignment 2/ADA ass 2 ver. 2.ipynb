{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually doing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import langid\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from itertools import chain\n",
    "import itertools\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import preprocessor as p\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from textblob import Word\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "\n",
    "from nltk.util import ngrams\n",
    "from itertools import chain\n",
    "from nltk.probability import *\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_data_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs                  9569\n",
      "math.AG             1280\n",
      "math.CO             1023\n",
      "astro-ph.HE          864\n",
      "math.AP              752\n",
      "                    ... \n",
      "math.HO               16\n",
      "physics.atm-clus      13\n",
      "physics.pop-ph        11\n",
      "nlin.CG               10\n",
      "stat.OT                7\n",
      "Name: label, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Counter(data['label'])\n",
    "\n",
    "count_class = pd.value_counts(data['label'])\n",
    "print(count_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'label')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "count_class.plot(kind='bar')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.tokenize.punkt.PunktSentenceTokenizer at 0x2c51c2ef508>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "sent_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = []\n",
    "with open('stopwords_en.txt') as f:\n",
    "    for line in f:\n",
    "        stopwords_list.append(line.strip('\\n'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data_labels.csv')\n",
    "test_data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'save for some special cases, current training methods for generative adversarial networks (gans) are at best guaranteed to converge to a `local nash equilibrium` (lne). such lnes, however, can be arbitrarily far from an actual nash equilibrium (ne), which implies that there are no guarantees on the quality of the found generator or classifier. this paper proposes to model gans explicitly as finite games in mixed strategies, thereby ensuring that every lne is an ne. with this formulation, we propose a solution method that is proven to monotonically converge to a resource-bounded nash equilibrium (rb-ne): by increasing computational resources we can find better solutions. we empirically demonstrate that our method is less prone to typical gan problems such as mode collapse, and produces solutions that are less exploitable than those produced by gans and mgans, and closely resemble theoretical predictions about nes.',\n",
       " 2: \"we consider a dynamical system with finitely many equilibria and perturbed by small noise, in addition to being controlled by an `expensive' control. the controlled process is optimal for an ergodic criterion with a running cost that consists the sum of the control effort and a penalty function on the state space. we study the optimal stationary distribution of the controlled process as the variance of the noise becomes vanishingly small. it is shown that depending on the relative magnitudes of the noise variance and the `running cost' for control, one can identify three regimes, in each of which the optimal control forces the invariant distribution of the process to concentrate near equilibria that can be characterized according to the regime. we also obtain moment bounds for the optimal stationary distribution. moreover, we show that in the vicinity of the points of concentration the density of optimal stationary distribution approximates the density of a gaussian, and we explicitly solve for its covariance matrix.\",\n",
       " 3: 'we consider discrete dynamical systems of \"ant-like\" agents engaged in a sequence of pursuits on a graph environment. the agents emerge one by one at equal time intervals from a source vertex $s$ and pursue each other by greedily attempting to close the distance to their immediate predecessor, the agent that emerged just before them from $s$, until they arrive at the destination point $t$. such pursuits have been investigated before in the continuous setting and in discrete time when the underlying environment is a regular grid. in both these settings the agents\\' walks provably converge to a shortest path from $s$ to $t$. furthermore, assuming a certain natural probability distribution over the move choices of the agents on the grid (in case there are multiple shortest paths between an agent and its predecessor), the walks converge to the uniform distribution over all shortest paths from $s$ to $t$.   we study the evolution of agent walks over a general finite graph environment $g$. our model is a natural generalization of the pursuit rule proposed for the case of the grid. the main results are as follows. we show that \"convergence\" to the shortest paths in the sense of previous work extends to all pseudo-modular graphs (i.e. graphs in which every three pairwise intersecting disks have a nonempty intersection), and also to environments obtained by taking graph products, generalizing previous results in two different ways. we show that convergence to the shortest paths is also obtained by chordal graphs, and discuss some further positive and negative results for planar graphs. in the most general case, convergence to the shortest paths is not guaranteed, and the agents may get stuck on sets of recurrent, non-optimal walks from $s$ to $t$. however, we show that the limiting distributions of the agents\\' walks will always be uniform distributions over some set of walks of equal length.',\n",
       " 4: 'retrofitting techniques, which inject external resources into word representations, have compensated the weakness of distributed representations in semantic and relational knowledge between words. implicitly retrofitting word vectors by expansional technique outperforms retrofitting in word similarity tasks with word vector generalization. in this paper, we propose unsupervised extrofitting: expansional retrofitting (extrofitting) without external semantic lexicons. we also propose deep extrofitting: in-depth stacking of extrofitting and further combinations of extrofitting with retrofitting. when experimenting with glove, we show that our methods outperform the previous methods on most of word similarity tasks while requiring only synonyms as an external resource. lastly, we show the effect of word vector enrichment on text classification task, as a downstream task.',\n",
       " 5: \"approaches to decision-making under uncertainty in the belief function framework are reviewed. most methods are shown to blend criteria for decision under ignorance with the maximum expected utility principle of bayesian decision theory. a distinction is made between methods that construct a complete preference relation among acts, and those that allow incomparability of some acts due to lack of information. methods developed in the imprecise probability framework are applicable in the dempster-shafer context and are also reviewed. shafer's constructive decision theory, which substitutes the notion of goal for that of utility, is described and contrasted with other approaches. the paper ends by pointing out the need to carry out deeper investigation of fundamental issues related to decision-making with belief functions and to assess the descriptive, normative and prescriptive values of the different approaches.\",\n",
       " 6: 'multiview representation learning is very popular for latent factor analysis. it naturally arises in many data analysis, machine learning, and information retrieval applications to model dependent structures among multiple data sources. for computational convenience, existing approaches usually formulate the multiview representation learning as convex optimization problems, where global optima can be obtained by certain algorithms in polynomial time. however, many pieces of evidence have corroborated that heuristic nonconvex approaches also have good empirical computational performance and convergence to the global optima, although there is a lack of theoretical justification. such a gap between theory and practice motivates us to study a nonconvex formulation for multiview representation learning, which can be efficiently solved by a simple stochastic gradient descent (sgd) algorithm. we first illustrate the geometry of the nonconvex formulation; then, we establish asymptotic global rates of convergence to the global optima by diffusion approximations. numerical experiments are provided to support our theory.',\n",
       " 7: \"we develop a comprehensive mathematical framework for polynomial jump-diffusions in a semimartingale context, which nest affine jump-diffusions and have broad applications in finance. we show that the polynomial property is preserved under polynomial transformations and l\\\\'evy time change. we present a generic method for option pricing based on moment expansions. as an application, we introduce a large class of novel financial asset pricing models with excess log returns that are conditional l\\\\'evy based on polynomial jump-diffusions.\",\n",
       " 8: 'features below the first conductance plateau in ballistic quantum point contacts (qpcs) are often ascribed to electron interaction and spin effects within the single mode limit. in qpcs with a highly asymmetric geometry, we observe sharp resonance peaks when the point contacts are gated to the single mode regime, and surprisingly, under certain gating conditions, a complete destruction of the 2e^2/h, first quantum plateau. the temperature evolution of the resonances suggest non-fermi liquid behavior, while the overall nonlinear characterizations reveal features reminiscent of the 0.7 effect. we attribute these unusual behaviors to the formation of a quasi bound state, which is stabilized by a momentum-mismatch accentuated by asymmetry.',\n",
       " 9: 'facial landmarks are highly correlated with each other since a certain landmark can be estimated by its neighboring landmarks. most of the existing deep learning methods only use one fully-connected layer called shape prediction layer to estimate the locations of facial landmarks. in this paper, we propose a novel deep learning framework named multi-center learning with multiple shape prediction layers for face alignment. in particular, each shape prediction layer emphasizes on the detection of a certain cluster of semantically relevant landmarks respectively. challenging landmarks are focused firstly, and each cluster of landmarks is further optimized respectively. moreover, to reduce the model complexity, we propose a model assembling method to integrate multiple shape prediction layers into one shape prediction layer. extensive experiments demonstrate that our method is effective for handling complex occlusions and appearance variations with real-time performance. the code for our method is available at https://github.com/zhiwenshao/mcnet-extension.',\n",
       " 10: \"we study the problem of subspace tracking in the presence of missing data (st-miss). in recent work, we studied a related problem called robust st. in this work, we show that a simple modification of our robust st solution also provably solves st-miss and robust st-miss. to our knowledge, our result is the first `complete' guarantee for st-miss. this means that we can prove that under assumptions on only the algorithm inputs, the output subspace estimates are close to the true data subspaces at all times. our guarantees hold under mild and easily interpretable assumptions, and allow the underlying subspace to change with time in a piecewise constant fashion. in contrast, all existing guarantees for st are partial results and assume a fixed unknown subspace. extensive numerical experiments are shown to back up our theoretical claims. finally, our solution can be interpreted as a provably correct mini-batch and memory-efficient solution to low-rank matrix completion (mc).\",\n",
       " 11: 'this special issue brings together eight papers from experts of communities which often have been perceived as different once: bibliometrics, scientometrics and informetrics on the one side and information retrieval on the other. the idea of this special issue started at the workshop \"combining bibliometrics and information retrieval\" held at the 14th international conference of scientometrics and informetrics, vienna, july 14-19, 2013. our motivation as guest editors started from the observation that main discourses in both fields are different, that communities are only partly overlapping and from the belief that a knowledge transfer would be profitable for both sides.',\n",
       " 12: 'the radial velocity experiment (rave) is a large wide-field spectroscopic stellar survey of the milky way. over the period 2003-2013, 574,630 spectra for 483,330 stars have been amassed at a resolution of r=7500 in the ca-triplet region of 8410-8795\\\\aa. wavelength coverage and resolution are thus comparable to that anticipated from the gaia rvs. derived data products of rave include radial velocities, stellar parameters, chemicals abundances for mg, al, si, ca, ti, fe, and ni, and absorption measures based on the diffuse interstellar bands (dib) at 8620\\\\aa. since more than 290000 rave targets are drawn from the tycho-2 catalogue, rave will be an interesting prototype for the anticipated full gaia data releases, in particular when combined with the early gaia data releases, which contain astrometry but not yet stellar parameters and abundances.',\n",
       " 13: 'we analyze dynamics of 3d coreless vortices in superfluid films covering porous substrates. the 3d vortex dynamics is derived from the 2d dynamics of the film. the motion of a 3d vortex is a sequence of jumps between neighboring substrate cells, which can be described, nevertheless, in terms of quasi-continuous motion with average vortex velocity. the vortex velocity is derived from the dissociation rate of vortex-antivortex pairs in a 2d film, which was developed in the past on the basis of the kosterlitz-thouless theory. the theory explains the rotation-induced dissipation peak in torsion-oscillator experiments on $^4$he films on rotating porous substrates and can be used in the analysis of other phenomena related to vortex motion in films on porous substrates.',\n",
       " 14: 'for a long time, designing neural architectures that exhibit high performance was considered a dark art that required expert hand-tuning. one of the few well-known guidelines for architecture design is the avoidance of exploding gradients, though even this guideline has remained relatively vague and circumstantial. we introduce the nonlinearity coefficient (nlc), a measurement of the complexity of the function computed by a neural network that is based on the magnitude of the gradient. via an extensive empirical study, we show that the nlc is a powerful predictor of test error and that attaining a right-sized nlc is essential for optimal performance.   the nlc exhibits a range of intriguing and important properties. it is closely tied to the amount of information gained from computing a single network gradient. it is tied to the error incurred when replacing the nonlinearity operations in the network with linear operations. it is not susceptible to the confounders of multiplicative scaling, additive bias and layer width. it is stable from layer to layer. hence, we argue that the nlc is the first robust predictor of overfitting in deep networks.',\n",
       " 15: 'exaggeration or context changes can render maintainability experience into prejudice. for example, javascript is often seen as least elegant language and hence of lowest maintainability. such prejudice should not guide decisions without prior empirical validation. we formulated 10 hypotheses about maintainability based on prejudices and test them in a large set of open-source projects (6,897 github repositories, 402 million lines, 5 programming languages). we operationalize maintainability with five static analysis metrics. we found that javascript code is not worse than other code, java code shows higher maintainability than c# code and c code has longer methods than other code. the quality of interface documentation is better in java code than in other code. code developed by teams is not of higher and large code bases not of lower maintainability. projects with high maintainability are not more popular or more often forked. overall, most hypotheses are not supported by open-source data.',\n",
       " 16: 'i extract the radio spectral index, $\\\\alpha$, from 541,195 common sources observed in the 150 mhz tifr gmrt sky survey (tgss) and the 1.4 ghz nrao vla sky survey (nvss). this large common source catalogue covers about $80\\\\%$ of the sky. the flux density limits in these surveys are such that the observed galaxies are presumably hosts of active galactic nuclei (agns). i confirm the steepening of $\\\\alpha$ with increasing flux density for this large sample and provide a parametric fit between $\\\\alpha$ and flux density. next, i divide the data into a low flux (lf) and a high flux (hf) density sample of roughly equal number of galaxies. the lf sample contains all galaxies below 100 mjy tgss and 20 mjy nvss flux density and the hf sample is all galaxies above 100 mjy tgss and 20 mjy nvss. i observe an increase in $\\\\alpha$ with source size (tgss measured), saturating for large sizes to $0.89\\\\pm0.22$ and $0.76\\\\pm 0.21$ for the lf and hf sources, respectively. i discuss the observed results and possible physical mechanisms to explain observed $\\\\alpha$ dependence with source size for lf and hf samples.',\n",
       " 17: 'in many real-world learning scenarios, features are only acquirable at a cost constrained under a budget. in this paper, we propose a novel approach for cost-sensitive feature acquisition at the prediction-time. the suggested method acquires features incrementally based on a context-aware feature-value function. we formulate the problem in the reinforcement learning paradigm, and introduce a reward function based on the utility of each feature. specifically, mc dropout sampling is used to measure expected variations of the model uncertainty which is used as a feature-value function. furthermore, we suggest sharing representations between the class predictor and value function estimator networks. the suggested approach is completely online and is readily applicable to stream learning setups. the solution is evaluated on three different datasets including the well-known mnist dataset as a benchmark as well as two cost-sensitive datasets: yahoo learning to rank and a dataset in the medical domain for diabetes classification. according to the results, the proposed method is able to efficiently acquire features and make accurate predictions.',\n",
       " 18: 'we investigate a correspondence between the complexity hierarchy of constraint satisfaction problems and a hierarchy of logical compactness hypotheses for finite relational structures. it seems that the harder a constraint satisfaction problem is, the stronger the corresponding compactness hypothesis is. at the top level, the np-complete constraint satisfaction problems correspond to compactness hypotheses that are equivalent to the ultrafilter axiom in all the cases we have investigated. at the bottom level, the simplest constraint satisfaction problems correspond to compactness hypotheses that are readily provable from the axioms of zermelo and fraenkel.',\n",
       " 19: 'it has been recognized that many complex dynamical systems in the real world require a description in terms of multiplex networks, where a set of common, mutually connected nodes belong to distinct network layers and play a different role in each layer. in spite of recent progress towards data based inference of single-layer networks, to reconstruct complex systems with a multiplex structure remains largely open. we articulate a mean-field based maximum likelihood estimation framework to solve this outstanding and challenging problem. we demonstrate the power of the reconstruction framework and characterize its performance using binary time series from a class of prototypical duplex network systems that host two distinct types of spreading dynamics. in addition to validating the framework using synthetic and real-world multiplex networks, we carry out a detailed analysis to elucidate the impacts of structural and dynamical parameters as well as noise on the reconstruction accuracy and robustness.',\n",
       " 20: 'let $r \\\\ge 2$ be a fixed constant and let $ {\\\\mathcal h}$ be an $r$-uniform, $d$-regular hypergraph on $n$ vertices. assume further that $ d \\\\to \\\\infty$ as $n \\\\to \\\\infty$ and that degrees of pairs of vertices in ${\\\\mathcal h}$ are at most $l$ where $l \\\\ = d/ (\\\\log n)^{\\\\omega(1)}$. we consider the random greedy algorithm for forming a matching in $ \\\\mathcal{h}$. we choose a matching at random by iteratively choosing edges uniformly at random to be in the matching and deleting all edges that share at least one vertex with a chosen edge before moving on to the next choice. this process terminates when there are no edges remaining in the graph. we show that with high probability the proportion of vertices of $ {\\\\mathcal h}$ that are not saturated by the final matching is at most $ (l/d)^{ \\\\frac{ 1}{ 2(r-1) } + o(1) } $. this point is a natural barrier in the analysis of the random greedy hypergraph matching process.',\n",
       " 21: \"a model, applicable to a range of innovation diffusion applications with a strong peer to peer component, is developed and studied, along with methods for its investigation and analysis. a particular application is to individual households deciding whether to install an energy efficiency measure in their home. the model represents these individuals as nodes on a network, each with a variable representing their current state of adoption of the innovation. the motivation to adopt is composed of three terms, representing personal preference, an average of each individual's network neighbours' states and a system average, which is a measure of the current social trend. the adoption state of a node changes if a weighted linear combination of these factors exceeds some threshold. numerical simulations have been carried out, computing the average uptake after a sufficient number of time-steps over many realisations at a range of model parameter values, on various network topologies, including random (erdos-renyi), small world (watts-strogatz) and (newman's) highly clustered, community-based networks. an analytical and probabilistic approach has been developed to account for the observed behaviour, which explains the results of the numerical calculations.\",\n",
       " 22: 'we present designs for variably polarizing beam splitters. these are beam splitters allowing the complete and independent control of the horizontal and vertical polarization splitting ratios. they have quantum optics and quantum information applications, such as quantum logic gates for quantum computing and non-local measurements for quantum state estimation. at the heart of each design is an interferometer. we experimentally demonstrate one particular implementation, a displaced sagnac interferometer configuration, that provides an inherent instability to air currents and vibrations. furthermore, this design does not require any custom-made optics but only common components which can be easily found in an optics laboratory.',\n",
       " 23: 'industrial pid consists of three elements: lag (integrator), lead (differentiator) and low pass filters (lpf). pid being a linear control method is inherently bounded by the waterbed effect due to which there exists a trade-off between precision \\\\& tracking, provided by lag and lpf on one side and stability \\\\& robustness, provided by lead on the other side. nonlinear reset strategies applied in lag and lpf elements have been very effective in reducing this trade-off. however, there is lack of study in developing a reset lead element. in this paper, we develop a novel lead element which provides higher precision and stability compared to the linear lead filter and can be used as a replacement for the same. the concept is presented and validated on a lorentz-actuated nanometer precision stage. improvements in precision, tracking and bandwidth are shown through two separate designs. performance is validated in both time and frequency domain to ensure that phase margin achieved on the practical setup matches design theories.',\n",
       " 24: 'we propose a generative adversarial network (gan) to forecast 3d human motion given a sequence of past 3d skeleton poses. while recent gans have shown promising results, they can only forecast plausible motion over relatively short periods of time (few hundred milliseconds) and typically ignore the absolute position of the skeleton w.r.t. the camera. our scheme provides long term predictions (two seconds or more) for both the body pose and its absolute position. our approach builds upon three main contributions. first, we represent the data using a spatio-temporal tensor of 3d skeleton coordinates which allows formulating the prediction problem as an inpainting one, for which gans work particularly well. secondly, we design an architecture to learn the joint distribution of body poses and global motion, capable to hypothesize large chunks of the input 3d tensor with missing data. and finally, we argue that the l2 metric, considered so far by most approaches, fails to capture the actual distribution of long-term human motion. we propose two alternative metrics, based on the distribution of frequencies, that are able to capture more realistic motion patterns. extensive experiments demonstrate our approach to significantly improve the state of the art, while also handling situations in which past observations are corrupted by occlusions, noise and missing frames.',\n",
       " 25: 'in this work, we describe a new deep learning based method that can effectively distinguish ai-generated fake videos (referred to as {\\\\em deepfake} videos hereafter) from real videos. our method is based on the observations that current deepfake algorithm can only generate images of limited resolutions, which need to be further warped to match the original faces in the source video. such transforms leave distinctive artifacts in the resulting deepfake videos, and we show that they can be effectively captured by convolutional neural networks (cnns). compared to previous methods which use a large amount of real and deepfake generated images to train cnn classifier, our method does not need deepfake generated images as negative training examples since we target the artifacts in affine face warping as the distinctive feature to distinguish real and fake images. the advantages of our method are two-fold: (1) such artifacts can be simulated directly using simple image processing operations on a image to make it as negative example. since training a deepfake model to generate negative examples is time-consuming and resource-demanding, our method saves a plenty of time and resources in training data collection; (2) since such artifacts are general existed in deepfake videos from different sources, our method is more robust compared to others. our method is evaluated on two sets of deepfake video datasets for its effectiveness in practice.',\n",
       " 26: 'we show that a large class of i.c.c., countable, discrete groups satisfying a weak negative curvature condition are not inner amenable. by recent work of hull and osin, our result recovers that mapping class groups and out(f_n) are not inner amenable. we also show that the group-measure space constructions associated to free, strongly ergodic p.m.p. actions of such groups do not have property gamma of murray and von neumann.',\n",
       " 27: \"we generalize two main theorems of matching polynomials of undirected simple graphs, namely, real-rootedness and the heilmann-lieb root bound. viewing the matching polynomial of a graph $g$ as the independence polynomial of the line graph of $g$, we determine conditions for the extension of these theorems to the independence polynomial of any graph. in particular, we show that a stability-like property of the multivariate independence polynomial characterizes claw-freeness. finally, we give and extend multivariate versions of godsil's theorems on the divisibility of matching polynomials of trees related to $g$.\",\n",
       " 28: 'the implementation difficulties of combining distribution matching (dm) and dematching (invdm) for probabilistic shaping (ps) with soft-decision forward error correction (fec) coding can be relaxed by reverse concatenation, for which the fec coding and decoding lies inside the shaping algorithms. ps can seemingly achieve performance close to the shannon limit, although there are practical implementation challenges that need to be carefully addressed. we propose a hierarchical dm (hidm) scheme, having fully parallelized input/output interfaces and a pipelined architecture that can efficiently perform the dm/invdm without the complex operations of previously proposed methods such as constant composition dm (ccdm). furthermore, hidm can operate at a significantly larger post-fec bit error rate (ber) for the same post-invdm ber performance, which facilitates simulations. these benefits come at the cost of a slightly larger rate loss and required signal-to-noise ratio at a given post-fec ber.',\n",
       " 29: 'by a theorem of r. stanley, a graded cohen-macaulay domain $a$ is gorenstein if and only if its hilbert series satisfies the functional equation \\\\[   \\\\operatorname{hilb}_a(t^{-1})=(-1)^d t^{-a}\\\\operatorname{hilb}_a(t), \\\\] where $d$ is the krull dimension and $a$ is the a-invariant of $a$. we reformulate this functional equation in terms of an infinite system of linear constraints on the laurent coefficients of $\\\\operatorname{hilb}_a(t)$ at $t=1$. the main idea consists of examining the graded algebra $\\\\mathcal f=\\\\bigoplus_{r\\\\in \\\\mathbb{z}}\\\\mathcal f_r$ of formal power series in the variable $x$ that fulfill the condition $\\\\varphi(x/(x-1))=(1-x)^r\\\\varphi(x)$. as a byproduct, we derive quadratic and cubic relations for the bernoulli numbers. the cubic relations have a natural interpretation in terms of coefficients of the euler polynomials. for the special case of degree $r=-(a+d)=0$, these results have been investigated previously by the authors and involved merely even euler polynomials. a link to the work of h. w. gould and l. carlitz on power sums of symmetric number triangles is established.',\n",
       " 30: 'in this work we investigate the betweenness centrality in geographical networks and its relationship with network communities. we show that vertices with large betweenness define what we call characteristic betweenness paths in both modeled and real-world geographical networks. we define a geographical network model that possess a simple topology while still being able to present such betweenness paths. using this model, we show that such paths represent pathways between entry and exit points of highly connected regions, or communities, of geographical networks. by defining a new network, containing information about community adjacencies in the original network, we describe a means to characterize the mesoscale connectivity provided by such characteristic betweenness paths.',\n",
       " 31: \"for the universal family of cyclic covers of projective spaces branched along hyperplane arrangements in general position, we consider its monodromy group acting on an eigen linear subspace of the middle cohomology of the fiber. we prove the monodromy group is zariski dense in the corresponding linear group. it can be viewed as a degenerate analogy of   carlson-toledo's result about the monodromy groups of smooth hypersurfaces [duke math. j. 97(3) (1999), 621-648]. the main ingredient in the proof is a picard-lefschetz type formula for a suitable degeneration of this family.\",\n",
       " 32: \"we have used ultrahigh vacuum (uhv) scanning tunneling microscopy (stm) to investigate the effect of thermal annealing of graphene grown by chemical vapour deposition (cvd) on a cu(110) foil. we show that the annealing appears to induce a reconstruction of the cu surface along the [210] direction, with a period of 1.43 nm. such reconstructions have been ascribed to the tensile strain induced in the cu surface by differential thermal expansion of it relative to the graphene overlayer, but we show that it is in fact a moir\\\\'e pattern due to interference between the graphene and the underlying atomic lattice as evidenced by the appearance of an odd-even transition only observed due to mis-orientation of the top layer of a crystal. this highlights that the analysis of stm measurements of graphene on metal surfaces should take such interference into account and that the graphene-cu interface is more complex than previously thought.\",\n",
       " 33: 'we introduce diophantine approximation groups and their associated kronecker foliations, using them to provide new algebraic and geometric characterizations of $k$-linear and algebraic dependence. as a consequence we find reformulations -- as algebraic and geometric (graph) rigidities -- of the theorems of baker and lindemann-weierstrass, the logarithm conjecture and the schanuel conjecture. there is an appendix describing diophantine approximation groups as model theoretic types.',\n",
       " 34: 'we consider the normalized ricci flow evolving from an initial metric which is conformally compactifiable and asymptotically hyperbolic. we show that there is a unique evolving metric which remains in this class, and that the flow exists up to the time where the norm of the riemann tensor diverges. restricting to initial metrics which belong to this class and are rotationally symmetric, we prove that if the sectional curvature in planes tangent to the orbits of symmetry is initially nonpositive, the flow starting from such an initial metric exists for all time. moreover, if the sectional curvature in planes tangent to these orbits is initially negative, the flow converges at an exponential rate to standard hyperbolic space. this restriction on sectional curvature automatically rules out initial data admitting a minimal hypersphere.',\n",
       " 35: 'the presence of dark matter in the universe is nowadays widely supported by a large body of astronomical and cosmological observations. one of the best targets to look for dark matter particle self-annihilation into very high energy gamma-rays is the galactic center (gc) region. a search for annihilating dark matter in the central 300 parsecs around the gc is performed with the h.e.s.s. array of ground-based cherenkov telescopes. using the full h.e.s.s.- i dataset (2004-2014) for this region, new constraints are derived on the velocity-weighted annihilation cross section with a 2d likelihood method, taking advantage of differences in both spectral and spatial morphologies of signal and background. higher statistics from the 10-years gc dataset of h.e.s.s. i together with a novel analysis technique, allow to improve the present constraints by a factor of 2 for a dm particle mass of 1 tev. the expected improvement in sensitivity of the new analysis technique, applied to performances of the h.e.s.s.-ii array, is also presented.',\n",
       " 36: \"we first show that in the function realizability topos every metric space is separable, and every object with decidable equality is countable. more generally, working with synthetic topology, every $t_0$-space is separable and every discrete space is countable. it follows that intuitionistic logic does not show the existence of a non-separable metric space, or an uncountable set with decidable equality, even if we assume principles that are validated by function realizability, such as dependent and function choice, markov's principle, and brouwer's continuity and fan principles.\",\n",
       " 37: 'let $g$ be a real reductive group, and let $\\\\chi$ be a character of a reductive subgroup $h$ of $g$. we construct $\\\\chi$-invariant linear functionals on certain cohomologically induced representations of $g$, and show that these linear functionals do not vanish on the bottom layers. applying this construction, we prove two archimedean non-vanishing assumptions, which are crucial in the study of special values of l-functions via modular symbols.',\n",
       " 38: 'in this paper, we introduce an interactive simulator for programs in the form of llvm bitcode. the main features of the simulator include precise control over thread scheduling, automatic checkpoints and reverse stepping, support for source-level information about functions and variables in c and c++ programs and structured heap visualisation. additionally, the simulator is compatible with divm (divine vm) hypercalls, which makes it possible to load, simulate and analyse counterexamples from an existing model checker.',\n",
       " 39: 'transformative technologies are enabling the construction of three dimensional (3d) maps of tissues with unprecedented spatial and molecular resolution. over the next seven years, the nih common fund human biomolecular atlas program (hubmap) intends to develop a widely accessible framework for comprehensively mapping the human body at single-cell resolution by supporting technology development, data acquisition, and detailed spatial mapping. hubmap will integrate its efforts with other funding agencies, programs, consortia, and the biomedical research community at large towards the shared vision of a comprehensive, accessible 3d molecular and cellular atlas of the human body, in health and various disease settings.',\n",
       " 40: 'we define a subgroup of the universal sofic group, obtained as the normaliser of a separable abelian subalgebra. this subgroup can be obtained as an extension by the group of automorphisms on a standard probability space. we show that each sofic representation can be conjugated inside this subgroup.',\n",
       " 41: 'we study the effect of constant shifts on the zeros of rational harmomic functions $f(z) = r(z) - \\\\conj{z}$. in particular, we characterize how shifting through the caustics of $f$ changes the number of zeros and their respective orientations. this also yields insight into the nature of the singular zeros of $f$. our results have applications in gravitational lensing theory, where certain such functions $f$ represent gravitational point-mass lenses, and a constant shift can be interpreted as the position of the light source of the lens.',\n",
       " 42: 'the sage-spectroscopy spitzer legacy program (sage-spec; pi: f. kemper, pid: 40159; kemper et al. 2010) is the irs spectroscopic follow-up to the successful sage-lmc legacy program (meixner et al. 2006; pi: m. meixner, pid: 20203) that mapped the large magellanic cloud (lmc) with all bands of the irac and mips instruments on board the spitzer space telescope. this technical document gives details of the data-reduction procedure and the various data products that are publicly available through irsa: http://irsa.ipac.caltech.edu/data/spitzer/sage/',\n",
       " 43: 'in 3d reconstruction, the recovery of the calibration parameters of the cameras is paramount since it provides metric information about the observed scene, e.g., measures of angles and ratios of distances. autocalibration enables the estimation of the camera parameters without using a calibration device, but by enforcing simple constraints on the camera parameters. in the absence of information about the internal camera parameters such as the focal length and the principal point, the knowledge of the camera pixel shape is usually the only available constraint. given a projective reconstruction of a rigid scene, we address the problem of the autocalibration of a minimal set of cameras with known pixel shape and otherwise arbitrarily varying intrinsic and extrinsic parameters. we propose an algorithm that only requires 5 cameras (the theoretical minimum), thus halving the number of cameras required by previous algorithms based on the same constraint. to this purpose, we introduce as our basic geometric tool the six-line conic variety (slcv), consisting in the set of planes intersecting six given lines of 3d space in points of a conic. we show that the set of solutions of the euclidean upgrading problem for three cameras with known pixel shape can be parameterized in a computationally efficient way. this parameterization is then used to solve autocalibration from five or more cameras, reducing the three-dimensional search space to a two-dimensional one. we provide experiments with real images showing the good performance of the technique.',\n",
       " 44: 'accurate and repeatable delineation of corneal tissue interfaces is necessary for surgical planning during anterior segment interventions, such as keratoplasty. designing an approach to identify interfaces, which generalizes to datasets acquired from different optical coherence tomographic (oct) scanners, is paramount. in this paper, we present a convolutional neural network (cnn) based framework called cornet that can accurately segment three corneal interfaces across datasets obtained with different scan settings from different oct scanners. extensive validation of the approach was conducted across all imaged datasets. to the best of our knowledge, this is the first deep learning based approach to segment both anterior and posterior corneal tissue interfaces. our errors are 2x lower than non-proprietary state-of-the-art corneal tissue interface segmentation algorithms, which include image analysis-based and deep learning approaches.',\n",
       " 45: 'background. different mechanisms have been proposed to relate atrial fibrillation (af) and coronary flow impairment, even in absence of relevant coronary artery disease (cad). however, the underlying hemodynamics remains unclear. aim of the present work is to computationally explore whether and to what extent ventricular rate during af affects the coronary perfusion.   methods. af is simulated at different ventricular rates (50, 70, 90, 110, 130 bpm) through a 0d-1d multiscale validated model, which combines the left heart-arterial tree together with the coronary circulation. artificially-built rr stochastic extraction mimics the \\\\emph{in vivo} beating features. all the hemodynamic parameters computed are based on the left anterior descending (lad) artery and account for the waveform, amplitude and perfusion of the coronary blood flow.   results. alterations of the coronary hemodynamics are found to be associated either to the heart rate increase, which strongly modifies waveform and amplitude of the lad flow rate, and to the beat-to-beat variability. the latter is overall amplified in the coronary circulation as hr grows, even though the input rr variability is kept constant at all hrs.   conclusions. higher ventricular rate during af exerts an overall coronary blood flow impairment and imbalance of the myocardial oxygen supply-demand ratio. the combined increase of heart rate and higher af-induced hemodynamic variability lead to a coronary perfusion impairment exceeding 90-110 bpm in af. moreover, it is found that coronary perfusion pressure (cpp) is no longer a good measure of the myocardial perfusion for hr higher than 90 bpm.',\n",
       " 46: 'identity recognition from ear images is an active field of research within the biometric community. the ability to capture ear images from a distance and in a covert manner makes ear recognition technology an appealing choice for surveillance and security applications as well as related application domains. in contrast to other biometric modalities, where large datasets captured in uncontrolled settings are readily available, datasets of ear images are still limited in size and mostly of laboratory-like quality. as a consequence, ear recognition technology has not benefited yet from advances in deep learning and convolutional neural networks (cnns) and is still lacking behind other modalities that experienced significant performance gains owing to deep recognition technology. in this paper we address this problem and aim at building a cnnbased ear recognition model. we explore different strategies towards model training with limited amounts of training data and show that by selecting an appropriate model architecture, using aggressive data augmentation and selective learning on existing (pre-trained) models, we are able to learn an effective cnn-based model using a little more than 1300 training images. the result of our work is the first cnn-based approach to ear recognition that is also made publicly available to the research community. with our model we are able to improve on the rank one recognition rate of the previous state-of-the-art by more than 25% on a challenging dataset of ear images captured from the web (a.k.a. in the wild).',\n",
       " 47: 'we prove the existence of weak solutions of complex $m-$hessian equations on compact hermitian manifolds for the nonnegative right hand side belonging to $l^p, p>n/m$ ($n$ is the dimension of the manifold). for smooth, positive data the equation has been recently solved by szekelyhidi and zhang. we also give a stability result for such solutions.',\n",
       " 48: 'this article is concerned with developing an analytic theory for second order nonlinear parabolic equations on singular manifolds. existence and uniqueness of solutions in an lp-framework is established by maximal regularity tools. these techniques are applied to the yamabe flow. it is proven that the yamabe flow admits a unique local solution within a class of incomplete initial metrics.',\n",
       " 49: 'purpose: this paper focuses on an automated analysis of surgical motion profiles for objective skill assessment and task recognition in robot-assisted surgery. existing techniques heavily rely on conventional statistic measures or shallow modelings based on hand-engineered features and gesture segmentation. such developments require significant expert knowledge, are prone to errors, and are less efficient in online adaptive training systems. methods: in this work, we present an efficient analytic framework with a parallel deep learning architecture, satr-dl, to assess trainee expertise and recognize surgical training activity. through an end-to-end learning technique, abstract information of spatial representations and temporal dynamics is jointly obtained directly from raw motion sequences. results: by leveraging a shared high-level representation learning, the resulting model is successful in the recognition of trainee skills and surgical tasks, suturing, needle-passing, and knot-tying. meanwhile, we explore the use of ensemble in classification at the trial level, where the satr-dl outperforms state-of-the-art performance by achieving accuracies of 0.960 and 1.000 in skill assessment and task recognition, respectively. conclusion: this study highlights the potential of satr-dl to provide improvements for an efficient data-driven assessment in intelligent robotic surgery.',\n",
       " 50: 'constraint programming (cp) is a powerful declarative programming paradigm where inference and search are interleaved to find feasible and optimal solutions to various type of constraint systems. however, handling logical connectors with constructive information in cp is notoriously difficult. this paper presents if then else (ite), a lightweight implementation of stratified constructive reasoning for logical connectives. stratification is introduced to cope with the risk of combinatorial explosion of constructing information from nested and combined logical operators. ite is an open-source library built on top of sicstus prolog clp(fd), which proposes various operators, including constructive disjunction and negation, constructive implication and conditional. these operators can be used to express global constraints and to benefit from constructive reasoning for more domain pruning during constraint filtering. even though ite is not competitive with specialized filtering algorithms available in some global constraints implementations, its expressiveness allows users to easily define well-tuned constraints with powerful deduction capabilities. our extended experimental results show that ite is more efficient than available generic approaches that handle logical constraint systems over finite domains.',\n",
       " 51: 'we describe how mirkovic-vilonen polytopes arise naturally from the categorification of lie algebras using khovanov-lauda-rouquier algebras. this gives an explicit description of the unique crystal isomorphism between simple representations of the klr algebra and mv polytopes.   mv polytopes, as defined from the geometry of the affine grassmannian, only make sense for finite dimensional semi-simple lie algebras, but our construction actually gives a map from the infinity crystal to polytopes in all symmetrizable kac-moody algebras. however, to make the map injective and have well-defined crystal operators on the image, we must in general decorate our polytopes with some extra information. we suggest that the resulting klr polytopes are the general-type analogues of mv polytopes.   we give a combinatorial description of the resulting decorated polytopes in all affine cases, and show that this recovers the affine mv polytopes recently defined by kamnitzer and baumann and the first author in symmetric affine types. we also briefly discuss the situation beyond affine type.',\n",
       " 52: 'there are proposed models of contracts, technological equipment and gas networks and methods of their optimization. the flow in network undergoes restrictions of contracts and equipment to be operated. the values of sources and sinks are provided by contracts. the contract models represent (sub-) networks. the simplest contracts represent either nodes or edges. equipment is modeled by edges. more sophisticated equipment is represented by sub-networks. examples of such equipment are multi-poles and compressor stations with many entries and exits. the edges can be of different types corresponding to equipment and contracts. on such edges, there are given systems of equation and inequalities simulating the contracts and equipment. on this base, the methods proposed that allow: calculation and control of contract values for booking on future days and for accounting of sales and purchases; simulation and optimization of design and of operation of gas networks. these models and methods are implemented in software systems accord and graphicord as well as in the distributed control system used by wingas, germany. as numerical example, the industrial computations are presented.',\n",
       " 53: 'the plateau-rayleigh instability of a liquid column underlies a variety of fascinating phenomena that can be observed in everyday life. in contrast to the case of a free liquid cylinder, describing the evolution of a liquid layer on a solid fibre requires consideration of the solid-liquid interface. in this article, we revisit the plateau-rayleigh instability of a liquid coating a fibre by varying the hydrodynamic boundary condition at the fibre-liquid interface, from no-slip to slip. while the wavelength is not sensitive to the solid-liquid interface, we find that the growth rate of the undulations strongly depends on the hydrodynamic boundary condition. the experiments are in excellent agreement with a new thin film theory incorporating slip, thus providing an original, quantitative and robust tool to measure slip lengths.',\n",
       " 54: \"we prove a plancherel theorem for a nonlinear fourier transform in two dimensions arising in the inverse scattering method for the defocusing davey-stewartson ii equation. we then use it to prove global well-posedness and scattering in $l^2$ for defocusing dsii. this plancherel theorem also implies global uniqueness in the inverse boundary value problem of calder\\\\'on in dimension $2$, for conductivities $\\\\sigma>0$ with $\\\\log \\\\sigma \\\\in \\\\dot h^1$. the proof of the nonlinear plancherel theorem includes new estimates on classical fractional integrals, as well as a new result on $l^2$-boundedness of pseudo-differential operators with non-smooth symbols, valid in all dimensions.\",\n",
       " 55: 'the computational complexity of kernel methods has often been a major barrier for applying them to large-scale learning problems. we argue that this barrier can be effectively overcome. in particular, we develop methods to scale up kernel models to successfully tackle large-scale learning problems that are so far only approachable by deep learning architectures. based on the seminal work by rahimi and recht on approximating kernel functions with features derived from random projections, we advance the state-of-the-art by proposing methods that can efficiently train models with hundreds of millions of parameters, and learn optimal representations from multiple kernels. we conduct extensive empirical studies on problems from image recognition and automatic speech recognition, and show that the performance of our kernel models matches that of well-engineered deep neural nets (dnns). to the best of our knowledge, this is the first time that a direct comparison between these two methods on large-scale problems is reported. our kernel methods have several appealing properties: training with convex optimization, cost for training a single model comparable to dnns, and significantly reduced total cost due to fewer hyperparameters to tune for model selection. our contrastive study between these two very different but equally competitive models sheds light on fundamental questions such as how to learn good representations.',\n",
       " 56: 'previous approaches for scene text detection usually rely on manually defined sliding windows. this work presents an intuitive two-stage region-based method to detect multi-oriented text without any prior knowledge regarding the textual shape. in the first stage, we estimate the possible locations of text instances by detecting and linking corners instead of shifting a set of default anchors. the quadrilateral proposals are geometry adaptive, which allows our method to cope with various text aspect ratios and orientations. in the second stage, we design a new pooling layer named dual-roi pooling which embeds data augmentation inside the region-wise subnetwork for more robust classification and regression over these proposals. experimental results on public benchmarks confirm that the proposed method is capable of achieving comparable performance with state-of-the-art methods. the code is publicly available at https://github.com/xhzdeng/crpn',\n",
       " 57: 'in this paper we consider the density of maximal order elements in $\\\\mathrm{gl}_n(q)$. fixing any of the rank $n$ of the group, the characteristic $p$ or the degree $r$ of the extension of the underlying field $\\\\mathbb{f}_q$ of size $q=p^r$, we compute the expected value of the said density and establish that it follows a distribution law.',\n",
       " 58: 'we examine the interplay of symmetry and topological order in $2+1$ dimensional topological phases of matter. we present a definition of the \\\\it topological symmetry \\\\rm group, which characterizes the symmetry of the emergent topological quantum numbers of a topological phase, and we describe its relation with the microscopic symmetry of the underlying physical system. we derive a general framework to characterize and classify symmetry fractionalization in topological phases, including phases that are non-abelian and symmetries that permute the quasiparticle types and/or are anti-unitary. we develop a theory of extrinsic defects (fluxes) associated with elements of the symmetry group, which provides a general classification of symmetry-enriched topological phases derived from a topological phase of matter $\\\\mathcal{c}$ with symmetry group $g$. the algebraic theory of the defects, known as a $g$-crossed braided tensor category $\\\\mathcal{c}_{g}^{\\\\times}$, allows one to compute many properties, such as the number of topologically distinct types of defects associated with each group element, their fusion rules, quantum dimensions, zero modes, braiding exchange transformations, a generalized verlinde formula for the defects, and modular transformations of the $g$-crossed extensions of topological phases. we also examine the promotion of the global symmetry to a local gauge invariance, wherein the extrinsic $g$-defects are turned into deconfined quasiparticle excitations, which results in a different topological phase $(\\\\mathcal{c}_{g}^{\\\\times})^{g}$. a number of instructive and/or physically relevant examples are studied in detail.',\n",
       " 59: 'we consider group-valued cocycles over dynamical systems. the base system is a homeomorphism $f$ of a metric space satisfying a closing property, for example a hyperbolic dynamical system or a subshift of finite type. the cocycle $a$ takes values in the group of invertible bounded linear operators on a banach space and is h\\\\\"older continuous. we prove that upper and lower lyapunov exponents of $a$ with respect to an ergodic invariant measure $\\\\mu$ can be approximated in terms of the norms of the values of $a$ on periodic orbits of $f$. we also show that these exponents cannot always be approximated by the exponents of $a$ with respect to measures on periodic orbits. our arguments include a result of independent interest on construction and properties of a lyapunov norm for infinite dimensional setting. as a corollary, we obtain estimates of the growth of the norm and of the quasiconformal distortion of the cocycle in terms of the growth at the periodic points of $f$.',\n",
       " 60: 'age of information (aoi) is a recently proposed metric for measuring information freshness. aoi measures the time that elapsed since the last received update was generated. we consider the problem of minimizing average and peak aoi in a wireless networks, consisting of a set of source-destination links, under general interference constraints. when fresh information is always available for transmission, we show that a stationary scheduling policy is peak age optimal. we also prove that this policy achieves average age that is within a factor of two of the optimal average age. in the case where fresh information is not always available, and packet/information generation rate has to be controlled along with scheduling links for transmission, we prove an important separation principle: the optimal scheduling policy can be designed assuming fresh information, and independently, the packet generation rate control can be done by ignoring interference. peak and average aoi for discrete time g/ber/1 queue is analyzed for the first time, which may be of independent interest.',\n",
       " 61: 'rural areas in the developing countries are predominantly devoid of internet access as it is not viable for operators to provide broadband service in these areas. to solve this problem, we propose a middle mile long erm evolution advanced (lte-a) network operating in tv white space to connect villages to an optical point of presence (pop) located in the vicinity of a rural area. we study the problem of spectrum sharing for the middle mile networks deployed by multiple operators. a graph theory based fairness constrained channel allocation (fcca) algorithm is proposed, employing carrier aggregation (ca) and listen before talk (lbt) features of lte-a. we perform extensive system level simulations to demonstrate that fcca not only increases spectral efficiency but also improves system fairness.',\n",
       " 62: 'in the genomic era, the identification of gene signatures associated with disease is of significant interest. such signatures are often used to predict clinical outcomes in new patients and aid clinical decision-making. however, recent studies have shown that gene signatures are often not replicable. this occurrence has practical implications regarding the generalizability and clinical applicability of such signatures. to improve replicability, we introduce a novel approach to select gene signatures from multiple datasets whose effects are consistently non-zero and account for between-study heterogeneity. we build our model upon some rank-based quantities, facilitating integration over different genomic datasets. a high dimensional penalized generalized linear mixed model (pglmm) is used to select gene signatures and address data heterogeneity. we compare our method to some commonly used strategies that select gene signatures ignoring between-study heterogeneity. we provide asymptotic results justifying the performance of our method and demonstrate its advantage in the presence of heterogeneity through thorough simulation studies. lastly, we motivate our method through a case study subtyping pancreatic cancer patients from four gene expression studies.',\n",
       " 63: 'we introduce a model for the formation of social networks, which takes into account the homophily or the tendency of individuals to associate and bond with similar others, and the mechanisms of global and local attachment as well as tie reinforcement due to social interactions between people. we generalize the weighted social network model such that the nodes or individuals have $f$ features and each feature can have $q$ different values. here the tendency for the tie formation between two individuals due to the overlap in their features represents homophily. we find a phase transition as a function of $f$ or $q$, resulting in a phase diagram. for fixed $q$ and as a function of $f$ the system shows two phases separated at $f_c$. for $f{<}f_c$ large, homogeneous, and well separated communities can be identified within which the features match almost perfectly (segregated phase). when $f$ becomes larger than $f_c$, the nodes start to belong to several communities and within a community the features match only partially (overlapping phase). several quantities reflect this transition, including the average degree, clustering coefficient, feature overlap, and the number of communities per node. we also make an attempt to interpret these results in terms of observations on social behavior of humans.',\n",
       " 64: \"sampling efficiency in a highly constrained environment has long been a major challenge for sampling-based planners. in this work, we propose rapidly-exploring random disjointed-trees* (rrdt*), an incremental optimal multi-query planner. rrdt* uses multiple disjointed-trees to exploit local-connectivity of spaces via markov chain random sampling, which utilises neighbourhood information derived from previous successful and failed samples. to balance local exploitation, rrdt* actively explore unseen global spaces when local-connectivity exploitation is unsuccessful. the active trade-off between local exploitation and global exploration is formulated as a multi-armed bandit problem. we argue that the active balancing of global exploration and local exploitation is the key to improving sample efficient in sampling-based motion planners. we provide rigorous proofs of completeness and optimal convergence for this novel approach. furthermore, we demonstrate experimentally the effectiveness of rrdt*'s locally exploring trees in granting improved visibility for planning. consequently, rrdt* outperforms existing state-of-the-art incremental planners, especially in highly constrained environments.\",\n",
       " 65: 'we explore a natural class of semigroups that have word problem decidable by finite state automata. among the main results are invariance of this property under change of generators, invariance under basic algebraic constructions and algebraic properties of these semigroups.',\n",
       " 66: 'muons with a high transverse momentum (p_t) are produced in cosmic ray air showers via semileptonic decay of heavy quarks and the decay of high p_t kaons and pions. these high p_t muons have a large lateral separation from the shower core muon bundle. icecube is well suited for the detection of high p_t muons. the surface shower array can determine the energy, core location and direction of the cosmic ray air shower while the in-ice array can reconstruct the energy and direction of the high p_t muon. this makes it possible to measure the decoherence function (lateral separation spectrum) at distances greater than 150 meters. the muon p_t can be determined from the muon energy (measured by de/dx) and the lateral separation. the high p_t muon spectrum may also be calculated in a perturbative qcd framework; this spectrum is sensitive to the cosmic-ray composition.',\n",
       " 67: 'we consider the convex-concave saddle point problem $\\\\min_{x}\\\\max_{y} f(x)+y^\\\\top a x-g(y)$ where $f$ is smooth and convex and $g$ is smooth and strongly convex. we prove that if the coupling matrix $a$ has full column rank, the vanilla primal-dual gradient method can achieve linear convergence even if $f$ is not strongly convex. our result generalizes previous work which either requires $f$ and $g$ to be quadratic functions or requires proximal mappings for both $f$ and $g$. we adopt a novel analysis technique that in each iteration uses a \"ghost\" update as a reference, and show that the iterates in the primal-dual gradient method converge to this \"ghost\" sequence. using the same technique we further give an analysis for the primal-dual stochastic variance reduced gradient (svrg) method for convex-concave saddle point problems with a finite-sum structure.',\n",
       " 68: 'we study the bottom of the spectrum of the anderson hamiltonian $\\\\mathcal{h}_l := -\\\\partial_x^2 + \\\\xi$ on $[0,l]$ driven by a white noise $\\\\xi$ and endowed with either dirichlet or neumann boundary conditions. we show that, as $l\\\\rightarrow\\\\infty$, the point process of the (appropriately shifted and rescaled) eigenvalues converges to a poisson point process on $\\\\mathbb{r}$ with intensity $e^x dx$, and that the (appropriately rescaled) eigenfunctions converge to dirac masses located at independent and uniformly distributed points. furthermore, we show that the shape of each eigenfunction, recentered around its maximum and properly rescaled, is given by the inverse of a hyperbolic cosine. we also show that the eigenfunctions decay exponentially from their localization centers at an explicit rate, and we obtain very precise information on the zeros and local maxima of these eigenfunctions. finally, we show that the eigenvalues/eigenfunctions in the dirichlet and neumann cases are very close to each other and converge to the same limits.',\n",
       " 69: 'in the area of distributed graph algorithms a number of network\\'s entities with local views solve some computational task by exchanging messages with their neighbors. quite unfortunately, an inherent property of most existing distributed algorithms is that throughout the course of their execution, the nodes get to learn not only their own output but rather learn quite a lot on the inputs or outputs of many other entities. this leakage of information might be a major obstacle in settings where the output (or input) of network\\'s individual is a private information. in this paper, we introduce a new framework for \\\\emph{secure distributed graph algorithms} and provide the first \\\\emph{general compiler} that takes any \"natural\" non-secure distributed algorithm that runs in $r$ rounds, and turns it into a secure algorithm that runs in $\\\\widetilde{o}(r \\\\cdot d \\\\cdot poly(\\\\delta))$ rounds where $\\\\delta$ is the maximum degree in the graph and $d$ is its diameter. the security of the compiled algorithm is information-theoretic but holds only against a semi-honest adversary that controls a single node in the network.   this compiler is made possible due to a new combinatorial structure called \\\\emph{private neighborhood trees}: a collection of $n$ trees $t(u_1),\\\\ldots,t(u_n)$, one for each vertex $u_i \\\\in v(g)$, such that each tree $t(u_i)$ spans the neighbors of $u_i$ {\\\\em without going through $u_i$}. intuitively, each tree $t(u_i)$ allows all neighbors of $u_i$ to exchange a \\\\emph{secret} that is hidden from $u_i$, which is the basic graph infrastructure of the compiler. in a $(d,c)$-private neighborhood trees each tree $t(u_i)$ has depth at most $d$ and each edge $e \\\\in g$ appears in at most $c$ different trees. we show a construction of private neighborhood trees with $d=\\\\widetilde{o}(\\\\delta \\\\cdot d)$ and $c=\\\\widetilde{o}(d)$.',\n",
       " 70: 'here we describe a multi-compartment neuron circuit based on the adaptive-exponential i&f (adex) model, developed for the second-generation brainscales hardware. based on an existing modular leaky integrate-and-fire (lif) architecture designed in 65 nm cmos, the circuit features exponential spike generation, neuronal adaptation, inter-compartmental connections as well as a conductance-based reset. the design reproduces a diverse set of firing patterns observed in cortical pyramidal neurons. further, it enables the emulation of sodium and calcium spikes, as well as n-methyl-d-aspartate (nmda) plateau potentials known from apical and thin dendrites. we characterize the adex circuit extensions and exemplify how the interplay between passive and non-linear active signal processing enhances the computational capabilities of single (but structured) on-chip neurons.',\n",
       " 71: \"we generalise simpson's nonabelian hodge correspondence to the context of projective varieties with klt singularities. the proof relies on a descent theorem for numerically flat vector bundles along birational morphisms. in its simplest form, this theorem asserts that given any klt variety x and any resolution of singularities, then any vector bundle on the resolution that appears to come from x numerically, does indeed come from x. furthermore and of independent interest, a new restriction theorem for semistable higgs sheaves defined on the smooth locus of a normal, projective variety is established.\",\n",
       " 72: 'a dynamic self-organized morphology is the hallmark of network-shaped organisms like slime moulds and fungi. organisms continuously re-organize their flexible, undifferentiated body plans to forage for food. among these organisms the slime mould physarum polycephalum has emerged as a model to investigate how organism can self-organize their extensive networks and act as a coordinated whole. cytoplasmic fluid flows flowing through the tubular networks have been identified as key driver of morphological dynamics. inquiring how fluid flows can shape living matter from small to large scales opens up many new avenues for research.',\n",
       " 73: \"online learning has traditionally focused on the expected rewards. in this paper, a risk-averse online learning problem under the performance measure of the mean-variance of the rewards is studied. both the bandit and full information settings are considered. the performance of several existing policies is analyzed, and new fundamental limitations on risk-averse learning is established. in particular, it is shown that although a logarithmic distribution-dependent regret in time $t$ is achievable (similar to the risk-neutral problem), the worst-case (i.e. minimax) regret is lower bounded by $\\\\omega(t)$ (in contrast to the $\\\\omega(\\\\sqrt{t})$ lower bound in the risk-neutral problem). this sharp difference from the risk-neutral counterpart is caused by the the variance in the player's decisions, which, while absent in the regret under the expected reward criterion, contributes to excess mean-variance due to the non-linearity of this risk measure. the role of the decision variance in regret performance reflects a risk-averse player's desire for robust decisions and outcomes.\",\n",
       " 74: 'a crucial goal of funding research and development has always been to advance economic development. on this basis, a consider-able body of research undertaken with the purpose of determining what exactly constitutes economic impact and how to accurately measure that impact has been published. numerous indicators have been used to measure economic impact, although no single indicator has been widely adapted. based on patent data collected from altmetric we predict patent citations through various social media features using several classification models. patents citing a research paper implies the potential it has for direct application inits field. these predictions can be utilized by researchers in deter-mining the practical applications for their work when applying for patents.',\n",
       " 75: 'rheumatoid arthritis (ra) is a systemic autoimmune disease characterized by joint inflammation and joint pain. much of ra treatment is focused on suppressing inflammation, with the idea being that if inflammation is controlled other symptoms, such as pain, will disappear. however, pain is the most common complaint of ra patients, is often still present following the resolution of inflammation, and can develop prior to the onset of inflammation. thus, further research is needed to better understand ra-associated pain mechanisms. a number of preclinical rodent models commonly used in rheumatology research have been developed based on bedside-to-bench and reverse translational approaches. these models include collagen-induced arthritis, antigen-induced arthritis, streptococcal cell wall-induced arthritis, collagen antibody-induced arthritis, serum transfer from k/bxn transgenic mice and tumor necrosis factor (tnf)-transgene mice. they have led to increased understanding of ra pathogenesis and have aided the development of successful ra treatments. more recently, these models have been used to elucidate the complexities of ra associated pain. several potentially modifiable mechanisms, other than inflammation, have been investigated in these models and may in turn lead to more effective treatments. furthermore, preclinical research can indicate when specific treatment strategies may benefit specific patient subgroups or at which disease stage they are best used. this review not only highlights ra-associated pain mechanisms, but also suggests the usefulness of preclinical animal research based on a bedside-to-bench approach.',\n",
       " 76: 'we propose a framework for inversion-based estimation of certain categories of faults in discrete-time linear systems. the fault signal, as an unknown input, is reconstructed from its projections onto two subspaces. one projection is achieved through an algebraic operation, whereas the other is given by a dynamic filter whose poles coincide with the transmission zeros of the system. a feedback is then introduced to stabilize the above filter as well as to provide an unbiased estimate of the unknown input. our solution has two distinctive and practical advantages. first, it represents a unified approach to the problem of inversion of both minimum and non-minimum phase systems as well as systems having transmission zeros on the unit circle. second, the feedback structure makes the proposed scheme robust to noise. we have shown that the proposed inversion filter is unbiased for certain categories of faults. finally, we have illustrated the performance of our proposed methodologies through numerous simulation studies.',\n",
       " 77: 'this study uses a novel simulation framework to evaluate whether the time and effort necessary to achieve high recall using active learning is reduced by presenting the reviewer with isolated sentences, as opposed to full documents, for relevance feedback. under the weak assumption that more time and effort is required to review an entire document than a single sentence, simulation results indicate that the use of isolated sentences for relevance feedback can yield comparable accuracy and higher efficiency, relative to the state-of-the-art baseline model implementation (bmi) of the autotar continuous active learning (\"cal\") method employed in the trec 2015 and 2016 total recall track.',\n",
       " 78: 'we obtain an equivalent implicit characterization of $l^p$ banach spaces that is amenable to a logical treatment. using that, we obtain an axiomatization for such spaces into a higher-order logical system, the kind of which is used in proof mining, a research program that aims to obtain the hidden computational content of mathematical proofs using tools from mathematical logic. as an aside, we obtain a concrete way of formalizing $l^p$ spaces in positive-bounded logic. the axiomatization is followed by a corresponding metatheorem in the style of proof mining. we illustrate its use with the derivation for this class of spaces of the standard modulus of uniform convexity.',\n",
       " 79: 'we consider a model of an electric circuit, where differential algebraic equations for a circuit part are coupled to partial differential equations for an electromagnetic field part. an uncertainty quantification is performed by changing physical parameters into random variables. a random quantity of interest is expanded into the (generalised) polynomial chaos using orthogonal basis polynomials. we investigate the determination of sparse representations, where just a few basis polynomials are required for a sufficiently accurate approximation. furthermore, we apply model order reduction with proper orthogonal decomposition to obtain a low-dimensional representation in an alternative basis.',\n",
       " 80: 'kernel methods on discrete domains have shown great promise for many challenging data types, for instance, biological sequence data and molecular structure data. scalable kernel methods like support vector machines may offer good predictive performances but do not intrinsically provide uncertainty estimates. in contrast, probabilistic kernel methods like gaussian processes offer uncertainty estimates in addition to good predictive performance but fall short in terms of scalability. we present the first sparse gaussian process approximation framework on discrete input domains. our framework achieves good predictive performance as well as uncertainty estimates using discrete optimization techniques. we present competitive results comparing our framework to baseline methods such as support vector machines and full gaussian processes on synthetic data as well as on challenging real-world dna sequence data.',\n",
       " 81: 'how similar is the human mind to the sophisticated machine-learning systems that mirror its performance? models of object categorization based on convolutional neural networks (cnns) have achieved human-level benchmarks in assigning known labels to novel images. these advances promise to support transformative technologies such as autonomous vehicles and machine diagnosis; beyond this, they also serve as candidate models for the visual system itself -- not only in their output but perhaps even in their underlying mechanisms and principles. however, unlike human vision, cnns can be \"fooled\" by adversarial examples -- carefully crafted images that appear as nonsense patterns to humans but are recognized as familiar objects by machines, or that appear as one object to humans and a different object to machines. this seemingly extreme divergence between human and machine classification challenges the promise of these new advances, both as applied image-recognition systems and also as models of the human mind. surprisingly, however, little work has empirically investigated human classification of such adversarial stimuli: does human and machine performance fundamentally diverge? or could humans decipher such images and predict the machine\\'s preferred labels? here, we show that human and machine classification of adversarial stimuli are robustly related: in eight experiments on five prominent and diverse adversarial imagesets, human subjects reliably identified the machine\\'s chosen label over relevant foils. this pattern persisted for images with strong antecedent identities, and even for images described as \"totally unrecognizable to human eyes\". we suggest that human intuition may be a more reliable guide to machine (mis)classification than has typically been imagined, and we explore the consequences of this result for minds and machines alike.',\n",
       " 82: 'in ai research and industry, machine learning is the most widely used tool. one of the most important machine learning algorithms is gradient boosting decision tree, i.e. gbdt whose training process needs considerable computational resources and time. to shorten gbdt training time, many works tried to apply gbdt on parameter server. however, those gbdt algorithms are synchronous parallel algorithms which fail to make full use of parameter server. in this paper, we examine the possibility of using asynchronous parallel methods to train gbdt model and name this algorithm as asynch-sgbdt (asynchronous parallel stochastic gradient boosting decision tree). our theoretical and experimental results indicate that the scalability of asynch-sgbdt is influenced by the sample diversity of datasets, sampling rate, step length and the setting of gbdt tree. experimental results also show asynch-sgbdt training process reaches a linear speedup in asynchronous parallel manner when datasets and gbdt trees meet high scalability requirements.',\n",
       " 83: 'we demonstrate that a near-dissociation photoassociation resonance can be used to create a deeply bound molecular sample of ultracold nacs. to probe the resulting vibrational distribution of the sample, we use a new technique that can be applied to any ultracold molecular system. we utilize a tunable pulsed dye laser to produce efficient spectroscopic scans ($\\\\sim700$ cm$^{-1}$ at a time) in which we observe the $1^{1} \\\\sigma^{+}\\\\rightarrow 2^{1}\\\\sigma^{+}-2^{3}\\\\pi$ vibrational progression, as well as the dissociation limit to the cs 6$^{2}$p$_{3/2}$ asymptote. we assign $1^{1} \\\\sigma^{+}$$(\\\\emph{v}$ = 4, 5, 6, 11, 19) vibrational levels in our sample.',\n",
       " 84: 'we derive a continuum model for incompatible elasticity as a variational limit of a family of discrete nearest-neighbor elastic models. the discrete models are based on discretizations of a smooth riemannian manifold $(m,\\\\mathfrak{g})$, endowed with a flat, symmetric connection $\\\\nabla$. the metric $\\\\mathfrak{g}$ determines local equilibrium distances between neighboring points; the connection $\\\\nabla$ induces a lattice structure shared by all the discrete models. the limit model satisfies a fundamental rigidity property: there are no stress-free configurations, unless $\\\\mathfrak{g}$ is flat, i.e., has zero riemann curvature. our analysis focuses on two-dimensional systems, however, all our results readily generalize to higher dimensions.',\n",
       " 85: 'we present a parametrization for the dark energy equation of state \"eos\" which has a rich structure. our eos has a transition at pivotal redshift $z_t$ between the present day value $w_0$ to an early time $w_i=w_a+w_0\\\\equiv w(z>>0)$ and the steepness of this transition is given in terms of the $q$ parameter. the proposed parametrization is $w=w_0+w_a(z/z_t)^q/(1+(z/z_t))^q$, with $w_0$, $w_i$, $q $ and $z_t$ constant parameters. this transition is motivated by scalar field dynamics such as for example quintessence models. our parametrization reduces to the widely used eos $w=w_0+w_a(1-a)$ for $z_t=q=1$. we study if a late time transition is favored by bao measurements and planck priors. according to our results, an eos with a present value of $w_0 = -0.91$ and a high redshifts value $w_i =-0.62$, featuring a transition at a redshift of $z_t = 1.16$ with an exponent $q = 9.95$ is a good fit to the observational data. we found good agreement between the model and the data reported by the different surveys. a \"thawing\" dynamics is preferred by the use of bao data alone (including lymman-$\\\\alpha$ forest measurements) and a \"freezing\" evolution of the eos is preferred when we include the priors from planck. the constraints imposed by the available bao measurements (\\\\cite{beutler:2011hx, ross:2014qpa, anderson:2013oza, kazin:2014qga, font-ribera:2013wce, delubac:2014aqe, gong:2015tta}) and its physical behavior are discussed.',\n",
       " 86: \"a frequent topic in the study of pattern avoidance is identifying when two sets of patterns $\\\\pi, \\\\pi'$ are wilf equivalent, that is, when $|\\\\text{av}_n(\\\\pi)| = |\\\\text{av}_n(\\\\pi')|$ for all $n$. in recent work of dokos et al. the notion of wilf equivalence was refined to reflect when avoidance of classical patterns preserves certain statistics. in this article, we continue their work by examining $\\\\text{des}$-wilf equivalence when avoiding certain non-classical patterns.\",\n",
       " 87: 'we study an optimal control problem arising from a generalization of rock-paper-scissors in which the number of strategies may be selected from any positive odd number greater than 1 and in which the payoff to the winner is controlled by a control variable $\\\\gamma$. using the replicator dynamics as the equations of motion, we show that a quasi-linearization of the problem admits a special optimal control form in which explicit dynamics for the controller can be identified. we show that all optimal controls must satisfy a specific second order differential equation parameterized by the number of strategies in the game. we show that as the number of strategies increases, a limiting case admits a closed form for the open-loop optimal control. in performing our analysis we show necessary conditions on an optimal control problem that allow this analytic approach to function.',\n",
       " 88: 'in this work we will develop a new approach to solve the non repayment problem in microfinance due to the problem of asymmetric information. this approach is based on modeling and simulation of ordinary differential systems where time remains a primordial component, they thus enable microfinance institutions to manage their risk portfolios by a prediction of numbers of solvent and insolvent borrowers ever a period, in order to define or redefine its development strategy, investment and management in an area, where the population is often poor and in need a mechanism of financial inclusion.',\n",
       " 89: 'in this review paper, we will present different data-driven dimension reduction techniques for dynamical systems that are based on transfer operator theory as well as methods to approximate transfer operators and their eigenvalues, eigenfunctions, and eigenmodes. the goal is to point out similarities and differences between methods developed independently by the dynamical systems, fluid dynamics, and molecular dynamics communities such as time-lagged independent component analysis (tica), dynamic mode decomposition (dmd), and their respective generalizations. as a result, extensions and best practices developed for one particular method can be carried over to other related methods.',\n",
       " 90: 'recent progress in tissue clearing has allowed for the imaging of entire organs at single-cell resolution. these methods produce very large 3d images (several gigabytes for a whole mouse brain). a necessary step in analysing these images is registration across samples. existing methods of registration were developed for lower resolution image modalities (e.g. mri) and it is unclear whether their performance and accuracy is satisfactory at this larger scale. in this study, we used data from different mouse brains cleared with the cubic protocol to evaluate five freely available image registration tools. we used several performance metrics to assess accuracy, and completion time as a measure of efficiency. the results of this evaluation suggest that the ants registration tool provides the best registration accuracy while elastix has the highest computational efficiency among the methods with an acceptable accuracy. the results also highlight the need to develop new registration methods optimised for these high-resolution 3d images.',\n",
       " 91: 'given arbitrary monomial ideals $i$ and $j$ in polynomial rings $a$ and $b$ over a field $k$, we investigate the stanley depth of powers of the sum $i+j$, and their quotient rings, in $a\\\\otimes_k b$ in terms of those of $i$ and $j$. our results can be used to study the asymptotic behavior of the stanley depth of powers of a monomial ideal. for instance, we solved the case of monomial complete intersection.',\n",
       " 92: \"hybrid resonance is a physical mechanism for the heating of a magnetic plasma. in our context hybrid resonance is a solution of the time harmonic maxwell's equations with smooth coefficients, where the dielectric tensor is a non diagonal hermitian matrix. the main part of this work is dedicated to the construction and analysis of a mathematical solution of the hybrid resonance with the limit absorption principle. we prove that the limit solution is singular: it is constituted of a dirac mass at the origin plus a principle value and a smooth square integrable function. the formula obtained for the plasma heating is directly related to the singularity.\",\n",
       " 93: 'in the past few years, several disks with inner holes that are empty of small dust grains have been detected and are known as transitional disks. recently, spitzer has identified a new class of \"pre-transitional disks\" with gaps; these objects have an optically thick inner disk separated from an optically thick outer disk by an optically thin disk gap. a near-infrared spectrum provided the first confirmation of a gap in the pre-transitional disk of lkca 15 by verifying that the near-infrared excess emission in this object was due to an optically thick inner disk. here we investigate the difference between the nature of the inner regions of transitional and pre-transitional disks using the same veiling-based technique to extract the near-infrared excess emission above the stellar photosphere. we show that the near-infrared excess emission of the previously identified pre-transitional disks of lkca 15 and ux tau a in taurus as well as the newly identified pre-transitional disk of rox 44 in ophiuchus can be fit with an inner disk wall located at the dust destruction radius. we also model the broad-band seds of these objects, taking into account the effect of shadowing by the inner disk on the outer disk, considering the finite size of the star. the near-infrared excess continua of these three pre-transitional disks, which can be explained by optically thick inner disks, are significantly different from that of the transitional disks of gm aur, whose near-infrared excess continuum can be reproduced by emission from sub-micron-sized optically thin dust, and dm tau, whose near-infrared spectrum is consistent with a disk hole that is relatively free of small dust. the structure of pre-transitional disks may be a sign of young planets forming in these disks and future studies of pre-transitional disks will provide constraints to aid in theoretical modeling of planet formation.',\n",
       " 94: 'we give a polynomial-time algorithm for computing upper bounds on some of the smaller energy eigenvalues in a spin-1/2 ferromagnetic heisenberg model with any graph $g$ for the underlying interactions. an important ingredient is the connection between heisenberg models and the symmetric products of $g$. our algorithms for computing upper bounds are based on generalized diameters of graphs. computing the upper bounds amounts to solving the minimum assignment problem on $g$, which has well-known polynomial-time algorithms from the field of combinatorial optimization. we also study the possibility of computing the lower bounds on some of the smaller energy eigenvalues of heisenberg models. this amounts to estimating the isoperimetric inequalities of the symmetric product of graphs. by using connections with discrete sobolev inequalities, we show that this can be performed by considering just the vertex-induced subgraphs of $g$. if our conjecture for a polynomial time approximation algorithm to solve the edge-isoperimetric problem holds, then our proposed method of estimating the energy eigenvalues via approximating the edge-isoperimetric properties of vertex-induced subgraphs will yield a polynomial time algorithm for estimating the smaller energy eigenvalues of the heisenberg ferromagnet.',\n",
       " 95: 'for reliable transmission across a noisy communication channel, classical results from information theory show that it is asymptotically optimal to separate out the source and channel coding processes. however, this decomposition can fall short in the finite bit-length regime, as it requires non-trivial tuning of hand-crafted codes and assumes infinite computational power for decoding. in this work, we propose to jointly learn the encoding and decoding processes using a new discrete variational autoencoder model. by adding noise into the latent codes to simulate the channel during training, we learn to both compress and error-correct given a fixed bit-length and computational budget. we obtain codes that are not only competitive against several separation schemes, but also learn useful robust representations of the data for downstream tasks such as classification. finally, inference amortization yields an extremely fast neural decoder, almost an order of magnitude faster compared to standard decoding methods based on iterative belief propagation.',\n",
       " 96: 'advancing the sparse regularity method, we prove one-sided and two-sided regularity inheritance lemmas for subgraphs of bijumbled graphs, improving on results of conlon, fox and zhao [adv. math. 256 (2014), 206--290]. these inheritance lemmas also imply improved $h$-counting lemmas for subgraphs of bijumbled graphs, for some $h$.',\n",
       " 97: 'we show the cohen-macaulayness and describe the canonical module of residual intersections $j=\\\\mathfrak{a}\\\\colon_r i$ in a cohen-macaulay local ring $r$, under sliding depth type hypotheses. for this purpose, we construct and study, using a recent article of hassanzadeh and the second named author, a family of complexes that contains important informations on a residual intersection and its canonical module. we also determine several invariants of residual intersections as the graded canonical module, the hilbert series, the castelnuovo-mumford regularity and the type. finally, whenever $i$ is strongly cohen-macaulay, we show duality results for residual intersections that are closely connected to results by eisenbud and ulrich. it establishes some tight relations between the hilbert series of some symmetric powers of $i/\\\\mathfrak{a}$. we also provide closed formulas for the types and for the bass numbers of some symmetric powers of $i/\\\\mathfrak{a}.$',\n",
       " 98: \"we study the performance bounds of vehicle-to-vehicle (v2v) relative positioning for vehicles with multiple antenna arrays. the cram\\\\'{e}r-rao bound for the estimation of the relative position and the orientation of the tx vehicle is derived, when angle of arrival (aoa) measurements with or without time-difference of arrival (tdoa) measurements are used. in addition, geometrically intuitive expressions for the corresponding fisher information are provided. the derived bounds are numerically evaluated for different carrier frequencies, bandwidths and array configurations under different v2v scenarios, i.e. overtaking and platooning. the significance of the aoa and tdoa measurements for position estimation is investigated. the achievable positioning accuracy is then compared with the present requirements of the 3rd generation partnership project (3gpp) 5g new radio (nr) vehicle-to-everything (v2x) standardization.\",\n",
       " 99: 'we prove distributional limit theorems for random walk adic transformations obtaining ergodic distributional limits of exponential chi squared form.',\n",
       " 100: 'we consider the actions of (semi)groups on a locally compact group by automorphisms. we show the equivalence of distality and pointwise distality for the actions of a certain class of groups. we also show that a compactly generated locally compact group of polynomial growth has a compact normal subgroup $k$ such that $g/k$ is distal and the conjugacy action of $g$ on $k$ is ergodic; moreover, if $g$ itself is (pointwise) distal then $g$ is lie projective. we prove a decomposition theorem for contraction groups of an automorphism under certain conditions. we give a necessary and sufficient condition for distality of an automorphism in terms of its contraction group. we compare classes of (pointwise) distal groups and groups whose closed subgroups are unimodular. in particular, we study relations between distality, unimodularity and contraction subgroups.',\n",
       " 101: 'measuring conditional dependence is an important topic in statistics with broad applications including graphical models. under a factor model setting, a new conditional dependence measure based on projection is proposed. the corresponding conditional independence test is developed with the asymptotic null distribution unveiled where the number of factors could be high-dimensional. it is also shown that the new test has control over the asymptotic significance level and can be calculated efficiently. a generic method for building dependency graphs without gaussian assumption using the new test is elaborated. numerical results and real data analysis show the superiority of the new method.',\n",
       " 102: 'we provide a pointwise bipolar theorem for liminf-closed convex sets of positive borel measurable functions on a sigma-compact metric space without the assumption that the polar is a tight set of measures. as applications we derive a version of the transport duality under non-tight marginals, and a superhedging duality for semistatic hedging in discrete time.',\n",
       " 103: 'the advent of structured, high-dimensional entangled states brings new possibilities for quantum imaging, information processing and quantum key distribution. we experimentally generate and characterize a spatially entangled state stored in a quantum memory system, using entropic epr-steering inequality, yielding genuine violation of $1.06\\\\pm0.15$ bits and certifying entanglement of formation of at least $0.70\\\\pm0.15$ ebits. the supremacy of the entropic witness is demonstrated for a wide class of experimentally available states, giving prospects for epr-steering applications in noisy systems or with lossy quantum channels.',\n",
       " 104: 'gamma-ray bursts (grbs) were confirmed to be of extragalactic origin due to their isotropic angular distribution, combined with the fact that they exhibited an intensity distribution that deviated strongly from the $-3/2$ power law. this finding was later confirmed with the first redshift, equal to at least $z=0.835$, measured for grb970508. despite this result, the data from $cgro$/batse and $swift$/bat indicate that long grbs are indeed distributed isotropically, but the distribution of short grbs is anisotropic. $fermi$/gbm has detected 1669 grbs up to date, and their sky distribution is examined in this paper. a number of statistical tests is applied: nearest neighbour analysis, fractal dimension, dipole and quadrupole moments of the distribution function decomposed into spherical harmonics, binomial test, and the two point angular correlation function. monte carlo benchmark testing of each test is performed in order to evaluate its reliability. it is found that short grbs are distributed anisotropically on the sky, and long ones have an isotropic distribution. the probability that these results are not a chance occurence is equal to at least 99.98\\\\% and 30.68\\\\% for short and long grbs, respectively. the cosmological context of this finding and its relation to large-scale structures is discussed.',\n",
       " 105: 'the field of big code relies on mining large corpora of code to perform some learning task. a significant threat to this approach has been recently identified by lopes et al. (2017) who found a large amount of near-duplicate code on github. however, the impact of code duplication has not been noticed by researchers devising machine learning models for source code. in this work, we explore the effects of code duplication on machine learning models showing that reported performance metrics are sometimes inflated by up to 100% when testing on duplicated code corpora compared to the performance on de-duplicated corpora which more accurately represent how machine learning models of code are used by software engineers. we present a duplication index for widely used datasets, list best practices for collecting code corpora and evaluating machine learning models on them. finally, we release tools to help the community avoid this problem in future research.',\n",
       " 106: 'this paper is devoted to the study of the stokes and navier-stokes equations, in a half-space, for initial data in a class of locally uniform lebesgue integrable functions, namely $l^q_{uloc,\\\\sigma}(\\\\r^d_+)$. we prove the analyticity of the stokes semigroup $e^{-t{\\\\bf a}}$ in $l^q_{uloc,\\\\sigma}(\\\\r^d_+)$ for $1<q\\\\leq\\\\infty$. this follows from the analysis of the stokes resolvent problem for data in $l^q_{uloc,\\\\sigma}(\\\\r^d_+)$, $1<q\\\\leq\\\\infty$. we then prove bilinear estimates for the oseen kernel, which enables to prove the existence of mild solutions. the three main original aspects of our contribution are: (i) the proof of liouville theorems for the resolvent problem and the time dependent stokes system under weak integrability conditions, (ii) the proof of pressure estimates in the half-space and (iii) the proof of a concentration result for blow-up solutions of the navier-stokes equations. this concentration result improves a recent result by li, ozawa and wang and provides a new proof.',\n",
       " 107: \"a significant amount of information in today's world is stored in structured and semi-structured knowledge bases. efficient and simple methods to query them are essential and must not be restricted to only those who have expertise in formal query languages. the field of semantic parsing deals with converting natural language utterances to logical forms that can be easily executed on a knowledge base. in this survey, we examine the various components of a semantic parsing system and discuss prominent work ranging from the initial rule based methods to the current neural approaches to program synthesis. we also discuss methods that operate using varying levels of supervision and highlight the key challenges involved in the learning of such systems.\",\n",
       " 108: 'we use assembly maps to study $\\\\mathbf{tc}(\\\\mathbb{a}[g];p)$, the topological cyclic homology at a prime $p$ of the group algebra of a discrete group $g$ with coefficients in a connective ring spectrum $\\\\mathbb{a}$. for any finite group, we prove that the assembly map for the family of cyclic subgroups is an isomorphism on homotopy groups. for infinite groups, we establish pro-isomorphism, (split) injectivity, and rational injectivity results, as well as counterexamples to injectivity and surjectivity. in particular, for hyperbolic groups and for virtually finitely generated abelian groups, we show that the assembly map for the family of virtually cyclic subgroups is injective but in general not surjective.',\n",
       " 109: 'as wireless networks evolve towards high mobility and providing better support for connected vehicles, a number of new challenges arise due to the resulting high dynamics in vehicular environments and thus motive rethinking of traditional wireless design methodologies. future intelligent vehicles, which are at the heart of high mobility networks, are increasingly equipped with multiple advanced onboard sensors and keep generating large volumes of data. machine learning, as an effective approach to artificial intelligence, can provide a rich set of tools to exploit such data for the benefit of the networks. in this article, we first identify the distinctive characteristics of high mobility vehicular networks and motivate the use of machine learning to address the resulting challenges. after a brief introduction of the major concepts of machine learning, we discuss its applications to learn the dynamics of vehicular networks and make informed decisions to optimize network performance. in particular, we discuss in greater detail the application of reinforcement learning in managing network resources as an alternative to the prevalent optimization approach. finally, some open issues worth further investigation are highlighted.',\n",
       " 110: 'let $\\\\a$ be a ring with local units, $\\\\e$ a set of local units for $\\\\a$, $\\\\g$ an abelian group and $\\\\alpha$ a partial action of $\\\\g$ by ideals of $\\\\a$ that contain local units and such that the partial skew group ring $\\\\a\\\\star_{\\\\alpha} \\\\g$ is associative. we show that $\\\\a\\\\star_{\\\\alpha} \\\\g$ is simple if and only if $\\\\a$ is $\\\\g$-simple and the center of the corner $e\\\\delta_0 (\\\\a\\\\star_{\\\\alpha} \\\\g) e \\\\delta_0$ is a field for all $e\\\\in \\\\e$. we apply the result to characterize simplicity of partial skew group rings in two cases, namely for partial skew group rings arising from partial actions by clopen subsets of a compact set and partial actions on the set level.',\n",
       " 111: \"this paper describes a new mechanism that might help with defining pattern sequences, by the fact that it can produce an upper bound on the ensemble value that can persistently oscillate with the actual values produced from each pattern. with every firing event, a node also receives an on/off feedback switch. if the node fires, then it sends a feedback result depending on the input signal strength. if the input signal is positive or larger, it can store an 'on' switch feedback for the next iteration. if the signal is negative or smaller, it can store an 'off' switch feedback for the next iteration. if the node does not fire, then it does not affect the current feedback situation and receives the switch command produced by the last active pattern event for the same neuron. the upper bound therefore also represents the largest or most enclosing pattern set and the lower value is for the actual set of firing patterns. if the pattern sequence repeats, it will oscillate between the two values, allowing them to be recognised and measured more easily, over time. tests show that changing the sequence ordering produces different value sets, which can also be measured.\",\n",
       " 112: 'the kelvin-helmholtz instability is well-known in classical hydrodynamics, where it explains the sudden emergence of interfacial surface waves as a function of the velocity of flow parallel to the interface. it can be carried over to the inviscid two-fluid dynamics of superfluids, to study different types of interfaces and phase boundaries in quantum fluids. we report measurements on the stability of the phase boundary separating the two bulk phases of superfluid 3he in rotating flow, while the boundary is localized with the gradient of the magnetic field to a position perpendicular to the rotation axis. the results demonstrate that the classic stability condition, when modified for the superfluid environment, is obeyed down to 0.4 tc, if a large fraction of the magnetic polarization of the b-phase is attributed to a parabolic reduction of the interfacial surface tension with increasing magnetic field.',\n",
       " 113: 'we consider two group actions on $m$-tuples of $n \\\\times n$ matrices. the first is simultaneous conjugation by $\\\\operatorname{gl}_n$ and the second is the left-right action of $\\\\operatorname{sl}_n \\\\times \\\\operatorname{sl}_n$. we give efficient algorithms to decide if the orbit closures of two points intersect. we also improve the known bounds for the degree of separating invariants in these cases.',\n",
       " 114: 'electric field effects in ferromagnetic/oxide dielectric structures provide a new route to control domain wall (dw) dynamics with low power dissipation. however, electric field effects on dw velocities have only been observed so far in the creep regime where dw velocities are low due to strong interactions with pinning sites. here, we show gate voltage modulation of dw velocities ranging from the creep to the flow regime in ta/co40fe40b20/mgo/tio2 structures with perpendicular magnetic anisotropy. we demonstrate a universal description of the role of applied electric fields in the various pinning dependent regimes by taking into account an effective magnetic field being linear with the electric field. in addition, the electric field effect is found to change sign in the walker regime. our work opens new opportunities for the study and optimization of electric field effect at ferromagnetic metal/insulator interfaces.',\n",
       " 115: 'we developed omicsmapnet approach to take advantage of existing deep leaning frameworks to analyze high-dimensional omics data as 2-dimensional images. the omics data of individual samples were first rearranged into 2d images in which molecular features related in functions, ontologies, or other relationships were organized in spatially adjacent and patterned locations. deep learning neural networks were trained to classify the images. molecular features informative of classes of different phenotypes were subsequently identified. as an example, we used the kegg brite database to rearrange rna-seq expression data of tcga diffuse glioma samples as treemaps to capture the functional hierarchical structure of genes in 2d images. deep convolutional neural networks (cnn) were derived using tools from tensorflow to learn the grade of tcga lgg and gbm samples with relatively high accuracy. the most contributory features in the trained cnn were confirmed in pathway analysis for their plausible functional involvement.',\n",
       " 116: 'we study a family of mixed tate motives over $\\\\mathbb{z}$ whose periods are linear forms in the zeta values $\\\\zeta(n)$. they naturally include the beukers-rhin-viola integrals for $\\\\zeta(2)$ and the ball-rivoal linear forms in odd zeta values. we give a general integral formula for the coefficients of the linear forms and a geometric interpretation of the vanishing of the coefficients of a given parity. the main underlying result is a geometric construction of a minimal ind-object in the category of mixed tate motives over $\\\\mathbb{z}$ which contains all the non-trivial extensions between simple objects. in a joint appendix with don zagier, we prove the compatibility between the structure of the motives considered here and the representations of their periods as sums of series.',\n",
       " 117: \"to attain the targeted data rates of next generation cellular networks requires dense deployment of small cells in addition to macro cells which provide wide coverage. dynamic radio resource management is crucial to the success of such heterogeneous networks due to much more pronounced traffic and interference variations in small cells. this work proposes a framework for spectrum management organized according to two timescales, which include 1) centralized optimization on a moderate timescale corresponding to typical duration of user sessions (several seconds to minutes in today's networks), and 2) distributed spectrum allocation on a fast timescale corresponding to typical latency requirements (a few milliseconds). an optimization problem is formulated to allocate resources on the slower timescale with consideration of (distributed) opportunistic scheduling on the faster timescale. both fixed and fully flexible user association schemes are considered. iterative algorithms are developed to solve these optimization problems efficiently for a cluster of cells with guaranteed convergence. simulation results demonstrate advantages of the proposed framework and algorithms.\",\n",
       " 118: 'how many permutations of the natural numbers are needed so that every conditionally convergent series of real numbers can be rearranged to no longer converge to the same sum? we define the \\\\emph{rearrangement number}, a new cardinal characteristic of the continuum, as the answer to this question. we compare the rearrangement number with several natural variants, for example one obtained by requiring the rearranged series to still converge but to a new, finite limit. we also compare the rearrangement number with several well-studied cardinal characteristics of the continuum. we present some new forcing constructions designed to add permutations that rearrange series from the ground model in particular ways, thereby obtaining consistency results going beyond those that follow from comparisons with familiar cardinal characteristics. finally, we deal briefly with some variants concerning rearrangements by a special sort of permutation and with rearranging some divergent series to become (conditionally) convergent.',\n",
       " 119: \"l\\\\'evy driven term structure models have become an important subject in the mathematical finance literature. this paper provides a comprehensive analysis of the l\\\\'evy driven heath-jarrow-morton type term structure equation. this includes a full proof of existence and uniqueness in particular, which seems to have been lacking in the finance literature so far.\",\n",
       " 120: 'the term unimath refers both to a formal system for mathematics, as well as a computer-checked library of mathematics formalized in that system. the unimath system is a core dependent type theory, augmented by the univalence axiom. the system is kept as small as possible in order to ease verification of it - in particular, general inductive types are not part of the system.   in this work, we partially remedy the lack of inductive types by constructing some datatypes and their associated induction principles from other type constructors. this involves a formalization of a category-theoretic result on the construction of initial algebras, as well as a mechanism to conveniently use the datatypes obtained. we also connect this construction to a previous formalization of substitution for languages with variable binding. altogether, we construct a framework that allows us to concisely specify, via a simple notion of binding signature, a language with variable binding. from such a specification we obtain the datatype of terms of that language, equipped with a certified monadic substitution operation and a suitable recursion scheme. using this we formalize the untyped lambda calculus and the raw syntax of martin-l\\\\\"of type theory.',\n",
       " 121: \"this paper proposes medley of sub-attention networks (mosan), a new novel neural architecture for the group recommendation task. group-level recommendation is known to be a challenging task, in which intricate group dynamics have to be considered. as such, this is to be contrasted with the standard recommendation problem where recommendations are personalized with respect to a single user. our proposed approach hinges upon the key intuition that the decision making process (in groups) is generally dynamic, i.e., a user's decision is highly dependent on the other group members. all in all, our key motivation manifests in a form of an attentive neural model that captures fine-grained interactions between group members. in our mosan model, each sub-attention module is representative of a single member, which models a user's preference with respect to all other group members. subsequently, a medley of sub-attention modules is then used to collectively make the group's final decision. overall, our proposed model is both expressive and effective. via a series of extensive experiments, we show that mosan not only achieves state-of-the-art performance but also improves standard baselines by a considerable margin.\",\n",
       " 122: 'the asdc sed builder (http://tools.asdc.asi.it/sed/) is a web based program developed at the asi science data center to produce and display the spectral energy distribution (sed) of astrophysical sources. the tool combines data from several missions and experiments, both ground and space-based, together with catalogs and archival data. in the current version (v1.3) the obtained seds can be compared with theoretical expectations and with the sensitivity curve of several widely known instruments. the displayed data can also be fitted to simple analytical functions. providing a cosmological redshift, the sed can be visualized in rest-frame luminosities. the tool provides transparent access to asdc-resident catalogs (e.g. swift, agile, fermi etc.) as well as to external archives (e.g. ned, 2mass, sdss etc.) covering the whole electromagnetic spectrum, from radio to tev energies. proprietary data can also be properly handled. the intent of this document is to provide a brief description of the main capabilities of the asdc sed builder. specific details on the graphical interface and on the functionalities can be found in the appendix to this document which provides a tutorial to the tool.',\n",
       " 123: \"a novel surface interrogation technique is proposed to compute the intersection of curves with spline surfaces in isogeometric analysis. the intersection points are determined in one-shot without resorting to a newton-raphson iteration or successive refinement. surface-curve intersection is required in a wide range of applications, including contact, immersed boundary methods and lattice-skin structures, and requires usually the solution of a system of nonlinear equations. it is assumed that the surface is given in form of a spline, such as a nurbs, t-spline or catmull-clark subdivision surface, and is convertible into a collection of b\\\\'ezier patches. first, a hierarchical bounding volume tree is used to efficiently identify the b\\\\'ezier patches with a convex-hull intersecting the convex-hull of a given curve segment. for ease of implementation convex-hulls are approximated with k-dops (discrete orientation polytopes). subsequently, the intersections of the identified b\\\\'ezier patches with the curve segment are determined with a matrix-based implicit representation leading to the computation of a sequence of small singular value decompositions (svds). as an application of the developed interrogation technique the isogeometric design and analysis of lattice-skin structures is investigated. the skin is a spline surface that is usually created in a computer-aided design (cad) system and the periodic lattice to be fitted consists of unit cells, each containing a small number of struts. the lattice-skin structure is generated by projecting selected lattice nodes onto the surface after determining the intersection of unit cell edges with the surface. for mechanical analysis, the skin is modelled as a kirchhoff-love thin-shell and the lattice as a pin-jointed truss. the two types of structures are coupled with a standard lagrange multiplier approach.\",\n",
       " 124: 'we give a large family of weighted projective planes, blown up at a smooth point, that do not have finitely generated cox rings. we then use the method of castravet and tevelev to prove that the moduli space of stable n-pointed genus zero curves does not have a finitely generated cox ring if n is at least 13.',\n",
       " 125: 'we obtain an ordering of closed aspherical 4-manifolds that carry a non-hyperbolic thurston geometry. as application, we derive that the kodaira dimension of geometric 4-manifolds is monotone with respect to the existence of maps of non-zero degree.',\n",
       " 126: 'in the last two decades, there has been much progress on model checking of both probabilistic systems and higher-order programs. in spite of the emergence of higher-order probabilistic programming languages, not much has been done to combine those two approaches. in this paper, we initiate a study on the probabilistic higher-order model checking problem, by giving some first theoretical and experimental results. as a first step towards our goal, we introduce phors, a probabilistic extension of higher-order recursion schemes (hors), as a model of probabilistic higher-order programs. the model of phors may alternatively be viewed as a higher-order extension of recursive markov chains. we then investigate the probabilistic termination problem --- or, equivalently, the probabilistic reachability problem. we prove that almost sure termination of order-2 phors is undecidable. we also provide a fixpoint characterization of the termination probability of phors, and develop a sound (but possibly incomplete) procedure for approximately computing the termination probability. we have implemented the procedure for order-2 phorss, and confirmed that the procedure works well through preliminary experiments that are reported at the end of the article.',\n",
       " 127: 'this paper proposes a method to reduce noise in acyclic sensor networks enumerating targets using the integral theory with respect to euler characteristic. for an acyclic network (a partially ordered set) equipped with sensors detecting targets, we find reducible points for enumerating targets, as a generalization of weak beat points (homotopically reducible points). this theory is useful for improving the reliability and optimization of acyclic sensor networks.',\n",
       " 128: 'distributed machine learning has been widely studied in the literature to scale up machine learning model training in the presence of an ever-increasing amount of data. we study distributed machine learning from another perspective, where the information about the training same samples are inherently decentralized and located on different parities. we propose an asynchronous stochastic gradient descent (sgd) algorithm for such a feature distributed machine learning (fdml) problem, to jointly learn from decentralized features, with theoretical convergence guarantees under bounded asynchrony. our algorithm does not require sharing the original feature data or even local model parameters between parties, thus preserving a high level of data confidentiality. we implement our algorithm for fdml in a parameter server architecture. we compare our system with fully centralized training (which violates data locality requirements) and training only based on local features, through extensive experiments performed on a large amount of data from a real-world application, involving 5 million samples and $8700$ features in total. experimental results have demonstrated the effectiveness and efficiency of the proposed fdml system.',\n",
       " 129: 'we obtain new bounds of multivariate exponential sums with monomials, when the variables run over rather short intervals. furthermore, we use the same method to derive estimates on similar sums with multiplicative characters to which previously known methods do not apply. in particular, in the multiplicative characters modulo a prime $p$ we break the barrier of $p^{1/4}$ for ranges of individual variables.',\n",
       " 130: 'we classify the singular loci of surfaces in the 3-sphere that are the pointwise euclidean sum or hamiltonian product of circles. such surfaces are the union of circles in at least two ways. as an application we classify surfaces that are covered by both great circles and little circles up to homeomorphism.',\n",
       " 131: 'the conflict between pro-self and pro-social behaviour is at the core of many key problems of our time, as, for example, the reduction of air pollution and the redistribution of scarce resources. for the well-being of our societies, it is thus crucial to find mechanisms to promote pro-social choices over egoistic ones. particularly important, because cheap and easy to implement, are those mechanisms that can change people\\'s behaviour without forbidding any options or significantly changing their economic incentives, the so-called \"nudges\". previous research has found that moral nudges (e.g., making norms salient) can promote pro-social behaviour. however, little is known about whether their effect persists over time and spills across context. this question is key in light of research showing that pro-social actions are often followed by selfish actions, thus suggesting that some moral manipulations may backfire. here we present a class of simple moral nudges that have a great positive impact on pro-sociality. in studies 1-4 (total n = 1,400), we use economic games to demonstrate that asking subjects to self-report \"what they think is the morally right thing to do\" does not only increase pro-sociality in the choice immediately after, but also in subsequent choices, and even when the social context changes. in study 5, we explore whether moral nudges promote charity donations to humanitarian organisations in a large (n=1,800) crowdfunding campaign. we find that, in this context, moral nudges increase donations by about 44 percent.',\n",
       " 132: 'we present an $\\\\ell$-adic trace formula for saturated and admissible dg-categories over a base monoidal dg-category. moreover, we prove k\\\\\"unneth formulas for dg-category of singularities, and for inertia-invariant vanishing cycles. as an application, we prove a version of bloch\\'s conductor conjecture (stated by spencer bloch in 1985), under the additional hypothesis that the monodromy action of the inertia group is unipotent.',\n",
       " 133: 'in tropical regions, populations continue to suffer morbidity and mortality from malaria and arboviral diseases. in kedougou (senegal), these illnesses are all endemic due to the climate and its geographical position. the co-circulation of malaria parasites and arboviruses can explain the observation of coinfected cases. indeed there is strong resemblance in symptoms between these diseases making problematic targeted medical care of coinfected cases. this is due to the fact that the origin of illness is not obviously known. some cases could be immunized against one or the other of the pathogens, immunity typically acquired with factors like age and exposure as usual for endemic area. then, coinfection needs to be better diagnosed. using data collected from patients in kedougou region, from 2009 to 2013, we adjusted a multinomial logistic model and selected relevant variables in explaining coinfection status. we observed specific sets of variables explaining each of the diseases exclusively and the coinfection. we tested the independence between arboviral and malaria infections and derived coinfection probabilities from the model fitting. in case of a coinfection probability greater than a threshold value to be calibrated on the data, duration of illness above 3 days and age above 10 years-old are mostly indicative of arboviral disease while body temperature higher than 40{\\\\textdegree}c and presence of nausea or vomiting symptoms during the rainy season are mostly indicative of malaria disease.',\n",
       " 134: 'we address the classical problem of hierarchical clustering, but in a framework where one does not have access to a representation of the objects or their pairwise similarities. instead, we assume that only a set of comparisons between objects is available, that is, statements of the form \"objects $i$ and $j$ are more similar than objects $k$ and $l$.\" such a scenario is commonly encountered in crowdsourcing applications. the focus of this work is to develop comparison-based hierarchical clustering algorithms that do not rely on the principles of ordinal embedding. we show that single and complete linkage are inherently comparison-based and we develop variants of average linkage. we provide statistical guarantees for the different methods under a planted hierarchical partition model. we also empirically demonstrate the performance of the proposed approaches on several datasets.',\n",
       " 135: 'the pairwise maximum entropy model, also known as the ising model, has been widely used to analyze the collective activity of neurons. however, controversy persists in the literature about seemingly inconsistent findings, whose significance is unclear due to lack of reliable error estimates. we therefore develop a method for accurately estimating parameter uncertainty based on random walks in parameter space using adaptive markov chain monte carlo after the convergence of the main optimization algorithm. we apply our method to the spiking patterns of excitatory and inhibitory neurons recorded with multielectrode arrays in the human temporal cortex during the wake-sleep cycle. our analysis shows that the ising model captures neuronal collective behavior much better than the independent model during wakefulness, light sleep, and deep sleep when both excitatory (e) and inhibitory (i) neurons are modeled; ignoring the inhibitory effects of i-neurons dramatically overestimates synchrony among e-neurons. furthermore, information-theoretic measures reveal that the ising model explains about 80%-95% of the correlations, depending on sleep state and neuron type. thermodynamic measures show signatures of criticality, although we take this with a grain of salt as it may be merely a reflection of long-range neural correlations.',\n",
       " 136: 'financial time-series forecasting has long been a challenging problem because of the inherently noisy and stochastic nature of the market. in the high-frequency trading (hft), forecasting for trading purposes is even a more challenging task since an automated inference system is required to be both accurate and fast. in this paper, we propose a neural network layer architecture that incorporates the idea of bilinear projection as well as an attention mechanism that enables the layer to detect and focus on crucial temporal information. the resulting network is highly interpretable, given its ability to highlight the importance and contribution of each temporal instance, thus allowing further analysis on the time instances of interest. our experiments in a large-scale limit order book (lob) dataset show that a two-hidden-layer network utilizing our proposed layer outperforms by a large margin all existing state-of-the-art results coming from much deeper architectures while requiring far fewer computations.',\n",
       " 137: 'this numeric evaluation of string metric accuracy is based on the following idea: taking the paragraph of text in one language sort all paragraphs of the document in other language by similarity with given paragraph string and consider place of the right translation as the value of the evaluation score. such a search of proper translation provides an objective and reproducible quality assessment for known similarity metrics and shows the most accurate ones.',\n",
       " 138: 'when we physically interact with our environment using our hands, we touch objects and force them to move: contact and motion are defining properties of manipulation. in this paper, we present an active, bottom-up method for the detection of actor-object contacts and the extraction of moved objects and their motions in rgbd videos of manipulation actions. at the core of our approach lies non-rigid registration: we continuously warp a point cloud model of the observed scene to the current video frame, generating a set of dense 3d point trajectories. under loose assumptions, we employ simple point cloud segmentation techniques to extract the actor and subsequently detect actor-environment contacts based on the estimated trajectories. for each such interaction, using the detected contact as an attention mechanism, we obtain an initial motion segment for the manipulated object by clustering trajectories in the contact area vicinity and then we jointly refine the object segment and estimate its 6dof pose in all observed frames. because of its generality and the fundamental, yet highly informative, nature of its outputs, our approach is applicable to a wide range of perception and planning tasks. we qualitatively evaluate our method on a number of input sequences and present a comprehensive robot imitation learning example, in which we demonstrate the crucial role of our outputs in developing action representations/plans from observation.',\n",
       " 139: 'in this article, we present an innovative method to find particular solutions of the non-homogeneous cauchy-euler equations in several variables and sturm-liouville equations. the method is basically built on the application of the ponderation ring which introduced by assal and zeyada [2].',\n",
       " 140: \"we introduce higher-order variants of the frobenius-seshadri constant due to musta\\\\c{t}\\\\u{a} and schwede, which are defined for ample line bundles in positive characteristic. these constants are used to show that demailly's criterion for separation of higher-order jets by adjoint bundles also holds in positive characteristic. as an application, we give a characterization of projective space using seshadri constants in positive characteristic, which was proved in characteristic zero by bauer and szemberg. we also discuss connections with other characterizations of projective space.\",\n",
       " 141: 'we study the complexity of approximating complex zero sets of certain $n$-variate exponential sums. we show that the real part, $r$, of such a zero set can be approximated by the $(n-1)$-dimensional skeleton, $t$, of a polyhedral subdivision of $\\\\mathbb{r}^n$. in particular, we give an explicit upper bound on the hausdorff distance: $\\\\delta(r,t) =o\\\\left(t^{3.5}/\\\\delta\\\\right)$, where $t$ and $\\\\delta$ are respectively the number of terms and the minimal spacing of the frequencies of $g$. on the side of computational complexity, we show that even the $n=2$ case of the membership problem for $r$ is undecidable in the blum-shub-smale model over $\\\\mathbb{r}$, whereas membership and distance queries for our polyhedral approximation $t$ can be decided in polynomial-time for any fixed $n$.',\n",
       " 142: \"this paper addresses the following questions pertaining to the intrinsic dimensionality of any given image representation: (i) estimate its intrinsic dimensionality, (ii) develop a deep neural network based non-linear mapping, dubbed deepmds, that transforms the ambient representation to the minimal intrinsic space, and (iii) validate the veracity of the mapping through image matching in the intrinsic space. experiments on benchmark image datasets (lfw, ijb-c and imagenet-100) reveal that the intrinsic dimensionality of deep neural network representations is significantly lower than the dimensionality of the ambient features. for instance, sphereface's 512-dim face representation and resnet's 512-dim image representation have an intrinsic dimensionality of 16 and 19 respectively. further, the deepmds mapping is able to obtain a representation of significantly lower dimensionality while maintaining discriminative ability to a large extent, 59.75% tar @ 0.1% far in 16-dim vs 71.26% tar in 512-dim on ijb-c and a top-1 accuracy of 77.0% at 19-dim vs 83.4% at 512-dim on imagenet-100.\",\n",
       " 143: 'constitutive relations describe how materials respond to external stimuli such as forces. all materials respond heterogeneously at small scales, which limits what a localized sensor can discern about the global constitution of a material. in this paper, we quantify the limits of such constitutional sensing by determining the optimal measurement protocols for sensors embedded in disordered media. for an elastic medium, we find that the least fractional uncertainty with which a sensor can determine a material constant $\\\\lambda_0$ is approximately   \\\\begin{equation*}   \\\\frac{\\\\delta \\\\lambda_0}{\\\\lambda_0 } \\\\sim \\\\left( \\\\frac{\\\\delta_{\\\\lambda} }{ \\\\lambda_0^2} \\\\right)^{1/2} \\\\left( \\\\frac{ d }{ a } \\\\right)^{d/2} \\\\left( \\\\frac{ \\\\xi }{ a } \\\\right)^{d/2} \\\\end{equation*} for $a \\\\gg d \\\\gg \\\\xi$, $\\\\lambda_0 \\\\gg \\\\delta_{\\\\lambda}^{1/2}$, and $d>1$, where $a$ is the size of the sensor, $d$ is its spatial resolution, $\\\\xi$ is the correlation length of fluctuations in the material constant, $\\\\delta_{\\\\lambda}$ is the local variability of the material constant, and $d$ is the dimension of the medium. our results reveal how one can construct microscopic devices capable of sensing near these physical limits, e.g. for medical diagnostics. we show how our theoretical framework can be applied to an experimental system by estimating a bound on the precision of cellular mechanosensing in a biopolymer network.',\n",
       " 144: 'in this paper we present a simple, stochastic-geometric model of a wireless access network exploiting the lora (long range) protocol, which is a non-expensive technology allowing for long-range, single-hop connectivity for the internet of things. we assume a space-time poisson model of packets transmitted by lora nodes to a fixed base station. following previous studies of the impact of interference, we assume that a given packet is successfully received when no interfering packet arrives with similar power before the given packet payload phase. this is as a consequence of lora using different transmission rates for different link budgets (transmissions with smaller received powers use larger spreading factors) and lora intra-technology interference treatment. using our model, we study the scaling of the packet reception probabilities per link budget as a function of the spatial density of nodes and their rate of transmissions. we consider both the parameter values recommended by the lora provider, as well as proposing lora tuning to improve the equality of performance for all link budgets. we also consider spatially non-homogeneous distributions of lora nodes. we show also how a fair comparison to non-slotted aloha can be made within the same framework.',\n",
       " 145: \"this paper describes a new mechanism that might help with defining pattern sequences, by the fact that it can produce an upper bound on the ensemble value that can persistently oscillate with the actual values produced from each pattern. with every firing event, a node also receives an on/off feedback switch. if the node fires, then it sends a feedback result depending on the input signal strength. if the input signal is positive or larger, it can store an 'on' switch feedback for the next iteration. if the signal is negative or smaller, it can store an 'off' switch feedback for the next iteration. if the node does not fire, then it does not affect the current feedback situation and receives the switch command produced by the last active pattern event for the same neuron. the upper bound therefore also represents the largest or most enclosing pattern set and the lower value is for the actual set of firing patterns. if the pattern sequence repeats, it will oscillate between the two values, allowing them to be recognised and measured more easily, over time. tests show that changing the sequence ordering produces different value sets, which can also be measured.\",\n",
       " 146: 'in this paper we consider the development of algorithms for the automatic detection of buried threats using ground penetrating radar (gpr) measurements. gpr is one of the most studied and successful modalities for automatic buried threat detection (btd), and a large variety of btd algorithms have been proposed for it. despite this, large-scale comparisons of gpr-based btd algorithms are rare in the literature. in this work we report the results of a multi-institutional effort to develop advanced buried threat detection algorithms for a real-world gpr btd system. the effort involved five institutions with substantial experience with the development of gpr-based btd algorithms. in this paper we report the technical details of the advanced algorithms submitted by each institution, representing their latest technical advances, and many state-of-the-art gpr-based btd algorithms. we also report the results of evaluating the algorithms from each institution on the large experimental dataset used for development. the experimental dataset comprised 120,000 m^2 of gpr data using surface area, from 13 different lanes across two us test sites. the data was collected using a vehicle-mounted gpr system, the variants of which have supplied data for numerous publications. using these results, we identify the most successful and common processing strategies among the submitted algorithms, and make recommendations for gpr-based btd algorithm design.',\n",
       " 147: 'we consider finite groups acting on quantum (or skew) polynomial rings. deformations of the semidirect product of the quantum polynomial ring with the acting group extend symplectic reflection algebras and graded hecke algebras to the quantum setting over a field of arbitrary characteristic. we give necessary and sufficient conditions for such algebras to satisfy a poincare-birkhoff-witt property using the theory of noncommutative groebner bases. we include applications to the case of abelian groups and the case of groups acting on coordinate rings of quantum planes. in addition, we classify graded automorphisms of the coordinate ring of quantum 3-space. in characteristic zero, hochschild cohomology gives an elegant description of the poincare-birkhoff-witt conditions.',\n",
       " 148: 'we propose a hardware and software pipeline to fabricate flexible wearable sensors and use them to capture deformations without line of sight. our first contribution is a low-cost fabrication pipeline to embed multiple aligned conductive layers with complex geometries into silicone compounds. overlapping conductive areas from separate layers form local capacitors that measure dense area changes. contrary to existing fabrication methods, the proposed technique only requires hardware that is readily available in modern fablabs. while area measurements alone are not enough to reconstruct the full 3d deformation of a surface, they become sufficient when paired with a data-driven prior. a novel semi-automatic tracking algorithm, based on an elastic surface geometry deformation, allows to capture ground-truth data with an optical mocap system, even under heavy occlusions or partially unobservable markers. the resulting dataset is used to train a regressor based on deep neural networks, directly mapping the area readings to global positions of surface vertices. we demonstrate the flexibility and accuracy of the proposed hardware and software in a series of controlled experiments, and design a prototype of wearable wrist, elbow and biceps sensors, which do not require line-of-sight and can be worn below regular clothing.',\n",
       " 149: \"deep neural networks (dnns) have been demonstrated to be vulnerable to adversarial examples. specifically, adding imperceptible perturbations to clean images can fool the well trained deep neural networks. in this paper, we propose an end-to-end image compression model to defend adversarial examples: \\\\textbf{comdefend}. the proposed model consists of a compression convolutional neural network (comcnn) and a reconstruction convolutional neural network (rescnn). the comcnn is used to maintain the structure information of the original image and purify adversarial perturbations. and the rescnn is used to reconstruct the original image with high quality. in other words, comdefend can transform the adversarial image to its clean version, which is then fed to the trained classifier. our method is a pre-processing module, and does not modify the classifier's structure during the whole process. therefore, it can be combined with other model-specific defense models to jointly improve the classifier's robustness. a series of experiments conducted on mnist, cifar10 and imagenet show that the proposed method outperforms the state-of-the-art defense methods, and is consistently effective to protect classifiers against adversarial attacks.\",\n",
       " 150: 'data collected by the h.e.s.s. array between 2004 and 2012 have been used to search for photon bursts from primordial black hole explosions. bursts were searched for in a 30 second time-window. the duration of the search window has been optimized to increase the burst signal while keeping the statistical background low. no evidence for a burst signal was found. preliminary upper limits on the local rate of pbh explosions of $1.4\\\\times 10^{4} {pc}^{-3} {yr}^{-1}$ have been obtained, which improve previously published limits by almost an order of magnitude',\n",
       " 151: 'this paper gives a self-contained group-theoretic proof of a dual version of a theorem of ore on distributive intervals of finite groups. we deduce a bridge between combinatorics and representations in finite group theory.',\n",
       " 152: \"we show that the maximum likelihood degree of a smooth very affine variety is equal to the signed topological euler characteristic. this generalizes orlik and terao's solution to varchenko's conjecture on complements of hyperplane arrangements to smooth very affine varieties. for very affine varieties satisfying a genericity condition at infinity, the result is further strengthened to relate the variety of critical points to the chern-schwartz-macpherson class. the strengthened version recovers the geometric deletion-restriction formula of denham et al. for arrangement complements, and generalizes kouchnirenko's theorem on the newton polytope for nondegenerate hypersurfaces.\",\n",
       " 153: \"the construction of biologically plausible models of neural circuits is crucial for understanding the computational properties of the nervous system. constructing functional networks composed of separate excitatory and inhibitory neurons obeying dale's law presents a number of challenges. we show how a target-based approach, when combined with a fast online constrained optimization technique, is capable of building functional models of rate and spiking recurrent neural networks in which excitation and inhibition are balanced. balanced networks can be trained to produce complicated temporal patterns and to solve input-output tasks while retaining biologically desirable features such as dale's law and response variability.\",\n",
       " 154: 'over the past few years, neural networks were proven vulnerable to adversarial images: targeted but imperceptible image perturbations lead to drastically different predictions. we show that adversarial vulnerability increases with the gradients of the training objective when viewed as a function of the inputs. surprisingly, vulnerability does not depend on network topology: for many standard network architectures, we prove that at initialization, the $\\\\ell_1$-norm of these gradients grows as the square root of the input dimension, leaving the networks increasingly vulnerable with growing image size. we empirically show that this dimension dependence persists after either usual or robust training, but gets attenuated with higher regularization.',\n",
       " 155: \"we study a critical behavior for the eigenvalue statistics in the two-matrix model in the quartic/quadratic case. for certain parameters, the eigenvalue distribution for one of the matrices has a limit that vanishes with an exponent 1/2 in the interior of the support. the main result of the paper is a new kernel that describes the local eigenvalue correlations near that critical point. the kernel is expressed in terms of a 4 x 4 riemann-hilbert problem related to the hastings-mcleod solution of the painlev\\\\'e ii equation. we then compare the new kernel with two other critical phenomena that appeared in the literature before. first, we show that the critical kernel that appears in case of quadratic vanishing of the limiting eigenvalue distribution can be retrieved from the new kernel by means of a double scaling limit. second, we briefly discuss the relation with the tacnode singularity in non-colliding brownian motions that was recently analyzed. although the limiting density in that model also vanishes with an exponent 1/2 at a certain interior point, the process at the local scale is different from the process that we obtain in the two-matrix model.\",\n",
       " 156: 'probabilistic inversion within a multiple-point statistics framework is often computationally prohibitive for high-dimensional problems. to partly address this, we introduce and evaluate a new training-image based inversion approach for complex geologic media. our approach relies on a deep neural network of the generative adversarial network (gan) type. after training using a training image (ti), our proposed spatial gan (sgan) can quickly generate 2d and 3d unconditional realizations. a key characteristic of our sgan is that it defines a (very) low-dimensional parameterization, thereby allowing for efficient probabilistic inversion using state-of-the-art markov chain monte carlo (mcmc) methods. in addition, available direct conditioning data can be incorporated within the inversion. several 2d and 3d categorical tis are first used to analyze the performance of our sgan for unconditional geostatistical simulation. training our deep network can take several hours. after training, realizations containing a few millions of pixels/voxels can be produced in a matter of seconds. this makes it especially useful for simulating many thousands of realizations (e.g., for mcmc inversion) as the relative cost of the training per realization diminishes with the considered number of realizations. synthetic inversion case studies involving 2d steady-state flow and 3d transient hydraulic tomography with and without direct conditioning data are used to illustrate the effectiveness of our proposed sgan-based inversion. for the 2d case, the inversion rapidly explores the posterior model distribution. for the 3d case, the inversion recovers model realizations that fit the data close to the target level and visually resemble the true model well.',\n",
       " 157: 'in this paper we introduce the \\\\emph{semi-online} model that generalizes the classical online computational model. the semi-online model postulates that the unknown future has a predictable part and an adversarial part; these parts can be arbitrarily interleaved. an algorithm in this model operates as in the standard online model, i.e., makes an irrevocable decision at each step.   we consider bipartite matching in the semi-online model, for both integral and fractional cases. our main contributions are competitive algorithms for this problem that are close to or match a hardness bound. the competitive ratio of the algorithms nicely interpolates between the truly offline setting (no adversarial part) and the truly online setting (no predictable part).',\n",
       " 158: 'we show the kontsevich space of rational curves of degree at most roughly $\\\\frac{2-\\\\sqrt{2}}{2}n$ on a general hypersurface $x\\\\subset \\\\mathbb{p}^n$ of degree $n-1$ is equidimensional of expected dimension and has two components: one consisting generically of smooth, embedded rational curves and the other consisting of multiple covers of a line. this proves more cases of a conjecture of coskun, harris, and starr and shows the gromov-witten invariants in these cases are enumerative.',\n",
       " 159: \"almost 35 years since their suggestion as a good solution to the strong cp-problem, axions remain one of the few viable candidates for the dark matter, although still eluding detection. most of the methods for their detection are based on their coupling to photons, one of the most sensitive ones being the helioscope technique. we report on the current status of the cern axion solar telescope and the future international axion observatory (iaxo). recent results from the second part of cast phase ii, where the magnet bores were filled with 3he gas at variable pressure achieving sensibilities on the axion mass up to 1.2 ev, are presented. currently, cast is expecting to improve its sensitivity to solar axions with rest mass below 0.02 ev/c^2 after the upgrade of the x-ray detectors and with the implementation of a second x-ray optic. at the same time, it is exploring other possibilities at the low energy physics frontier. on the other hand iaxo, the fourth generation axion helioscope, aims to improve cast's performance in terms of axion-photon coupling by 1-1.5 orders of magnitude. the details of the project building a dedicated magnet, optics and x-ray detectors are given.\",\n",
       " 160: 'it is an open question whether the fractional parts of nonlinear polynomials at integers have the same fine-scale statistics as a poisson point process. most results towards an affirmative answer have so far been restricted to almost sure convergence in the space of polynomials of a given degree. we will here provide explicit diophantine conditions on the coefficients of polynomials of degree 2, under which the convergence of an averaged pair correlation density can be established. the limit is consistent with the poisson distribution. since quadratic polynomials at integers represent the energy levels of a class of integrable quantum systems, our findings provide further evidence for the berry-tabor conjecture in the theory of quantum chaos.',\n",
       " 161: 'we count the number of vertices in plane trees and $k$-ary trees with given outdegree, and prove that the total number of vertices of outdegree $i$ over all plane trees with $n$ edges is ${2n-i-1 \\\\choose n-1}$, and the total number of vertices of outdegree $i$ over all $k$-ary trees with $n$ edges is ${k\\\\choose i}{kn\\\\choose n-i}$. for both results we give bijective proofs as well as generating function proofs.',\n",
       " 162: \"the main challenge for adaptive regulation of linear-quadratic systems is the trade-off between identification and control. an adaptive policy needs to address both the estimation of unknown dynamics parameters (exploration), as well as the regulation of the underlying system (exploitation). to this end, optimism-based methods which bias the identification in favor of optimistic approximations of the true parameter are employed in the literature. a number of asymptotic results have been established, but their finite time counterparts are few, with important restrictions.   this study establishes results for the worst-case regret of optimism-based adaptive policies. the presented high probability upper bounds are optimal up to logarithmic factors. the non-asymptotic analysis of this work requires very mild assumptions; (i) stabilizability of the system's dynamics, and (ii) limiting the degree of heaviness of the noise distribution. to establish such bounds, certain novel techniques are developed to comprehensively address the probabilistic behavior of dependent random matrices with heavy-tailed distributions.\",\n",
       " 163: 'the magic two 17 meter diameter very high energy (vhe) gamma-ray telescopes have now operated for two years in stereoscopic mode. the performance of the instrument has been evaluated: the integral sensitivity for an energy above 300 gev is 0.76% crab units (10% crab units differential sensitivity below 100 gev) and the analysis threshold energy is 50 gev. highlights of the last two years of observations are the measurement of the crab nebula spectrum from ~50 gev to ~50 tev; the detection of the crab pulsar up to an energy of 400 gev, with energy spectra measured for both p1 and p2; the discovery of two new radiogalaxies at vhe (ngc 1275 and ic-310); the absence of an energy cutoff and the discovery of fast variability in the quasars 3c 279 and pks 1222+21; the discovery at vhe and the characterization of numerous blazars; upper limits to the vhe emission of the perseus cluster of galaxies and to dark matter annihilation in dwarf spheroidals and the measurement of the electron+positron spectrum between 100 gev and 3 tev. magic is currently undergoing a major upgrade of the readout and trigger electronics, and of the camera of the first telescope.',\n",
       " 164: 'the local zero structure of a smooth map may qualitatively change, when the map is subjected to small perturbations. the changes may include births and/or deaths of zeros. the qualitative properties are defined as the invariances of an appropriate equivalence relation. the occurrence of a qualitative change in the zero structures is called a bifurcation and the map is named a singularity. the local bifurcation analysis of singularities has been extensively studied in singularity theory and many powerful algebraic tools have been developed for their study. however, there does not exist any symbolic computer-library for this purpose. we suitably generalize some powerful tools from algebraic geometry for correct implementation of the results from singularity theory. we provide some required criteria along with rigorous proofs for efficient and cognitive computer-implementation. we have accordingly developed a maple end-user friendly library, named singularity, for an efficient and complete local bifurcation analysis of real zeros of scalar smooth maps. we have further written a comprehensive user-guide for singularity. the main features of singularity are briefly illustrated along with a few examples.',\n",
       " 165: 'grb 111209a, one of the longest gamma-ray bursts (grbs) ever observed, is linked to sn 2011kl, the most luminous grb-supernova (sn) detected so far, which shows evidence for being powered by a magnetar central engine. we place sn 2011kl into the context of large samples of sne, addressing in more detail the question of whether it could be radioactively powered, and whether it represents an extreme version of a grb-sn or an underluminous superluminous sn (slsn). we model sn 2011kl using sn 1998bw as a template and derive a bolometric light curve including near-infrared data. we compare the properties of sn 2011kl to literature results on stripped-envelope and superluminous supernovae. comparison in the k,s context, i.e., comparing it to sn 1998bw templates in terms of luminosity and light-curve stretch, clearly shows sn 2011kl is the most luminous grb-sn to date, and it is spectrally very dissimilar to other events, being significantly bluer/hotter. although sn 2011kl does not reach the classical luminosity threshold of slsne and evolves faster than any of them, it resembles slsne more than the classical grb-associated broad-lined type ic sne in several aspects. grb 111209a was a very energetic event, both at early (prompt emission) and at very late (sn) times. we have shown in a further publication that with the exception of the extreme duration, the grb and afterglow parameters are in agreement with the known distributions for these parameters. sn 2011kl, on the other hand, is exceptional both in luminosity and spectral characteristics, indicating that grb 111209a was likely not powered by a standard-model collapsar central engine, further supporting our earlier conclusions. instead, it reveals the possibility of a direct link between grbs and slsne.',\n",
       " 166: 'this paper presents a widely applicable approach to solving (multi-marginal, martingale) optimal transport and related problems via neural networks. the core idea is to penalize the optimization problem in its dual formulation and reduce it to a finite dimensional one which corresponds to optimizing a neural network with smooth objective function. we present numerical examples from optimal transport, martingale optimal transport, portfolio optimization under uncertainty and generative adversarial networks that showcase the generality and effectiveness of the approach.',\n",
       " 167: 'generative adversarial networks (gans) have shown remarkable success in generation of unstructured data, such as, natural images. however, discovery and separation of modes in the generated space, essential for several tasks beyond naive data generation, is still a challenge. in this paper, we address the problem of imposing desired modal properties on the generated space using a latent distribution, engineered in accordance with the modal properties of the true data distribution. this is achieved by training a latent space inversion network in tandem with the generative network using a divergence loss. the latent space is made to follow a continuous multimodal distribution generated by reparameterization of a pair of continuous and discrete random variables. in addition, the modal priors of the latent distribution are learned to match with the true data distribution using minimal-supervision with negligible increment in number of learnable parameters. we validate our method on multiple tasks such as mode separation, conditional generation, and attribute discovery on multiple real world image datasets and demonstrate its efficacy over other state-of-the-art methods.',\n",
       " 168: 'multiparametric families of hypergeometric $\\\\tau$-functions of kp or toda type serve as generating functions for weighted hurwitz numbers, providing weighted enumerations of branched covers of the riemann sphere. a graphical interpretation of the weighting is given in terms of constellations mapped onto the covering surface. the theory is placed within the framework of topological recursion, with the baker function at ${\\\\bf t} ={\\\\bf 0}$ shown to satisfy the quantum spectral curve equation, whose classical limit is rational. a basis for the space of formal power series in the spectral variable is generated that is adapted to the grassmannian element associated to the $\\\\tau$-function. multicurrent correlators are defined in terms of the $\\\\tau$-function and shown to provide an alternative generating function for weighted hurwitz numbers. fermionic vev representations are provided for the adapted bases, pair correlators and multicurrent correlators. choosing the weight generating function as a polynomial, and restricting the number of nonzero \"second\" kp flow parameters in the toda $\\\\tau$-function to be finite implies a finite rank covariant derivative equation with rational coefficients satisfied by a finite \"window\" of adapted basis elements. the pair correlator is shown to provide a christoffel-darboux type finite rank integrable kernel, and the wkb series coefficients of the associated adjoint system are computed recursively, leading to topological recursion relations for the generators of the weighted hurwitz numbers.',\n",
       " 169: 'we extend the definition of bockstein basis $\\\\sigma(g)$ to nilpotent groups $g$. a metrizable space $x$ is called a {\\\\it bockstein space} if $\\\\dim_g(x) = \\\\sup\\\\{\\\\dim_h(x) | h\\\\in \\\\sigma(g)\\\\}$ for all abelian groups $g$. bockstein first theorem says that all compact spaces are bockstein spaces.   here are the main results of the paper: let $x$ be a bockstein space. if $g$ is nilpotent, then $\\\\dim_g(x) \\\\leq 1$ if and only if $\\\\sup\\\\{\\\\dim_h(x) | h\\\\in\\\\sigma(g)\\\\}\\\\leq 1$.   $x$ is a bockstein space if and only if $\\\\dim_{\\\\z_{(l)}} (x) = \\\\dim_{\\\\hat{z}_{(l)}}(x)$ for all subsets $l$ of prime numbers.',\n",
       " 170: 'we present the science enabled by cross-correlations of the ska1-low 21-cm eor surveys with other line mapping programs. in particular, we identify and investigate potential synergies with planned programs, such as the line intensity mapping of redshifted co rotational lines, [cii] and ly-$\\\\alpha$ emissions during reionization. we briefly describe how these tracers of the star-formation rate at $z \\\\sim 8$ can be modeled jointly before forecasting their auto- and cross-power spectra measurements with the nominal 21cm eor survey. the use of multiple line tracers would be invaluable to validate and enrich our understanding of the eor.',\n",
       " 171: 'let the circle act symplectically on a compact, connected symplectic manifold $m$. if there are exactly three fixed points, $m$ is equivariantly symplectomorphic to $\\\\mathbb{cp}^2$.',\n",
       " 172: 'the main themes of this survey are as follows: (a) the canonical (riesz--nevanlinna) factorization in various classes of analytic functions on the disk that are smooth up to its boundary, and (b) model subspaces (i.e., invariant subspaces of the backward shift) in the hardy spaces $h^p$ and in bmoa. it is the interrelationship and a peculiar cross-fertilization between the two topics that we wish to highlight.',\n",
       " 173: \"the resampling algorithm of moser \\\\& tardos is a powerful approach to develop constructive versions of the lov\\\\'{a}sz local lemma (lll). we generalize this to partial resampling: when a bad event holds, we resample an appropriately-random subset of the variables that define this event, rather than the entire set as in moser & tardos. this is particularly useful when the bad events are determined by sums of random variables. this leads to several improved algorithmic applications in scheduling, graph transversals, packet routing etc. for instance, we settle a conjecture of szab\\\\'{o} & tardos (2006) on graph transversals asymptotically, and obtain improved approximation ratios for a packet routing problem of leighton, maggs, & rao (1994).\",\n",
       " 174: \"we prove $l^{p_1}(\\\\mathbb r^d)\\\\times \\\\dots \\\\times l^{p_{n+2}}(\\\\mathbb r^{d})$ polynomial growth estimates for the christ-journ\\\\'e multilinear singular integral forms and suitable generalizations.\",\n",
       " 175: 'we functorially associate to each relative $\\\\infty$-category $(r,w)$ a simplicial space $n^r_\\\\infty(r,w)$, called its rezk nerve (a straightforward generalization of rezk\\'s \"classification diagram\" construction for relative categories). we prove the following local and global universal properties of this construction: (i) that the complete segal space generated by the rezk nerve $n^r_\\\\infty(r,w)$ is precisely the one corresponding to the localization $r[[w^{-1}]]$; and (ii) that the rezk nerve functor defines an equivalence $relcat_\\\\infty [[ w_{bk}^{-1} ]] \\\\xrightarrow{\\\\sim} cat_\\\\infty$ from a localization of the $\\\\infty$-category of relative $\\\\infty$-categories to the $\\\\infty$-category of $\\\\infty$-categories.',\n",
       " 176: 'identifying coordinate transformations that make strongly nonlinear dynamics approximately linear is a central challenge in modern dynamical systems. these transformations have the potential to enable prediction, estimation, and control of nonlinear systems using standard linear theory. the koopman operator has emerged as a leading data-driven embedding, as eigenfunctions of this operator provide intrinsic coordinates that globally linearize the dynamics. however, identifying and representing these eigenfunctions has proven to be mathematically and computationally challenging. this work leverages the power of deep learning to discover representations of koopman eigenfunctions from trajectory data of dynamical systems. our network is parsimonious and interpretable by construction, embedding the dynamics on a low-dimensional manifold that is of the intrinsic rank of the dynamics and parameterized by the koopman eigenfunctions. in particular, we identify nonlinear coordinates on which the dynamics are globally linear using a modified auto-encoder. we also generalize koopman representations to include a ubiquitous class of systems that exhibit continuous spectra, ranging from the simple pendulum to nonlinear optics and broadband turbulence. our framework parametrizes the continuous frequency using an auxiliary network, enabling a compact and efficient embedding at the intrinsic rank, while connecting our models to half a century of asymptotics. in this way, we benefit from the power and generality of deep learning, while retaining the physical interpretability of koopman embeddings.',\n",
       " 177: 'in this paper we find tight sufficient conditions for the continuity of the value of the utility maximization problem from terminal wealth with respect to the convergence in distribution of the underlying processes. we also establish a weak convergence result for the terminal wealths of the optimal portfolios. finally, we apply our results to the computation of the minimal expected shortfall (shortfall risk) in the heston model by building an appropriate lattice approximation.',\n",
       " 178: 'nonlinear ica is a fundamental problem for unsupervised representation learning, emphasizing the capacity to recover the underlying latent variables generating the data (i.e., identifiability). recently, the very first identifiability proofs for nonlinear ica have been proposed, leveraging the temporal structure of the independent components. here, we propose a general framework for nonlinear ica, which, as a special case, can make use of temporal structure. it is based on augmenting the data by an auxiliary variable, such as the time index, the history of the time series, or any other available information. we propose to learn nonlinear ica by discriminating between true augmented data, or data in which the auxiliary variable has been randomized. this enables the framework to be implemented algorithmically through logistic regression, possibly in a neural network. we provide a comprehensive proof of the identifiability of the model as well as the consistency of our estimation method. the approach not only provides a general theoretical framework combining and generalizing previously proposed nonlinear ica models and algorithms, but also brings practical advantages.',\n",
       " 179: \"we consider the problem of generating automatic code given sample input-output pairs. we train a neural network to map from the current state and the outputs to the program's next statement. the neural network optimizes multiple tasks concurrently: the next operation out of a set of high level commands, the operands of the next statement, and which variables can be dropped from memory. using our method we are able to create programs that are more than twice as long as existing state-of-the-art solutions, while improving the success rate for comparable lengths, and cutting the run-time by two orders of magnitude. our code, including an implementation of various literature baselines, is publicly available at https://github.com/amitz25/pccoder\",\n",
       " 180: 'we consider the inverse problem of determining the density coefficient appearing in the wave equation from separated point source and point receiver data. under some assumptions on the coefficients, we prove uniqueness results.',\n",
       " 181: 'we introduce and investigate an sis-type model for the spread of an infectious disease, where the infected population is structured with respect to the different strain of the virus/bacteria they are carrying. our aim is to capture the interesting scenario when individuals infected with different strains cause secondary (new) infections at different rates. therefore, we consider a nonlinear infection process, which generalises the bilinear process arising from the classic mass-action assumption. our main motivation is to study competition between different strains of a virus/bacteria. from the mathematical point of view, we are interested whether the nonlinear infection process leads to a well-posed model. we use a semilinear formulation to show global existence and positivity of solutions up to a critical value of the exponent in the nonlinearity. furthermore, we establish the existence of the endemic steady state for particular classes of nonlinearities.',\n",
       " 182: \"starcraft ii poses a grand challenge for reinforcement learning. the main difficulties of it include huge state and action space and a long-time horizon. in this paper, we investigate a hierarchical reinforcement learning approach for starcraft ii. the hierarchy involves two levels of abstraction. one is the macro-action automatically extracted from expert's trajectories, which reduces the action space in an order of magnitude yet remains effective. the other is a two-layer hierarchical architecture which is modular and easy to scale, enabling a curriculum transferring from simpler tasks to more complex tasks. the reinforcement training algorithm for this architecture is also investigated. on a 64x64 map and using restrictive units, we achieve a winning rate of more than 99\\\\% against the difficulty level-1 built-in ai. through the curriculum transfer learning algorithm and a mixture of combat model, we can achieve over 93\\\\% winning rate of protoss against the most difficult non-cheating built-in ai (level-7) of terran, training within two days using a single machine with only 48 cpu cores and 8 k40 gpus. it also shows strong generalization performance, when tested against never seen opponents including cheating levels built-in ai and all levels of zerg and protoss built-in ai. we hope this study could shed some light on the future research of large-scale reinforcement learning.\",\n",
       " 183: 'we consider the problem of existence of constant scalar curvature kaehler metrics on complete intersections of sections of vector bundles. in particular we give general formulas relating the futaki invariant of such a manifold to the weight of sections defining it and to the futaki invariant of the ambient manifold. as applications we give a new mukai-umemura-tian like example of fano 5-fold admitting no kaehler-einstein metric and a strong evidence of k-stability of complete intersections on grassmannians.',\n",
       " 184: 'we compute the rational stable homology of the automorphism groups of free nilpotent groups. these groups interpolate between the general linear groups over the ring of integers and the automorphism groups of free groups, and we employ functor homology to reduce to the abelian case. as an application, we also compute the rational stable homology of the outer automorphism groups and of the mapping class groups of the associated aspherical nil-manifolds in the top, pl, and diff categories.',\n",
       " 185: \"in this paper, we give a proof of gersten's conjecture for any commutative regular local ring.\",\n",
       " 186: \"we propose a planning and control approach to physics-based manipulation. the key feature of the algorithm is that it can adapt to the accuracy requirements of a task, by slowing down and generating `careful' motion when the task requires high accuracy, and by speeding up and moving fast when the task tolerates inaccuracy. we formulate the problem as an mdp with action-dependent stochasticity and propose an approximate online solution to it. we use a trajectory optimizer with a deterministic model to suggest promising actions to the mdp, to reduce computation time spent on evaluating different actions. we conducted experiments in simulation and on a real robotic system. our results show that with a task-adaptive planning and control approach, a robot can choose fast or slow actions depending on the task accuracy and uncertainty level. the robot makes these decisions online and is able to maintain high success rates while completing manipulation tasks as fast as possible.\",\n",
       " 187: \"extracting associations that recur across multiple studies while controlling the false discovery rate is a fundamental challenge. here, we consider an extension of efron's single-study two-groups model to allow joint analysis of multiple studies. we assume that given a set of p-values obtained from each study, the researcher is interested in associations that recur in at least $k>1$ studies. we propose new algorithms that differ in how the study dependencies are modeled. we compared our new methods and others using various simulated scenarios. the top performing algorithm, screen (scalable cluster-based replicability enhancement), is our new algorithm that is based on three stages: (1) clustering an estimated correlation network of the studies, (2) learning replicability (e.g., of genes) within clusters, and (3) merging the results across the clusters using dynamic programming. we applied screen to two real datasets and demonstrated that it greatly outperforms the results obtained via standard meta-analysis. first, on a collection of 29 case-control large-scale gene expression cancer studies, we detected a large up-regulated module of genes related to proliferation and cell cycle regulation. these genes are both consistently up-regulated across many cancer studies, and are well connected in known gene networks. second, on a recent pan-cancer study that examined the expression profiles of patients with or without mutations in the hla complex, we detected an active module of up-regulated genes that are related to immune responses. thanks to our ability to quantify the false discovery rate, we detected thrice more genes as compared to the original study. our module contains most of the genes reported in the original study, and many new ones. interestingly, the newly discovered genes are needed to establish the connectivity of the module.\",\n",
       " 188: 'this paper studies the concept of instantaneous arbitrage in continuous time and its relation to the instantaneous capm. absence of instantaneous arbitrage is equivalent to the existence of a trading strategy which satisfies the capm beta pricing relation in place of the market. thus the difference between the arbitrage argument and the capm argument in black and scholes (1973) is this: the arbitrage argument assumes that there exists some portfolio satisfying the capm equation, whereas the capm argument assumes, in addition, that this portfolio is the market portfolio.',\n",
       " 189: 'we study the complexity of approximations to the normalized information distance. we introduce a hierarchy of computable approximations by considering the number of oscillations. this is a function version of the difference hierarchy for sets. we show that the normalized information distance is not in any level of this hierarchy, strengthening previous nonapproximability results. as an ingredient to the proof, we also prove a conditional undecidability result about independence.',\n",
       " 190: 'we present brainnet which, to our knowledge, is the first multi-person non-invasive direct brain-to-brain interface for collaborative problem solving. the interface combines electroencephalography (eeg) to record brain signals and transcranial magnetic stimulation (tms) to deliver information noninvasively to the brain. the interface allows three human subjects to collaborate and solve a task using direct brain-to-brain communication. two of the three subjects are \"senders\" whose brain signals are decoded using real-time eeg data analysis to extract decisions about whether to rotate a block in a tetris-like game before it is dropped to fill a line. the senders\\' decisions are transmitted via the internet to the brain of a third subject, the \"receiver,\" who cannot see the game screen. the decisions are delivered to the receiver\\'s brain via magnetic stimulation of the occipital cortex. the receiver integrates the information received and makes a decision using an eeg interface about either turning the block or keeping it in the same position. a second round of the game gives the senders one more chance to validate and provide feedback to the receiver\\'s action. we evaluated the performance of brainnet in terms of (1) group-level performance during the game; (2) true/false positive rates of subjects\\' decisions; (3) mutual information between subjects. five groups of three subjects successfully used brainnet to perform the tetris task, with an average accuracy of 0.813. furthermore, by varying the information reliability of the senders by artificially injecting noise into one sender\\'s signal, we found that receivers are able to learn which sender is more reliable based solely on the information transmitted to their brains. our results raise the possibility of future brain-to-brain interfaces that enable cooperative problem solving by humans using a \"social network\" of connected brains.',\n",
       " 191: 'the contaminated gaussian distribution represents a simple heavy-tailed elliptical generalization of the gaussian distribution; unlike the often-considered t-distribution, it also allows for automatic detection of mild outlying or \"bad\" points in the same way that observations are typically assigned to the groups in the finite mixture model context. starting from this distribution, we propose the contaminated factor analysis model as a method for dimensionality reduction and detection of bad points in higher dimensions. a mixture of contaminated gaussian factor analyzers (mcgfa) model follows therefrom, and extends the recently proposed mixture of contaminated gaussian distributions to high-dimensional data. we introduce a family of 32 parsimonious models formed by introducing constraints on the covariance and contamination structures of the general mcgfa model. we outline a variant of the expectation-maximization algorithm for parameter estimation. various implementation issues are discussed, and the novel family of models is compared to well-established approaches on both simulated and real data.',\n",
       " 192: 'building models capable of generating structured output is a key challenge for ai and robotics. while generative models have been explored on many types of data, little work has been done on synthesizing lidar scans, which play a key role in robot mapping and localization. in this work, we show that one can adapt deep generative models for this task by unravelling lidar scans into a 2d point map. our approach can generate high quality samples, while simultaneously learning a meaningful latent representation of the data. we demonstrate significant improvements against state-of-the-art point cloud generation methods. furthermore, we propose a novel data representation that augments the 2d signal with absolute positional information. we show that this helps robustness to noisy and imputed input; the learned model can recover the underlying lidar scan from seemingly uninformative data',\n",
       " 193: 'we propose power slow feature analysis, a gradient-based method to extract temporally slow features from a high-dimensional input stream that varies on a faster time-scale, as a variant of slow feature analysis (sfa) that allows end-to-end training of arbitrary differentiable architectures and thereby significantly extends the class of models that can effectively be used for slow feature extraction. we provide experimental evidence that powersfa is able to extract meaningful and informative low-dimensional features in the case of (a) synthetic low-dimensional data, (b) ego-visual data, and also for (c) a general dataset for which symmetric non-temporal similarities between points can be defined.',\n",
       " 194: 'whole-cell computational models aim to predict cellular phenotypes from genotype by representing the entire genome, the structure and concentration of each molecular species, each molecular interaction, and the extracellular environment. whole-cell models have great potential to transform bioscience, bioengineering, and medicine. however, numerous challenges remain to achieve whole-cell models. nevertheless, researchers are beginning to leverage recent progress in measurement technology, bioinformatics, data sharing, rule-based modeling, and multi-algorithmic simulation to build the first whole-cell models. we anticipate that ongoing efforts to develop scalable whole-cell modeling tools will enable dramatically more comprehensive and more accurate models, including models of human cells.',\n",
       " 195: 'the concentration of the population in coastal regions, in addition to the direct human use, is leading to an accelerated process of change and deterioration of the marine ecosystems. human activities such as fishing together with environmental drivers (e.g. climate change) are triggering major threats to marine biodiversity, and impact directly the services they provide. in the south and southwest coasts of portugal, the deep-water crustacean trawl fishery is not exemption. this fishery is recognized to have large effects on a number of species while generating high rates of unwanted catches. however, taking into account an ecosystem-based perspective, the fishing impacts along the food web accounting for biological interactions between and among species caught remains poorly understood. these impacts are particularly troubling and are a cause of concern given the cascading effects that might arise. facing the main policies and legislative instruments for the restoration and conservation of the marine environment, times are calling for implementing ecosystem-based approaches to fisheries management. to this end, we use a food web modelling (ecopath with ecosim) approach to assess the fishing impacts of this particular fishery on the marine ecosystem of southern and southwestern portugal. in particular, we describe the food web structure and functioning, identify the main keystone species and/or groups, quantify the major trophic and energy flows, and ultimately assess the impact of fishing on the target species but also on the ecosystem by means of ecological and ecosystem-based indicators. finally, we examine limitations and weaknesses of the model for potential improvements and future research directions.',\n",
       " 196: 'uplift modeling aims to directly model the incremental impact of a treatment on an individual response. in this work, we address the problem from a new angle and reformulate it as a markov decision process (mdp). we conducted extensive experiments on both a synthetic dataset and real-world scenarios, and showed that our method can achieve significant improvement over previous methods.',\n",
       " 197: 'at present, cryptocurrencies have become a global phenomenon in financial sectors as it is one of the most traded financial instruments worldwide. cryptocurrency is not only one of the most complicated and abstruse fields among financial instruments, but it is also deemed as a perplexing problem in finance due to its high volatility. this paper makes an attempt to apply machine learning techniques on the index and constituents of cryptocurrency with a goal to predict and forecast prices thereof. in particular, the purpose of this paper is to predict and forecast the close (closing) price of the cryptocurrency index 30 and nine constituents of cryptocurrencies using machine learning algorithms and models so that, it becomes easier for people to trade these currencies. we have used several machine learning techniques and algorithms and compared the models with each other to get the best output. we believe that our work will help reduce the challenges and difficulties faced by people, who invest in cryptocurrencies. moreover, the obtained results can play a major role in cryptocurrency portfolio management and in observing the fluctuations in the prices of constituents of cryptocurrency market. we have also compared our approach with similar state of the art works from the literature, where machine learning approaches are considered for predicting and forecasting the prices of these currencies. in the sequel, we have found that our best approach presents better and competitive results than the best works from the literature thereby advancing the state of the art. using such prediction and forecasting methods, people can easily understand the trend and it would be even easier for them to trade in a difficult and challenging financial instrument like cryptocurrency.',\n",
       " 198: 'we study 3-random-like graphs, that is, sequences of graphs in which the densities of triangles and anti-triangles converge to 1/8. since the random graph ${\\\\mathcal g}_{n,1/2}$ is, in particular, 3-random-like, this can be viewed as a weak version of quasirandomness. we first show that 3-random-like graphs are 4-universal, that is, they contain induced copies of all 4-vertex graphs. this settles a question of linial and morgenstern. we then show that for larger subgraphs, 3-random-like sequences demonstrate a completely different behaviour. we prove that for every graph $h$ on $n\\\\geq r(10,10)$ vertices there exist 3-random-like graphs without an induced copy of $h$. moreover, we prove that for every $\\\\ell$ there are 3-random-like graphs which are $\\\\ell$-universal but not $m$-universal when $m$ is sufficiently large compared to $\\\\ell$.',\n",
       " 199: 'the expediency of using the augmented reality in the case of using of stem-education in ukraine is shown. the features of the augmented reality and its classification are described. the possibilities of using the google expeditions and google lens as platforms of the augmented reality is analyzed. a comparison, analysis, synthesis, induction and deduction was carried out to study the potential of using augmented reality platforms in the educational process. main haracteristics of google expeditions and google lens are described. there determined that augmented reality tools can improve students motivation to learn and correspond to trends of stem-education. however, there problems of using of augmented reality platforms, such as the lack of awareness of this system by teachers, the lack of guidance, the absence of the ukrainian-language interface and responding of educational programs of the ministry of education and science of ukraine. there proposed to involve methodical and pedagogical specialists to development of methodical provision of the tools of augmented reality.',\n",
       " 200: \"we apply the procedure of lee et al. to the problem of performing inference on the signal-noise ratio of the asset which displays maximum sample sharpe ratio over a set of possibly correlated assets. we find a multivariate analogue of the commonly used approximate standard error of the sharpe ratio to use in this conditional estimation procedure. we also consider several alternative procedures, including the simple bonferroni correction for multiple hypothesis testing, which we fix for the case of positive common correlation among assets, the chi-bar square test against one-sided alternatives, follman's test, and hansen's asymptotic adjustments.   testing indicates the conditional inference procedure achieves nominal type i rate, and does not appear to suffer from non-normality of returns. the conditional estimation test has low power under the alternative where there is little spread in the signal-noise ratios of the assets, and high power under the alternative where a single asset has high signal-noise ratio. unlike the alternative procedures, it appears to enjoy rejection probabilities montonic in the signal-noise ratio of the selected asset.\",\n",
       " 201: \"dynamic behavior of a weightless rod with a point mass sliding along the rod axis according to periodic law is studied. this is the simplest model of child's swing. melnikov's analysis is carried out to find bifurcations of homoclinic, subharmonic oscillatory, and subharmonic rotational orbits. for the analysis of superharmonic rotational orbits the averaging method is used and stability of obtained approximate solution is checked. the analytical results are compared with numerical simulation results.\",\n",
       " 202: 'chaperones are binding proteins which work as a driving force to bias the biopolymer translocation by binding to it near the pore and preventing its backsliding. chaperones may have different spatial distribution. recently we show the importance of their spatial distribution in translocation and how it effects on sequence dependency of the translocation time. here we focus on homopolymers and exponential distribution. as a result of the exponential distribution of chaperones, energy dependency of the translocation time will changed and one see a minimum in translocation time versus effective energy curve. the same trend can be seen in scaling exponent of time versus polymer length, $\\\\beta$ ($t\\\\sim\\\\beta$). interestingly in some special cases e.g. chaperones of size $\\\\lambda=6$ and with exponential distribution rate of $\\\\alpha=5$, the minimum reaches even to amount of less than $1$ ($\\\\beta<1$). we explain the possibility of this rare result and base on a theoretical discussion we show that by taking into account the velocity dependency of the translocation on polymer length, one could truly predict the amount of this minimum.',\n",
       " 203: 'monero is a privacy-centric cryptocurrency that makes payments untraceable by adding decoys to every real input spent in a transaction. two studies from 2017 found methods to distinguish decoys from real inputs, which enabled traceability for a majority of transactions. since then, a number protocol changes have been introduced, but their effectiveness has not yet been reassessed. furthermore, little is known about traceability of monero transactions across hard fork chains. we formalize a new method for tracing monero transactions, which is based on analyzing currency hard forks. we use that method to perform a (passive) traceability analysis on data from the monero, monerov and monero original blockchains and find that only a small amount of inputs are traceable. we then use the results to estimate the effectiveness of known heuristics for recent transactions and find that they do not significantly outperform random guessing. our findings suggest that monero is currently mostly immune to known passive attack vectors and resistant to tracking and tracing methods applied to other cryptocurrencies.',\n",
       " 204: 'the free energy principle has been proposed as a unifying account of brain function. it is closely related, and in some cases subsumes, earlier unifying ideas such as bayesian inference, predictive coding, and active learning. this article clarifies these connections, teasing apart distinctive and shared predictions.',\n",
       " 205: \"we present a model of groundwater dynamics under stationary flow and governed by darcy's law of water motion through porous media, we apply it to study a 2d aquifer with water table of constant slope comprised of an homogeneous and isotropic media, the more realistic case of an homogeneous anisotropic soil is also considered. taking into account some geophysical parameters we develop a computational routine, in the finite difference method, that solves the resulting elliptic partial equation, both in a homogeneous isotropic and homogeneous anisotropic media. after calibration of the numerical model, this routine is used to begin a study of the ayamonte-huelva aquifer in spain, a modest analysis of the system is given, we compute the average discharge vector as well as its root mean square as a first predictive approximation of the flux in this system, providing us a signal of the location of best exploitation; long term goal is to develop a complete computational tool for the analysis of groundwater dynamics.\",\n",
       " 206: 'this paper deals with the establishment of input-to-state stability (iss) estimates for infinite dimensional systems with respect to both boundary and distributed disturbances. first, a new approach is developed for the establishment of iss estimates for a class of riesz-spectral boundary control systems satisfying certain eigenvalue constraints. second, a concept of weak solutions is introduced in order to relax the disturbances regularity assumptions required to ensure the existence of classical solutions. the proposed concept of weak solutions, that applies to a large class of boundary control systems which is not limited to the riesz-spectral ones, provides a natural extension of the concept of both classical and mild solutions. assuming that an iss estimate holds true for classical solutions, we show the existence, the uniqueness, and the iss property of the weak solutions.',\n",
       " 207: '3d data is a valuable asset the computer vision filed as it provides rich information about the full geometry of sensed objects and scenes. recently, with the availability of both large 3d datasets and computational power, it is today possible to consider applying deep learning to learn specific tasks on 3d data such as segmentation, recognition and correspondence. depending on the considered 3d data representation, different challenges may be foreseen in using existent deep learning architectures. in this work, we provide a comprehensive overview about various 3d data representations highlighting the difference between euclidean and non-euclidean ones. we also discuss how deep learning methods are applied on each representation, analyzing the challenges to overcome.',\n",
       " 208: 'a novel explicit constraint handling technique for the covariance matrix adaptation evolution strategy (cma-es) is proposed. the proposed constraint handling exhibits two invariance properties. one is the invariance to arbitrary element-wise increasing transformation of the objective and constraint functions. the other is the invariance to arbitrary affine transformation of the search space. the proposed technique virtually transforms a constrained optimization problem into an unconstrained optimization problem by considering an adaptive weighted sum of the ranking of the objective function values and the ranking of the constraint violations that are measured by the mahalanobis distance between each candidate solution to its projection onto the boundary of the constraints. simulation results are presented and show that the cma-es with the proposed constraint handling exhibits the affine invariance and performs similarly to the cma-es on unconstrained counterparts.',\n",
       " 209: 'we develop a non-cooperative game-theoretic model for the problem of graph minor-embedding to show that optimal compiling of adiabatic quantum programs in the sense of nash equilibrium is possible.',\n",
       " 210: \"the kilo degree survey (kids) is a 1500 square degree optical imaging survey with the recently commissioned omegacam wide-field imager on the vlt survey telescope (vst). a suite of data products will be delivered to eso and the community by the kids survey team. spread over europe, the kids team uses astro-wise to collaborate efficiently and pool hardware resources. in astro-wise the team shares, calibrates and archives all survey data. the data-centric architectural design realizes a dynamic 'live archive' in which new kids survey products of improved quality can be shared with the team and eventually the full astronomical community in a flexible and controllable manner\",\n",
       " 211: \"the origins of new genes are among the most fundamental questions in evolutionary biology. our understanding of the ways that new genetic material appears and how that genetic material shapes population variation remains incomplete. de novo genes and duplicate genes are a key source of new genetic material on which selection acts. to better understand the origins of these new gene sequences, we explored the ways that structural variation might alter expression patterns and form novel transcripts. we provide evidence that chromosomal rearrangements are a source of novel genetic variation that facilitates the formation of de novo genes in drosophila. we identify 52 cases of de novo gene formation created by chromosomal rearrangements in 14 strains of d. yakuba. these new genes inherit transcription start signals and open reading frames when the 5' end of existing genes are combined with previously untranscribed regions. such new genes would appear with novel peptide sequences, without the necessity for secondary transitions from non-coding rna to protein. this mechanism of new peptide formations contrasts with canonical theory of de novo gene progression requiring non-coding intermediaries that must acquire new mutations prior to loss via pseudogenization. hence, these mutations offer a means to de novo gene creation and protein sequence formation in a single mutational step, answering a long standing open question concerning new gene formation. we further identify gene expression changes to 134 existing genes, indicating that these mutations can alter gene regulation. population variability for chromosomal rearrangements is considerable, with 2368 rearrangements observed across 14 inbred lines. more rearrangements were identified on the x chromosome than any of the autosomes, suggesting the x is more susceptible to chromosome alterations.\",\n",
       " 212: 'robust principal component analysis (rpca) via rank minimization is a powerful tool for recovering underlying low-rank structure of clean data corrupted with sparse noise/outliers. in many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. this observation motivates us to investigate whether there is a better alternative solution when using rank minimization. in this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values, which implicitly encourages the target rank constraint. our experimental analyses show that, when the number of samples is deficient, our approach leads to a higher success rate than conventional rank minimization, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. we apply our approach to various low-level vision problems, e.g. high dynamic range imaging, motion edge detection, photometric stereo, image alignment and recovery, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method.',\n",
       " 213: \"let $(x,d)$ be a log smooth pair of dimension $n$, where $d$ is a reduced effective divisor such that the log canonical divisor $k_x + d$ is pseudo-effective. let $g$ be a connected algebraic subgroup of $\\\\mathrm{aut}(x,d)$. we show that $g$ is a semi-abelian variety of dimension $\\\\le \\\\min\\\\{n-\\\\bar{\\\\kappa}(v), n\\\\}$ with $v := x\\\\setminus d$. in the dimension two, shigeru iitaka claimed in his 1979 osaka j. math. paper that $\\\\dim g\\\\le \\\\bar{q}(v)$ for a log smooth surface pair with $\\\\bar{\\\\kappa}(v) = 0$ and $\\\\bar{p}_g(v) = 1$. we (re)prove and generalize this classical result for all surfaces with $\\\\bar{\\\\kappa}=0$ without assuming iitaka's classification of logarithmic iitaka surfaces or logarithmic $k3$ surfaces.\",\n",
       " 214: 'we prove that any compact manifold without boundary admits a pair of diffeomorphisms that generates $c^1$ robustly minimal dynamics. we apply the results to the construction of blenders and robustly transitive skew product diffeomorphisms.',\n",
       " 215: \"let $v$ be a complete discrete valuation ring with residue field $k$ and with fraction field $k$ of characteristic 0. we clarify the analysis behind the monsky--washnitzer completion of a commutative $v$-algebra using spectral radius estimates for bounded subsets in complete bornological $v$-algebras. this leads us to a functorial chain complex for commutative $k$-algebras that computes berthelot's rigid cohomology. this chain complex is related to the periodic cyclic homology of certain complete bornological $v$-algebras.\",\n",
       " 216: 'in quantum chemistry, one of the most important challenges is the static correlation problem when solving the electronic schr\\\\\"odinger equation for molecules in the born--oppenheimer approximation. in this article, we analyze the tailored coupled-cluster method (tcc), one particular and promising method for treating molecular electronic-structure problems with static correlation. the tcc method combines the single-reference coupled-cluster (cc) approach with an approximate reference calculation in a subspace [complete active space (cas)] of the considered hilbert space that covers the static correlation. a one-particle spectral gap assumption is introduced, separating the cas from the remaining hilbert space. this replaces the nonexisting or nearly nonexisting gap between the highest occupied molecular orbital and the lowest unoccupied molecular orbital usually encountered in standard single-reference quantum chemistry. the analysis covers, in particular, cc methods tailored by tensor-network states (tns-tcc methods). the problem is formulated in a nonlinear functional analysis framework, and, under certain conditions such as the aforementioned gap, local uniqueness and existence are proved using zarantonello\\'s lemma. from the aubin--nitsche-duality method, a quadratic error bound valid for tns-tcc methods is derived, e.g., for linear-tensor-network tcc schemes using the density matrix renormalization group method.',\n",
       " 217: 'continual learning is the problem of learning new tasks or knowledge while protecting old knowledge and ideally generalizing from old experience to learn new tasks faster. neural networks trained by stochastic gradient descent often degrade on old tasks when trained successively on new tasks with different data distributions. this phenomenon, referred to as catastrophic forgetting, is considered a major hurdle to learning with non-stationary data or sequences of new tasks, and prevents networks from continually accumulating knowledge and skills. we examine this issue in the context of reinforcement learning, in a setting where an agent is exposed to tasks in a sequence. unlike most other work, we do not provide an explicit indication to the model of task boundaries, which is the most general circumstance for a learning agent exposed to continuous experience. while various methods to counteract catastrophic forgetting have recently been proposed, we explore a straightforward, general, and seemingly overlooked solution - that of using experience replay buffers for all past events - with a mixture of on- and off-policy learning, leveraging behavioral cloning. we show that this strategy can still learn new tasks quickly yet can substantially reduce catastrophic forgetting in both atari and dmlab domains, even matching the performance of methods that require task identities. when buffer storage is constrained, we confirm that a simple mechanism for randomly discarding data allows a limited size buffer to perform almost as well as an unbounded one.',\n",
       " 218: 'earlier we have proposed a new approach to the analysis of superconducting phase diagrams for cuprates and pnictides and have shown that the positions of superconducting domes on the diagrams can be predicted with high accuracy proceeding from only the crystal structure of a particular compound. the proposed approach uses the concept of the self-localization of doped carriers due to their formation of trion complexes that represent a bound state of the doped carrier and charge transfer excitons emerging under its influence. here, as exemplified by cuprates, we show that the use of the proposed approach to the analysis of the transformation of an electronic structure with doping enables an explanation to a range of their anomalies: fermi arcs, large and small pseudogaps etc. the basic conclusion is that the role of the fermi surface in cuprates is played by an isoenergetic contour that emerges at the sectioning of the surface of a band dispersion by a dispersionless \"biexciton\" pair level. this level additionally plays the role of an acceptor to lead to the emergence of hole carriers on the isoenergetic contour and to a jump of the chemical potential. based on the conducted consideration, we propose a possible mechanism of superconducting pairing genetically inherent in such a system.',\n",
       " 219: 'in this paper we study the effect of absorption peak correlation in finite length carbon nanotubes and graphene nanoribbons. it is shown, in the orthogonal {\\\\pi}-orbital tight-binding model with the nearest neighbor approximation, that if the ribbon width is a half of the tube circumference the effect takes place for all achiral ribbons (zigzag, armchair and bearded), and corresponding tubes, starting from lengths of about 30 nm. this correlation should be useful in designing nanoribbon-based optoelectronics devices fully integrated into a single layer of graphene.',\n",
       " 220: 'self-avoiding walks (saws) and loop-erased random walks (lerws) are two ensembles of random paths with numerous applications in mathematics, statistical physics and quantum field theory. while saws are described by the $n \\\\to 0$ limit of $\\\\phi^4$-theory with $o(n)$-symmetry, lerws have no obvious field-theoretic description. we analyse two candidates for a field theory of lerws, and discover a connection between the corresponding and a priori unrelated theories. the first such candidate is the $o(n)$-symmetric $\\\\phi^4$ theory at $n=-2$ whose link to lerws was known in two dimensions due to conformal field theory. here it is established in arbitrary dimension via a perturbation expansion in the coupling constant. the second candidate is a field theory for charge-density waves pinned by quenched disorder, whose relation to lerws had been conjectured earlier using analogies with abelian sandpiles. we explicitly show that both theories yield identical results to 4-loop order and give both a perturbative and a non-perturbative proof of their equivalence. this allows us to compute the fractal dimension of lerws to order $\\\\epsilon^5$ where $\\\\epsilon=4-d$. in particular, in $d=3$ our theory gives $z_{\\\\rm lerw}(d=3)= 1.6243 \\\\pm 0.001$, in excellent agreement with the estimate $z = 1.624 00 \\\\pm 0.00005$ of numerical simulations.',\n",
       " 221: 'the squiral inflation rule is equivalent to a bijective block substitution rule and leads to an interesting lattice dynamical system under the action of $\\\\mathbb{z}^{2}$. in particular, its balanced version has purely singular continuous diffraction. the dynamical spectrum is of mixed type, with pure point and singular continuous components. we present a constructive proof that admits a generalisation to bijective block substitutions of trivial height on $\\\\mathbb{z}^{d}$.',\n",
       " 222: \"we give an efficient algorithm for the enumeration up to isomorphism of the inverse semigroups of order n, and we count the number s(n) of inverse semigroups of order n<=15. this improves considerably on the previous highest-known value s(9). we also give a related algorithm for the enumeration up to isomorphism of the finite inverse semigroups s with a given underlying semilattice of idempotents e, a given restriction of green's d-relation on s to e, and a given list of maximal subgroups of s associated to the elements of e.\",\n",
       " 223: 'we develop a hierarchical gaussian process model for forecasting and inference of functional time series data. unlike existing methods, our approach is especially suited for sparsely or irregularly sampled curves and for curves sampled with non-negligible measurement error. the latent process is dynamically modeled as a functional autoregression (far) with gaussian process innovations. we propose a fully nonparametric dynamic functional factor model for the dynamic innovation process, with broader applicability and improved computational efficiency over standard gaussian process models. we prove finite-sample forecasting and interpolation optimality properties of the proposed model, which remain valid with the gaussian assumption relaxed. an efficient gibbs sampling algorithm is developed for estimation, inference, and forecasting, with extensions for far(p) models with model averaging over the lag p. extensive simulations demonstrate substantial improvements in forecasting performance and recovery of the autoregressive surface over competing methods, especially under sparse designs. we apply the proposed methods to forecast nominal and real yield curves using daily u.s. data. real yields are observed more sparsely than nominal yields, yet the proposed methods are highly competitive in both settings.',\n",
       " 224: 'in this paper, first we obtain some new and interesting results on projective modules and on the upper topology of an ordinal number. then it is shown that the rank map of a locally of finite type projective module is continuous with respect to the upper topology (by contract, it is well known this map is not necessarily continuous with respect to the discrete topology). it is also proved that a finitely generated flat module is projective if and only if its rank map is continuous with respect to the upper topology.',\n",
       " 225: 'we present a weakly supervised model that jointly performs both semantic- and instance-segmentation -- a particularly relevant problem given the substantial cost of obtaining pixel-perfect annotation for these tasks. in contrast to many popular instance segmentation approaches based on object detectors, our method does not predict any overlapping instances. moreover, we are able to segment both \"thing\" and \"stuff\" classes, and thus explain all the pixels in the image. \"thing\" classes are weakly-supervised with bounding boxes, and \"stuff\" with image-level tags. we obtain state-of-the-art results on pascal voc, for both full and weak supervision (which achieves about 95% of fully-supervised performance). furthermore, we present the first weakly-supervised results on cityscapes for both semantic- and instance-segmentation. finally, we use our weakly supervised framework to analyse the relationship between annotation quality and predictive performance, which is of interest to dataset creators.',\n",
       " 226: 'in this paper we demonstrate the effectiveness of a well trained u-net in the context of the brats 2018 challenge. this endeavour is particularly interesting given that researchers are currently besting each other with architectural modifications that are intended to improve the segmentation performance. we instead focus on the training process arguing that a well trained u-net is hard to beat. our baseline u-net, which has only minor modifications and is trained with a large patch size and a dice loss function indeed achieved competitive dice scores on the brats2018 validation data. by incorporating additional measures such as region based training, additional training data, a simple postprocessing technique and a combination of loss functions, we obtain dice scores of 77.88, 87.81 and 80.62, and hausdorff distances (95th percentile) of 2.90, 6.03 and 5.08 for the enhancing tumor, whole tumor and tumor core, respectively on the test data. this setup achieved rank two in brats2018, with more than 60 teams participating in the challenge.',\n",
       " 227: 'learning and memory are intertwined in our brain and their relationship is at the core of several recent neural network models. in particular, the attention-gated memory tagging model (augment) is a reinforcement learning network with an emphasis on biological plausibility of memory dynamics and learning. we find that the augment network does not solve some hierarchical tasks, where higher-level stimuli have to be maintained over a long time, while lower-level stimuli need to be remembered and forgotten over a shorter timescale. to overcome this limitation, we introduce hybrid augment, with leaky or short-timescale and non-leaky or long-timescale units in memory, that allow to exchange lower-level information while maintaining higher-level one, thus solving both hierarchical and distractor tasks.',\n",
       " 228: 'we exhibit a family of computably enumerable sets which can be learned within polynomial resource bounds given access only to a teacher, but which requires exponential resources to be learned given access only to a membership oracle. in general, we compare the families that can be learned with and without teachers and oracles for four measures of efficient learning.',\n",
       " 229: 'we calculate the exact amenability constant of the centre of $\\\\ell^1(g)$ when $g$ is one of the following classes of finite group: dihedral; extraspecial; or frobenius with abelian complement and kernel. this is done using a formula which applies to all finite groups with two character degrees. in passing, we answer in the negative a question raised in work of the third author with azimifard and spronk (j. funct. anal. 2009).',\n",
       " 230: 'we study the parameterized and classical complexity of two related problems on undirected graphs $g=(v,e)$. in strong triadic closure we aim to label the edges in $e$ as strong and weak such that at most~$k$ edges are weak and $g$ contains no induced $p_3$ with two strong edges. in cluster deletion, we aim to destroy all induced $p_3$s by a minimum number of edge deletions. we first show that strong triadic closure admits a $4k$-vertex kernel. then, we study parameterization by $\\\\ell:=|e|-k$ and show that both problems are fixed-parameter tractable and unlikely to admit a polynomial kernel with respect to $\\\\ell$. finally, we give a dichotomy of the classical complexity of both problems on $h$-free graphs for all $h$ of order four.',\n",
       " 231: 'this paper describes a novel hierarchical attention network for reading comprehension style question answering, which aims to answer questions for a given narrative paragraph. in the proposed method, attention and fusion are conducted horizontally and vertically across layers at different levels of granularity between question and paragraph. specifically, it first encode the question and paragraph with fine-grained language embeddings, to better capture the respective representations at semantic level. then it proposes a multi-granularity fusion approach to fully fuse information from both global and attended representations. finally, it introduces a hierarchical attention network to focuses on the answer span progressively with multi-level softalignment. extensive experiments on the large-scale squad and triviaqa datasets validate the effectiveness of the proposed method. at the time of writing the paper (jan. 12th 2018), our model achieves the first position on the squad leaderboard for both single and ensemble models. we also achieves state-of-the-art results on triviaqa, addsent and addone-sent datasets.',\n",
       " 232: \"modeling fashion compatibility is challenging due to its complexity and subjectivity. existing work focuses on predicting compatibility between product images (e.g. an image containing a t-shirt and an image containing a pair of jeans). however, these approaches ignore real-world 'scene' images (e.g. selfies); such images are hard to deal with due to their complexity, clutter, variations in lighting and pose (etc.) but on the other hand could potentially provide key context (e.g. the user's body type, or the season) for making more accurate recommendations. in this work, we propose a new task called 'complete the look', which seeks to recommend visually compatible products based on scene images. we design an approach to extract training data for this task, and propose a novel way to learn the scene-product compatibility from fashion or interior design images. our approach measures compatibility both globally and locally via cnns and attention mechanisms. extensive experiments show that our method achieves significant performance gains over alternative systems. human evaluation and qualitative analysis are also conducted to further understand model behavior. we hope this work could lead to useful applications which link large corpora of real-world scenes with shoppable products.\",\n",
       " 233: 'we consider spin-vorticity coupling - the generation of spin polarization by vorticity - in viscous two-dimensional electron systems with spin-orbit coupling. we first derive hydrodynamic equations for spin and momentum densities in which their mutual coupling is determined by the rotational viscosity. we then calculate the rotational viscosity microscopically in the limits of weak and strong spin-orbit coupling. we provide estimates that show that the spin-orbit coupling achieved in recent experiments is strong enough for the spin-vorticity coupling to be observed. on the one hand, this coupling provides a way to image viscous electron flows by imaging spin densities. on the other hand, we show that the spin polarization generated by spin-vorticity coupling in the hydrodynamic regime can, in principle, be much larger than that generated, e.g. by the spin hall effect, in the diffusive regime.',\n",
       " 234: \"recently, there has been a drive towards the realization of topological phases beyond conventional electronic materials, including phases defined in more than three dimensions. we propose a versatile and experimentally realistic approach of realizing a large variety of multi-component topological phases in 2d photonic crystals with quasi-periodically modulated defects. with a length scale introduced by a background resonator lattice, the defects are found to host various effective orbitals of $s$, $p$ and $d$-type symmetries, thus providing a monolithic platform for realizing multi-component topological states without requiring separate internal degrees of freedom in the physical setup. notably, by coupling the defect modulations diagonally, we report the novel realization of an ``entangled'' 4d qh phase which cannot be factorized into two copies of 2d qh phases, each described by the 1st chern number. the structure of this non-factorizability can be quantified by a classical entanglement entropy inspired by quantum information theory. in another embodiment, we present 4d p-orbital nodal lines in a nonsymmorphic photonic lattice, hosting boundary states with an exotic manifold. our simple and versatile approach holds the promise of novel topological optoelectronic and photonic applications such as one-way optical fibers.\",\n",
       " 235: 'this is an exposition of the donaldson geometric flow on the space of symplectic forms on a closed smooth four-manifold, representing a fixed cohomology class. the original work appeared in [1].',\n",
       " 236: 'crucial to gaining control over crystallisation in multicomponent materials or accurately modelling rheological behaviour of magma flows is to understand the mechanisms by which crystal nuclei form. the microscopic nature of such nuclei, however, makes this extremely hard in experiments, while computer simulations have hitherto been hampered by their short timescales and small system sizes due to limited computational power. here we use highly-efficient gpu simulation techniques to access system sizes around 100 times larger than previous studies. this makes it possible to elucidate the nucleation mechanism in a well-studied binary glassformer. we discover that the supercooled liquid is inherently unstable for system sizes of 10,000 particles and larger. this effect is due to compositional fluctuations leading to regions comprised of large particles only which rapidly nucleate. we argue that this mechanism provides a minimum rate of crystallisation in mixtures in general, and use our results to stabilise a model binary mixture and predict glassforming ability for the cuzr metallic glassformer.',\n",
       " 237: 'the single mirror small-size telescope (sst-1m) is one of the telescope projects being proposed for the cherenkov telescope array observatory by a sub-consortium of polish and swiss institutions. the sst-1m prototype structure is currently being constructed at the institute of nuclear physics in cracow, poland, while the camera will be assembled at the university of geneva, switzerland. this prototype enables measurements of parameters having a decisive influence on the telescope performance. we present results of numerical simulations of the sst-1m performance based on such measurements. the telescope effective area, the expected trigger rates and the optical point spread function are calculated.',\n",
       " 238: 'lagrangian data assimilation is a complex problem in oceanic and atmospheric modeling. tracking drifters in large-scale geophysical flows can involve uncertainty in drifter location, complex inertial effects, and other factors which make comparing them to simulated lagrangian trajectories from numerical models extremely challenging. temporal and spatial discretization, factors necessary in modeling large scale flows, also contribute to separation between real and simulated drifter trajectories. the chaotic advection inherent in these turbulent flows tends to separate even closely spaced tracer particles, making error metrics based solely on drifter displacements unsuitable for estimating model parameters. we propose to instead use error in the coherent structure coloring (csc) field to assess model skill. the csc field provides a spatial representation of the underlying coherent patterns in the flow, and we show that it is a more robust metric for assessing model accuracy. through the use of two test cases, one considering spatial uncertainty in particle initialization, and one examining the influence of stochastic error along a trajectory and temporal discretization, we show that error in the coherent structure coloring field can be used to accurately determine single or multiple simultaneously unknown model parameters, whereas a conventional error metric based on error in drifter displacement fails. because the csc field enhances the difference in error between correct and incorrect model parameters, error minima in model parameter sweeps become more distinct. the effectiveness and robustness of this method for single and multi-parameter estimation in analytical flows suggests that lagrangian data assimilation for real oceanic and atmospheric models would benefit from a similar approach.',\n",
       " 239: \"originally inspired by neurobiology, deep neural network models have become a powerful tool of machine learning and artificial intelligence, where they are used to approximate functions and dynamics by learning from examples. here we give a brief introduction to neural network models and deep learning for biologists. we introduce feedforward and recurrent networks and explain the expressive power of this modeling framework and the backpropagation algorithm for setting the parameters. finally, we consider how deep neural networks might help us understand the brain's computations.\",\n",
       " 240: \"only few categories of free arrangements are known in which terao's conjecture holds. one of such categories consists of $3$-arrangements with unbalanced ziegler restrictions. in this paper, we generalize this result to arbitrary dimensional arrangements in terms of flags by introducing unbalanced multiarrangements. for that purpose, we generalize several freeness criterions for simple arrangements, including yoshinaga's freeness criterion, to unbalanced multiarrangements.\",\n",
       " 241: 'emergence of generalized synchronization patterns in a ring of identical and locally coupled kuramoto-type rotators are investigated by different methods. these approaches offer a useful visual picture for understanding the complexity of the dynamics in the high dimensional state-space of this system. beside the known stable stationary points novel unstable states are revealed. we find that the prediction of the final stationary state is limited by the presence of such saddle points. this is illustrated by considering and comparing two different attempts for forecasting the final stationary state',\n",
       " 242: 'octave-spanning, self-referenced frequency combs are applied in diverse fields ranging from precision metrology to astrophysical spectrometer calibration. in the past decade, kerr frequency comb generators have emerged as alternative scheme offering chip-scale integration, high repetition rate and bandwidths that are only limited by group velocity dispersion. the recent observation of kerr frequency combs operating in the dissipative kerr soliton (dks) regime, along with dispersive wave formation, has provided the means for fully coherent, broadband kerr frequency comb generation with engineered spectral envelope. here, by carefully optimizing the photonic damascene fabrication process, and dispersion engineering of $\\\\mathrm{si_{3}n_{4}}$ microresonators with $1\\\\,\\\\mathrm{thz}$ free spectral range, we achieve bandwidths exceeding one octave at low powers ($\\\\mathcal{o}(100\\\\,\\\\mathrm{mw})$) for pump lasers residing in the telecom c-band ($1.55\\\\,\\\\mathrm{\\\\mu m}$), as well as for the first time in the o-band ($1.3\\\\,\\\\mathrm{\\\\mu m}$). equally important, we find that for thz repetition rate comb states, conventional criteria applied to identify dks comb states fail. investigating the coherence of generated, octave-spanning kerr comb states we unambiguously identify dks states using a response measurement. this allows to demonstrate octave-spanning dks comb states at both pump laser wavelengths of $1.3\\\\mathrm{\\\\,\\\\mu m}$ and $1.55\\\\,\\\\mathrm{\\\\mu m}$ including the broadest dks state generated to date, spanning more than $200\\\\,\\\\mathrm{thz}$ of optical bandwidth. octave spanning dks frequency combs can form essential building blocks for metrology or spectroscopy, and their operation at $1.3\\\\mathrm{\\\\,\\\\mu m}$ enables applications in life sciences such as kerr comb based optical coherence tomography or dual comb coherent antistokes raman scattering.',\n",
       " 243: 'we study the relative value iteration for the ergodic control problem under a near-monotone running cost structure for a nondegenerate diffusion controlled through its drift. this algorithm takes the form of a quasilinear parabolic cauchy initial value problem in $\\\\rr^{d}$. we show that this cauchy problem stabilizes, or in other words, that the solution of the quasilinear parabolic equation converges for every bounded initial condition in $\\\\cc^{2}(\\\\rr^{d})$ to the solution of the hamilton--jacobi--bellman (hjb) equation associated with the ergodic control problem.',\n",
       " 244: 'the purpose of this paper is to introduce a set of four test images containing features and structures that can facilitate effective examination and comparison of image processing algorithms. more specifically, the images are designed to more explicitly expose the characteristic properties of algorithms for image compression, virtual resolution adjustment, and enhancement. this set was developed at the naval research laboratory (nrl) in the late 1990s as a more rigorous alternative to lena and other images that have come into common use for purely ad hoc reasons with little or no rigorous consideration of their suitability. the increasing number of test images appearing in the literature not only makes it more difficult to compare results from different papers, it also introduces the potential for cherry-picking to influence results. the key contribution of this paper is the proposal to establish {\\\\em some} canonical set to ensure that published results can be analyzed and compared in a rigorous way from one paper to another, and consideration of the four nrl images is proposed for this purpose.',\n",
       " 245: 'analytical solutions for both a finite assembly and a periodic array of bubbles steadily moving in a hele-shaw channel are presented. the particular case of multiple fingers penetrating into the channel and moving jointly with an assembly of bubbles is also analysed. the solutions are given by a conformal mapping from a multiply connected circular domain in an auxiliary complex plane to the fluid region exterior to the bubbles. in all cases the desired mapping is written explicitly in terms of certain special transcendental functions, known as the secondary schottky-klein prime functions. taken together, the solutions reported here represent the complete set of solutions for steady bubbles and fingers in a horizontal hele-shaw channel when surface tension is neglected. all previous solutions under these assumptions are particular cases of the general solutions reported here. other possible applications of the formalism described here are also discussed.',\n",
       " 246: 'spectrum of the pauli projector of a quantum many-body system is studied. it is proven that the kern of the complete many-body projector is identical to the kern of the sum of two-body projectors. since the kern of the many-body pauli projector defines an allowed subspace of the complete hilbert space, it is argued that a truncation of the many-body model space following the two-body pauli projectors is a natural way when solving the schr\\\\\"{o}dinger equation for the many-body system. these relations clarify a role of the many-body pauli forces in a multicluster system.',\n",
       " 247: 'in this talk i present a simple and unified approach to both exact and quasi-exact solvabilities of the one-dimensional schr\\\\\"odinger equation. it is based on the prepotential together with bethe ansatz equations. this approach gives the potential as well as the eigenfunctions and eigenvalues simultaneously. in this approach the system is completely defined by the choice of the change of variables, and the so-called zero-th order prepotential. we illustrate the approach by several examples of hermitian and non-hermitian hamiltonians with real energies. the method can be easily extended to the constructions of exactly and quasi-exactly solvable dirac, pauli, and fokker-planck equations, and to quasinormal modes.',\n",
       " 248: 'planning has been very successful for control tasks with known environment dynamics. to leverage planning in unknown environments, the agent needs to learn the dynamics from interactions with the world. however, learning dynamics models that are accurate enough for planning has been a long-standing challenge, especially in image-based domains. we propose the deep planning network (planet), a purely model-based agent that learns the environment dynamics from images and chooses actions through fast online planning in latent space. to achieve high performance, the dynamics model must accurately predict the rewards ahead for multiple time steps. we approach this using a latent dynamics model with both deterministic and stochastic transition components. moreover, we propose a multi-step variational inference objective that we name latent overshooting. using only pixel observations, our agent solves continuous control tasks with contact dynamics, partial observability, and sparse rewards, which exceed the difficulty of tasks that were previously solved by planning with learned models. planet uses substantially fewer episodes and reaches final performance close to and sometimes higher than strong model-free algorithms.',\n",
       " 249: \"we demonstrate a generalization of quantum discord using a generalized definition of von-neumann entropy, which is sharma-mittal entropy; and the new definition of discord is called sharma-mittal quantum discord. its analytic expressions are worked out for two qubit quantum states as well as werner, isotropic, and pointer states as special cases. the r{\\\\'e}nyi, tsallis, and von-neumann entropy based quantum discords can be expressed as limiting cases for of sharma-mittal quantum discord. we also numerically compare all these discords and entanglement negativity.\",\n",
       " 250: \"generalizing a theorem of albert, saltman showed that an azumaya algebra $a$ over a ring represents a $2$-torsion class in the brauer group if and only if there is an algebra $a'$ in the brauer class of $a$ admitting an involution of the first kind. knus, parimala, and srinivas later showed that one can choose $a'$ such that $\\\\mathrm{deg}\\\\, a'=2\\\\mathrm{deg}\\\\, a$. we show that $2\\\\mathrm{deg}\\\\, a$ is the lowest degree one can expect in general. specifically, we construct an azumaya algebra $a$ of degree $4$ and period $2$ such that the degree of any algebra $a'$ in the brauer class of $a$ admitting an involution is divisible by $8$.   separately, we provide examples of split and non-split azumaya algebras of degree $2$ admitting symplectic involutions, but no orthogonal involutions. these stand in contrast to the case of central simple algebras of even degree over fields, where the presence of a symplectic involution implies the existence of an orthogonal involution and vice versa.\",\n",
       " 251: 'risk stratification (characterization) of tumors from radiology images can be more accurate and faster with computer-aided diagnosis (cad) tools. tumor characterization through such tools can also enable non-invasive cancer staging, prognosis, and foster personalized treatment planning as a part of precision medicine. in this study, we propose both supervised and unsupervised machine learning strategies to improve tumor characterization. our first approach is based on supervised learning for which we demonstrate significant gains with deep learning algorithms, particularly by utilizing a 3d convolutional neural network and transfer learning. motivated by the radiologists\\' interpretations of the scans, we then show how to incorporate task dependent feature representations into a cad system via a graph-regularized sparse multi-task learning (mtl) framework. in the second approach, we explore an unsupervised learning algorithm to address the limited availability of labeled training data, a common problem in medical imaging applications. inspired by learning from label proportion (llp) approaches in computer vision, we propose to use proportion-svm for characterizing tumors. we also seek the answer to the fundamental question about the goodness of \"deep features\" for unsupervised tumor classification. we evaluate our proposed supervised and unsupervised learning algorithms on two different tumor diagnosis challenges: lung and pancreas with 1018 ct and 171 mri scans, respectively, and obtain the state-of-the-art sensitivity and specificity results in both problems.',\n",
       " 252: 'synchronization phenomena are of broad interest across disciplines and increasingly of interest in a multiplex network setting. here we show how the master stability function, a celebrated framework for analyzing synchronization on a single network, can be extended to certain classes of multiplex networks with different intra-layer and inter-layer coupling functions. we derive three master stability equations that determine respectively the necessary regions of complete synchronization, intra-layer synchronization and inter-layer synchronization. we calculate these three regions explicitly for the case of a two-layer network of r{\\\\\"o}ssler oscillators and show that the overlap of the regions determines the type of synchronization achieved. in particular, if the inter- or intra-layer coupling function is such that the inter-layer or intra-layer synchronization region is empty, complete synchronization cannot be achieved regardless of the coupling strength. furthermore, for any given nodal dynamics and network structure, the occurrence of intra-layer and inter-layer synchronization depend mainly on the coupling functions of nodes within a layer and across layers, respectively. our mathematical analysis requires that the intra- and inter-layer supra-laplacians commute. but we show this is only a sufficient, and not necessary, condition and that the results can be applied more generally.',\n",
       " 253: 'the object of study in the present dissertation are some topics in differential geometry of smooth manifolds with additional tensor structures and metrics of norden type. there are considered four cases depending on the dimension of the manifold: 2n, 2n + 1, 4n and 4n + 3. the studied tensor structures, which are counterparts in the different related dimensions, are the almost complex/contact/hypercomplex structure and the almost contact 3-structure. the considered metric on the 2n-dimensional case is the norden metric, and the metrics in the other three cases are generated by it. the purpose of the dissertation is to carry out the following: 1. further investigations of almost complex manifolds with norden metric including studying of natural connections with conditions for their torsion and invariant tensors under the twin interchange of norden metrics. 2. further investigations of almost contact manifolds with b-metric including studying of natural connections with conditions for their torsion and associated schouten-van kampen connections as well as a classification of affine connections. 3. introducing and studying of sasaki-like almost contact complex riemannian manifolds. 4. further investigations of almost hypercomplex manifolds with hermitian-norden metrics including studying of integrable structures of the considered type on 4-dimensional lie algebra and tangent bundles with the complete lift of the base metric; introducing of associated nijenhuis tensors in relation with natural connections having totally skew-symmetric torsion as well as quaternionic k\\\\\"ahler manifolds with hermitian-norden metrics. 5. introducing and studying of manifolds with almost contact 3-structures and metrics of hermitian-norden type and, in particular, associated nijenhuis tensors and their relationship with natural connections having totally skew-symmetric torsion.',\n",
       " 254: 'we propose an approach for dense semantic 3d reconstruction which uses a data term that is defined as potentials over viewing rays, combined with continuous surface area penalization. our formulation is a convex relaxation which we augment with a crucial non-convex constraint that ensures exact handling of visibility. to tackle the non-convex minimization problem, we propose a majorize-minimize type strategy which converges to a critical point. we demonstrate the benefits of using the non-convex constraint experimentally. for the geometry-only case, we set a new state of the art on two datasets of the commonly used middlebury multi-view stereo benchmark. moreover, our general-purpose formulation directly reconstructs thin objects, which are usually treated with specialized algorithms. a qualitative evaluation on the dense semantic 3d reconstruction task shows that we improve significantly over previous methods.',\n",
       " 255: 'this paper aims to quantitatively explain rationales of each prediction that is made by a pre-trained convolutional neural network (cnn). we propose to learn a decision tree, which clarifies the specific reason for each prediction made by the cnn at the semantic level. i.e., the decision tree decomposes feature representations in high conv-layers of the cnn into elementary concepts of object parts. in this way, the decision tree tells people which object parts activate which filters for the prediction and how much they contribute to the prediction score. such semantic and quantitative explanations for cnn predictions have specific values beyond the traditional pixel-level analysis of cnns. more specifically, our method mines all potential decision modes of the cnn, where each mode represents a common case of how the cnn uses object parts for prediction. the decision tree organizes all potential decision modes in a coarse-to-fine manner to explain cnn predictions at different fine-grained levels. experiments have demonstrated the effectiveness of the proposed method.',\n",
       " 256: \"this paper investigates a hybrid stochastic differential reinsurance and investment game between one reinsurer and two insurers, including a stochastic stackelberg differential subgame and a non-zero-sum stochastic differential subgame. the reinsurer, as the leader of the stackelberg game, can price reinsurance premium and invest its wealth in a financial market that contains a risk-free asset and a risky asset. the two insurers, as the followers of the stackelberg game, can purchase proportional reinsurance from the reinsurer and invest in the same financial market. the competitive relationship between two insurers is modeled by the non-zero-sum game, and their decision making will consider the relative performance measured by the difference in their terminal wealth. we consider wealth processes with delay to characterize the bounded memory feature. this paper aims to find the equilibrium strategy for the reinsurer and insurers by maximizing the expected utility of the reinsurer's terminal wealth with delay and maximizing the expected utility of the combination of insurers' terminal wealth and the relative performance with delay. by using the idea of backward induction and the dynamic programming approach, we derive the equilibrium strategy and value functions explicitly. then, we provide the corresponding verification theorem. finally, some numerical examples and sensitivity analysis are presented to demonstrate the effects of model parameters on the equilibrium strategy. we find the delay factor discourages or stimulates investment depending on the length of delay. moreover, competitive factors between two insurers make their optimal reinsurance-investment strategy interact, and reduce reinsurance demand and reinsurance premium price.\",\n",
       " 257: 'modern large-scale datasets are frequently said to be high-dimensional. however, their data point clouds frequently possess structures, significantly decreasing their intrinsic dimensionality (id) due to the presence of clusters, points being located close to low-dimensional varieties or fine-grained lumping. we test a recently introduced dimensionality estimator, based on analysing the separability properties of data points, on several benchmarks and real biological datasets. we show that the introduced measure of id has performance competitive with state-of-the-art measures, being efficient across a wide range of dimensions and performing better in the case of noisy samples. moreover, it allows estimating the intrinsic dimension in situations where the intrinsic manifold assumption is not valid.',\n",
       " 258: 'autonomous vehicle manufacturers recognize that lidar provides accurate 3d views and precise distance measures under highly uncertain driving conditions. its practical implementation, however, remains costly. this paper investigates the optimal lidar configuration problem to achieve utility maximization. we use the perception area and non-detectable subspace to construct the design procedure as solving a min-max optimization problem and propose a bio-inspired measure -- volume to surface area ratio (vsr) -- as an easy-to-evaluate cost function representing the notion of the size of the non-detectable subspaces of a given configuration. we then adopt a cuboid-based approach to show that the proposed vsr-based measure is a well-suited proxy for object detection rate. it is found that the artificial bee colony evolutionary algorithm yields a tractable cost function computation. our experiments highlight the effectiveness of our proposed vsr measure in terms of cost-effectiveness configuration as well as providing insightful analyses that can improve the design of av systems.',\n",
       " 259: 'we give a finite presentation by generators and relations of the unitary operators expressible over the {cnot, t, x} gate set, also known as cnot-dihedral operators. to this end, we introduce a notion of normal form for cnot-dihedral circuits and prove that every cnot-dihedral operator admits a unique normal form. moreover, we show that in the presence of certain structural rules only finitely many circuit identities are required to reduce an arbitrary cnot-dihedral circuit to its normal form.   by appropriately restricting our relations, we obtain a finite presentation of unitary operators expressible over the {cnot, t} gate set as a corollary.',\n",
       " 260: 'let $\\\\lambda$ be a partition with no more than $n$ parts. let $\\\\beta$ be a weakly increasing $n$-tuple with entries from $\\\\{ 1, ... , n \\\\}$. the flagged schur function in the variables $x_1, ... , x_n$ that is indexed by $\\\\lambda$ and $\\\\beta$ has been defined to be the sum of the content weight monomials for the semistandard young tableaux of shape $\\\\lambda$ whose values are row-wise bounded by the entries of $\\\\beta$. gessel and viennot gave a determinant expression for the flagged schur function indexed by $\\\\lambda$ and $\\\\beta$; this could be done since the pair $(\\\\lambda, \\\\beta)$ satisfied their \"nonpermutable\" condition for the sequence of terminals of an $n$-tuple of lattice paths that they used to model the tableaux. we generalize flagged schur functions by dropping the requirement that $\\\\beta$ be weakly increasing. then for each $\\\\lambda$ we give a condition on the entries of $\\\\beta$ for the pair $(\\\\lambda, \\\\beta)$ to be nonpermutable that is both necessary and sufficient. when the parts of $\\\\lambda$ are not distinct there will be multiple row bound $n$-tuples $\\\\beta$ that will produce the same set of tableaux. we accordingly group the bounding $\\\\beta$ into equivalence classes and identify the most efficient $\\\\beta$ in each class for the determinant computation. we recently showed that many other sets of objects that are indexed by $n$ and $\\\\lambda$ are enumerated by the number of these efficient $n$-tuples. we called these counts \"parabolic catalan numbers\". it is noted that the $gl(n)$ demazure characters (key polynomials) indexed by 312-avoiding permutations can also be expressed with these determinants.',\n",
       " 261: 'modern embedded technology is a driving factor in satellite miniaturization, contributing to a massive boom in satellite launches and a rapidly evolving new space industry. miniaturized satellites, however, suffer from low reliability, as traditional hardware-based fault-tolerance (ft) concepts are ineffective for on-board computers (obcs) utilizing modern systems-on-a-chip (soc). therefore, larger satellites continue to rely on proven processors with large feature sizes. software-based concepts have largely been ignored by the space industry as they were researched only in theory, and have not yet reached the level of maturity necessary for implementation. we present the first integral, real-world solution to enable fault-tolerant general-purpose computing with modern multiprocessor-socs (mpsocs) for spaceflight, thereby enabling their use in future high-priority space missions. the presented multi-stage approach consists of three ft stages, combining coarse-grained thread-level distributed self-validation, fpga reconfiguration, and mixed criticality to assure long-term ft and excellent scalability for both resource constrained and critical high-priority space missions. early benchmark results indicate a drastic performance increase over state-of-the-art radiation-hard obc designs and considerably lower software- and hardware development costs. this approach was developed for a 4-year european space agency (esa) project, and we are implementing a tiled mpsoc prototype jointly with two industrial partners.',\n",
       " 262: 'we calculate stationary probability distribution of magnetic field, generated by moving charges of plasma environment, and stationary probability distribution of force, acting on charged particle in this environment, with magnetic interaction taken into account. while the former happens to be the holtsmark distribution, the latter is a modified holtsmark distribution. in contrast to prior works, we did no assumptions on the velocity distribution function and thus obtained results should be applicable to wider spectrum of models. presented results can be experimentally verified through studies of zeeman effect or movement of small charged brownian particles in plasma.',\n",
       " 263: 'batch normalization (bn) has become a core design block of modern convolutional neural networks (cnns). a typical modern cnn has a large number of bn layers in its lean and deep architecture. bn requires mean and variance calculations over each mini-batch during training. therefore, the existing memory access reduction techniques, such as fusing multiple conv layers, are not effective for accelerating bn due to their inability to optimize mini-batch related calculations during training. to address this increasingly important problem, we propose to restructure bn layers by first splitting a bn layer into two sub-layers (fission) and then combining the first sub-layer with its preceding conv layer and the second sub-layer with the following activation and conv layers (fusion). the proposed solution can significantly reduce main-memory accesses while training the latest cnn models, and the experiments on a chip multiprocessor show that the proposed bn restructuring can improve the performance of densenet-121 by 25.7%.',\n",
       " 264: 'the 20 questions (q20) game is a well known game which encourages deductive reasoning and creativity. in the game, the answerer first thinks of an object such as a famous person or a kind of animal. then the questioner tries to guess the object by asking 20 questions. in a q20 game system, the user is considered as the answerer while the system itself acts as the questioner which requires a good strategy of question selection to figure out the correct object and win the game. however, the optimal policy of question selection is hard to be derived due to the complexity and volatility of the game environment. in this paper, we propose a novel policy-based reinforcement learning (rl) method, which enables the questioner agent to learn the optimal policy of question selection through continuous interactions with users. to facilitate training, we also propose to use a reward network to estimate the more informative reward. compared to previous methods, our rl method is robust to noisy answers and does not rely on the knowledge base of objects. experimental results show that our rl method clearly outperforms an entropy-based engineering system and has competitive performance in a noisy-free simulation environment.',\n",
       " 265: \"it is proved that replica symmetry is not broken in the transverse and longitudinal random field ising model. in this model, the variance of spin overlap of any component vanishes in any dimension almost everywhere in the coupling constant space in the infinite volume limit. the weak fortuin-kasteleyn-ginibre property in this model and the ghirlanda-guerra identities in artificial models in a path integral representation based on the lie-trotter-suzuki formula enable us to extend chatterjee's proof for the random field ising model to the quantum model.\",\n",
       " 266: 'we study vietoris-rips complexes of metric wedge sums and metric gluings. we show that the vietoris-rips complex of a wedge sum, equipped with a natural metric, is homotopy equivalent to the wedge sum of the vietoris-rips complexes. we also provide generalizations for when two metric spaces are glued together along a common isometric subset. as our main example, we deduce the homotopy type of the vietoris-rips complex of two metric graphs glued together along a sufficiently short path (compared to lengths of certain loops in the input graphs). as a result, we can describe the persistent homology, in all homological dimensions, of the vietoris-rips complexes of a wide class of metric graphs.',\n",
       " 267: 'cellular signaling is essential in information processing and decision making. therefore, a variety of experimental approaches have been developed to study signaling on bulk and single-cell level. single-cell measurements of signaling molecules demonstrated a substantial cell-to-cell variability, raising questions about its causes and mechanisms and about how cell populations cope with or exploit cellular heterogeneity. to gain insights from single-cell signaling data, analysis and modeling approaches have been introduced. this review discusses these modeling approaches, with a focus on recent advances in the development and calibration of mechanistic models. additionally, it outlines current and future challenges.',\n",
       " 268: 'the price volatility of cryptocurrencies is often cited as a major hindrance to their wide-scale adoption. consequently, during the last two years, multiple so called stablecoins have surfaced---cryptocurrencies focused on maintaining stable exchange rates. in this paper, we systematically explore and analyze the stablecoin landscape. based on a survey of 24 specific stablecoin projects, we go beyond individual coins for extracting general concepts and approaches. we combine our findings with learnings from classical monetary policy, resulting in a comprehensive taxonomy of cryptocurrency stabilization. we use our taxonomy to highlight the current state of development from different perspectives and show blank spots. for instance, while over 91% of projects promote 1-to-1 stabilization targets to external assets, monetary policy literature suggests that the smoothing of short term volatility is often a more sustainable alternative. our taxonomy bridges computer science and economics, fostering the transfer of expertise. for example, we find that 38% of the reviewed projects use a combination of exchange rate targeting and specific stabilization techniques that can render them vulnerable to speculative economic attacks - an avoidable design flaw.',\n",
       " 269: \"livestock industries are vulnerable to disease threats, which can cost billions of dollars and have substantial negative social ramifications. losses are mitigated through increased use of disease-related biosecurity practices, making increased biosecurity an industry goal. currently, there is no industry-wide standard for sharing information about disease incidence or on-site biosecurity strategies, resulting in uncertainty regarding disease prevalence and biosecurity strategies employed by industry stakeholders. using an experimental simulation game, we examined human participant's willingness to invest in biosecurity when confronted with disease outbreak scenarios. we varied the scenarios by changing the information provided about 1) disease incidence and 2) biosecurity strategy or response by production facilities to the threat of disease. here we show that willingness to invest in biosecurity increases with increased information about disease incidence, but decreases with increased information about biosecurity practices used by nearby facilities. thus, the type or context of the uncertainty confronting the decision maker may be a major factor influencing behavior. our findings suggest that policies and practices that encourage greater sharing of disease incidence information should have the greatest benefit for protecting herd health.\",\n",
       " 270: 'we obtain an example of a compact locally conformal symplectic nilmanifold which admits no locally conformal k\\\\\"ahler metrics. this gives a new positive answer to a question raised by l. ornea and m. verbitsky.',\n",
       " 271: 'we present direct constraints on how the formation of low-mass x-ray binary (lmxb) populations in galactic fields depends on stellar age. in this pilot study, we utilize chandra and hubble space telescope (hst) data to detect and characterize the x-ray point source populations of three nearby early-type galaxies: ngc 3115, 3379, and 3384. the luminosity-weighted stellar ages of our sample span 3-10 gyr. x-ray binary population synthesis models predict that the field lmxbs associated with younger stellar populations should be more numerous and luminous per unit stellar mass than older populations due to the evolution of lmxb donor star masses. crucially, the combination of deep chandra and hst observations allows us to test directly this prediction by identifying and removing counterparts to x-ray point sources that are unrelated to the field lmxb populations, including lmxbs that are formed dynamically in globular clusters, galactic stars, and background agn/galaxies. we find that the \"young\" early-type galaxy ngc 3384 (~2-5 gyr) has an excess of luminous field lmxbs (l_x > (5-10) x 10^37 erg/s) per unit k-band luminosity (l_k; a proxy for stellar mass) than the \"old\" early-type galaxies ngc 3115 and 3379 (~8-10 gyr), which results in a factor of ~2-3 excess of lx/lk for ngc 3384. this result is consistent with the x-ray binary population synthesis model predictions; however, our small galaxy sample size does not allow us to draw definitive conclusions on the evolution field lmxbs in general. we discuss how future surveys of larger galaxy samples that combine deep chandra and hst data could provide a powerful new benchmark for calibrating x-ray binary population synthesis models.',\n",
       " 272: 'differential privacy is a leading protection setting, focused by design on individual privacy. many applications, in medical / pharmaceutical domains or social networks, rather posit privacy at a group level, a setting we call integral privacy. we aim for the strongest form of privacy: the group size is in particular not known in advance. we study a problem with related applications in domains cited above that have recently met with substantial recent press: sampling.   keeping correct utility levels in such a strong model of statistical indistinguishability looks difficult to be achieved with the usual differential privacy toolbox because it would typically scale in the worst case the sensitivity by the sample size and so the noise variance by up to its square. we introduce a trick specific to sampling that bypasses the sensitivity analysis. privacy enforces an information theoretic barrier on approximation, and we show how to reach this barrier with guarantees on the approximation of the target non private density. we do so using a recent approach to non private density estimation relying on the original boosting theory, learning the sufficient statistics of an exponential family with classifiers. approximation guarantees cover the mode capture problem. in the context of learning, the sampling problem is particularly important: because integral privacy enjoys the same closure under post-processing as differential privacy does, any algorithm using integrally privacy sampled data would result in an output equally integrally private. we also show that this brings fairness guarantees on post-processing that would eventually elude classical differential privacy: any decision process has bounded data-dependent bias when the data is integrally privately sampled. experimental results against private kernel density estimation and private gans displays the quality of our results.',\n",
       " 273: \"in this paper we prove a version of curved koszul duality for z/2z-graded curved coalgebras and their cobar differential graded algebras. a curved version of the homological perturbation lemma is also obtained as a useful technical tool for studying curved (co)algebras and precomplexes.   the results of koszul duality can be applied to study the category of matrix factorizations mf(r,w). we show how dyckerhoff's generating results fit into the framework of curved koszul duality theory. this enables us to clarify the relationship between the borel-moore hochschild homology of curved (co)algebras and the ordinary hochschild homology of the category mf(r,w). similar results are also obtained in the orbifold case and in the graded case.\",\n",
       " 274: 'systems of random linear equations may or may not have solutions with all components being non-negative. the question is, e.g., of relevance when the unknowns are concentrations or population sizes. in the present paper we show that if such systems are large the transition between these two possibilities occurs at a sharp value of the ratio between the number of unknowns and the number of equations. we analytically determine this threshold as a function of the statistical properties of the random parameters and show its agreement with numerical simulations. we also make contact with two special cases that have been studied before: the storage problem of a perceptron and the resource competition model of macarthur.',\n",
       " 275: 'we describe the (complex) quaternionic geometry encoded by the embeddings of the riemann sphere, with nonnegative normal bundles.',\n",
       " 276: \"the molecular dynamics simulation package gromacs runs efficiently on a wide variety of hardware from commodity workstations to high performance computing clusters. hardware features are well exploited with a combination of simd, multi-threading, and mpi-based spmd/mpmd parallelism, while gpus can be used as accelerators to compute interactions offloaded from the cpu. here we evaluate which hardware produces trajectories with gromacs 4.6 or 5.0 in the most economical way. we have assembled and benchmarked compute nodes with various cpu/gpu combinations to identify optimal compositions in terms of raw trajectory production rate, performance-to-price ratio, energy efficiency, and several other criteria. though hardware prices are naturally subject to trends and fluctuations, general tendencies are clearly visible. adding any type of gpu significantly boosts a node's simulation performance. for inexpensive consumer-class gpus this improvement equally reflects in the performance-to-price ratio. although memory issues in consumer-class gpus could pass unnoticed since these cards do not support ecc memory, unreliable gpus can be sorted out with memory checking tools. apart from the obvious determinants for cost-efficiency like hardware expenses and raw performance, the energy consumption of a node is a major cost factor. over the typical hardware lifetime until replacement of a few years, the costs for electrical power and cooling can become larger than the costs of the hardware itself. taking that into account, nodes with a well-balanced ratio of cpu and consumer-class gpu resources produce the maximum amount of gromacs trajectory over their lifetime.\",\n",
       " 277: 'when training a deep neural network for image classification, one can broadly distinguish between two types of latent features of images that will drive the classification. we can divide latent features into (i) \"core\" or \"conditionally invariant\" features $x^\\\\text{core}$ whose distribution $x^\\\\text{core}\\\\vert y$, conditional on the class $y$, does not change substantially across domains and (ii) \"style\" features $x^{\\\\text{style}}$ whose distribution $x^{\\\\text{style}} \\\\vert y$ can change substantially across domains. examples for style features include position, rotation, image quality or brightness but also more complex ones like hair color, image quality or posture for images of persons. our goal is to minimize a loss that is robust under changes in the distribution of these style features. in contrast to previous work, we assume that the domain itself is not observed and hence a latent variable.   we do assume that we can sometimes observe a typically discrete identifier or \"$\\\\mathrm{id}$ variable\". in some applications we know, for example, that two images show the same person, and $\\\\mathrm{id}$ then refers to the identity of the person. the proposed method requires only a small fraction of images to have $\\\\mathrm{id}$ information. we group observations if they share the same class and identifier $(y,\\\\mathrm{id})=(y,\\\\mathrm{id})$ and penalize the conditional variance of the prediction or the loss if we condition on $(y,\\\\mathrm{id})$. using a causal framework, this conditional variance regularization (core) is shown to protect asymptotically against shifts in the distribution of the style variables. empirically, we show that the core penalty improves predictive accuracy substantially in settings where domain changes occur in terms of image quality, brightness and color while we also look at more complex changes such as changes in movement and posture.',\n",
       " 278: 'quantized electric quadrupole insulators have recently been proposed as novel quantum states of matter in two spatial dimensions. gapped otherwise, they can feature zero-dimensional topological corner mid-gap states protected by the bulk spectral gap, reflection symmetries and a spectral symmetry. here we introduce a topolectrical circuit design for realizing such corner modes experimentally and report measurements in which the modes appear as topological boundary resonances in the corner impedance profile of the circuit. whereas the quantized bulk quadrupole moment of an electronic crystal does not have a direct analogue in the classical topolectrical-circuit framework, the corner modes inherit the identical form from the quantum case. due to the flexibility and tunability of electrical circuits, they are an ideal platform for studying the reflection symmetry-protected character of corner modes in detail. our work therefore establishes an instance where topolectrical circuitry is employed to bridge the gap between quantum theoretical modelling and the experimental realization of topological band structures.',\n",
       " 279: 'i rebut some erroneous statements and attempt to clear up some misunderstandings in a recent set of critical remarks by marchildon regarding the relativistic transactional interpretation (rti), showing that his negative conclusions regarding the transactional model are ill-founded.',\n",
       " 280: 'we carry out enhanced symmetry analysis of a two-dimensional burgers system. the complete point symmetry group of this system is found using an enhanced version of the algebraic method. lie reductions of the burgers system are comprehensively studied in the optimal way and new lie invariant solutions are constructed. we prove that this system admits no local conservation laws and then study hidden conservation laws, including potential ones. various kinds of hidden symmetries (continuous, discrete and potential ones) are considered for this system as well. we exhaustively describe the solution subsets of the burgers system that are its common solutions with its inviscid counterpart and with the two-dimensional navier-stokes equations. using the method of differential constraints, which is particularly efficient for the burgers system, we construct a number of wide families of solutions of this system that are expressed in terms of solutions of the (1+1)-dimensional linear heat equation although they are not related to the well-known linearizable solution subset of the burgers system.',\n",
       " 281: \"the {\\\\em rank $n$ swapping algebra} is a poisson algebra defined on the set of ordered pairs of points of the circle using linking numbers, whose geometric model is given by a certain subspace of $(\\\\mathbb{k}^n \\\\times \\\\mathbb{k}^{n*})^r/\\\\operatorname{gl}(n,\\\\mathbb{k})$. for any ideal triangulation of $d_k$---a disk with $k$ points on its boundary, using determinants, we find an injective poisson algebra homomorphism from the fraction algebra generated by the fock--goncharov coordinates for $\\\\mathcal{x}_{\\\\operatorname{pgl}_n,d_k}$ to the rank $n$ swapping multifraction algebra for $r=k\\\\cdot(n-1)$ with respect to the (atiyah--bott--)goldman poisson bracket and the swapping bracket. this is the building block of the general surface case. two such injective poisson algebra homomorphisms related to two ideal triangulations $\\\\mathcal{t}$ and $\\\\mathcal{t}'$ are compatible with each other under the flips.\",\n",
       " 282: \"we show that if a graph $g$ with $n \\\\geq 3$ vertices can be drawn in the plane such that each of its edges is involved in at most four crossings, then $g$ has at most $6n-12$ edges. this settles a conjecture of pach, radoi\\\\v{c}i\\\\'{c}, tardos, and t\\\\'oth, and yields a better bound for the famous crossing lemma: the crossing number, $\\\\mbox{cr}(g)$, of a (not too sparse) graph $g$ with $n$ vertices and $m$ edges is at least $c\\\\frac{m^3}{n^2}$, where $c > 1/29$. this bound is known to be tight, apart from the constant $c$ for which the previous best lower bound was $1/31.1$. as another corollary we obtain some progress on the albertson conjecture: albertson conjectured that if the chromatic number of a graph $g$ is $r$, then $\\\\mbox{cr}(g) \\\\geq \\\\mbox{cr}(k_r)$. this was verified by albertson, cranston, and fox for $r \\\\leq 12$, and for $r \\\\leq 16$ by bar\\\\'at and t\\\\'oth. our results imply that albertson conjecture holds for $r \\\\leq 18$.\",\n",
       " 283: 'synthetic biology is a rapidly emerging research area, with expected wide-ranging impact in biology, nanofabrication, and medicine. a key technical challenge lies in embedding computation in molecular contexts where electronic micro-controllers cannot be inserted. this necessitates effective representation of computation using molecular components. while previous work established the turing-completeness of chemical reactions, defining representations that are faithful, efficient, and practical remains challenging. this paper introduces crn++, a new language for programming deterministic (mass-action) chemical kinetics to perform computation. we present its syntax and semantics, and build a compiler translating crn++ programs into chemical reactions, thereby laying the foundation of a comprehensive framework for molecular programming. our language addresses the key challenge of embedding familiar imperative constructs into a set of chemical reactions happening simultaneously and manipulating real-valued concentrations. although some deviation from ideal output value cannot be avoided, we develop methods to minimize the error, and implement error analysis tools. we demonstrate the feasibility of using crn++ on a suite of well-known algorithms for discrete and real-valued computation. crn++ can be easily extended to support new commands or chemical reaction implementations, and thus provides a foundation for developing more robust and practical molecular programs.',\n",
       " 284: 'state estimation estimates the system condition in real-time and provides a base case for other energy management system (ems) applications including real-time contingency analysis and security-constrained economic dispatch. recent work in the literature shows malicious cyber-attack can inject false measurements that bypass traditional bad data detection in state estimation and cause actual overloads. thus, it is very important to detect such cyber-attack. in this paper, multiple metrics are proposed to monitor abnormal load deviations and suspicious branch flow changes. a systematic two-stage approach is proposed to detect false data injection (fdi) cyber-attack. the first stage determines whether the system is under attack while the second stage identifies the target branch. numerical simulations verify that fdi can cause severe system violations and demonstrate the effectiveness of the proposed two-stage fdi detection (fdid) method. it is concluded that the proposed fdid approach can efficiently detect fdi cyber-attack and identify the target branch, which will substantially improve operators situation awareness in real-time.',\n",
       " 285: 'deep learning fostered a leap ahead in automated skin lesion analysis in the last two years. those models are expensive to train and difficult to parameterize. objective: we investigate methodological issues for designing and evaluating deep learning models for skin lesion analysis. we explore 10 choices faced by researchers: use of transfer learning, model architecture, train dataset, image resolution, type of data augmentation, input normalization, use of segmentation, duration of training, additional use of svms, and test data augmentation. methods: we perform two full factorial experiments, for five different test datasets, resulting in 2560 exhaustive trials in our main experiment, and 1280 trials in our assessment of transfer learning. we analyze both with multi-way anova. we use the exhaustive trials to simulate sequential decisions and ensembles, with and without the use of privileged information from the test set. results -- main experiment: amount of train data has disproportionate influence, explaining almost half the variation in performance. of the other factors, test data augmentation and input resolution are the most influential. deeper models, when combined, with extra data, also help. -- transfer experiment: transfer learning is critical, its absence brings huge performance penalties. -- simulations: ensembles of models are the best option to provide reliable results with limited resources, without using privileged information and sacrificing methodological rigor. conclusions and significance: advancing research on automated skin lesion analysis requires curating larger public datasets. indirect use of privileged information from the test set to design the models is a subtle, but frequent methodological mistake that leads to overoptimistic results. ensembles of models are a cost-effective alternative to the expensive full-factorial and to the unstable sequential designs.',\n",
       " 286: 'unsupervised domain adaptation (uda) transfers knowledge from a label-rich source domain to a fully-unlabeled target domain. to tackle this task, recent approaches resort to discriminative domain transfer in virtue of pseudo-labels to enforce the class-level distribution alignment across the source and target domains. these methods, however, are vulnerable to the error accumulation and thus incapable of preserving cross-domain category consistency, as the pseudo-labeling accuracy is not guaranteed explicitly. in this paper, we propose the progressive feature alignment network (pfan) to align the discriminative features across domains progressively and effectively, via exploiting the intra-class variation in the target domain. to be specific, we first develop an easy-to-hard transfer strategy (ehts) and an adaptive prototype alignment (apa) step to train our model iteratively and alternatively. moreover, upon observing that a good domain adaptation usually requires a non-saturated source classifier, we consider a simple yet efficient way to retard the convergence speed of the source classification loss by further involving a temperature variate into the soft-max function. the extensive experimental results reveal that the proposed pfan exceeds the state-of-the-art performance on three uda datasets.',\n",
       " 287: 'weakly disordered two-dimensional superconductors undergo a kosterlitz-thouless (kt) transition, where at a critical temperature vortices proliferate through the system and destroy the superconducting (sc) order. on the other hand, it was suggested that for large disorder the systems separates into regions of high sc order, and it is the percolation of coherence between these regions that is lost at the critical temperature. here we demonstrate that these two descriptions are just the dual of each other. a vortex causes loss of local correlations, and thus the loss of percolation of correlations is concomitant with percolation of vortices on the dual lattice, in the perpendicular direction, i.e. the kt transition.',\n",
       " 288: \"in the article we introduce an analytical solution for reissner's large-deflection finite-strain planar beam subject to an end force and a bending moment. the solution is given in terms of jacobi elliptical functions. the obtained analytical solution is enhanced with numerical examples. a buckling and post buckling behavior of a beam under axial compressive load applied at the end and subject to various boundary conditions is also discussed in some details. in particular, the buckling factor is derived for each case of the boundary conditions.\",\n",
       " 289: 'we survey some results on the existence (and non-existence) of periodic reeb orbits on contact manifolds, both in the open and closed case. we place these statements in the context of finsler geometry by including a proof of the folklore theorem that the finsler geodesic flow can be interpreted as a reeb flow. as a mild extension of previous results we present existence statements on periodic reeb orbits on contact manifolds with suitable supporting open books.',\n",
       " 290: 'gibbs sampling is a widely used markov chain monte carlo (mcmc) method for numerically approximating integrals of interest in bayesian statistics and other mathematical sciences. many implementations of mcmc methods do not extend easily to parallel computing environments, as their inherently sequential nature incurs a large synchronization cost. in the case study illustrated by this paper, we show how to do gibbs sampling in a fully data-parallel manner on a graphics processing unit, for a large class of exchangeable models that admit latent variable representations. our approach takes a systems perspective, with emphasis placed on efficient use of compute hardware. we demonstrate our method on a horseshoe probit regression model and find that our implementation scales effectively to thousands of predictors and millions of data points simultaneously.',\n",
       " 291: 'the technological innovation of the direct conversion of solar energy to electric plays an important role in electric power generation. earlier discussions of band bending in a semiconductor contacting a metal and liquid electrolyte solutions containing redox couples with different electrochemical potentials should not overshadow the fact that under absorption of photons takes place in a solar cell, which can generate free charge for an electrical circuit. here we propose new band bending of zno and cu2o semiconductors induced by a liquid self-assembled microdrop of a physiological salt solution.',\n",
       " 292: 'we consider models of csp based on recording what events are available as possible alternatives to the events that are actually performed. we present many different varieties of such models. for each, we give a compositional semantics, congruent to the operational semantics, and prove full abstraction and no-junk results. we compare the expressiveness of the different models.',\n",
       " 293: 'this paper is a sequel of \"forward analysis for wsts, part i: completions\" [stacs 2009, lzi intl. proc. in informatics 3, 433-444] and \"forward analysis for wsts, part ii: complete wsts\" [logical methods in computer science 8(3), 2012]. in these two papers, we provided a framework to conduct forward reachability analyses of wsts, using finite representations of downwards-closed sets. we further develop this framework to obtain a generic karp-miller algorithm for the new class of very-wsts. this allows us to show that coverability sets of very-wsts can be computed as their finite ideal decompositions. under natural effectiveness assumptions, we also show that ltl model checking for very-wsts is decidable. the termination of our procedure rests on a new notion of acceleration levels, which we study. we characterize those domains that allow for only finitely many accelerations, based on ordinal ranks.',\n",
       " 294: 'we introduce and study a log discrepancy function on the space of semivaluations centered on an integral noetherian scheme of positive characteristic. our definition shares many properties with the analogue in characteristic zero; we prove that if log resolutions exist, then our definition agrees with previous approaches to log discrepancies of semivaluations that these resolutions. we then apply this log discrepancy to a variety of topics in singularity theory over fields of positive characteristic. strong f-regularity and sharp $f$-purity of cartier subalgebras are detected using positivity and non-negativity of log discrepancies of semivaluations, just as kawamata log terminal and log canonical singularities are defined using divisorial log discrepancies, making precise a long-standing heuristic. we prove, in positive characteristic, several theorems of jonsson and mustata in characteristic zero regarding log canonical thresholds of graded sequences of ideals. along the way, we give a valuation-theoretic proof that asymptotic multiplier ideals are coherent on strongly f-regular schemes.',\n",
       " 295: \"in this paper we propose a new method for sharpening and refinements of some trigonometric inequalities. we apply these ideas to some inequalities of wilker-cusa-huygens's type.\",\n",
       " 296: 'we give new combinatorial proofs of known almost-periodicity results for sumsets of sets with small doubling in the spirit of croot and sisask, whose almost-periodicity lemma has had far-reaching implications in additive combinatorics. we provide an alternative (and l^p-norm free) point of view, which allows for proofs to easily be converted to probabilistic algorithms that decide membership in almost-periodic sumsets of dense subsets of f_2^n.   as an application, we give a new algorithmic version of the quasipolynomial bogolyubov-ruzsa lemma recently proved by sanders. together with the results by the last two authors, this implies an algorithmic version of the quadratic goldreich-levin theorem in which the number of terms in the quadratic fourier decomposition of a given function is quasipolynomial in the error parameter, compared with an exponential dependence previously proved by the authors. it also improves the running time of the algorithm to have quasipolynomial dependence instead of an exponential one.   we also give an application to the problem of finding large subspaces in sumsets of dense sets. green showed that the sumset of a dense subset of f_2^n contains a large subspace. using fourier analytic methods, sanders proved that such a subspace must have dimension bounded below by a constant times the density times n. we provide an alternative (and l^p norm-free) proof of a comparable bound, which is analogous to a recent result of croot, laba and sisask in the integers.',\n",
       " 297: 'a partially hyperbolic diffeomorphism $f$ has quasi-shadowing property if for any pseudo orbit ${x_k}_{k\\\\in \\\\mathbb{z}}$, there is a sequence of points ${y_k}_{k\\\\in \\\\mathbb{z}}$ tracing it in which $y_{k+1}$ is obtained from $f(y_k)$ by a motion $\\\\tau$ along the center direction. we show that any partially hyperbolic diffeomorphism has quasi-shadowing property, and if $f$ has $c^1$ center foliation then we can require $\\\\tau$ to move the points along the center foliation. as applications, we show that any partially hyperbolic diffeomorphism is topologically quasi-stable under $c^0$-perturbation. when $f$ has uniformly compact $c^1$ center foliation, we also give partially hyperbolic diffeomorphism versions of some theorems holden for uniformly hyperbolic systems, such as anosov closing lemma, cloud lemma and spectral decomposition theorem.',\n",
       " 298: \"hotelling's $t^2$-test for the mean of a multivariate normal distribution is one of the triumphs of classical multivariate analysis. it is uniformly most powerful among invariant tests, and admissible, proper bayes, and locally and asymptotically minimax among all tests. nonetheless, investigators often prefer non-invariant tests, especially those obtained by selecting only a small subset of variables from which the $t^2$-statistic is to be calculated, because such reduced statistics are more easily interpretable for their specific application. thus it is relevant to ask the extent to which power is lost when variable selection is limited to very small subsets of variables, e.g. of size one (yielding univariate student-$t^2$ tests) or size two (yielding bivariate $t^2$-tests). this study presents some evidence, admittedly fragmentary and incomplete, suggesting that in some cases no power may be lost over a wide range of alternatives.\",\n",
       " 299: \"in this paper we study functions on the interval that have the same persistent homology. by introducing an equivalence relation modeled after topological conjugacy, which we call graph-equivalence, a precise enumeration of functions with the same persistent homology is given, inviting comparisons with arnold's calculus of snakes. the equivalence classes used here are indexed by chiral merge trees, which are binary merge trees where a left-right ordering of the children of each vertex is given. enumeration of merge trees and chiral merge trees with the same persistence makes essential use of the elder rule (a criterion for pairing critical points), which is given a new proof here as well.\",\n",
       " 300: \"consider the problem of modeling memory effects in discrete-state random walks using higher-order markov chains. this paper explores cross validation and information criteria as proxies for a model's predictive accuracy. our objective is to select, from data, the number of prior states of recent history upon which a trajectory is statistically dependent. through simulations, i evaluate these criteria in the case where data are drawn from systems with fixed orders of history, noting trends in the relative performance of the criteria. as a real-world illustrative example of these methods, this manuscript evaluates the problem of detecting statistical dependencies in shot outcomes in free throw shooting. over three nba seasons analyzed, several players exhibited statistical dependencies in free throw hitting probability of various types - hot handedness, cold handedness, and error correction. for the 2013-2014 through 2015-2016 nba seasons, i detected statistical dependencies in 23% of all player-seasons. focusing on a single player, in two of these three seasons, lebron james shot a better percentage after an immediate miss than otherwise. in those seasons, conditioning on the previous outcome makes for a more predictive model than treating free throw makes as independent. when extended to data from the 2016-2017 nba season specifically for lebron james, a model depending on the previous shot (single-step markovian) does not clearly beat a model with independent outcomes. an error-correcting variable length model of two parameters, where james shoots a higher percentage after a missed free throw than otherwise, is more predictive than either model.\",\n",
       " 301: 'measuring conditional dependence is an important topic in statistics with broad applications including graphical models. under a factor model setting, a new conditional dependence measure based on projection is proposed. the corresponding conditional independence test is developed with the asymptotic null distribution unveiled where the number of factors could be high-dimensional. it is also shown that the new test has control over the asymptotic significance level and can be calculated efficiently. a generic method for building dependency graphs without gaussian assumption using the new test is elaborated. numerical results and real data analysis show the superiority of the new method.',\n",
       " 302: 'two fundamental questions in the theory of groebner bases are decision (\"is a basis g of a polynomial ideal a groebner basis?\") and transformation (\"if it is not, how do we transform it into a groebner basis?\") this paper considers the first question. it is well-known that g is a groebner basis if and only if a certain set of polynomials (the s-polynomials) satisfy a certain property. in general there are m(m-1)/2 of these, where m is the number of polynomials in g, but criteria due to buchberger and others often allow one to consider a smaller number.   this paper presents two original results. the first is a new characterization theorem for groebner bases that makes use of a new criterion that extends buchberger\\'s criteria. the second is the identification of a class of polynomial systems g for which the new criterion has dramatic impact, reducing the worst-case scenario from m(m-1)/2 s-polynomials to m-1.',\n",
       " 303: \"in section 1 of the paper, we prove mccoy's property for the zero-divisors of polynomials in semirings. we also investigate zero-divisors of semimodules and prove that under suitable conditions, the monoid semimodule $m[g]$ has very few zero-divisors if and only if the $s$-semimodule $m$ does so. the concept of auslander semimodules are introduced in this section as well. in section 2, we introduce ohm-rush and mccoy semialgebras and prove some interesting results for prime ideals of monoid semirings. in section 3, we investigate the set of zero-divisors of mccoy semialgebras. we also introduce strong krull primes for semirings and investigate their extension in semialgebras.\",\n",
       " 304: 'the imaging atmospheric cherenkov telescope (iact) works by imaging the very short flash of cherenkov radiation generated by the cascade of relativistic charged particles produced when a tev gamma ray strikes the atmosphere. this energetic air shower is initiated at an altitude of 10-30 km depending on the energy and the arrival direction of the primary gamma ray. whether the best image of the shower is obtained by focusing the telescope at infinity and measuring the cherenkov photon angles or focusing on the central region of the shower is a not obvious question. this is particularly true for large size iact for which the depth of the field is much smaller. we address this issue in particular with the fifth telescope (ct5) of the high energy stereoscopic system (h.e.s.s.); a 28 m dish large size telescope recently entered in operation and sensitive to an energy threshold of tens of gevs. ct5 is equipped with a focus system, its working principle and the expected effect of focusing depth on the telescope sensitivity at low energies (50-200 gev) is discussed.',\n",
       " 305: \"we introduce a condition on accretive matrix functions, called $p$-ellipticity, and discuss its applications to the $l^p$ theory of elliptic pde with complex coefficients. our examples are:   (i) generalized convexity of power functions (bellman functions),   (ii) dimension-free bilinear embeddings,   (iii) $l^p$-contractivity of semigroups and   (iv) holomorphic functional calculus.   recent work by dindo\\\\v{s} and pipher (arxiv:1612.01568v3) established close ties between $p$-ellipticity and   (v) regularity theory of elliptic pde with complex coefficients.   the $p$-ellipticity condition arises from studying uniform positivity of a quadratic form associated with the matrix in question on one hand, and the hessian of a power function on the other. our results regarding contractivity extend earlier theorems by cialdea and maz'ya.\",\n",
       " 306: 'this article presents a set of tools for the modeling of a spatial allocation problem in a large geographic market and gives examples of applications. in our settings, the market is described by a network that maps the cost of travel between each pair of adjacent locations. two types of agents are located at the nodes of this network. the buyers choose the most competitive sellers depending on their prices and the cost to reach them. their utility is assumed additive in both these quantities. each seller, taking as given other sellers prices, sets her own price to have a demand equal to the one we observed. we give a linear programming formulation for the equilibrium conditions. after formally introducing our model we apply it on two examples: prices offered by petrol stations and quality of services provided by maternity wards. these examples illustrate the applicability of our model to aggregate demand, rank prices and estimate cost structure over the network. we insist on the possibility of applications to large scale data sets using modern linear programming solvers such as gurobi. in addition to this paper we released a r toolbox to implement our results and an online tutorial (http://optimalnetwork.github.io)',\n",
       " 307: 'the instanton partition functions of $\\\\mathcal{n}=1$ 5d super yang-mills are built using elements of the representation theory of quantum $\\\\mathcal{w}_{1+\\\\infty}$ algebra: gaiotto state, intertwiner, vertex operator. this algebra is also known under the names of ding-iohara-miki and quantum toroidal $\\\\widehat{\\\\mathfrak{gl}}(1)$ algebra. exploiting the explicit action of the algebra on the partition function, we prove the regularity of the 5d qq-characters. these characters provide a solution to the schwinger-dyson equations, and they can also be interpreted as a quantum version of the seiberg-witten curve.',\n",
       " 308: 'we present a general bijective approach to planar hypermaps with two main results. first we obtain unified bijections for all classes of maps or hypermaps defined by face-degree constraints and girth constraints. to any such class we associate bijectively a class of plane trees characterized by local constraints. this unifies and greatly generalizes several bijections for maps and hypermaps. second, we present yet another level of generalization of the bijective approach by considering classes of maps with non-uniform girth constraints. more precisely, we consider \"well-charged maps\", which are maps with an assignment of \"charges\" (real numbers) on vertices and faces, with the constraints that the length of any cycle of the map is at least equal to the sum of the charges of the vertices and faces enclosed by the cycle. we obtain a bijection between charged hypermaps and a class of plane trees characterized by local constraints.',\n",
       " 309: 'this document describes the astronomical data query language (adql). adql has been developed based on sql92. this document describes the subset of the sql grammar supported by adql. special restrictions and extensions to sql92 have been defined in order to support generic and astronomy specific operations.',\n",
       " 310: 'a currently successful approach to computational semantics is to represent words as embeddings in a machine-learned vector space. we present an ensemble method that combines embeddings produced by glove (pennington et al., 2014) and word2vec (mikolov et al., 2013) with structured knowledge from the semantic networks conceptnet (speer and havasi, 2012) and ppdb (ganitkevitch et al., 2013), merging their information into a common representation with a large, multilingual vocabulary. the embeddings it produces achieve state-of-the-art performance on many word-similarity evaluations. its score of $\\\\rho = .596$ on an evaluation of rare words (luong et al., 2013) is 16% higher than the previous best known system.',\n",
       " 311: 'social media can be a double-edged sword for society, either as a convenient channel exchanging ideas or as an unexpected conduit circulating fake news through a large population. while existing studies of fake news focus on theoretical modeling of propagation or identification methods based on machine learning, it is important to understand the realistic mechanisms between theoretical models and black-box methods. here we track large databases of fake news and real news in both, weibo in china and twitter in japan from different culture, which include their complete traces of re-postings. we find in both online social networks that fake news spreads distinctively from real news even at early stages of propagation, e.g. five hours after the first re-postings. our finding demonstrates collective structural signals that help to understand the different propagation evolution of fake news and real news. different from earlier studies, identifying the topological properties of the information propagation at early stages may offer novel features for early detection of fake news in social media.',\n",
       " 312: 'in this article, we apply the methods of our work on fontaine\\'s theory in equal characteristics to the $\\\\varphi/\\\\mathfrak s$-modules of breuil and kisin. thanks to a previous article of kisin, this yields a new and rather elementary proof of the theorem \"weakly admissible implies admissible\" of colmez-fontaine.',\n",
       " 313: 'the prisoner\\'s dilemma game has a long history stretching across the social, biological, and physical sciences. in 2012, press and dyson developed a method for analyzing the mapping of the 8-dimensional strategy profile onto the 2-dimensional payoff space in an infinitely iterated prisoner\\'s dilemma game, based on markov chain analysis and memory-one strategies. we generalize this approach and introduce the concept of strategy parameter to show that linear relations among player payoffs are a ubiquitous feature of the infinitely iterated prisoner\\'s dilemma game. our extended analysis is applied to various strategy profiles including tit-for-tat, win-stay-lose-shift, and other randomized strategy sets. strategy profiles are identified that map onto the vertices, edges, and interior of the prisoner\\'s dilemma quadrilateral in the 2-dimensional payoff (score) space. a damd strategy is defined based solely on \"defection after mutual defection\" and leads to linear relations between player scores using strategy parameter analysis. the damd strategy is shown to result in an equal (reciprocal) or larger (extortive) score for its user compare to the other player, independent of the strategy of the other player. the extortive scores occur when the probabilities for the damd player to cooperate after conflicting plays (cooperate-defect or defect-cooperate) sum to less than 1. the equal reciprocal scores occur when the probabilities for the damd player to cooperate after conflicting plays (cooperate-defect or defect-cooperate) sum to 1. when one player selects the extortive damd, the opposing player can force the equal punishment payoffs for both players in the infinitely iterated prisoner\\'s dilemma by also choosing the damd strategy. possible pathways to mutual cooperation based on damd are discussed.',\n",
       " 314: 'in a multilayer comprising ferromagnet and heavy metal, in-plane carrier spin is induced by applied electric current owing to rashba spin-orbit coupling, while the out-of-plane component is absent. we propose the out-of-plane carrier spin can emerge in ferromagnetic transition-metal dichalcogenides monolayer, by symmetry arguments and first-principles calculations. an intrinsic spin-orbit coupling in the monolayer provides valley-contrasting zeeman-type spin splitting for generating the vertical induced spin. the current direction can be exploited to tune the induced spin, accompanied with valley polarization. the exotic spin accumulation paves an accessible way for perpendicular magnetization switching and electric control of valleys.',\n",
       " 315: 'the pierre auger observatory infers the chemical composition of ultra-high-energy cosmic rays through two independent detection techniques. the fluorescence detector (fd) measures the longitudinal profile of high energy air showers and can determine the depth of the shower maximum $x_{max}$, which is sensitive to the chemical composition of the primary cosmic rays. additionally, measurements by the surface detector (sd) provide independent experimental observables based on the muonic shower component to analyze the chemical composition. we present the results for the $x_{max}$ distributions and the mass composition results measured by the fd and the sd for the energies $e \\\\geq 10^{18}$\\\\,ev. the data will be compared with the expectations for proton and iron primaries according to different hadronic interaction models.',\n",
       " 316: 'this work is concerned with modeling and simulation of the mitral valve, one of the four valves in the human heart. the valve is composed of leaflets, the free edges of which are supported by a system of chordae, which themselves are anchored to the papillary muscles inside the left ventricle. first, we examine valve anatomy and present the results of original dissections. these display the gross anatomy and information on fiber structure of the mitral valve. next, we build a model valve following a design-based methodology, meaning that we derive the model geometry and the forces that are needed to support a given load, and construct the model accordingly. we incorporate information from the dissections to specify the fiber topology of this model. we assume the valve achieves mechanical equilibrium while supporting a static pressure load. the solution to the resulting differential equations determines the pressurized configuration of the valve model. to complete the model we then specify a constitutive law based on a stress-strain relation consistent with experimental data that achieves the necessary forces computed in previous steps. finally, using the immersed boundary method, we simulate the model valve in fluid in a computer test chamber. the model opens easily and closes without leak when driven by physiological pressures over multiple beats. further, its closure is robust to driving pressures that lack atrial systole or are much lower or higher than normal.',\n",
       " 317: 'in the modern era where highly-commodified cultural products compete heavily for mass consumption, finding the principles behind the complex process of how successful, \"hit\" products emerge remains a vital scientific goal that requires an interdisciplinary approach. here we present a framework for tracing the cycle of prosperity-and-decline of a product to find insights into influential and potent factors that determine its success. as a rapid, high-throughput indicator of the preference of the public, popularity charts have emerged as a useful information source for finding the market performance patterns of products over time, which we call the on-chart life trajectories that show how the products enter the chart, fare inside it, and eventually exit from it. we propose quantitative parameters to characterise a life trajectory, and analyse a large-scale data set of nearly $7\\\\,000$ songs from gaon chart, a major weekly korean pop (k-pop) chart that cover a span of six years. we find that a significant role is played by non-musical extrinsic factors such as the established fan base of the artist and the might of production companies in the on-chart success of songs, strongly indicative of the commodified nature of modern cultural products. we also review a possible mathematical model of this phenomenon, and discuss several nontrivial yet intriguing trajectories that we call the \"late bloomers\" and the \"re-entrants\" that appears to be strongly driven by serendipitous exposure on mass media and the changes of seasons.',\n",
       " 318: \"we develop a variant of multiclass logistic regression that is significantly more robust to noise. the algorithm has one weight vector per class and the surrogate loss is a function of the linear activations (one per class). the surrogate loss of an example with linear activation vector $\\\\mathbf{a}$ and class $c$ has the form $-\\\\log_{t_1} \\\\exp_{t_2} (a_c - g_{t_2}(\\\\mathbf{a}))$ where the two temperatures $t_1$ and $t_2$ ''temper'' the $\\\\log$ and $\\\\exp$, respectively, and $g_{t_2}(\\\\mathbf{a})$ is a scalar value that generalizes the log-partition function. we motivate this loss using the tsallis divergence. our method allows transitioning between non-convex and convex losses by the choice of the temperature parameters. as the temperature $t_1$ of the logarithm becomes smaller than the temperature $t_2$ of the exponential, the surrogate loss becomes ''quasi convex''. various tunings of the temperatures recover previous methods and tuning the degree of non-convexity is crucial in the experiments. in particular, quasi-convexity and boundedness of the loss provide significant robustness to the outliers. we explain this by showing that $t_1 < 1$ caps the surrogate loss and $t_2 >1$ makes the predictive distribution have a heavy tail.   we show that the surrogate loss is bayes-consistent, even in the non-convex case. additionally, we provide efficient iterative algorithms for calculating the log-partition value only in a few number of iterations. our compelling experimental results on large real-world datasets show the advantage of using the two-temperature variant in the noisy as well as the noise free case.\",\n",
       " 319: 'a dramatic progress in the field of computer vision has been made in recent years by applying deep learning techniques. state-of-the-art performance in image recognition is thereby reached with convolutional neural networks (cnns). cnns are a powerful class of artificial neural networks, characterized by requiring fewer connections and free parameters than traditional neural networks and exploiting spatial symmetries in the input data. moreover, cnns have the ability to automatically extract general characteristic features from data sets and create abstract data representations which can perform very robust predictions. this suggests that experiments using cherenkov telescopes could harness these powerful machine learning algorithms to improve the analysis of particle-induced air-showers, where the properties of primary shower particles are reconstructed from shower images recorded by the telescopes. in this work, we present initial results of a cnn-based analysis for background rejection and shower reconstruction, utilizing simulation data from the h.e.s.s. experiment. we concentrate on supervised training methods and outline the influence of image sampling on the performance of the cnn-model predictions.',\n",
       " 320: 'in this paper, we investigate a sheaf-theoretic interpretation of stratification learning from geometric and topological perspectives. our main result is the construction of stratification learning algorithms framed in terms of a sheaf on a partially ordered set with the alexandroff topology. we prove that the resulting decomposition is the unique minimal stratification for which the strata are homogeneous and the given sheaf is constructible. in particular, when we choose to work with the local homology sheaf, our algorithm gives an alternative to the local homology transfer algorithm given in bendich et al. (2012), and the cohomology stratification algorithm given in nanda (2017). additionally, we give examples of stratifications based on the geometric techniques of breiding et al. (2018), illustrating how the sheaf-theoretic approach can be used to study stratifications from both topological and geometric perspectives. this approach also points toward future applications of sheaf theory in the study of topological data analysis by illustrating the utility of the language of sheaf theory in generalizing existing algorithms.',\n",
       " 321: 'we propose the algorithms for online convex optimization which lead to cumulative squared constraint violations of the form $\\\\sum\\\\limits_{t=1}^t\\\\big([g(x_t)]_+\\\\big)^2=o(t^{1-\\\\beta})$, where $\\\\beta\\\\in(0,1)$. previous literature has focused on long-term constraints of the form $\\\\sum\\\\limits_{t=1}^tg(x_t)$. there, strictly feasible solutions can cancel out the effects of violated constraints. in contrast, the new form heavily penalizes large constraint violations and cancellation effects cannot occur.   furthermore, useful bounds on the single step constraint violation $[g(x_t)]_+$ are derived.   for convex objectives, our regret bounds generalize existing bounds, and for strongly convex objectives we give improved regret bounds.   in numerical experiments, we show that our algorithm closely follows the constraint boundary leading to low cumulative violation.',\n",
       " 322: 'we use the nihao simulations to investigate the effects of baryonic physics on the time evolution of dark matter central density profiles. the sample is made of $\\\\approx 70$ independent high resolution hydrodynamical simulations of galaxy formation and covers a wide mass range: 1e10< mhalo <1e12, i.e., from dwarfs to l* . we confirm previous results on the dependence of the inner dark matter density slope, $\\\\alpha$, on the ratio between stellar-to-halo mass. we show that this relation holds approximately at all redshifts (with an intrinsic scatter of ~0.18 in $\\\\alpha$). this implies that in practically all haloes the shape of their inner density profile changes quite substantially over cosmic time, as they grow in stellar and total mass. thus, depending on their final stellar-to-halo mass ratio, haloes can either form and keep a substantial density core (size~1 kpc), or form and then destroy the core and re-contract the halo, going back to a cuspy profile, which is even steeper than cdm predictions for massive galaxies (~1e12 msun). we show that results from the nihao suite are in good agreement with recent observational measurements of $\\\\alpha$ in dwarf galaxies. overall our results suggest that the notion of a universal density profile for dark matter haloes is no longer valid in the presence of galaxy formation.',\n",
       " 323: 'amongst the population of tev gamma-ray sources detected with the high energy stereoscopic system (h.e.s.s.) in the galactic plane, clearly identified supernova remnant (snr) shells constitute a small but precious source class. tev-selected snrs are prime candidates for sources of efficient cosmic-ray acceleration. in this work, we present new snr candidates that have been identified in the entire h.e.s.s. phase i data set of the galactic plane recorded over the past ten years. identification with a known snr shell candidate was successful for one new source, hess j1534-571. in other cases, tev-only shell candidates are challenging to firmly identify as snrs due to their lack of detected non-thermal emission in lower energy bands. we will discuss how these objects may present an important link between young and evolved snrs, since their shell emission may be dominated by hadronic processes.',\n",
       " 324: \"in this paper, the third in a series illustrating the power of generalized linear models (glms) for the astronomical community, we elucidate the potential of the class of glms which handles count data. the size of a galaxy's globular cluster population $n_{\\\\rm gc}$ is a prolonged puzzle in the astronomical literature. it falls in the category of count data analysis, yet it is usually modelled as if it were a continuous response variable. we have developed a bayesian negative binomial regression model to study the connection between $n_{\\\\rm gc}$ and the following galaxy properties: central black hole mass, dynamical bulge mass, bulge velocity dispersion, and absolute visual magnitude. the methodology introduced herein naturally accounts for heteroscedasticity, intrinsic scatter, errors in measurements in both axes (either discrete or continuous), and allows modelling the population of globular clusters on their natural scale as a non-negative integer variable. prediction intervals of 99% around the trend for expected $n_{\\\\rm gc}$comfortably envelope the data, notably including the milky way, which has hitherto been considered a problematic outlier. finally, we demonstrate how random intercept models can incorporate information of each particular galaxy morphological type. bayesian variable selection methodology allows for automatically identifying galaxy types with different productions of gcs, suggesting that on average s0 galaxies have a gc population 35% smaller than other types with similar brightness.\",\n",
       " 325: 'log-brunn-minkowski inequality was conjectured by bor\\\\\"oczky, lutwak, yang and zhang \\\\cite{blyz}, and it states that a certain strengthening of the classical brunn-minkowski inequality is admissible in the case of symmetric convex sets. it was recently shown by nayar, zvavitch, the second and the third authors \\\\cite{lmnz}, that log-brunn-minkowski inequality implies a certain dimensional brunn-minkowski inequality for log-concave measures, which in the case of gaussian measure was conjectured by gardner and zvavitch \\\\cite{gz}.   in this note, we obtain stability results for both log-brunn-minkowski and dimensional brunn-minkowski inequalities for rotation invariant log-conave measures near a ball. remarkably, the assumption of symmetry is only necessary for log-brunn-minkowski stability, which emphasizes an important difference between the two conjectured inequalities.   also, we determine the infinitesimal version of the log-brunn-minkowski inequality. as a consequence, we obtain a strong poincar\\\\\\'{e}-type inequality in the case of unconditional convex sets, as well as for symmetric convex sets on the plane.   additionally, we derive an infinitesimal equivalent version of the b-conjecture for an arbitrary measure.',\n",
       " 326: 'neural circuits are able to perform computations under very diverse conditions and requirements. the required computations impose clear constraints on their fine-tuning: a rapid and maximally informative response to stimuli in general requires decorrelated baseline neural activity. such network dynamics is known as asynchronous-irregular. in contrast, spatio-temporal integration of information requires maintenance and transfer of stimulus information over extended time periods. this can be realized at criticality, a phase transition where correlations, sensitivity and integration time diverge. being able to flexibly switch, or even combine the above properties in a task-dependent manner would present a clear functional advantage. we propose that cortex operates in a \"reverberating regime\" because it is particularly favorable for ready adaptation of computational properties to context and task. this reverberating regime enables cortical networks to interpolate between the asynchronous-irregular and the critical state by small changes in effective synaptic strength or excitation-inhibition ratio. these changes directly adapt computational properties, including sensitivity, amplification, integration time and correlation length within the local network. we review recent converging evidence that cortex in vivo operates in the reverberating regime, and that various cortical areas have adapted their integration times to processing requirements. in addition, we propose that neuromodulation enables a fine-tuning of the network, so that local circuits can either decorrelate or integrate, and quench or maintain their input depending on task. we argue that this task-dependent tuning, which we call \"dynamic adaptive computation\", presents a central organization principle of cortical networks and discuss first experimental evidence.',\n",
       " 327: 'improving the accuracy and thus broadening the applicability of electronic density functional theory (dft) is crucial to many research areas, from material science, to theoretical chemistry, biophysics and biochemistry. in the last three years, the mathematical structure of the strong-interaction limit of density functional theory has been uncovered, and exact information on this limit has started to become available. the aim of this paper is to give a perspective on how this new piece of exact information can be used to treat situations that are problematic for standard kohn-sham dft. one way to use the strong-interaction limit, more relevant for solid-state physical devices, is to define a new framework to do practical, non-conventional, dft calculations in which a strong-interacting reference system is used instead of the traditional non-interacting one of kohn and sham. another way to proceed, more related to chemical applications, is to include the exact treatment of the strong-interaction limit into approximate exchange-correlation energy density functionals in order to describe difficult situations such as the breaking of the chemical bond.',\n",
       " 328: 'convolutional networks have achieved great success in various vision tasks. this is mainly due to a considerable amount of research on network structure. in this study, instead of focusing on architectures, we focused on the convolution unit itself. the existing convolution unit has a fixed shape and is limited to observing restricted receptive fields. in earlier work, we proposed the active convolution unit (acu), which can freely define its shape and learn by itself. in this paper, we provide a detailed analysis of the previously proposed unit and show that it is an efficient representation of a sparse weight convolution. furthermore, we extend an acu to a grouped acu, which can observe multiple receptive fields in one layer. we found that the performance of a naive grouped convolution is degraded by increasing the number of groups; however, the proposed unit retains the accuracy even though the number of parameters decreases. based on this result, we suggest a depthwise acu, and various experiments have shown that our unit is efficient and can replace the existing convolutions.',\n",
       " 329: 'backlash, also known as mechanical play, is a piecewise differentiable nonlinearity which exists in several actuated systems, comprising, e.g., rack-and-pinion drives, shaft couplings, toothed gears, and other machine elements. generally, the backlash is nested between the moving parts of a complex dynamic system, which handicaps its proper detection and identification. a classical example is the two-mass system which can approximate numerous mechanisms connected by a shaft (or link) with relatively high stiffness and backlash in series. information about the presence and extent of the backlash is seldom exactly known and is rather conditional upon factors such as wear, fatigue and incipient failures in the components. this paper proposes a novel backlash identification method using one-side sensing of a two-mass system. the method is based on the delayed relay operator in feedback that allows stable and controllable limit cycles to be induced and operated within the (unknown) backlash gap. the system model, with structural transformations required for the one-side backlash measurements, is given, along with the analysis of the delayed relay in velocity feedback. experimental evaluations are shown for a two-inertia motor bench that has coupling with backlash gap of about one degree.',\n",
       " 330: 'in this paper we study the topological t-dual of spaces with a non-free circle action mainly using the stack theory method of bunke and co-workers \\\\cite{bunke1}. we first compare three formalisms for obtaining the topological t-dual of a semi-free $s^1$-space in a simple example. then, we calculate the t-dual of general kk-monopole backgrounds using the stack theory method. we define the dyonic coordinate for these backgrounds. we introduce an approach to topological t-duality using classifying spaces which simultaneously generalizes the methods of bunke et al \\\\cite{bunke1} and mathai and wu \\\\cite{mawu}. then, we define a cohomology gysin sequence for prinicpal bundles of stacks and describe an application to topological t-duality for stacks. we apply the above to calculate the topological t-dual of a general compact three-manifold with an {\\\\em arbitrary} smooth circle action. we point out a possible application of these t-duals to higher-dimensional black holes.',\n",
       " 331: 'this paper investigates the construction of rank-metric codes with specified ferrers diagram shapes. these codes play a role in the multilevel construction for subspace codes. a conjecture from 2009 provides an upper bound for the dimension of a rank-metric code with given specified ferrers diagram shape and rank distance. while the conjecture in its generality is wide open, several cases have been established in the literature. this paper contributes further cases of ferrers diagrams and ranks for which the conjecture holds true. in addition, the proportion of maximal ferrers diagram codes within the space of all rank-metric codes with the same shape and dimension is investigated. special attention is being paid to mrd codes. it is shown that for growing field size the limiting proportion depends highly on the ferrers diagram. for instance, for $[m\\\\times 2]$-mrd codes with rank~$2$ this limiting proportion is close to $1/e$.',\n",
       " 332: 'we prove the ramsey property for classes of ordered structures with closures and given local properties. this generalises earlier results: the ne\\\\v{s}et\\\\v{r}il-r\\\\\"odl theorem, the ramsey property of partial orders and metric spaces as well as the authors\\' ramsey lift of bowtie-free graphs. we use this framework to solve several open problems and give new examples of ramsey classes. among others, we find ramsey lifts of convexly ordered $s$-metric spaces and prove the ramsey theorem for finite models (i.e. structures with both functions and relations) thus providing the ultimate generalisation of the structural ramsey theorem. both of these results are natural, and easy to state, yet their proofs involve most of the theory developed here.   we also characterise ramsey lifts of classes of structures defined by finitely many forbidden homomorphisms and extend this to special cases of classes with closures. this has numerous applications. for example, we find ramsey lifts of many cherlin-shelah-shi classes.',\n",
       " 333: \"we examine two recent artificial intelligence (ai) based deep learning algorithms for visual blending in convolutional neural networks (mordvintsev et al. 2015, gatys et al. 2015). to investigate the potential value of these algorithms as tools for computational creativity research, we explain and schematize the essential aspects of the algorithms' operation and give visual examples of their output. we discuss the relationship of the two algorithms to human cognitive science theories of creativity such as conceptual blending theory and honing theory, and characterize the algorithms with respect to generation of novelty and aesthetic quality.\",\n",
       " 334: 'we present soseleto (source selection for target optimization), a new method for exploiting a source dataset to solve a classification problem on a target dataset. soseleto is based on the following simple intuition: some source examples are more informative than others for the target problem. to capture this intuition, source samples are each given weights; these weights are solved for jointly with the source and target classification problems via a bilevel optimization scheme. the target therefore gets to choose the source samples which are most informative for its own classification task. furthermore, the bilevel nature of the optimization acts as a kind of regularization on the target, mitigating overfitting. soseleto may be applied to both classic transfer learning, as well as the problem of training on datasets with noisy labels; we show state of the art results on both of these problems.',\n",
       " 335: 'the present article provides an efficient and accurate hybrid method to price american standard options in certain jump-diffusion models as well as american barrier-type options under the black & scholes framework. our method generalizes the quadratic approximation scheme of barone-adesi & whaley (1987) and several of its extensions. using perturbative arguments, we decompose the early exercise pricing problem into sub-problems of different orders and solve these sub-problems successively. the obtained solutions are combined to recover approximations to the original pricing problem of multiple orders, with the 0-th order version matching the general barone-adesi & whaley ansatz. we test the accuracy and efficiency of the approximations via numerical simulations. the results show a clear dominance of higher order approximations over their respective 0-th order version and reveal that significantly more pricing accuracy can be obtained by relying on approximations of the first few orders. additionally, they suggest that increasing the order of any approximation by one generally refines the pricing precision, however that this happens at the expense of greater computational costs.',\n",
       " 336: \"let $g$ be an undirected bipartite graph with positive integer weights on the edges. we refine the existing decomposition theorem originally proposed by kao et al., for computing maximum weight bipartite matching. we apply it to design an efficient version of the decomposition algorithm to compute the weight of a maximum weight bipartite matching of $g$ in $o(\\\\sqrt{|v|}w'/k(|v|,w'/n))$-time by employing an algorithm designed by feder and motwani as a subroutine, where $|v|$ and $n$ denote the number of nodes and the maximum edge weight of $g$, respectively and $k(x,y)=\\\\log x /\\\\log(x^2/y)$. the parameter $w'$ is smaller than the total edge weight $w,$ essentially when the largest edge weight differs by more than one from the second largest edge weight in the current working graph in any decomposition step of the algorithm. in best case $w'=o(|e|)$ where $|e|$ be the number of edges of $g$ and in worst case $w'=w,$ that is, $|e| \\\\leq w' \\\\leq w.$ in addition, we talk about a scaling property of the algorithm and research a better bound of the parameter $w'$. an experimental evaluation on randomly generated data shows that the proposed improvement is significant in general.\",\n",
       " 337: 'gamma-ray astronomy holds a great potential for astrophysics, particle physics and cosmology. the cta is an inter- national initiative to build the next generation of ground-based gamma-ray observatories, which will represent a factor of 5-10 times improvement in the sensitivity of observations in the range 100 gev - 10 tev, as well as an extension of the observational capabilities down to energies below 100 gev and beyond 100 tev. the array will consist of two telescope networks (one in the northern hemisphere and another in the south) so to achieve a full-sky coverage, and will be com- posed by a hybrid system of 4 different telescope types. it will operate as an observatory, granting open access to the community through calls for submission of proposals competing for observation time. the cta will give us access to the non-thermal and high-energy universe at an unprecedented level, and will be one of the main instruments for high-energy astrophysics and astroparticle physics of the next 30 years. cta has now entered its prototyping phase with the first, stand-alone instruments being built. brazil is an active member of the cta consortium, and the project is represented in latin america also by argentina, mexico and chile. in the next few months the consortium will define the site for instal- lation of cta south, which might come to be hosted in the chilean andes, with important impact for the high-energy community in latin america. in this talk we will present the basic concepts of the cta and the detailed project of the observatory. emphasis will be put on its scientific potential and on the latin-american involvement in the preparation and construction of the observatory, whose first seed, the astri mini-array, is currently being constructed in sicily, in a cooperation between italy, brazil and south africa.',\n",
       " 338: 'we study the 2d ginzburg-landau theory for a type-ii superconductor in an applied magnetic field varying between the second and third critical value. in this regime the order parameter minimizing the gl energy is concentrated along the boundary of the sample and is well approximated to leading order by a simplified 1d profile in the direction perpendicular to the boundary. motivated by a conjecture of xing-bin pan, we address the question of whether this approximation can hold uniformly in the boundary region. we prove that this is indeed the case as a corollary of a refined, second order energy expansion including contributions due to the curvature of the sample. local variations of the gl order parameter are controlled by the second order term of this energy expansion, which allows us to prove the desired uniformity of the surface superconductivity layer.',\n",
       " 339: 'synchronization of neurons forming a network with a hierarchical structure is essential for the brain to be able to function optimally. in this paper we study synchronization of phase oscillators on the most basic example of such a network, namely, the hierarchical lattice. each site of the lattice carries an oscillator that is subject to noise. pairs of oscillators interact with each other at a strength that depends on their hierarchical distance, modulated by a sequence of interaction parameters. we look at block averages of the oscillators on successive hierarchical scales, which we think of as block communities. in the limit as the number of oscillators per community tends to infinity, referred to as the hierarchical mean-field limit, we find a separation of time scales, i.e., each block community behaves like a single oscillator evolving on its own time scale. we argue that the evolution of the block communities is given by a renormalized mean-field noisy kuramoto equation, with a synchronization level that depends on the hierarchical scale of the block community. we find three universality classes for the synchronization levels on successive hierarchical scales, characterized in terms of the sequence of interaction parameters.   what makes our model specifically challenging is the non-linearity of the interaction betweenthe oscillators. the main results of our paper therefore come in three parts: (i) a conjecture about the nature of the renormalisation transformation connecting successive hierarchical scales; (ii) a truncation approximation that leads to a simplified renormalization transformation; (iii) a rigorous analysis of the simplified renormalization transformation. we provide compelling arguments in support of (i) and (ii), but a full verification remains an open problem.',\n",
       " 340: 'we apply analytic conformal bootstrap ideas in mellin space to conformal field theories with $o(n)$ symmetry and cubic anisotropy. we write down the conditions arising from the consistency between the operator product expansion and crossing symmetry in mellin space. we solve the constraint equations to compute the anomalous dimension and the ope coefficients of all operators quadratic in the fields in the epsilon expansion. we reproduce known results and derive new results up to $o(\\\\epsilon^3)$. for the $o(n)$ case, we also study the large $n$ limit in general dimensions and reproduce known results at the leading order in $1/n$.',\n",
       " 341: 'we consider a system where dark matter dynamics is enriched by the presence of clustering quintessence in the approximation where the system is effectively reduced to one degree of freedom. we study the corresponding observables up to one-loop order and then point out similarities between the power spectrum of the reduced system and the behaviour of non-equal time pure dark matter correlators. we then focus on the one-loop total density power spectrum in the ir limit as a diagnostic tool for consistency relations breaking. unlike the non-equal time case, the reduced system does still obey consistency relations; we illustrate this by explicitly verifying the 1-loop ir cancellation. a more general setup, obtained by relaxing the assumption of a vanishing sound speed, is also analyzed. in this and similar scenarios the presence of additional dynamics, typical of dark energy and modified gravity models, implies that one may no longer gauge away the squeezed contribution of observables such as the dark matter bispectrum. we show how these effects propagate all the way to biased tracers.',\n",
       " 342: \"adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. in this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. by enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. we demonstrate that our proposed variational discriminator bottleneck (vdb) leads to significant improvements across three distinct application areas for adversarial learning algorithms. our primary evaluation studies the applicability of the vdb to imitation learning of dynamic continuous control skills, such as running. we show that our method can learn such skills directly from \\\\emph{raw} video demonstrations, substantially outperforming prior adversarial imitation learning methods. the vdb can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. finally, we demonstrate that vdb can train gans more effectively for image generation, improving upon a number of prior stabilization methods.\",\n",
       " 343: 'we study effects of high-energy particles on the accretion flows onto a supermassive black hole and luminosities of escaping particles such as protons, neutrons, gamma-rays, and neutrinos. we formulate a one-dimensional model of the two-component accretion flow consisting of thermal particles and high-energy particles, supposing that some fraction of the released energy is converted to the acceleration of the high-energy particles. the thermal component is governed by fluid dynamics while the high-energy particles obey the moment equations of the diffusion-convection equation. by solving the time evolution of these equations, we obtain advection dominated flows as the steady state solutions. effects of the high-energy particles on the flow structures turn out to be small even if the pressure of the high-energy particles dominates over the thermal pressure. for a model in which the escaping protons take away almost all the released energy, the high-energy particles have large influence enough to make the flow have the keplerian angular velocity at the inner region. we calculate the luminosities of the escaping particles for these steady solutions. the escaping particles can extract the energy from about $10^{-4}\\\\dot m c^2$ to $10^{-2}\\\\dot m c^2$, where $\\\\dot m$ is the mass accretion rates. the luminosities of the escaping particles depend on the parameters such as the injection lorentz factors, the mass accretion rates, and the diffusion coefficients. we also discuss some implications on the relativistic jet production by the escaping particles.',\n",
       " 344: 'lopes is a digitally read out antenna array consisting of 30 calibrated dipole antennas. it is located at the site of the kascade-grande experiment at forschungszentrum karlsruhe and measures the radio emission of cosmic ray air showers in the frequency band from 40 to 80 mhz. lopes is triggered by kascade and uses the kascade reconstruction of the shower axis as an input for the analysis of the radio pulses. thereby lopes works as an interferometer when the signal of all antennas is digitally merged to form a beam into the shower direction. to be sensitive to the coherence of the radio signal, a precise time calibration with an accuracy in the order of 1 ns is required. thus, it is necessary to know the delay of each antenna which is time and frequency dependent. several calibration measurements are performed to correct for this delay in the analysis: the group delay of every antenna is measured regularly (roughly once per year) by recording a test pulse which is emitted at a known time. furthermore, the delay is monitored continuously by the so called phase calibration method: a beacon (a dipole antenna) emits continuously two sine waves at 63.5 mhz and 68.1 mhz. by that a variation of the delay can be detected in a subsequent analysis of the radio events as a change of the phase at these frequencies. finally, the dispersion of the analog electronics has been measured to account for the frequency dependence of the delay.',\n",
       " 345: 'in this article, we present data-subsetting algorithms that allow for the approximate and scalable implementation of the bayesian bootstrap. they are analogous to two existing algorithms in the frequentist literature: the bag of little bootstraps (kleiner et al., 2014) and the subsampled double bootstrap (sdb; sengupta et al., 2016). our algorithms have appealing theoretical and computational properties that are comparable to those of their frequentist counterparts. additionally, we provide a strategy for performing lossless inference for a class of functionals of the bayesian bootstrap, and briefly introduce extensions to the dirichlet process.',\n",
       " 346: 'sen attached to each p-adic galois representation of a p-adic field a multiset of numbers called generalized hodge-tate weights. in this paper, we discuss a rigidity of these numbers in a geometric family. more precisely, we consider a p-adic local system on a rigid analytic variety over a p-adic field and show that the multiset of generalized hodge-tate weights of the local system is constant. the proof uses the p-adic riemann-hilbert correspondence by liu and zhu, a sen-fontaine decompletion theory in the relative setting, and the theory of formal connections. we also discuss basic properties of hodge-tate sheaves on a rigid analytic variety.',\n",
       " 347: 'data structures that allow efficient distance estimation (distance oracles, distance sketches, etc.) have been extensively studied, and are particularly well studied in centralized models and classical distributed models such as congest. we initiate their study in newer (and arguably more realistic) models of distributed computation: the congested clique model and the massively parallel computation (mpc) model. we provide efficient constructions in both of these models, but our core results are for mpc. in mpc we give two main results: an algorithm that constructs stretch/space optimal distance sketches but takes a (small) polynomial number of rounds, and an algorithm that constructs distance sketches with worse stretch but that only takes polylogarithmic rounds.   along the way, we show that other useful combinatorial structures can also be computed in mpc. in particular, one key component we use to construct distance sketches are an mpc construction of the hopsets of elkin and neiman (2016). this result has additional applications such as the first polylogarithmic time algorithm for constant approximate single-source shortest paths for weighted graphs in the low memory mpc setting.',\n",
       " 348: 'we study the problem of motion feasibility for multiagent control systems on lie groups with collision avoidance constraints. we first consider the problem for kinematic left invariant control systems and next, for dynamical control systems given by a left-trivialized lagrangian function. solutions of the kinematic problem give rise to linear combinations of the control inputs in a linear subspace annihilating the collision avoidance constraints. in the dynamical problem, motion feasibility conditions are obtained by using techniques from variational calculus on manifolds, given by a set of equations in a vector space, and lagrange multipliers annihilating the constraint force that prevents deviation of solutions from a constraint submanifold.',\n",
       " 349: \"the goal of this paper is to clarify when a semilinear stochastic partial differential equation driven by l\\\\'evy processes admits an affine realization. our results are accompanied by several examples arising in natural sciences and economics.\",\n",
       " 350: 'in the present work we study elliptic operators on manifolds with singularities in the situation, when the manifold is endowed with an action of a discrete group $g$. as usual in elliptic theory, the fredholm property of an operator is governed by the properties of its principal symbol. we show that the principal symbol in our situation is a pair, consisting of the symbol on the main stratum (interior symbol) and the symbol at the conical point (conormal symbol). fredholm property of elliptic elements is obtained.',\n",
       " 351: 'albeit epidemic models have evolved into powerful predictive tools for the spread of diseases and opinions, most assume memoryless agents and independent transmission channels. we develop an infection mechanism that is endowed with memory of past exposures and simultaneously incorporates the joint effect of multiple infectious sources. analytic equations and simulations of the susceptible-infected-susceptible model in unstructured substrates reveal the emergence of an additional phase that separates the usual healthy and endemic ones. this intermediate phase shows fundamentally distinct characteristics, and the system exhibits either excitability or an exotic variant of bistability. moreover, the transition to endemicity presents hybrid aspects. these features are the product of an intricate balance between two memory modes and indicate that non-markovian effects significantly alter the properties of spreading processes.',\n",
       " 352: 'rumour is a collective emergent phenomenon with a potential for provoking a crisis. modelling approaches have been deployed since five decades ago; however, the focus was mostly on epidemic behaviour of the rumours which does not take into account the differences of the agents. we use social practice theory to model agent decision making in organizational rumourmongering. such an approach provides us with an opportunity to model rumourmongering agents with a layer of cognitive realism and study the impacts of various intervention strategies for prevention and control of rumours in organizations.',\n",
       " 353: 'exploiting low-rank structure of the user-item rating matrix has been the crux of many recommendation engines. however, existing recommendation engines force raters with heterogeneous behavior profiles to map their intrinsic rating scales to a common rating scale (e.g. 1-5). this non-linear transformation of the rating scale shatters the low-rank structure of the rating matrix, therefore resulting in a poor fit and consequentially, poor recommendations. in this paper, we propose clustered monotone transforms for rating factorization (cmtrf), a novel approach to perform regression up to unknown monotonic transforms over unknown population segments. essentially, for recommendation systems, the technique searches for monotonic transformations of the rating scales resulting in a better fit. this is combined with an underlying matrix factorization regression model that couples the user-wise ratings to exploit shared low dimensional structure. the rating scale transformations can be generated for each user, for a cluster of users, or for all the users at once, forming the basis of three simple and efficient algorithms proposed in this paper, all of which alternate between transformation of the rating scales and matrix factorization regression. despite the non-convexity, cmtrf is theoretically shown to recover a unique solution under mild conditions. experimental results on two synthetic and seven real-world datasets show that cmtrf outperforms other state-of-the-art baselines.',\n",
       " 354: \"acoustic excitations in topologically disordered media at mesoscale present anomalous features with respect to the debye's theory. in a three-dimensional medium an acoustic excitation is characterized by its phase velocity, intensity and polarization. the so-called rayleigh anomalies, which manifest in attenuation and retardation of the acoustic excitations, affect the first two properties. the topological disorder is, however, expected to influence also the third one. acoustic excitations with a well-defined polarization in the continuum limit present indeed a so-called mixing of polarizations at nanoscale, as attested by experimental observations and molecular dynamics simulations. we provide a comprehensive experimental characterization of acoustic dynamics properties of a selected glass, 1-octyl-3-methylimidazolium chloride glass, whose heterogeneous structure at nanoscale is well-assessed. distinctive features, which can be related to the occurrence of the rayleigh anomalies and of the mixing of polarizations are observed. we develop, in the framework of the random media theory, an analytical model that allows a quantitative description of all the rayleigh anomalies and the mixing of polarizations. contrast between theoretical and experimental features for the selected glass reveals an excellent agreement. the quantitative theoretical approach permits thus to demonstrate how the mixing of polarizations generates distinctive feature in the dynamic structure factor of glasses and to unambiguously identify them. the robustness of the proposed theoretical approach is validated by its ability to describe as well transverse acoustic dynamics.\",\n",
       " 355: 'the vespa data access system focuses on applying virtual observatory (vo) standards and tools to planetary science. building on a previous ec-funded europlanet program, it has reached maturity during the first year of a new europlanet 2020 program (started in 2015 for 4 years). the infrastructure has been upgraded to handle many fields of solar system studies, with a focus both on users and data providers. this paper describes the broad lines of the current vespa infrastructure as seen by a potential user, and provides examples of real use cases in several thematic areas. these use cases are also intended to identify hints for future developments and adaptations of vo tools to planetary science.',\n",
       " 356: 'we consider an additive partially linear framework for modelling massive heterogeneous data. the major goal is to extract multiple common features simultaneously across all sub-populations while exploring heterogeneity of each sub-population. we propose an aggregation type of estimators for the commonality parameters that possess the asymptotic optimal bounds and the asymptotic distributions as if there were no heterogeneity. this oracle result holds when the number of sub-populations does not grow too fast and the tuning parameters are selected carefully. a plug-in estimator for the heterogeneity parameter is further constructed, and shown to possess the asymptotic distribution as if the commonality information were available. furthermore, we develop a heterogeneity test for the linear components and a homogeneity test for the non-linear components accordingly. the performance of the proposed methods is evaluated via simulation studies and an application to the medicare provider utilization and payment data.',\n",
       " 357: 'in the past few years, various advancements have been made in generative models owing to the formulation of generative adversarial networks (gans). gans have been shown to perform exceedingly well on a wide variety of tasks pertaining to image generation and style transfer. in the field of natural language processing, word embeddings such as word2vec and glove are state-of-the-art methods for applying neural network models on textual data. attempts have been made for utilizing gans with word embeddings for text generation. this work presents an approach to text generation using skip-thought sentence embeddings in conjunction with gans based on gradient penalty functions and f-measures. the results of using sentence embeddings with gans for generating text conditioned on input information are comparable to the approaches where word embeddings are used.',\n",
       " 358: 'genetic inactivation of essential genes creates an evolutionary scenario distinct from escape from drug inhibition, but the mechanisms of microbe adaptations in such cases remain unknown. here we inactivate e. coli dihydrofolate reductase (dhfr) by introducing d27g,n,f chromosomal mutations in a key catalytic residue with subsequent adaptation by serial dilutions. the partial reversal g27->c occurred in three evolutionary trajectories. conversely, in one trajectory for d27g and in all trajectories for d27f,n strains adapted to grow at very low supplement folamix concentrations but did not escape entirely from supplement auxotrophy. major global shifts in metabolome and proteome occurred upon dhfr inactivation, which were partially reversed in adapted strains. loss of function mutations in two genes, thya and deob, ensured adaptation to low folamix by rerouting the 2-deoxy-d-ribose-phosphate metabolism from glycolysis towards synthesis of dtmp. multiple evolutionary pathways of adaptation to low folamix converge to highly accessible yet suboptimal fitness peak.',\n",
       " 359: \"scalable qr factorization algorithms for solving least squares and eigenvalue problems are critical given the increasing parallelism within modern machines. we introduce a more general parallelization of the choleskyqr2 algorithm and show its effectiveness for a wide range of matrix sizes. our algorithm executes over a 3d processor grid, the dimensions of which can be tuned to trade-off costs in synchronization, interprocessor communication, computational work, and memory footprint. we implement this algorithm, yielding a code that can achieve a factor of $\\\\theta(p^{1/6})$ less interprocessor communication on $p$ processors than any previous parallel qr implementation. our performance study on intel knights-landing and cray xe supercomputers demonstrates the effectiveness of this choleskyqr2 parallelization on a large number of nodes. specifically, relative to scalapack's qr, on 1024 nodes of stampede2, our choleskyqr2 implementation is faster by 2.6x-3.3x in strong scaling tests and by 1.1x-1.9x in weak scaling tests.\",\n",
       " 360: 'the long-time existence and umbilicity estimates for compact, graphical solutions to expanding curvature flows are deduced in riemannian warped products of a real interval with a compact fibre. notably we do not assume the ambient manifold to be rotationally symmetric, nor the radial curvature to converge, nor a lower bound on the ambient sectional curvature. the inverse speeds are given by powers $p\\\\leq 1$ of a curvature function satisfying few common properties.',\n",
       " 361: 'we revisit the celebrated wilemski-fixman (wf) treatment for the looping time of a free-draining polymer. the wf theory introduces a sink term into the fokker-planck equation for the $3(n+1)$-dimensional ornstein-uhlenbeck process of the polymer dynamics, which accounts for the appropriate boundary condition due to the formation of a loop. the assumption for wf theory is considerably relaxed. a perturbation method approach is developed that justifies and generalizes the previous results using either a delta sink or a heaviside sink. for both types of sinks, we show that under the condition of a small dimensionless $\\\\epsilon$, the ratio of capture radius to the kuhn length, we are able to systematically produce all known analytical and asymptotic results obtained by other methods. this includes most notably the transition regime between the $n^2$ scaling of doi, and $n\\\\sqrt{n}/\\\\epsilon$ scaling of szabo, schulten, and schulten. the mathematical issue at play is the non-uniform convergence of $\\\\epsilon\\\\to 0$ and $n\\\\to\\\\infty$, the latter being an inherent part of the theory of a gaussian polymer. our analysis yields a novel term in the analytical expression for the looping time with small $\\\\epsilon$, which is previously unknown. monte carlo numerical simulations corroborate the analytical findings. the systematic method developed here can be applied to other systems modeled by multi-dimensional smoluchowski equations.',\n",
       " 362: 'we study algorithms for the fast computation of modular inverses. newton-raphson iteration over $p$-adic numbers gives a recurrence relation computing modular inverse modulo $p^m$, that is logarithmic in $m$. we solve the recurrence to obtain an explicit formula for the inverse. then we study different implementation variants of this iteration and show that our explicit formula is interesting for small exponent values but slower or large exponent, say of more than $700$ bits. overall we thus propose a hybrid combination of our explicit formula and the best asymptotic variants. this hybrid combination yields then a constant factor improvement, also for large exponents.',\n",
       " 363: 'principal affine open subsets in affine schemes are an important tool in the foundations of algebraic geometry. given a commutative ring $r$, $\\\\,r$-modules built from the rings of functions on principal affine open subschemes in $\\\\operatorname{spec}r$ using ordinal-indexed filtrations and direct summands are called very flat. the related class of very flat quasi-coherent sheaves over a scheme is intermediate between the classes of locally free and flat sheaves, and has serious technical advantages over both. in this paper we show that very flat modules and sheaves are ubiquitous in algebraic geometry: if $s$ is a finitely presented commutative $r$-algebra which is flat as an $r$-module, then $s$ is a very flat $r$-module. this proves a conjecture formulated in the february 2014 version of the long preprint arxiv:1209.2995. we also show that the (finite) very flatness property of a flat module satisfies descent with respect to commutative ring homomorphisms of finite presentation inducing surjective maps of the spectra.',\n",
       " 364: 'polar codes have drawn much attention and been adopted in 5g new radio (nr) due to their capacity-achieving performance. recently, as the emerging deep learning (dl) technique has breakthrough achievements in many fields, neural network decoder was proposed to obtain faster convergence and better performance than belief propagation (bp) decoding. however, neural networks are memory-intensive and hinder the deployment of dl in communication systems. in this work, a low-complexity recurrent neural network (rnn) polar decoder with codebook-based weight quantization is proposed. our test results show that we can effectively reduce the memory overhead by 98% and alleviate computational complexity with slight performance loss.',\n",
       " 365: 'neural network-based algorithms provide a promising approach to jet classification problems, such as boosted top jet tagging. to date, nn-based top taggers demonstrated excellent performance in monte carlo studies. in this paper, we construct a top-jet tagger based on a convolutional neural network (cnn), and apply it to parton-level boosted top samples, with and without an additional gluon in the final state. we show that the jet observable defined by the cnn obeys the canonical definition of infrared safety: it is unaffected by the presence of the extra gluon, as long as it is soft or collinear with one of the quarks. our results indicate that the cnn tagger is robust with respect to possible mis-modeling of soft and collinear final-state radiation by monte carlo generators.',\n",
       " 366: 'we determine the effective complex permittivity of a two-dimensional composite, consisting of an arbitrary doubly periodic array of identical circular cylinders in a homogeneous matrix, and whose dielectric properties are complex-valued. efficient formulas are provided to determine the effective complex permittivity tensor which are in excellent agreement with numerical calculations. we also show that in contrast to the real-valued case, the real and imaginary parts of the effective complex-valued tensor can exhibit non-monotonic behavior as functions of volume fraction of cylinders, and can be either greater or less than that of the constituents.',\n",
       " 367: 'this paper presents a widely applicable approach to solving (multi-marginal, martingale) optimal transport and related problems via neural networks. the core idea is to penalize the optimization problem in its dual formulation and reduce it to a finite dimensional one which corresponds to optimizing a neural network with smooth objective function. we present numerical examples from optimal transport, martingale optimal transport, portfolio optimization under uncertainty and generative adversarial networks that showcase the generality and effectiveness of the approach.',\n",
       " 368: \"let $x$ be a normal complex projective variety, $t\\\\subseteq x$ a subvariety, $a\\\\colon x\\\\rightarrow a$ a morphism to an abelian variety such that $\\\\rm{pic}^0(a)$ injects into $\\\\rm{pic}^0(t)$ and let $l$ be a line bundle on $x$.   denote by $x^{(d)}\\\\to x$ the connected \\\\'etale cover induced by the $d$-th multiplication map of $a$, by $t^{(d)} \\\\subseteq x^{(d)}$ the preimage of $t$ and by $l^{(d)}$ the pull-back of $l$ to $x^{(d)}$. for $\\\\alpha\\\\in \\\\rm{pic}^0(a)$ general, we study the restricted linear system $|l^{(d)}\\\\otimes a^*\\\\alpha|_{|t^{(d)}}$: if for some $d$ this gives a generically finite map $\\\\varphi^{(d)}$, we show that f $\\\\varphi^{(d)}$ is independent of $\\\\alpha$ or $d$ sufficiently large and divisible, and is induced by the {\\\\em eventual map} $\\\\varphi\\\\colon t\\\\to z$ such that $a_{|t}$ factorizes through $\\\\varphi$.   the generic value $h^0_a(x_{|t}, l)$ of $h^0(x_{|t}, l\\\\otimes\\\\alpha)$ is called the {\\\\em (restricted) continuous rank.} we prove that if $m$ is the pull back of an ample divisor of $a$, then $x\\\\mapsto h^0_a(x_{|t}, l+xm)$ extends to a continuous function of $x\\\\in\\\\mathbb{r}$, which is differentiable except possibly at countably many points; when $x=t$ we compute the left derivative explicitly.   in the case when $x$ and $t$ are smooth, combining the above results we prove clifford-severi type inequalities, i.e., geographical bounds of the form $$\\\\rm{vol}_{x|t}(l)\\\\geq c(m) h^0_a(x_{|t},l),$$ where $c(m)={\\\\mathcal o}(m!)$.\",\n",
       " 369: 'in the present paper we analyze the linear stability of a hierarchical size-structured population model where the vital rates (mortality, fertility and growth rate) depend both on size and a general functional of the population density (\"environment\"). we derive regularity properties of the governing linear semigroup, implying that linear stability is governed by a dominant real eigenvalue of the semigroup generator, which arises as a zero of an associated characteristic function. in the special case where neither the growth rate nor the mortality depend on the environment, we explicitly calculate the characteristic function and use it to formulate simple conditions for the linear stability of population equilibria. in the general case we derive a dissipativity condition for the linear semigroup, thereby characterizing exponential stability of the steady state.',\n",
       " 370: 'we use the contact invariant defined in [2] to construct a new invariant of legendrian knots in kronheimer and mrowka\\'s monopole knot homology theory (khm), following a prescription of stipsicz and v\\\\\\'ertesi. our legendrian invariant improves upon an earlier legendrian invariant in khm defined by the second author in several important respects. most notably, ours is preserved by negative stabilization. this fact enables us to define a transverse knot invariant in khm via legendrian approximation. it also makes our invariant a more likely candidate for the monopole floer analogue of the \"loss\" invariant in knot floer homology. like its predecessor, our legendrian invariant behaves functorially with respect to lagrangian concordance. we show how this fact can be used to compute our invariant in several examples. as a byproduct of our investigations, we provide the first infinite family of nonreversible lagrangian concordances between prime knots.',\n",
       " 371: 'opioid addiction has become a global epidemic and a national health crisis in recent years, with the number of opioid overdose fatalities steadily increasing since the 1990s. in contrast to the dynamics of a typical illicit drug or disease epidemic, opioid addiction has its roots in legal, prescription medication - a fact which greatly increases the exposed population and provides additional drug accessibility for addicts. in this paper, we present a mathematical model for prescription drug addiction and treatment with parameters and validation based on data from the opioid epidemic. key dynamics considered include addiction through prescription, addiction from illicit sources, and treatment. through mathematical analysis, we show that no addiction-free equilibrium can exist without stringent control over how opioids are administered and prescribed, effectively transforming the dynamics of the opioid epidemic into those found in a purely illicit drug model. numerical sensitivity analysis suggests that relatively low states of endemic addiction can be obtained by primarily focusing on medical prevention followed by aggressive treatment of remaining cases - even when the probability of relapse from treatment remains high. further empirical study focused on understanding the rate of illicit drug dependence versus overdose risk, along with the current and changing rates of opioid prescription and treatment, would shed significant light on optimal control efforts and feasible outcomes for this epidemic and drug epidemics in general.',\n",
       " 372: 'using the concept of strong necessary conditions (csnc), we derive a complete decomposition of the minimal skyrme model into a sum of three coupled bps submodels with the same topological bound. the bounds are saturated if corresponding bogomolny equations, different for each submodel, are obeyed.',\n",
       " 373: 'chiral nematic liquid crystals exhibit both a helical planar ground state with uniform twist and a metastable defect-rich focal conic texture, and can be switched between the two microstructures via application of transient voltage pulses. in this work, we model these electrically-induced texture transitions using finite difference methods to examine resulting microstructural evolution, the first time this transition has been modeled in three dimensions. we analyze the planar to focal conic, focal conic to planar, and planar to planar transitions depending on voltage pulse magnitude. we consider first the special case of chiral nematics with matched twist and bend elastic constants. results show a variety of defect-rich morphologies in the disordered focal conic texture and demonstrate a fast recovery of the planar ground state on switching without formation of a transient planar state. we evaluate both texture microstructural evolution as well as cell capacitance. beyond the single elastic constant approximation, we evaluate the planar to transient-planar as well as the planar to helfrich-deformed transitions in simulations of a liquid crystal compound with different elastic constants. our methods represent the evolving microstructure as a uniaxial director field, with relaxation dynamics calculated from a tensor representation so that half charge disclination defects are not suppressed. we discuss potential application of these computationally efficient three-dimensional modeling approaches for design and optimization of chiral nematic devices.',\n",
       " 374: \"transport in biological systems often occurs in complex spatial environments involving random structures. motivated by such applications, we investigate an idealised model for solute transport past an array of point sinks, randomly distributed along a line, which remove solute via first-order kinetics. random sink locations give rise to long-range spatial correlations in the solute field and influence the mean concentration. we present a non-standard approach to evaluating these features based on rationally approximating integrals of a suitable green's function, which accommodates contributions varying on short and long lengthscales and has deterministic and stochastic components. we refine the results of classical two-scale methods for a periodic sink array (giving more accurate higher-order corrections with non-local contributions) and find explicit predictions for the fluctuations in concentration and disorder-induced corrections to the mean for both weakly and strongly disordered sink locations. our predictions are validated across a large region of parameter space.\",\n",
       " 375: 'quantification of risk positions under model uncertainty is of crucial importance from both viewpoints of external regulation and internal management. the concept of model uncertainty, sometimes also referred to as model ambiguity. although we know the family of models, we cannot precisely decide which one to use. given the set $\\\\mathcal{p}$, the value of the risk measure $\\\\rho$ varies in a range over the set of all possible models. the largest value in such a range is referred to as a worst-case value, and the corresponding model is called a worst scenario. value-at-risk(var) has become a very popular risk-measurement tool since it was first proposed. naturally, wvar(worst-case value-at-risk) attracts the attention of many researchers. although many literatures investigated wvar, the implications for empirical data analysis remain rare. in this paper, we proposed a special model uncertainty market model to simply the $\\\\mathcal{p}$ to a set contain finite number of probability distributions. the model has the structure of the two-layer mixed distribution model. we used change point detection method to divide the returns series and then used em algorithm to estimate the parameters. finally, we calculated var, wvar(worst-case value-at-risk) and bvar(best-case value-at-risk) for four financial markets and then analyzed their different performance.',\n",
       " 376: 'we list up all the possible local orbit types of hyperbolic or elliptic orbits for the isotropy representations of semisimple pseudo-riemannian symmetric spaces. it is key to give a recipe to determine the local orbit types of hyperbolic principal orbits by using three kind of restricted root systems and satake diagrams associated with semisimple pseudo-riemannian symmetric spaces.',\n",
       " 377: 'a restricted boltzmann machine (rbm) is an unsupervised machine-learning bipartite graphical model that jointly learns a probability distribution over data and extracts their relevant statistical features. as such, rbm were recently proposed for characterizing the patterns of coevolution between amino acids in protein sequences and for designing new sequences. here, we study how the nature of the features learned by rbm changes with its defining parameters, such as the dimensionality of the representations (size of the hidden layer) and the sparsity of the features. we show that for adequate values of these parameters, rbm operate in a so-called compositional phase in which visible configurations sampled from the rbm are obtained by recombining these features. we then compare the performance of rbm with other standard representation learning algorithms, including principal or independent component analysis, autoencoders (ae), variational auto-encoders (vae), and their sparse variants. we show that rbm, due to the stochastic mapping between data configurations and representations, better capture the underlying interactions in the system and are significantly more robust with respect to sample size than deterministic methods such as pca or ica. in addition, this stochastic mapping is not prescribed a priori as in vae, but learned from data, which allows rbm to show good performance even with shallow architectures. all numerical results are illustrated on synthetic lattice-protein data, that share similar statistical features with real protein sequences, and for which ground-truth interactions are known.',\n",
       " 378: 'heterostructures of superconducting and ferromagnetic materials are of fundamental interest because of the mutual interaction of antagonistic kinds of ordering at the s-f interface. normally, the superconducting transition temperature tc should be strongly suppressed at the s-f interface owing to the penetration of cooper pairs into the ferromagnetic side. nevertheless, constructive interactions between s and f orders have been suggested to occur via the modification of ferromagnetic order by the superconducting state. this may induce an inhomogeneous magnetic state, often called a cryptoferromagnetic state, and the relevant domain wall effect, which will lead to a local decrease of the pair-breaking parameter. however, the domain wall effect, even if it exists, is quite subtle from the experimental view point and is normally difficult to observe. here we show that the defect-related d0 ferromagnetism in mgo and the superconductivity in mgb2 do not antagonize, but rather enhance the superconducting transition temperature tc to any significant degree. we found in superconducting mgb2-d0 ferromagnetic mgo composites that the superconducting transition proceeds in two steps. the first at the s-f interface, between 110-120 k, then in the rest of the bulk at 39 k, which is the tc of single phase mgb2 superconductor. moreover, the additional transition emerges at 60 k at the s-f interface especially in the ferromagnetic side, showing a spin-glass-like magnetic state. our findings reveal that the proximity effect in the superconductor-d0 ferromagnet heterostructures will provide the knowledge and basis to enhance the tc value of the existing superconductors.',\n",
       " 379: 'the success of deep convolutional architectures is often attributed in part to their ability to learn multiscale and invariant representations of natural signals. however, a precise study of these properties and how they affect learning guarantees is still missing. in this paper, we consider deep convolutional representations of signals; we study their invariance to translations and to more general groups of transformations, their stability to the action of diffeomorphisms, and their ability to preserve signal information. this analysis is carried by introducing a multilayer kernel based on convolutional kernel networks and by studying the geometry induced by the kernel mapping. we then characterize the corresponding reproducing kernel hilbert space (rkhs), showing that it contains a large class of convolutional neural networks with homogeneous activation functions. this analysis allows us to separate data representation from learning, and to provide a canonical measure of model complexity, the rkhs norm, which controls both stability and generalization of any learned model. in addition to models in the constructed rkhs, our stability analysis also applies to convolutional networks with generic activations such as rectified linear units, and we discuss its relationship with recent generalization bounds based on spectral norms.',\n",
       " 380: 'we compute the hausdorff and minkowski dimension of subsets of the symbolic space $\\\\sigma_m=\\\\{0,...,m-1\\\\}^\\\\n$ that are invariant under multiplication by integers. the results apply to the sets $\\\\{x\\\\in \\\\sigma_m: \\\\forall\\\\, k, \\\\ x_k x_{2k}... x_{n k}=0\\\\}$, where $n\\\\ge 3$. we prove that for such sets, the hausdorff and minkowski dimensions typically differ.',\n",
       " 381: 'the frequency and harmfulness of cyber-attacks are increasing every day, and with them also the amount of data that the cyber-forensics analysts need to collect and analyze. in this paper, we propose a formal analysis process that allows an analyst to filter the enormous amount of evidence collected and either identify crucial information about the attack (e.g., when it occurred, its culprit, its target) or, at the very least, perform a pre-analysis to reduce the complexity of the problem in order to then draw conclusions more swiftly and efficiently. we introduce the evidence logic el for representing simple and derived pieces of evidence from different sources. we propose a procedure, based on monotonic reasoning, that rewrites the pieces of evidence with the use of tableau rules, based on relations of trust between sources and the reasoning behind the derived evidence, and yields a consistent set of pieces of evidence. as proof of concept, we apply our analysis process to a concrete cyber-forensics case study.',\n",
       " 382: 'we present a bayesian hierarchical multi-view mixture model termed symphony that simultaneously learns clusters of cells representing cell types and their underlying gene regulatory networks by integrating data from two views: single-cell gene expression data and paired epigenetic data, which is informative of gene-gene interactions. this model improves interpretation of clusters as cell types with similar expression patterns as well as regulatory networks driving expression, by explaining gene-gene covariances with the biological machinery regulating gene expression. we show the theoretical advantages of the multi-view learning approach and present a variational em inference procedure. we demonstrate superior performance on both synthetic data and real genomic data with subtypes of peripheral blood cells compared to other methods.',\n",
       " 383: 'recently, the topic of graph representation learning has received plenty of attention. existing approaches usually focus on structural properties only and thus they are not sufficient for those spatial graphs where the nodes are associated with some spatial information. in this paper, we present the first deep learning approach called s2vec for learning spatial graph representations, which is based on denoising autoencoders framework (daf). we evaluate the learned representations on real datasets and the results verified the effectiveness of s2vec when used for spatial clustering.',\n",
       " 384: 'we apply the method of filling with holomorphic discs to a 4-dimensional symplectic cobordism with the standard contact 3-sphere as a convex boundary component. we establish the following dichotomy: either the cobordism is diffeomorphic to a ball, or there is a periodic reeb orbit of quantifiably short period in the concave boundary of the cobordism. this allows us to give a unified treatment of various results concerning reeb dynamics on contact 3-manifolds, symplectic fillability, the topology of symplectic cobordisms, symplectic non-squeezing, and the non-existence of exact lagrangian surfaces in standard symplectic 4-space.',\n",
       " 385: 'we propose a novel framework for controllable natural language transformation. realizing that the requirement of parallel corpus is practically unsustainable for controllable generation tasks, an unsupervised training scheme is introduced. the crux of the framework is a deep neural encoder-decoder that is reinforced with text-transformation knowledge through auxiliary modules (called scorers). the scorers, based on off-the-shelf language processing tools, decide the learning scheme of the encoder-decoder based on its actions. we apply this framework for the text-transformation task of formalizing an input text by improving its readability grade; the degree of required formalization can be controlled by the user at run-time. experiments on public datasets demonstrate the efficacy of our model towards: (a) transforming a given text to a more formal style, and (b) introducing appropriate amount of formalness in the output text pertaining to the input control. our code and datasets are released for academic use.',\n",
       " 386: \"we consider jacobi matrices whose essential spectrum is a finite union of closed intervals. we focus on szego's theorem, jost solutions, and szego asymptotics for this situation. this announcement describes talks the authors gave at opsfa 2007.\",\n",
       " 387: 'in this article, we present a novel scheme for segmenting the image boundary (with the background) in optoacoustic small animal in vivo imaging systems. the method utilizes a multiscale edge detection algorithm to generate a binary edge map. a scale dependent morphological operation is employed to clean spurious edges. thereafter, an ellipse is fitted to the edge map through constrained parametric transformations and iterative goodness of fit calculations. the method delimits the tissue edges through the curve fitting model, which has shown high levels of accuracy. thus, this method enables segmentation of optoacoutic images with minimal human intervention, by eliminating need of scale selection for multiscale processing and seed point determination for contour mapping.',\n",
       " 388: 'this study explores the validity of chain effects of clean water, which are known as the \"mills-reincke phenomenon,\" in early twentieth-century japan. recent studies have reported that water purifications systems are responsible for huge contributions to human capital. although some studies have investigated the instantaneous effects of water-supply systems in pre-war japan, little is known about the chain effects of these systems. by analyzing city-level cause-specific mortality data from 1922-1940, we find that a decline in typhoid deaths by one per 1,000 people decreased the risk of death due to non-waterborne diseases such as tuberculosis and pneumonia by 0.742-2.942 per 1,000 people. our finding suggests that the observed mills-reincke phenomenon could have resulted in the relatively rapid decline in the mortality rate in early twentieth-century japan.',\n",
       " 389: 'approximate bayesian computation (abc) provides methods for bayesian inference in simulation-based stochastic models which do not permit tractable likelihoods. we present a new abc method which uses probabilistic neural emulator networks to learn synthetic likelihoods on simulated data -- both local emulators which approximate the likelihood for specific observed data, as well as global ones which are applicable to a range of data. simulations are chosen adaptively using an acquisition function which takes into account uncertainty about either the posterior distribution of interest, or the parameters of the emulator. our approach does not rely on user-defined rejection thresholds or distance functions. we illustrate inference with emulator networks on synthetic examples and on a biophysical neuron model, and show that emulators allow accurate and efficient inference even on high-dimensional problems which are challenging for conventional abc approaches.',\n",
       " 390: 'we describe a tip-scan-type high-speed xyz-nanopositioner designed for scanning ion conductance microscopy (sicm), with a special care being devoted to the way of nanopipette holding. the nanopipette probe is mounted in the center of a hollow piezoactuator, both ends of which are attached to identical diaphragm flexures, for z-positioning. this design minimizes the generation of undesirable mechanical vibrations. mechanical amplification is used to increase the xy-travel range of the nanopositioner. the first resonance frequencies of the nanopositioner are measured as $\\\\sim$100 khz and $\\\\sim$2.3 khz for the z- and xy-displacements, respectively. the travel ranges are $\\\\sim$6 $\\\\mu$m and $\\\\sim$34 $\\\\mu$m for z and xy, respectively. when this nanopositioner is used for hopping mode imaging of sicm with a $\\\\sim$10-nm radius tip, the vertical tip velocity can be increased to 400 nm/ms; hence, the one-pixel acquisition time can be minimized to $\\\\sim$1 ms.',\n",
       " 391: 'we study the theory $t_{m,n}$ of existentially closed incidence structures omitting the complete incidence structure $k_{m,n}$, which can also be viewed as existentially closed $k_{m,n}$-free bipartite graphs. in the case $m = n = 2$, this is the theory of existentially closed projective planes. we give an $\\\\forall\\\\exists$-axiomatization of $t_{m,n}$, show that $t_{m,n}$ does not have a countable saturated model when $m,n\\\\geq 2$, and show that the existence of a prime model for $t_{2,2}$ is equivalent to a longstanding open question about finite projective planes. finally, we analyze model theoretic notions of complexity for $t_{m,n}$. we show that $t_{m,n}$ is nsop$_1$, but not simple when $m,n\\\\geq 2$, and we show that $t_{m,n}$ has weak elimination of imaginaries but not full elimination of imaginaries. these results rely on combinatorial characterizations of various notions of independence, including algebraic independence, kim independence, and forking independence.',\n",
       " 392: 'given a graph $g=(v,e)$, two vertices $s,t\\\\in v$, and two integers $k,\\\\ell$, the short secluded path problem is to find a simple $s$-$t$-path with at most $k$ vertices and $\\\\ell$ neighbors. we study the parameterized complexity of the problem with respect to four structural graph parameters: the vertex cover number, treewidth, feedback vertex number, and feedback edge number. in particular, we completely settle the question of the existence of problem kernels with size polynomial in these parameters and their combinations with $k$ and $\\\\ell$. we also obtain a $2^{o(w)}\\\\cdot \\\\ell^2\\\\cdot n$-time algorithm for graphs of treewidth $w$, which yields subexponential-time algorithms in several graph classes.',\n",
       " 393: \"we consider reasoning and minimization in systems of polynomial ordinary differential equations (ode's). the ring of multivariate polynomials is employed as a syntax for denoting system behaviours. we endow this set with a transition system structure based on the concept of lie-derivative, thus inducing a notion of l-bisimulation. we prove that two states (variables) are l-bisimilar if and only if they correspond to the same solution in the ode's system. we then characterize l-bisimilarity algebraically, in terms of certain ideals in the polynomial ring that are invariant under lie-derivation. this characterization allows us to develop a complete algorithm, based on building an ascending chain of ideals, for computing the largest l-bisimulation containing all valid identities that are instances of a user-specified template. a specific largest l-bisimulation can be used to build a reduced system of ode's, equivalent to the original one, but minimal among all those obtainable by linear aggregation of the original equations. a computationally less demanding approximate reduction and linearization technique is also proposed.\",\n",
       " 394: 'the search of unconventional magnetic and nonmagnetic states is a major topic in the study of frustrated magnetism. canonical examples of those states include various spin liquids and spin nematics. however, discerning their existence and the correct characterization is usually challenging. here we introduce a machine-learning protocol that can identify general nematic order and their order parameter from seemingly featureless spin configurations, thus providing comprehensive insight on the presence or absence of hidden orders. we demonstrate the capabilities of our method by extracting the analytical form of nematic order parameter tensors up to rank 6. this may prove useful in the search for novel spin states and for ruling out spurious spin liquid candidates.',\n",
       " 395: 'two different types of perturbations of the lorenz 63 dynamical system for rayleigh-benard convection by multiplicative noise -- called stochastic advection by lie transport (salt) noise and fluctuation-dissipation (fd) noise -- are found to produce qualitatively different effects, possibly because the total phase-space volume contraction rates are different. in the process of making this comparison between effects of salt and fd noise on the lorenz 63 system, a stochastic version of a robust deterministic numerical algorithm for obtaining the individual numerical lyapunov exponents was developed. with this stochastic version of the algorithm, the value of the sum of the lyapunov exponents for the fd noise was found to differ significantly from the value of the deterministic lorenz 63 system, whereas the salt noise preserves the lorenz 63 value with high accuracy. the lagrangian averaged version of the salt equations (la salt) is found to yield a closed deterministic subsystem for the expected solutions which is found to be isomorphic to the original lorenz 63 dynamical system. the solutions of the closed chaotic subsystem, in turn, drive a linear stochastic system for the fluctuations of the la salt solutions around their expected values.',\n",
       " 396: \"the random forest algorithm (rf) has several hyperparameters that have to be set by the user, e.g., the number of observations drawn randomly for each tree and whether they are drawn with or without replacement, the number of variables drawn randomly for each split, the splitting rule, the minimum number of samples that a node must contain and the number of trees. in this paper, we first provide a literature review on the parameters' influence on the prediction performance and on variable importance measures.   it is well known that in most cases rf works reasonably well with the default values of the hyperparameters specified in software packages. nevertheless, tuning the hyperparameters can improve the performance of rf. in the second part of this paper, after a brief overview of tuning strategies we demonstrate the application of one of the most established tuning strategies, model-based optimization (mbo). to make it easier to use, we provide the tuneranger r package that tunes rf with mbo automatically. in a benchmark study on several datasets, we compare the prediction performance and runtime of tuneranger with other tuning implementations in r and rf with default hyperparameters.\",\n",
       " 397: 'the combined information from cosmic ray air showers that trigger both the surface and underground parts of the icecube neutrino observatory allows the reconstruction of both the energy and mass of the primary particle through the knee region of the energy spectrum and above. the properties of high-energy muon bundles, created early in the formation of extensive air showers and capable of penetrating deep into the ice, are related to the primary energy and composition. new methods for reconstructing the direction and composition-sensitive properties of muon bundles are shown. based on a likelihood minimization procedure using icecube signals, and accounting for photon propagation, ice properties, and the energy loss processes of muons in ice, the muon bundle energy loss is reconstructed. the results of the high-energy muon bundle reconstruction in the deep ice and the reconstruction of the lateral distribution of low energy particles in the surface detector can be combined to study primary composition and energy. the performance and composition sensitivity for both simulated and experimental data are discussed.',\n",
       " 398: 'we present the results of an analysis of data collected by icecube/deepcore in 2010-2011 resulting in the first significant detection of neutrino oscillations in a high-energy neutrino telescope. a low-energy muon neutrino sample (20-100 gev) containing the oscillation signal was extracted from data collected by deepcore. a high-energy muon neutrino sample (100 gev -10 tev) was extracted from icecube data in order to constrain the systematic uncertainties. the non-oscillation hypothesis was rejected with more than $5\\\\sigma$. we fitted the oscillation parameters $\\\\delta m^2_{23}$ and $\\\\sin^22 \\\\theta_{23}$ to these data samples. in a 2-flavor formalism we find $\\\\delta m^2_{23}= (2.5\\\\pm0.6)\\\\cdot10^{-3}$ ev$^2$ and $\\\\sin^22 \\\\theta_{23}>0.92$ while maximum mixing is favored. these results are in good agreement with the world average values.',\n",
       " 399: 'we determine explicit generators for a cohomology group constructed from a solution of a fuchsian linear differential equation and describe its relation with cohomology groups with coefficients in a local system. in the parameterized case, this yields into an algorithm which computes new fuchsian differential equations from those depending on multi-parameters. this generalizes the classical convolution of solutions of fuchsian differential equations.',\n",
       " 400: 'the planned cherenkov telescope array (cta), a future ground-based very-high-energy (vhe) gamma-ray observatory, will be the largest project of its kind. it aims to provide an order of magnitude increase in sensitivity compared to currently operating vhe experiments and open access to guest observers. these features, together with the thirty years lifetime planned for the installation, impose severe constraints on the data model currently being developed for the project.   in this contribution we analyze the challenges faced by the cta data model development and present the requirements imposed to face them. while the full data model is still not completed we show the organization of the work, status of the design, and an overview of the prototyping efforts carried out so far. we also show examples of specific aspects of the data model currently under development.',\n",
       " 401: 'for the root systems of type $b_l, c_l$ and $d_l$, we generalize the result of \\\\cite{dz1998} by showing the existence of frobenius manifold structures on the orbit spaces of the extended affine weyl groups that correspond to any vertex of the dynkin diagram instead of a particular choice made in \\\\cite{dz1998}. it also depends on certain additional data. we also construct lg superpotentials for these frobenius manifold structures.',\n",
       " 402: 'in this paper we consider the notion of normality of sequences in shifts of finite type. a sequence is normal if the frequency of each block exists and is equal to the parry measure of the block. we give a characterization of normality in terms of incompressibility by lossless transducers. the result was already known in the case of the full shift.',\n",
       " 403: 'quantum simulation of chemistry and materials is predicted to be an important application for both near-term and fault-tolerant quantum devices. however, at present, developing and studying algorithms for these problems can be difficult due to the prohibitive amount of domain knowledge required in both the area of chemistry and quantum algorithms. to help bridge this gap and open the field to more researchers, we have developed the openfermion software package (www.openfermion.org). openfermion is an open-source software library written largely in python under an apache 2.0 license, aimed at enabling the simulation of fermionic models and quantum chemistry problems on quantum hardware. beginning with an interface to common electronic structure packages, it simplifies the translation between a molecular specification and a quantum circuit for solving or studying the electronic structure problem on a quantum computer, minimizing the amount of domain expertise required to enter the field. the package is designed to be extensible and robust, maintaining high software standards in documentation and testing. this release paper outlines the key motivations behind design choices in openfermion and discusses some basic openfermion functionality which we believe will aid the community in the development of better quantum algorithms and tools for this exciting area of research.',\n",
       " 404: \"in multi-prover interactive proofs, the verifier interrogates the provers and attempts to steal their knowledge. other than that, the verifier's role has not been studied. we have discovered that the verifier plays a much more important role than previously thought. simply put, the verifier has the capability of providing non-local resources for the provers intrinsically. existing mips' proofs of soundness implicitly depend on the fact that the verifier is not a non-local resource provider. the verifier's non-locality is a new unused tool and liability for protocol design and analysis.\",\n",
       " 405: 'given samples from an unknown multivariate distribution $p$, is it possible to distinguish whether $p$ is the product of its marginals versus $p$ being far from every product distribution? similarly, is it possible to distinguish whether $p$ equals a given distribution $q$ versus $p$ and $q$ being far from each other? these problems of testing independence and goodness-of-fit have received enormous attention in statistics, information theory, and theoretical computer science, with sample-optimal algorithms known in several interesting regimes of parameters. unfortunately, it has also been understood that these problems become intractable in large dimensions, necessitating exponential sample complexity.   motivated by the exponential lower bounds for general distributions as well as the ubiquity of markov random fields (mrfs) in the modeling of high-dimensional distributions, we initiate the study of distribution testing on structured multivariate distributions, and in particular the prototypical example of mrfs: the ising model. we demonstrate that, in this structured setting, we can avoid the curse of dimensionality, obtaining sample and time efficient testers for independence and goodness-of-fit. one of the key technical challenges we face along the way is bounding the variance of functions of the ising model.',\n",
       " 406: 'we construct convergent and divergent lattices in negative curvature and give a precise asymptotic description of the behavior of their counting function.',\n",
       " 407: \"grinberg theorem, a necessary condition only for planar hamilton graphs, was proved in 1968. in this paper, we use the cycles in a cycle basis of a simple connected graph to replace the faces in planar graphs and present a new proof of the equality $\\\\sum_{i=3}^{|v|}(if'_i-2 f'_i)=|v|-2$ in grinberg theorem, where $f'_i$ is the number of faces of degree i. this result implies that grinberg theorem can be extended into simple connected graphs.\",\n",
       " 408: 'we generalize the decomposition theorem for perverse sheaves to artin stacks with affine stabilizers over finite fields.',\n",
       " 409: 'we introduce the analogues of the notions of complete segal space and of segal category in the context of equivariant operads with norm maps, and build model categories with these as the fibrant objects. we then show that these model categories are quillen equivalent to each other and to the model category for $g$-$\\\\infty$-operads built in a previous paper. moreover, we establish variants of these results for the blumberg-hill indexing systems. in an appendix, we discuss reedy categories in the equivariant context.',\n",
       " 410: 'baudot and bennequin introduced a cohomological construction adapted to information theory, called \\\\emph{information cohomology}; it characterizes shannon entropy as the only nontrivial cohomology class in degree one, for suitable coefficients. this text develops the relation between information cohomology and topos theory. to this end, we redefine information structures, as categories of random variables related by a notion of extension or refinement; classical and quantum probability spaces appear as models (or representations) of them. these generalized information structures form a category with finite products and coproducts. information cohomology is a derived functor in the abelian category of modules over an algebra of random variables, a subcategory of the presheaf topos associated with the information structure. the cohomology is invariant under isomorphisms of generalized structures. we prove that the relatively free bar construction gives a projective object for the computation of this invariant. we provide detailed computations of $h^0$ and $h^1$ when the coefficients are functionals of classical probabilities, including the degenerate cases. in the process, we also establish the homological nature of tsallis entropies, as the only cocycles in degree one for certain one-parameter family of modules.',\n",
       " 411: 'efficient exploration remains a major challenge for reinforcement learning. one reason is that the variability of the returns often depends on the current state and action, and is therefore heteroscedastic. classical exploration strategies such as upper confidence bound algorithms and thompson sampling fail to appropriately account for heteroscedasticity, even in the bandit setting. motivated by recent findings that address this issue in bandits, we propose to use information-directed sampling (ids) for exploration in reinforcement learning. as our main contribution, we build on recent advances in distributional reinforcement learning and propose a novel, tractable approximation of ids for deep q-learning. the resulting exploration strategy explicitly accounts for both parametric uncertainty and heteroscedastic observation noise. we evaluate our method on atari games and demonstrate a significant improvement over alternative approaches.',\n",
       " 412: 'the ultimatum game has been a prominent paradigm in studying the evolution of fairness. it predicts that responders should accept any nonzero offer and proposers should offer the smallest possible amount according to orthodox game theory. however, the prediction strongly contradicts with experimental findings where responders usually reject low offers below $20\\\\%$ and proposers usually make higher offers than expected. to explain the evolution of such fair behaviors, we here introduce empathy in group-structured populations by allowing a proportion $\\\\alpha$ of the population to play empathetic strategies. interestingly, we find that for high mutation probabilities, the mean offer decreases with $\\\\alpha$ and the mean demand increases, implying empathy inhibits the evolution of fairness. for low mutation probabilities, the mean offer and demand approach to the fair ones with increasing $\\\\alpha$, implying empathy promotes the evolution of fairness. furthermore, under both weak and strong intensities of natural selection, we analytically calculate the mean offer and demand for different levels of $\\\\alpha$. counterintuitively, we demonstrate that although a higher mutation probability leads to a higher level of fairness under weak selection, an intermediate mutation probability corresponds to the lowest level of fairness under strong selection. our study provides systematic insights into the evolutionary origin of fairness in group-structured populations with empathetic strategies.',\n",
       " 413: 'topological orders and associated topological protected excitations satisfying non-abelian statistics have been widely explored in various platforms. the $\\\\mathbb{z}_3$ parafermions are regarded as the most natural generation of the majorana fermions to realize these topological orders. here we investigate the topological phase and emergent $\\\\mathbb{z}_2$ spin phases in an extended parafermion chain. this model exhibits rich variety of phases, including not only topological ferromagnetic phase, which supports non-abelian anyon excitation, but also spin-fluid, dimer and chiral phases from the emergent $\\\\mathbb{z}_2$ spin model. we generalize the measurement tools in $\\\\mathbb{z}_2$ spin models to fully characterize these phases in the extended parafermion model and map out the corresponding phase diagram. surprisingly, we find that all the phase boundaries finally merge to a single supercritical point. in regarding of the rather generality of emergent phenomena in parafermion models, this approach opens a wide range of intriguing applications in investigating the exotic phases in other parafermion models.',\n",
       " 414: 'the mohr-coulomb criterion is widely used in geosciences to relate the state of stress at failure to the observed orientation of the resulting faults. this relation is based on the assumption that the fault occurs along a plane that maximizes the coulomb stress. here, we test this hypothesis using an elastic, progressive damage model that implements the mohr-coulomb criterion at the local scale. we find that the orientation of the fault is not given by the mohr-coulomb criterion. instead, for minimal disorder, it corresponds to the most unstable mode of damage in the model, which we determine through a linear stability analysis of the homogeneously damaged state. our simulations show that microstructural disorder significantly affects the orientation of the fault, which, however, remains always far from the mohr-coulomb prediction.',\n",
       " 415: 'let the circle act in a hamiltonian fashion on a compact symplectic manifold $(m, \\\\omega)$ of dimension $2n$. then the $s^1$-action has at least $n+1$ fixed points. we study the case when the fixed point set consists of precisely $n+1$ isolated points. we show certain equivalence on the first chern class of $m$ and some particular weight of the $s^1$-action at some fixed point. we show that the particular weight can completely determine the integral cohomology ring of $m$, the total chern class of $m$, and the sets of weights of the $s^1$-action at all the fixed points. we will see that all these data are isomorphic to those of known examples, $\\\\cp^n$, or $\\\\gt_2(\\\\r^{n+2})$ with $n\\\\geq 3$ odd, equipped with standard circle actions.',\n",
       " 416: 'in this paper we propose a method to improve the accuracy of trajectory optimization for dynamic robots with intermittent contact by using orthogonal collocation. until recently, most trajectory optimization methods for systems with contacts employ mode-scheduling, which requires an a priori knowledge of the contact order and thus cannot produce complex or non-intuitive behaviors. contact-implicit trajectory optimization methods offer a solution to this by allowing the optimization to make or break contacts as needed, but thus far have suffered from poor accuracy. here, we combine methods from direct collocation using higher order orthogonal polynomials with contact-implicit optimization to generate trajectories with significantly improved accuracy. the key insight is to increase the order of the polynomial representation while maintaining the assumption that impact occurs over the duration of one finite element.',\n",
       " 417: 'we study the assignment problem of objects to agents with heterogeneous preferences under distributional constraints. each agent is associated with a publicly known type and has a private ordinal ranking over objects. we are interested in assigning as many agents as possible. our first contribution is a generalization of the well-known and widely used serial dictatorship. our mechanism maintains several desirable properties of serial dictatorship, including strategyproofness, pareto efficiency, and computational tractability while satisfying the distributional constraints with a small error. we also propose a generalization of the probabilistic serial algorithm, which finds an ordinally efficient and envy-free assignment, and also satisfies the distributional constraints with a small error. we show, however, that no ordinally efficient and envy-free mechanism is also weakly strategyproof. both of our algorithms assign at least the same number of students as the optimum fractional assignment.',\n",
       " 418: \"we exhibit cocycles representing certain classes in the rational cohomology of of the general linear group with coefficients in the divided powers of a frobenius twist of the adjoint representation. these classes' existence was anticipated by van der kallen, and they intervene in the proof that reductive linear algebraic groups have finitely generated cohomology algebras.\",\n",
       " 419: \"generalized trigonometric functions with two parameters were introduced by dr\\\\'{a}bek and man\\\\'{a}sevich to study an inhomogeneous eigenvalue problem of the $p$-laplacian. concerning these functions, no multiple-angle formula has been known except for the classical cases and a special case discovered by edmunds, gurka and lang, not to mention addition theorems. in this paper, we will present new multiple-angle formulas which are established between two kinds of the generalized trigonometric functions, and apply the formulas to generalize classical topics related to the trigonometric functions and the lemniscate function.\",\n",
       " 420: 'the number of ways to place $q$ nonattacking queens, bishops, or similar chess pieces on an $n\\\\times n$ square chessboard is essentially a quasipolynomial function of $n$ (by part i of this series). the period of the quasipolynomial is difficult to settle. here we prove that the empirically observed period 2 for three to ten bishops is the exact period for every number of bishops greater than 2. the proof depends on signed graphs and the ehrhart theory of inside-out polytopes.',\n",
       " 421: \"we prove that to every inclusion $a\\\\hookrightarrow l$ of lie algebroids over the same base manifold $m$ corresponds a kapranov dg-manifold structure on $a[1]\\\\oplus l/a$, which is canonical up to isomorphism. as a consequence, $\\\\gamma(\\\\lambda^\\\\bullet a^\\\\vee\\\\otimes l/a)$ carries a canonical $l_\\\\infty[1]$ algebra structure whose unary bracket is the chevalley--eilenberg differential corresponding to the bott representation of $a$ on $l/a$ and whose binary bracket is a cocycle representative of the atiyah class of the lie pair $(l,a)$. to this end, we construct explicit isomorphisms of $c^\\\\infty(m)$-coalgebras $\\\\gamma\\\\big(s(l/a)\\\\big)\\\\xrightarrow{\\\\sim}\\\\frac{\\\\mathcal{u}(l)}{\\\\mathcal{u}(l)\\\\gamma(a)}$, which we elect to call poincar\\\\'e--birkhoff--witt maps. these maps admit a recursive characterization that allows for explicit computations. they generalize both the classical symmetrization map $s(\\\\mathfrak{g})\\\\to\\\\mathcal{u}(\\\\mathfrak{g})$ of lie theory and (the inverse of) the complete symbol map for differential operators. finally, we prove that the kapranov dg-manifold $a[1]\\\\oplus l/a$ is linearizable if and only if the atiyah class of the lie pair $(l,a)$ vanishes.\",\n",
       " 422: 'we prove that on any compact manifold $m^n$ with boundary, there exist a conformal class $c$ such that for any riemannian metric $g\\\\in c$, $\\\\lambda_1(m^n,g)vol(m^n,g)^{2/n}< n.vol(s^n,g_{\\\\textrm{can}})^{2/n}$ and $\\\\sigma_1(m,g,\\\\rho)\\\\mathcal m(\\\\partial m)vol(m)^{\\\\frac{2-n}n}<n.vol(s^n,g_{\\\\textrm{can}})^{2/n}$, where $\\\\lambda_1(m^n,g)$ denotes the first positive eigenvalue of the neumann laplacian on $(m,g)$, $\\\\sigma_1(m,g,\\\\rho)$ the first positive steklov eigenvalue for the density $\\\\rho$ on $\\\\partial m$, and $\\\\mathcal m(\\\\partial m)=\\\\int_{\\\\partial m}\\\\rho dv_g$. the proof relies on a handle decomposition of the manifold. we also prove that the conformal volume of $(m,c)$ is $vol(s^n,g_{\\\\textrm{can}})$, and that the friedlander-nadirashvili and the m\\\\\"obius volume of $m$ are equal to those of the sphere. if $m$ is a domain in a space form, $c$ is the conformal class of the canonical metric.',\n",
       " 423: 'mendelian randomization (mr) is a method of exploiting genetic variation to unbiasedly estimate a causal effect in presence of unmeasured confounding. mr is being widely used in epidemiology and other related areas of population science. in this paper, we study statistical inference in the increasingly popular two-sample summary-data mr design. we show a linear model for the observed associations approximately holds in a wide variety of settings when all the genetic variants satisfy the exclusion restriction assumption, or in genetic terms, when there is no pleiotropy. in this scenario, we derive a maximum profile likelihood estimator with provable consistency and asymptotic normality. however, through analyzing real datasets, we find strong evidence of both systematic and idiosyncratic pleiotropy in mr, echoing the omnigenic model of complex traits that is recently proposed in genetics. we model the systematic pleiotropy by a random effects model, where no genetic variant satisfies the exclusion restriction condition exactly. in this case we propose a consistent and asymptotically normal estimator by adjusting the profile score. we then tackle the idiosyncratic pleiotropy by robustifying the adjusted profile score. we demonstrate the robustness and efficiency of the proposed methods using several simulated and real datasets.',\n",
       " 424: 'in the context of 2d/3d registration, this paper introduces an approach that allows to match features detected in two different modalities: photographs and 3d models, by using a common 2d reprensentation. more precisely, 2d images are matched with a set of depth images, representing the 3d model. after introducing the concept of curvilinear saliency, related to curvature estimation, we propose a new ridge and valley detector for depth images rendered from 3d model. a variant of this detector is adapted to photographs, in particular by applying it in multi-scale and by combining this feature detector with the principle of focus curves. finally, a registration algorithm for determining the correct viewpoint of the 3d model and thus the pose is proposed. it is based on using histogram of gradients features adapted to the features manipulated in 2d and in 3d, and the introduction of repeatability scores. the results presented highlight the quality of the features detected, in term of repeatability, and also the interest of the approach for registration and pose estimation.',\n",
       " 425: 'the correlation between active galactic nuclei (agn) and environment provides important clues to agn fueling and the relationship of black hole growth to galaxy evolution. in this paper, we analyze the fraction of galaxies in clusters hosting agn as a function of redshift and cluster richness for x-ray detected agn associated with clusters of galaxies in dark energy survey (des) science verification data. the present sample includes 33 agn with l_x > 10^43 ergs s^-1 in non-central, host galaxies with luminosity greater than 0.5 l* from a total sample of 432 clusters in the redshift range of 0.1<z<0.95. analysis of the present sample reveals that the agn fraction in red-sequence cluster members has a strong positive correlation with redshift such that the agn fraction increases by a factor of ~8 from low to high redshift, and the fraction of cluster galaxies hosting agn at high redshifts is greater than the low-redshift fraction at 3.6 sigma. in particular, the agn fraction increases steeply at the highest redshifts in our sample at z>0.7. this result is in good agreement with previous work and parallels the increase in star formation in cluster galaxies over the same redshift range. however, the agn fraction in clusters is observed to have no significant correlation with cluster mass. future analyses with des year 1 through year 3 data will be able to clarify whether agn activity is correlated to cluster mass and will tightly constrain the relationship between cluster agn populations and redshift.',\n",
       " 426: 'objective: numerous glucose prediction algorithm have been proposed to empower type 1 diabetes (t1d) management. most of these algorithms only account for input such as glucose, insulin and carbohydrate, which limits their performance. here, we present a novel glucose prediction algorithm which, in addition to standard inputs, accounts for meal absorption and physical exercise information to enhance prediction accuracy. methods: a compartmental model of glucose-insulin dynamics combined with a deconvolution technique for state estimation is employed for glucose prediction. in silico data corresponding from the 10 adult subjects of uva-padova simulator, and clinical data from 10 adults with t1d were used. finally, a comparison against a validated glucose prediction algorithm based on a latent variable with exogenous input (lvx) model is provided. results: for a prediction horizon of 60 minutes, accounting for meal absorption and physical exercise improved glucose forecasting accuracy. in particular, root mean square error (mg/dl) went from 26.68 to 23.89, p<0.001 (in silico data); and from 37.02 to 35.96, p<0.001 (clinical data - only meal information). such improvement in accuracy was translated into significant improvements on hypoglycaemia and hyperglycaemia prediction. finally, the performance of the proposed algorithm is statistically superior to that of the lvx algorithm (26.68 vs. 32.80, p<0.001 (in silico data); 37.02 vs. 49.17, p<0.01 (clinical data). conclusion: taking into account meal absorption and physical exercise information improves glucose prediction accuracy.',\n",
       " 427: 'online class imbalance learning constitutes a new problem and an emerging research topic that focusses on the challenges of online learning under class imbalance and concept drift. class imbalance deals with data streams that have very skewed distributions while concept drift deals with changes in the class imbalance status. little work exists that addresses these challenges and in this paper we introduce queue-based resampling, a novel algorithm that successfully addresses the co-existence of class imbalance and concept drift. the central idea of the proposed resampling algorithm is to selectively include in the training set a subset of the examples that appeared in the past. results on two popular benchmark datasets demonstrate the effectiveness of queue-based resampling over state-of-the-art methods in terms of learning speed and quality.',\n",
       " 428: 'the icecube neutrino observatory is a kilometer-scale detector currently under construction at the south pole. the full detector will comprise 5,160 photomultipliers (pmts) deployed on 86 strings from 1.45-2.45 km deep within the ice. as of the austral summer of 2009-10, 73 out of the total number strings have been deployed, and the detector is reaching its final construction phase. a dense sub-array of 6 strings in the center of the detector (deepcore) has been already installed for enhancing the sensitivity to low energy neutrinos. the icecube de- tection principle is based on the measurement of the cherenkov light induced by ultra-relativistic muons and showers produced by neutrino interactions in the target matter of the detector. the main scientific goal of the icecube experiment is the detection of astrophysical neu- trinos that will help to understand and settle the unresolved questions about the origin and nature of cosmic rays. in this contribution we will present the latest results of the experiment concerning the search for neutrino point sources using the experimental data taken during 2008- 09 where the detector was operated with a 40-string configuration. the results of the analysis for steady individual neutrino sources as well as the stacking analysis from different catalogs will be presented.',\n",
       " 429: 'given a set of empirical observations, conditional density estimation aims to capture the statistical relationship between a conditional variable $\\\\mathbf{x}$ and a dependent variable $\\\\mathbf{y}$ by modeling their conditional probability $p(\\\\mathbf{y}|\\\\mathbf{x})$. the paper develops best practices for conditional density estimation for finance applications with neural networks, grounded on mathematical insights and empirical evaluations. in particular, we introduce a noise regularization and data normalization scheme, alleviating problems with over-fitting, initialization and hyper-parameter sensitivity of such estimators. we compare our proposed methodology with popular semi- and non-parametric density estimators, underpin its effectiveness in various benchmarks on simulated and euro stoxx 50 data and show its superior performance. our methodology allows to obtain high-quality estimators for statistical expectations of higher moments, quantiles and non-linear return transformations, with very little assumptions about the return dynamic.',\n",
       " 430: \"we construct a non-normal affine monoid together with its modules associated with a negative definite plumbed $3$-manifold $m$. in terms of their structure, we describe the $h_1(m,\\\\mathbb{z})$-equivariant parts of the topological poincar\\\\'e series. in particular, we give combinatorial formulas for the seiberg--witten invariants of $m$ and for polynomial generalizations defined in a previous paper of the authors.\",\n",
       " 431: 'we construct and classify all groups, given by triangular presentations associated to the smallest thick generalized quadrangle, that act simply transitively on the vertices of hyperbolic triangular buildings of the smallest non-trivial thickness. our classification shows 23 non-isomorphic torsion free groups (obtained in an earlier work) and 168 non-isomorphic torsion groups acting on one of two possible buildings with the smallest thick generalized quadrangle as the link of each vertex. in analogy with the euclidean case, we find both torsion and torsion free groups acting on the same building.',\n",
       " 432: 'multi-agent cooperation is an important feature of the natural world. many tasks involve individual incentives that are misaligned with the common good, yet a wide range of organisms from bacteria to insects and humans are able to overcome their differences and collaborate. therefore, the emergence of cooperative behavior amongst self-interested individuals is an important question for the fields of multi-agent reinforcement learning (marl) and evolutionary theory. here, we study a particular class of multi-agent problems called intertemporal social dilemmas (isds), where the conflict between the individual and the group is particularly sharp. by combining marl with appropriately structured natural selection, we demonstrate that individual inductive biases for cooperation can be learned in a model-free way. to achieve this, we introduce an innovative modular architecture for deep reinforcement learning agents which supports multi-level selection. we present results in two challenging environments, and interpret these in the context of cultural and ecological evolution.',\n",
       " 433: 'a novel positron emission tomography system, based on plastic scintillators, is being developed by the j-pet collaboration. in this article we present the simulation results of the scatter fraction, representing one of the parameters crucial for background studies defined in the nema-nu-2-2012 norm. we elaborate an event selection methods allowing to suppress events in which gamma quanta were scattered in the phantom or underwent the multiple scattering in the detector. the estimated scatter fraction for the single-layer j-pet scanner varies from 37% to 53% depending on the applied energy threshold.',\n",
       " 434: 'we present a robust test for change-points in time series which is based on the two-sample hodges-lehmann estimator. we develop new limit theory for a class of statistics based on the two-sample u-quantile processes, in the case of short range dependent observations. using this theory we can derive the asymptotic distribution of our test statistic under the null hypothesis. we study the finite sample properties of our test via a simulation study and compare the test with the classical cusum test and a test based on the wilcoxon-mann-whitney statistic.',\n",
       " 435: 'this work studies the problem of stochastic dynamic filtering and state propagation with complex beliefs. the main contribution is gp-sum, a filtering algorithm tailored to dynamic systems and observation models expressed as gaussian processes (gp), and to states represented as a weighted sum of gaussians. the key attribute of gp-sum is that it does not rely on linearizations of the dynamic or observation models, or on unimodal gaussian approximations of the belief, hence enables tracking complex state distributions. the algorithm can be seen as a combination of a sampling-based filter with a probabilistic bayes filter. on the one hand, gp-sum operates by sampling the state distribution and propagating each sample through the dynamic system and observation models. on the other hand, it achieves effective sampling and accurate probabilistic propagation by relying on the gp form of the system, and the sum-of-gaussian form of the belief. we show that gp-sum outperforms several gp-bayes and particle filters on a standard benchmark. we also demonstrate its use in a pushing task, predicting with experimental accuracy the naturally occurring non-gaussian distributions.',\n",
       " 436: 'a common challenge in estimating parameters of probability density functions is the intractability of the normalizing constant. while in such cases maximum likelihood estimation may be implemented using numerical integration, the approach becomes computationally intensive. the score matching method of hyv\\\\\"arinen [2005] avoids direct calculation of the normalizing constant and yields closed-form estimates for exponential families of continuous distributions over $\\\\mathbb{r}^m$. hyv\\\\\"arinen [2007] extended the approach to distributions supported on the non-negative orthant, $\\\\mathbb{r}_+^m$. in this paper, we give a generalized form of score matching for non-negative data that improves estimation efficiency. as an example, we consider a general class of pairwise interaction models. addressing an overlooked inexistence problem, we generalize the regularized score matching method of lin et al. [2016] and improve its theoretical guarantees for non-negative gaussian graphical models.',\n",
       " 437: 'we propose a probabilistic numerical algorithm to solve backward stochastic differential equations (bsdes) with nonnegative jumps, a class of bsdes introduced in [9] for representing fully nonlinear hjb equations. in particular, this allows us to numerically solve stochastic control problems with controlled volatility, possibly degenerate. our backward scheme, based on least-squares regressions, takes advantage of high-dimensional properties of monte-carlo methods, and also provides a parametric estimate in feedback form for the optimal control. a partial analysis of the error of the scheme is provided, as well as numerical tests on the problem of superreplication of option with uncertain volatilities and/or correlations, including a detailed comparison with the numerical results from the alternative scheme proposed in [7].',\n",
       " 438: \"following a line of reasoning suggested by eliashberg, we prove cerf's theorem that any diffeomorphism of the 3-sphere extends over the 4-ball. to this end we develop a moduli-theoretic version of eliashberg's filling-with-holomorphic-discs method.\",\n",
       " 439: 'let $\\\\{\\\\infty^+, \\\\infty^-\\\\}$ be the two points above $\\\\infty$ on the real hyperelliptic curve $h: y^2 = (x^2 - 1) \\\\prod_{i=1}^{2g} (x - a_i)$. we show that the divisor $([\\\\infty^+] - [\\\\infty^-])$ is torsion in $\\\\operatorname{jac} j$ for a dense set of $(a_1, a_2, \\\\ldots, a_{2g}) \\\\in (-1, 1)^{2g}$. in fact, we prove by degeneration to a nodal $\\\\mathbb{p}^1$ that an associated period map has derivative generically of full rank.',\n",
       " 440: 'a theorem of hukuhara, levelt, and turrittin states that every formal differential operator has a jordan decomposition. this theorem was generalised by babbit and varadarajan to the case of formal $g$-connections where $g$ is a semisimple group. in this paper, we provide straightforward proofs of these facts, highlighting the analogy between the linear and differential settings.',\n",
       " 441: 'the dream of room temperature superconductors has inspired intense research effort to find routes for enhancing the superconducting transition temperature (tc). therefore, single-layer fese on a srtio3 substrate, with its extraordinarily high tc amongst all interfacial superconductors and iron based superconductors, is particularly interesting, but the mechanism underlying its high tc has remained mysterious. here we show through isotope effects that electrons in fese couple with the oxygen phonons in the substrate, and the superconductivity is enhanced linearly with the coupling strength atop the intrinsic superconductivity of heavily-electron-doped fese. our observations solve the enigma of fese/srtio3, and experimentally establish the critical role and unique behavior of electron-phonon forward scattering in a correlated high-tc superconductor. the effective cooperation between interlayer electron-phonon interactions and correlations suggests a path forward in developing more high-tc interfacial superconductors, and may shed light on understanding the high tc of bulk high temperature superconductors with layered structures.',\n",
       " 442: 'massively parallel recordings of spiking activity in cortical networks show that covariances vary widely across pairs of neurons. their low average is well understood, but an explanation for the wide distribution in relation to the static (quenched) disorder of the connectivity in recurrent random networks was so far elusive. we here derive a finite-size mean-field theory that reduces a disordered to a highly symmetric network with fluctuating auxiliary fields. the exposed analytical relation between the statistics of connections and the statistics of pairwise covariances shows that both, average and dispersion of the latter, diverge at a critical coupling. at this point, a network of nonlinear units transits from regular to chaotic dynamics. applying these results to recordings from the mammalian brain suggests its operation close to this edge of criticality.',\n",
       " 443: 'many cellular responses to surrounding cues require temporally concerted transcriptional regulation of multiple genes. in prokaryotic cells, a single-input-module motif with one transcription factor regulating multiple target genes can generate coordinated gene expression. in eukaryotic cells, transcriptional activity of a gene is affected by not only transcription factors but also the epigenetic modifications and three-dimensional chromosome structure of the gene. to examine how local gene environment and transcription factor regulation are coupled, we performed a combined analysis of time-course rna-seq data of tgf-\\\\b{eta} treated mcf10a cells and related epigenomic and hi-c data. using dynamic regulatory events miner (drem), we clustered differentially expressed genes based on gene expression profiles and associated transcription factors. genes in each class have similar temporal gene expression patterns and share common transcription factors. next, we defined a set of linear and radial distribution functions, as used in statistical physics, to measure the distributions of genes within a class both spatially and linearly along the genomic sequence. remarkably, genes within the same class despite sometimes being separated by tens of million bases (mb) along genomic sequence show a significantly higher tendency to be spatially close despite sometimes being separated by tens of mb along the genomic sequence than those belonging to different classes do. analyses extended to the process of mouse nervous system development arrived at similar conclusions. future studies will be able to test whether this spatial organization of chromosomes contributes to concerted gene expression.',\n",
       " 444: 'different evolutionary models are known to make disparate predictions for the success of an invading mutant in some situations. for example, some evolutionary mechanics lead to amplification of selection in structured populations, while others suppress it. here, we use computer simulations to study evolutionary populations moved by flows, and show how the speed of this motion impacts the fixation probability of an invading mutant. flows of different speeds interpolate between evolutionary dynamics on fixed heterogeneous graphs and in well-stirred populations. we find that the motion has an active role in amplifying or suppressing selection, accomplished by fragmenting and reconnecting the interaction graph. while increasing flow speeds suppress selection for most evolutionary models, we identify characteristic responses to flow for the different update rules we test. we suggest these responses as a potential aid for choosing the most suitable update rule for a given biological system.',\n",
       " 445: \"when considering perceptions, the observation scale and resolution are closely related properties. there is consensus in considering resolution as the density of elementary pieces of information in a specified information space. differently, with the concept of scale, several conceptions compete for a consistent meaning. scale is typically regarded as way to indicate the degree of detail in which an observation is performed. but surprisingly, there is not a unified definition of scale as a description's property. this paper offers a precise definition of scale, and a method to quantify it as a property associated to the interpretation of a description. to complete the parameters needed to describe the perception of a description, the concepts of scope and resolution are also exposed with an exact meaning. a model describing the recursive process of interpretation, based on evolving steps of scale, scope and resolution, is introduced. the model relies on the conception of observation scale and its association to the selection of symbols. five experiments illustrate the application of these concepts, showing that resolution, scale and scope integrate the set of properties to define any point of view from which an observation is performed and interpreted.\",\n",
       " 446: 'we present a method that maintains a balanced binary search tree without using any tree balance criterion at all, with the ultimate aim of maximum simplicity. in fact, our method is highly intuitive, and we only need to add minimal extra code and a simple partial-rebuilding algorithm to a naive binary search tree. our method will be suitable as a highly simple and short solution when amortized logarithmic costs are enough.',\n",
       " 447: 'many theoretical works have attempted to coarse grain gene expression at the level of transcription and translation via frameworks based on exclusion processes. usually in these models the three-dimensional conformation of the substrates (dna and mrna) is neglected, and particles move on a static unidimensional lattice in contact to an infinite reservoir. in this work we generalise the paradigmatic exclusion process and study the transport of particles along a unidimensional polymer-like flexible lattice immersed in a three-dimensional particle reservoir. we study the recycling of particles in the reservoir, how the transport is influenced by the global conformation of the lattice and, in turn, how particle density dictates the structure of the polymer.',\n",
       " 448: 'most contextual bandit algorithms minimize regret against the best fixed policy, a questionable benchmark for non-stationary environments that are ubiquitous in applications. in this work, we develop several efficient contextual bandit algorithms for non-stationary environments by equipping existing methods for i.i.d. problems with sophisticated statistical tests so as to dynamically adapt to a change in distribution.   we analyze various standard notions of regret suited to non-stationary environments for these algorithms, including interval regret, switching regret, and dynamic regret. when competing with the best policy at each time, one of our algorithms achieves regret $\\\\mathcal{o}(\\\\sqrt{st})$ if there are $t$ rounds with $s$ stationary periods, or more generally $\\\\mathcal{o}(\\\\delta^{1/3}t^{2/3})$ where $\\\\delta$ is some non-stationarity measure. these results almost match the optimal guarantees achieved by an inefficient baseline that is a variant of the classic exp4 algorithm. the dynamic regret result is also the first one for efficient and fully adversarial contextual bandit.   furthermore, while the results above require tuning a parameter based on the unknown quantity $s$ or $\\\\delta$, we also develop a parameter free algorithm achieving regret $\\\\min\\\\{s^{1/4}t^{3/4}, \\\\delta^{1/5}t^{4/5}\\\\}$. this improves and generalizes the best existing result $\\\\delta^{0.18}t^{0.82}$ by karnin and anava (2016) which only holds for the two-armed bandit problem.',\n",
       " 449: \"we prove the equivalence between the categories of motives of rigid analytic varieties over a perfectoid field $k$ of mixed characteristic and over the associated (tilted) perfectoid field $k^{\\\\flat}$ of equal characteristic. this can be considered as a motivic generalization of a theorem of fontaine and wintenberger, claiming that the galois groups of $k$ and $k^\\\\flat$ are isomorphic. a main tool for constructing the equivalence is scholze's theory of perfectoid spaces.\",\n",
       " 450: 'finite-size fluctuations in coevolutionary dynamics arise in models of biological as well as of social and economic systems. this brief tutorial review surveys a systematic approach starting from a stochastic process discrete both in time and state. the limit $n\\\\to \\\\infty$ of an infinite population can be considered explicitly, generally leading to a replicator-type equation in zero order, and to a fokker-planck-type equation in first order in $1/\\\\sqrt{n}$. consequences and relations to some previous approaches are outlined.',\n",
       " 451: 'lhaaso-wcda is a large ground-based water cherenkov detector array planned to be built at shangri-la, yunnan province, china. as a major component of lhaaso project, the main purpose of lhaaso-wcda is to survey the northern sky for very-high-energy (above 100 gev) gamma ray sources. to gain full knowledge of water cherenkov technique and to well investigate engineering issues, a 9-cell detector array has been built at yang-ba-jing site, neighboring to the argo-ybj experiment. with the array, charge calibration methods for low and high ranges of the pmt readout are studied, whose result shows that a very high precision at several percentages can be reached. these calibration methods are proposed to be applied in the future lhaaso-wcda project.',\n",
       " 452: 'in many high-throughput experimental design settings, such as those common in biochemical engineering, batched queries are more cost effective than one-by-one sequential queries. furthermore, it is often not possible to directly choose items to query. instead, the experimenter specifies a set of constraints that generates a library of possible items, which are then selected stochastically. motivated by these considerations, we investigate \\\\emph{batched stochastic bayesian optimization} (bsbo), a novel bayesian optimization scheme for choosing the constraints in order to guide exploration towards items with greater utility. we focus on \\\\emph{site-saturation mutagenesis}, a prototypical setting of bsbo in biochemical engineering, and propose a natural objective function for this problem. importantly, we show that our objective function can be efficiently decomposed as a difference of submodular functions (ds), which allows us to employ ds optimization tools to greedily identify sets of constraints that increase the likelihood of finding items with high utility. our experimental results show that our algorithm outperforms common heuristics on both synthetic and two real protein datasets.',\n",
       " 453: 'we investigate spin transport in 2-dimensional insulators, with the long-term goal of establishing whether any of the transport coefficients corresponds to the fu-kane-mele index which characterizes 2d time-reversal-symmetric topological insulators. inspired by the kubo theory of charge transport, and by using a proper definition of the spin current operator, we define the kubo-like spin conductance $g_k^{s_z}$ and spin conductivity $\\\\sigma_k^{s_z}$. we prove that for any gapped, periodic, near-sighted discrete hamiltonian, the above quantities are mathematically well-defined and the equality $g_k^{s_z} = \\\\sigma_k^{s_z}$ holds true. moreover, we argue that the physically relevant condition to obtain the equality above is the vanishing of the mesoscopic average of the spin-torque response, which holds true under our hypotheses on the hamiltonian operator. this vanishing condition might be relevant in view of further extensions of the result, e.g. to ergodic random discrete hamiltonians or to schr\\\\\"odinger operators on the continuum. a central role in the proof is played by the trace per unit volume and by two generalizations of the trace, the principal value trace and it directional version.',\n",
       " 454: 'a robust power gating design using graphene nano-ribbon field effect transistors (gnrfet) is proposed using 16nm technology. the power gating (pg) structure is composed of gnrfet as a power switch and mos power gated module. the proposed structure resolves the main drawbacks of the traditional pg design from the point of view increasing the propagation delay and wake-up time in low voltage regions. gnrfet/mosfet conjunction (gmc) is employed to build various structures of pg, gmcpg-ss and gmcpg-ns. in addition to exploiting it to build two multi-mode pg structures. circuit analysis for cmos power gated logic modules iscas85 benchmark of 16nm technology is used to evaluate the performance of the proposed gnr power switch is compared to the traditional mos one. leakage power, wake-up time and power delay product are used as performance circuit parameters for the evaluation.',\n",
       " 455: 'characterizing the dynamics of time-evolving data within the framework of topological data analysis (tda) has been attracting increasingly more attention. popular instances of time-evolving data include flocking/swarming behaviors in animals and social networks in the human sphere. a natural mathematical model for such collective behaviors is a dynamic point cloud, or more generally a dynamic metric space (dms).   in this paper we extend the rips filtration stability result for (static) metric spaces to the setting of dmss. we do this by devising a certain three-parameter \"spatiotemporal\" filtration of a dms. applying the homology functor to this filtration gives rise to multidimensional persistence module derived from the dms. we show that this multidimensional module enjoys stability under a suitable generalization of the gromov-hausdorff distance which permits metrizing the collection of all dmss.   on the other hand, it is recognized that, in general, comparing two multidimensional persistence modules leads to intractable computational problems. for the purpose of practical comparison of dmss, we focus on both the rank invariant or the dimension function of the multidimensional persistence module that is derived from a dms. we specifically propose to utilize a certain metric d for comparing these invariants: in our work this d is either (1) a certain generalization of the erosion distance by patel, or (2) a specialized version of the well known interleaving distance. we also study the computational complexity associated to both choices of d.',\n",
       " 456: 'we studied the depth dependent magnetization profile of the magnetostrictive co thin film layer in a pmn-pt (011)/ta/co/ta structure under both zero and nonzero applied electric field using polarized neutron reflectometry. application of electric field across the pmn-pt substrate generates a strain, which rotates the magnetization of the co layer consistent with the villari effect. at low magnetic fields (near remanence and coercive field conditions), we find that the depth dependent magnetization profile is non-uniform, under both zero and nonzero applied electric fields. these variations are attributable to the depth dependent strain profile in the co film, as determined by finite element analysis simulations.',\n",
       " 457: 'device-to-device (d2d) communications have recently emerged as a novel transmission paradigm in wireless cellular networks. d2d transmissions take place concurrently with the usual cellular connections, and thus, controlling the interference brought to the macro-cellular user equipment (ue) is of vital importance. in this paper, we consider the uplink transmission of a tier of d2d users that operates as an underlay for the traditional cellular network. using network model based on stochastic geometry, we derive the equilibrium cumulative distribution function (cdf) of the d2d transmit power. considering interference-limited and relatively lossy environment cases, closed form equations are derived for the power cdf. finally, a tight closed-form upper-bound for the derived power distribution is proposed, and the analytical results are validated via simulation.',\n",
       " 458: 'a linear map between matrix spaces is positive if it maps positive semidefinite matrices to positive semidefinite ones, and is called completely positive if all its ampliations are positive. in this article quantitative bounds on the fraction of positive maps that are completely positive are proved. a main tool are real algebraic geometry techniques developed by blekherman to study the gap between positive polynomials and sums of squares. finally, an algorithm to produce positive maps which are not completely positive is given.',\n",
       " 459: 'we study rough high-dimensional landscapes in which an increasingly stronger preference for a given configuration emerges. such energy landscapes arise in glass physics and inference. in particular we focus on random gaussian functions, and on the spiked-tensor model and generalizations. we thoroughly analyze the statistical properties of the corresponding landscapes and characterize the associated geometrical phase transitions. in order to perform our study, we develop a framework based on the kac-rice method that allows to compute the complexity of the landscape, i.e. the logarithm of the typical number of stationary points and their hessian. this approach generalizes the one used to compute rigorously the annealed complexity of mean-field glass models. we discuss its advantages with respect to previous frameworks, in particular the thermodynamical replica method which is shown to lead to partially incorrect predictions.',\n",
       " 460: 'the control of the spread of dengue fever by introduction of the intracellular parasitic bacterium wolbachia in populations of the vector aedes aegypti, is presently one of the most promising tools for eliminating dengue, in the absence of an efficient vaccine. the success of this operation requires locally careful planning to determine the adequate number of individuals carrying the wolbachia parasite that need to be introduced into the natural population. the introduced mosquitoes are expected to eventually replace the wolbachia-free population and guarantee permanent protection against the transmission of dengue to human.   in this study, we propose and analyze a model describing the fundamental aspects of the competition between mosquitoes carrying wolbachia and mosquitoes free of the parasite. we then use feedback control techniques to devise an introduction protocol which is proved to guarantee that the population converges to a stable equilibrium where the totality of mosquitoes carry wolbachia.',\n",
       " 461: 'in this paper, we investigate the stability of the particle trajectories in fixed field alternating gradient accelerators (ffa) in the presence of field errors: the emphasis is on the scaling radial sector ffa type: a collaboration work is on-going in view of better understanding the properties of the 150 mev scaling ffa at kurri in japan, and progress towards high intensity operation. analysis of certain types of field imperfections revealed some interesting features about this machine that explain some of the experimental results and generalize the concept of a scaling ffa to a non-scaling one for which the tune variations obey a well defined law. a compensation scheme of tune variations in imperfect scaling ffas is presented. this is the cornerstone of a novel concept of a non-linear non-scaling radial sector fixed tune ffa that we present and discuss in details in the last part of this paper.',\n",
       " 462: 'understanding physical rules underlying collective motions requires perturbation of controllable parameters in self-propelled particles. however, controlling parameters in animals is generally not easy, which makes collective behaviours of animals elusive. here, we report an experimental system in which a conventional model animal, \\\\textit {caenorhabditis elegans}, collectively forms dynamical networks of bundle-shaped aggregates. we investigate the dependence of our experimental system on various extrinsic parameters (material of substrate, ambient humidity and density of worms). taking advantage of well-established \\\\textit {c.~elegans} genetics, we also control the intrinsic parameters (genetically determined motility) by mutations and by forced neural activation via optogenetics. furthermore, we develop a minimal agent-based model that reproduces the dynamical network formation and its dependence on the parameters, suggesting that the key factors are alignment of worms after collision and smooth turning. our findings imply that the concepts of active matter physics may help us to understand biological functions of animal groups.',\n",
       " 463: 'analysis of sleep for the diagnosis of sleep disorders such as type-1 narcolepsy (t1n) currently requires visual inspection of polysomnography records by trained scoring technicians. here, we used neural networks in approximately 3,000 normal and abnormal sleep recordings to automate sleep stage scoring, producing a hypnodensity graph - a probability distribution conveying more information than classical hypnograms. accuracy of sleep stage scoring was validated in 70 subjects assessed by six scorers. the best model performed better than any individual scorer (87% versus consensus). it also reliably scores sleep down to 5 instead of 30 second scoring epochs. a t1n marker based on unusual sleep-stage overlaps achieved a specificity of 96% and a sensitivity of 91%, validated in independent datasets. addition of hla-dqb1*06:02 typing increased specificity to 99%. our method can reduce time spent in sleep clinics and automates t1n diagnosis. it also opens the possibility of diagnosing t1n using home sleep studies.',\n",
       " 464: 'we prove a derived analogue to the results of borisov, clarke, kelly, and shoemaker on the birationality of berglund-hubsch-krawitz mirrors. heavily bootstrapping off work of seidel and sheridan, we obtain homological mirror symmetry for berglund-hubsch-krawitz mirror pencils to hypersurfaces in projective space.',\n",
       " 465: 'the autoencoder is an artificial neural network model that learns hidden representations of unlabeled data. with a linear transfer function it is similar to the principal component analysis (pca). while both methods use weight vectors for linear transformations, the autoencoder does not come with any indication similar to the eigenvalues in pca that are paired with the eigenvectors. we propose a novel supervised node saliency (sns) method that ranks the hidden nodes by comparing class distributions of latent representations against a fixed reference distribution. the latent representations of a hidden node can be described using a one-dimensional histogram. we apply normalized entropy difference (ned) to measure the \"interestingness\" of the histograms, and conclude a property for ned values to identify a good classifying node. by applying our methods to real data sets, we demonstrate the ability of sns to explain what the trained autoencoders have learned.',\n",
       " 466: 'let $g$ be a compact connected simple lie group and let $m=g^{\\\\bb{c}}/p=g/k$ be a generalized flag manifold. in this article we focus on an important invariant of $g/k$, the so called $\\\\fr{t}$-root system $r_{\\\\fr{t}}$, and we introduce the notion of symmetric $\\\\fr{t}$-triples, that is triples of $\\\\fr{t}$-roots $\\\\xi, \\\\zeta, \\\\eta\\\\in r_{\\\\fr{t}}$ such that $\\\\xi+\\\\eta+\\\\zeta=0$. we describe their properties and we present an interesting application on the structure constants of $g/k$, quantities which are straightforward related to the construction of the homogeneous einstein metric on $g/k$. next we classify symmetric $\\\\fr{t}$-triples for generalized flag manifolds $g/k$ with second betti number $b_{2}(g/k)=1$, and we treat also the case of full flag manifolds $g/t$, where $t$ is a maximal torus of $g$. in the last section we construct the homogeneous einstein equation on flag manifolds $g/k$ with five isotropy summands, determined by the simple lie group $g=\\\\so(7)$. by solving the corresponding algebraic system we classify all $\\\\so(7)$-invariant (non-isometric) einstein metrics, and these are the very first results towards the classification of homogeneous einstein metrics on flag manifolds with five isotropy summands.',\n",
       " 467: \"in this article we identify social communities among gang members in the hollenbeck policing district in los angeles, based on sparse observations of a combination of social interactions and geographic locations of the individuals. this information, coming from lapd field interview cards, is used to construct a similarity graph for the individuals. we use spectral clustering to identify clusters in the graph, corresponding to communities in hollenbeck, and compare these with the lapd's knowledge of the individuals' gang membership. we discuss different ways of encoding the geosocial information using a graph structure and the influence on the resulting clusterings. finally we analyze the robustness of this technique with respect to noisy and incomplete data, thereby providing suggestions about the relative importance of quantity versus quality of collected data.\",\n",
       " 468: 'icosahedral virus capsids are composed of symmetrons, organized arrangements of capsomers. there are three types of symmetrons: disymmetrons, trisymmetrons, and pentasymmetrons, which have different shapes and are centered on the icosahedral 2-fold, 3-fold and 5-fold axes of symmetry, respectively. in 2010 [sinkovits & baker] gave a classification of all possible ways of building an icosahedral structure solely from trisymmetrons and pentasymmetrons, which requires the triangulation number t to be odd. in the present paper we incorporate disymmetrons to obtain a geometric classification of icosahedral viruses formed by regular penta-, tri-, and disymmetrons. for every class of solutions, we further provide formulas for symmetron sizes and parity restrictions on h, k, and t numbers. we also present several methods in which invariants may be used to classify a given configuration.',\n",
       " 469: 'in this paper we propose a perturbative method for the reconstruction of the covariance matrix of a multinormal distribution, under the assumption that the only available information amounts to the covariance matrix of a spherically truncated counterpart of the same distribution. we expand the relevant equations up to the fourth perturbative order and discuss the analytic properties of the first few perturbative terms. we finally compare the proposed approach with an exact iterative algorithm (presented in palombi et al. (2017)) in the hypothesis that the spherically truncated covariance matrix is estimated from samples of various sizes.',\n",
       " 470: 'in this paper, a new data-driven multiscale material modeling method, which we refer to as deep material network, is developed based on mechanistic homogenization theory of representative volume element (rve) and advanced machine learning techniques. we propose to use a collection of connected mechanistic building blocks with analytical homogenization solutions which avoids the loss of essential physics in generic neural networks, and this concept is demonstrated for 2-dimensional rve problems and network depth up to 7. based on linear elastic rve data from offline direct numerical simulations, the material network can be effectively trained using stochastic gradient descent with backpropagation algorithm, enhanced by model compression methods. importantly, the trained network is valid for any local material laws without the need for additional calibration or micromechanics assumption. its extrapolations to unknown material and loading spaces for a wide range of problems are validated through numerical experiments, including linear elasticity with high contrast of phase properties, nonlinear history-dependent plasticity and finite-strain hyperelasticity under large deformations.   by discovering a proper topological representation of rve with fewer degrees of freedom, this intelligent material model is believed to open new possibilities of high-fidelity efficient concurrent simulations for a large-scale heterogeneous structure. it also provides a mechanistic understanding of structure-property relations across material length scales and enables the development of parameterized microstructural database for material design and manufacturing.',\n",
       " 471: 'we introduce bayesian additive regression trees (bart) for log-linear models including multinomial logistic regression and count regression with zero-inflation and overdispersion. bart has been applied to nonparametric mean regression and binary classification problems in a range of settings. however, existing applications of bart have been limited to models for gaussian \"data\", either observed or latent. this is primarily because efficient mcmc algorithms are available for gaussian likelihoods. but while many useful models are naturally cast in terms of latent gaussian variables, many others are not -- including models considered in this paper.   we develop new data augmentation strategies and carefully specified prior distributions for these new models. like the original bart prior, the new prior distributions are carefully constructed and calibrated to be flexible while guarding against overfitting. together the new priors and data augmentation schemes allow us to implement an efficient mcmc sampler outside the context of gaussian models. the utility of these new methods is illustrated with examples and an application to a previously published dataset.',\n",
       " 472: 'modern pattern recognition methods are based on convolutional networks since they are able to learn complex patterns that benefit the classification. however, convolutional networks are computationally expensive and require a considerable amount of memory, which limits their deployment on low-power and resource-constrained systems. to handle these problems, recent approaches have proposed pruning strategies that find and remove unimportant neurons (i.e., filters) in these networks. despite achieving remarkable results, existing pruning approaches are ineffective since the accuracy of the original network is degraded. in this work, we propose a novel approach to efficiently remove filters from convolutional networks. our approach estimates the filter importance based on its relationship with the class label on a low-dimensional space. this relationship is computed using partial least squares (pls) and variable importance in projection (vip). our method is able to reduce up to 67% of the floating point operations (flops) without penalizing the network accuracy. with a negligible drop in accuracy, we can reduce up to 90% of flops. additionally, sometimes the method is even able to improve the accuracy compared to original, unpruned, network. we show that employing pls+vip as the criterion for detecting the filters to be removed is better than recent feature selection techniques, which have been employed by state-of-the-art pruning methods. finally, we show that the proposed method achieves the highest flops reduction and the smallest drop in accuracy when compared to state-of-the-art pruning approaches. codes are available at: https://github.com/arturjordao/pruningneuralnetworks',\n",
       " 473: \"we propose a simple and robust non-parameterized approach for building sentence representations. inspired by the gram-schmidt process in geometric theory, we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. we model the semantic meaning of a word in a sentence based on two aspects. one is its relatedness to the word vector subspace already spanned by its contextual words. the other is the word's novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace. following this motivation, we develop an innovative method based on orthogonal basis to combine pre-trained word embeddings into sentence representations. this approach requires zero parameters, along with efficient inference performance. we evaluate our approach on 11 downstream nlp tasks. our model shows superior performance compared with non-parameterized alternatives and it is competitive to other approaches relying on either large amounts of labelled data or prolonged training time.\",\n",
       " 474: 'using video microscopy, we measure local spatial constraints in disordered binary colloidal samples, ranging from dilute fluids to jammed glasses, and probe their spatial and temporal correlations to local dynamics during the glass transition. we observe the emergence of significant correlations between constraints and local dynamics within the lindemann criterion, which coincides with the onset of glassy dynamics in supercooled liquids. rigid domains in fluids are identified based on local constraints, and demonstrate a percolation transition near glass transition, accompanied by the emergence of dynamical heterogeneities. our results show that the spatial constraints instead of the geometry of amorphous structures is the key that connects the complex spatial-temporal correlations in disordered materials.',\n",
       " 475: 'assuming the existence of a proper class of supercompact cardinals, we force that for every regular cardinal $\\\\kappa$, there are $\\\\kappa^+$-aronszajn trees and all such trees are special.',\n",
       " 476: \"we investigate the nonparametric, composite hypothesis testing problem for arbitrary unknown distributions in the asymptotic regime where both the sample size and the number of hypotheses grow exponentially large. such asymptotic analysis is important in many practical problems, where the number of variations that can exist within a family of distributions can be countably infinite. we introduce the notion of \\\\emph{discrimination capacity}, which captures the largest exponential growth rate of the number of hypotheses relative to the sample size so that there exists a test with asymptotically vanishing probability of error. our approach is based on various distributional distance metrics in order to incorporate the generative model of the data. we provide analyses of the error exponent using the maximum mean discrepancy (mmd) and kolmogorov-smirnov (ks) distance and characterize the corresponding discrimination rates, i.e., lower bounds on the discrimination capacity, for these tests. finally, an upper bound on the discrimination capacity based on fano's inequality is developed. numerical results are presented to validate the theoretical results.\",\n",
       " 477: 'we derive a lower bound on the location of global extrema of eigenfunctions for a large class of non-local schr\\\\\"odinger operators in convex domains under dirichlet exterior conditions, featuring the symbol of the kinetic term, the strength of the potential, and the corresponding eigenvalue, and involving a new universal constant. we show a number of probabilistic and spectral geometric implications, and derive a faber-krahn type inequality for non-local operators. our study also extends to potentials with compact support, and we establish bounds on the location of extrema relative to the boundary edge of the support or level sets around minima of the potential.',\n",
       " 478: 'we investigate optimal geographical caching in heterogeneous cellular networks, where different types of base stations (bss) have different cache capacities. the content library contains files with different popularities. the performance metric is the total hit probability.   the problem of optimally placing content in all bss jointly is not convex in general. however, we show that when bss are deployed according to homogeneous poisson point processes (ppp), independently for each type, we can formulate the problem as a convex problem. we give the optimal solution to the joint problem for ppp deployment. for the general case, we provide a distributed local optimization algorithm (loa) that finds the optimal placement policies for different types of bss. we find the optimal placement policy of the small bss (sbss) depending on the placement policy of the macro bss (mbss). we show that storing the most popular content in the mbss is almost optimal if the sbss are using an optimal placement policy. also, for the sbss no such heuristic can be used; the optimal placement is significantly better than storing the most popular content. finally, we numerically verify that loa gives the same hit probability as the joint optimal solution for the ppp model.',\n",
       " 479: \"this paper describes the outlines of a research program for understanding the cognitive-emotional brain, with an emphasis on the issue of dynamics: how can we study, characterize, and understand the neural underpinnings of cognitive-emotional behaviors as inherently dynamic processes? the framework embraces many of the central themes developed by steve grossberg in his extensive body of work in the past 50 years. by embracing head on the leitmotifs of dynamics, decentralized computation, emergence, selection and competition, and autonomy, it is proposed that a science of the mind-brain can be developed that is built upon a solid foundation of understanding behavior while employing computational and mathematical tools in an integral manner. a key implication of the framework is that standard ways of thinking about causation are inadequate when unravelling the workings of a complex system such as the brain. instead, it is proposed that researchers should focus on determining the dynamic multivariate structure of brain data. accordingly, central problems become to characterize the dimensionality of neural trajectories, and the geometry of the underlying neural space. at a time when the development of neurotechniques has reached a fever pitch, neuroscience needs to redirect its focus and invest comparable energy in the conceptual and theoretical dimensions of its research endeavor. otherwise we run the risk of being able to measure 'every atom' in the brain in a theoretical vacuum.\",\n",
       " 480: 'coniii (pronounced con-ee) is an open-source python project providing a simple interface to solving the pairwise and higher order ising model and a base for extension to other maximum entropy models. we describe the maximum entropy problem and give an overview of the algorithms that are implemented as part of coniii (https://github.com/eltrompetero/coniii) including monte carlo histogram, pseudolikelihood, minimum probability flow, a regularized mean field method, and a cluster expansion method. our goal is to make a variety of maximum entropy techniques accessible to those unfamiliar with the techniques and accelerate workflow for users.',\n",
       " 481: 'in natural language, words and phrases themselves imply the semantics. in contrast, the meaning of identifiers in mathematical formulae is undefined. thus scientists must study the context to decode the meaning. the mathematical language processing (mlp) project aims to support that process. in this paper, we compare two approaches to discover identifier-definition tuples. at first we use a simple pattern matching approach. second, we present the mlp approach that uses part-of-speech tag based distances as well as sentence positions to calculate identifier-definition probabilities. the evaluation of our prototypical system, applied on the wikipedia text corpus, shows that our approach augments the user experience substantially. while hovering the identifiers in the formula, tool-tips with the most probable definitions occur. tests with random samples show that the displayed definitions provide a good match with the actual meaning of the identifiers.',\n",
       " 482: 'recently, along with the rapid development of mobile communication technology, edge computing theory and techniques have been attracting more and more attentions from global researchers and engineers, which can significantly bridge the capacity of cloud and requirement of devices by the network edges, and thus can accelerate the content deliveries and improve the quality of mobile services. in order to bring more intelligence to the edge systems, compared to traditional optimization methodology, and driven by the current deep learning techniques, we propose to integrate the deep reinforcement learning techniques and federated learning framework with the mobile edge systems, for optimizing the mobile edge computing, caching and communication. and thus, we design the \"in-edge ai\" framework in order to intelligently utilize the collaboration among devices and edge nodes to exchange the learning parameters for a better training and inference of the models, and thus to carry out dynamic system-level optimization and application-level enhancement while reducing the unnecessary system communication load. \"in-edge ai\" is evaluated and proved to have near-optimal performance but relatively low overhead of learning, while the system is cognitive and adaptive to the mobile communication systems. finally, we discuss several related challenges and opportunities for unveiling a promising upcoming future of \"in-edge ai\".',\n",
       " 483: 'this paper presents the probability hypothesis density filter (phd) and the cardinality phd (cphd) filter for sets of trajectories, which are referred to as the trajectory phd (tphd) and trajectory cphd (tcphd) filters. contrary to the phd/cphd filters, the tphd/tcphd filters are able to produce trajectory estimates from first principles. the tphd filter is derived by recursively obtaining the best poisson multitrajectory density approximation to the posterior density over the alive trajectories by minimising the kullback-leibler divergence. the tcphd is derived in the same way but propagating an independent identically distributed (iid) cluster multitrajectory density approximation. we also propose the gaussian mixture implementations of the tphd and tcphd recursions, the gaussian mixture tphd (gmtphd) and the gaussian mixture tcphd (gmtcphd), and the l-scan computationally efficient implementations, which only update the density of the trajectory states of the last l time steps.',\n",
       " 484: 'we consider a novel multi-armed bandit framework where the rewards obtained by pulling the arms are functions of a common latent random variable. the correlation between arms due to the common random source can be used to design a generalized upper-confidence-bound (ucb) algorithm that identifies certain arms as $non-competitive$, and avoids exploring them. as a result, we reduce a $k$-armed bandit problem to a $c+1$-armed problem, where $c+1$ includes the best arm and $c$ $competitive$ arms. our regret analysis shows that the competitive arms need to be pulled $\\\\mathcal{o}(\\\\log t)$ times, while the non-competitive arms are pulled only $\\\\mathcal{o}(1)$ times. as a result, there are regimes where our algorithm achieves a $\\\\mathcal{o}(1)$ regret as opposed to the typical logarithmic regret scaling of multi-armed bandit algorithms. we also evaluate lower bounds on the expected regret and prove that our correlated-ucb algorithm achieves $\\\\mathcal{o}(1)$ regret whenever possible.',\n",
       " 485: \"we derive a new outer bound on the capacity region of broadcast traffic in multiple input broadcast packet erasure channels with feedback, and extend this outer bound to packet erasure relay networks with feedback. we show the tightness of the outer bound for various classes of networks. an important engineering implication of this work is that for network coding schemes for parallel broadcast channels, the `xor' packets should be sent over correlated broadcast subchannels.\",\n",
       " 486: 'given a finite set of european call option prices on a single underlying, we want to know when there is a market model which is consistent with these prices. in contrast to previous studies, we allow models where the underlying trades at a bid-ask spread. the main question then is how large (in terms of a deterministic bound) this spread must be to explain the given prices. we fully solve this problem in the case of a single maturity, and give several partial results for multiple maturities. for the latter, our main mathematical tool is a recent result on approximation by peacocks [s. gerhold, i.c. g\\\\\"ul\\\\\"uum, arxiv:1512.06640].',\n",
       " 487: 'discussions of the hippocampus often focus on place cells, but many neurons are not place cells in any given environment. here we describe the collective activity in such mixed populations, treating place and non-place cells on the same footing. we start with optical imaging experiments on ca1 in mice as they run along a virtual linear track, and use maximum entropy methods to approximate the distribution of patterns of activity in the population, matching the correlations between pairs of cells but otherwise assuming as little structure as possible. we find that these simple models accurately predict the activity of each neuron from the state of all the other neurons in the network, regardless of how well that neuron codes for position. these and other results suggest that place cells are not a distinct sub-network, but part of a larger system that encodes, collectively, more than just place information.',\n",
       " 488: 'we survey results concerning special elements of nine types (modular, lower-modular, upper-modular, cancellable, distributive, codistributive, standard, costandard and neutral elements) in the lattice of all semigroup varieties and certain its sublattices, mainly in the lattices of all commutative varieties and of all overcommutative ones. several open questions are formulated. the work is regularly updated and modified as new results and/or articles appear.',\n",
       " 489: 'we investigate the techniques and ideas used in the convergence analysis of two proximal admm algorithms for solving convex optimization problems involving compositions with linear operators. besides this, we formulate a variant of the admm algorithm that is able to handle convex optimization problems involving an additional smooth function in its objective, and which is evaluated through its gradient. moreover, in each iteration we allow the use of variable metrics, while the investigations are carried out in the setting of infinite dimensional hilbert spaces. this algorithmic scheme is investigated from the point of view of its convergence properties.',\n",
       " 490: 'how can local-search methods such as stochastic gradient descent (sgd) avoid bad local minima in training multi-layer neural networks? why can they fit random labels even given non-convex and non-smooth architectures? most existing theory only covers networks with one hidden layer, so can we go deeper?   in this paper, we focus on recurrent neural networks (rnns) which are multi-layer networks widely used in natural language processing. they are harder to analyze than feedforward neural networks, because the $\\\\textit{same}$ recurrent unit is repeatedly applied across the entire time horizon of length $l$, which is analogous to feedforward networks of depth $l$. we show when the number of neurons is sufficiently large, meaning polynomial in the training data size and in $l$, then sgd is capable of minimizing the regression loss in the linear convergence rate. this gives theoretical evidence of how rnns can memorize data.   more importantly, in this paper we build general toolkits to analyze multi-layer networks with relu activations. for instance, we prove why relu activations can prevent exponential gradient explosion or vanishing, and build a perturbation theory to analyze first-order approximation of multi-layer networks.',\n",
       " 491: 'we apply the generalized method of separation of variables (gmsv) to solve boundary value problems for the laplace operator in three-dimensional domains with disconnected spherical boundaries (i.e., an arbitrary configuration of non-overlapping partially reactive spherical sinks or obstacles). we consider both exterior and interior problems and all most common boundary conditions: dirichlet, neumann, robin, and conjugate one. using the translational addition theorems for solid harmonics to switch between the local spherical coordinates, we obtain a semi-analytical expression of the green function as a linear combination of partial solutions whose coefficients are fixed by boundary conditions. although the numerical computation of the coefficients involves series truncation and matrix inversion, the use of the solid harmonics as basis functions naturally adapted to the intrinsic symmetries of the problem makes the gmsv particularly efficient, especially for exterior problems. the obtained green function is the key ingredient to solve boundary value problems and to determine various characteristics of stationary diffusion such as reaction rate, escape probability, harmonic measure, residence time, and mean first passage time, to name but a few. the relevant aspects of the numerical implementation and potential applications in chemical physics, heat transfer, electrostatics, and hydrodynamics are discussed.',\n",
       " 492: 'let (x,d) be a dlt pair, where x is a normal projective variety. let s denote the support of the rounddown of d, and k the canonical divisor of x. we show that any smooth family of canonically polarized varieties over x\\\\s is isotrivial if the divisor -(k+d) is ample. this result extends results of viehweg-zuo and kebekus-kovacs.   to prove this result we show that any extremal ray of the moving cone is generated by a family of curves, and these curves are contracted after a certain run of the minimal model program. in the log fano case, this generalizes a theorem by araujo from the klt to the dlt case.   in order to run the minimal model program, we have to switch to a q-factorialization of x. as q-factorializations are generally not unique, we use flops to pass from one q-factorialization to another, proving the existence of a q-factorialization suitable for our purposes.',\n",
       " 493: 'statistical characteristics of deep network representations, such as sparsity and correlation, are known to be relevant to the performance and interpretability of deep learning. when a statistical characteristic is desired, often an adequate regularizer can be designed and applied during the training phase. typically, such a regularizer aims to manipulate a statistical characteristic over all classes together. for classification tasks, however, it might be advantageous to enforce the desired characteristic per class such that different classes can be better distinguished. motivated by the idea, we design two class-wise regularizers that explicitly utilize class information: class-wise covariance regularizer (cw-cr) and class-wise variance regularizer (cw-vr). cw-cr targets to reduce the covariance of representations calculated from the same class samples for encouraging feature independence. cw-vr is similar, but variance instead of covariance is targeted to improve feature compactness. for the sake of completeness, their counterparts without using class information, covariance regularizer (cr) and variance regularizer (vr), are considered together. the four regularizers are conceptually simple and computationally very efficient, and the visualization shows that the regularizers indeed perform distinct representation shaping. in terms of classification performance, significant improvements over the baseline and l1/l2 weight regularization methods were found for 21 out of 22 tasks over popular benchmark datasets. in particular, cw-vr achieved the best performance for 13 tasks including resnet-32/110.',\n",
       " 494: 'purpose: to apply deep cnn to the segmentation task in myocardial arterial spin labeled (asl) perfusion imaging and to develop methods that measure uncertainty and that adapt the cnn model to a specific false positive vs. false negative tradeoff.   methods: the monte carlo dropout (mcd) u-net was trained on data from 22 subjects and tested on data from 6 heart transplant recipients. manual segmentation and regional myocardial blood flow (mbf) were available for comparison. we consider two global uncertainty measures, named dice uncertainty and mcd uncertainty, which were calculated with and without the use of manual segmentation, respectively. tversky loss function with a hyperparameter $\\\\beta$ was used to adapt the model to a specific false positive vs. false negative tradeoff.   results: the mcd u-net achieved dice coefficient of mean(std) = 0.91(0.04) on the test set. mbf measured using automatic segmentations was highly correlated to that measured using the manual segmentation ($r^2$ = 0.96). dice uncertainty and mcd uncertainty were in good agreement ($r^2$ = 0.64). as $\\\\beta$ increased, the false positive rate systematically decreased and false negative rate systematically increased.   conclusion: we demonstrate the feasibility of deep cnn for automatic segmentation of myocardial asl, with good accuracy. we also introduce two simple methods for assessing model uncertainty. finally, we demonstrate the ability to adapt the cnn model to a specific false positive vs. false negative tradeoff. these findings are directly relevant to automatic segmentation in quantitative cardiac mri and are broadly applicable to automatic segmentation problems in diagnostic imaging.',\n",
       " 495: 'self-sustained activity in the brain is observed in the absence of external stimuli and contributes to signal propagation, neural coding, and dynamic stability. it also plays an important role in cognitive processes. in this work, by means of studying intracellular recordings from ca1 neurons in rats and results from numerical simulations, we demonstrate that self-sustained activity presents high variability of patterns, such as low neural firing rates and activity in the form of small-bursts in distinct neurons. in our numerical simulations, we consider random networks composed of coupled, adaptive exponential integrate-and-fire neurons. the neural dynamics in the random networks simulate regular spiking (excitatory) and fast-spiking (inhibitory) neurons. we show that both the connection probability and network size are fundamental properties that give rise to self-sustained activity in qualitative agreement with our experimental results. finally, we provide a more detailed description of the self-sustained activity in terms of lifetime distributions, synaptic conductances, and synaptic currents.',\n",
       " 496: 'cortical network functioning critically depends on finely tuned interactions to afford neuronal activity propagation over long distances while avoiding runaway excitation. this importance is highlighted by the pathological consequences and impaired performance resulting from aberrant network excitability in psychiatric and neurological diseases, such as epilepsy. theory and experiment suggest that the control of activity propagation by network interactions can be adequately described by a branching process. this hypothesis is partially supported by strong evidence for balanced spatiotemporal dynamics observed in the cerebral cortex, however, evidence of a causal relationship between network interactions and cortex activity, as predicted by a branching process, is missing in humans. here we test this cause-effect relationship by monitoring cortex activity under systematic pharmacological reduction of cortical network interactions with antiepileptic drugs. we report that cortical activity cascades, presented by the propagating patterns of epileptic spikes, as well as temporal correlations decline precisely as predicted for a branching process. our results provide the missing link to the branching process theory of cortical network function with implications for understanding the foundations of cortical excitability and its monitoring in conditions like epilepsy.',\n",
       " 497: 'we present a comprehensive study of deep bidirectional long short-term memory (lstm) recurrent neural network (rnn) based acoustic models for automatic speech recognition (asr). we study the effect of size and depth and train models of up to 8 layers. we investigate the training aspect and study different variants of optimization methods, batching, truncated backpropagation, different regularization techniques such as dropout and $l_2$ regularization, and different gradient clipping variants.   the major part of the experimental analysis was performed on the quaero corpus. additional experiments also were performed on the switchboard corpus. our best lstm model has a relative improvement in word error rate of over 14\\\\% compared to our best feed-forward neural network (ffnn) baseline on the quaero task. on this task, we get our best result with an 8 layer bidirectional lstm and we show that a pretraining scheme with layer-wise construction helps for deep lstms.   finally we compare the training calculation time of many of the presented experiments in relation with recognition performance.   all the experiments were done with returnn, the rwth extensible training framework for universal recurrent neural networks in combination with rasr, the rwth asr toolkit.',\n",
       " 498: 'in this paper, we analyze the benefits of including downlink pilots in a cell-free massive mimo system. we derive an approximate per-user achievable downlink rate for conjugate beamforming processing, which takes into account both uplink and downlink channel estimation errors, and power control. a performance comparison is carried out, in terms of per-user net throughput, considering cell-free massive mimo operation with and without downlink training, for different network densities. we take also into account the performance improvement provided by max-min fairness power control in the downlink. numerical results show that, exploiting downlink pilots, the performance can be considerably improved in low density networks over the conventional scheme where the users rely on statistical channel knowledge only. in high density networks, performance improvements are moderate.',\n",
       " 499: 'we introduce length dilatation structures on metric spaces, tempered dilatation structures and coherent projections and explore the relations between these objects and the radon-nikodym property and gamma-convergence of length functionals. then we show that the main properties of sub-riemannian spaces can be obtained from pairs of length dilatation structures, the first being a tempered one and the second obtained via a coherent projection.   thus we get an intrinsic, synthetic, axiomatic description of sub-riemannian geometry, which transforms the classical construction of a carnot-caratheodory distance on a regular sub-riemannian manifold into a model for this abstract sub-riemannian geometry.',\n",
       " 500: 'a \"signed graph\" is a graph $\\\\gamma$ where the edges are assigned sign labels, either \"$+$\" or \"$-$\". the sign of a cycle is the product of the signs of its edges. let $\\\\mathrm{specc}(\\\\gamma)$ denote the list of lengths of cycles in $\\\\gamma$. we equip each signed graph with a vector whose entries are the numbers of negative $k$-cycles for $k\\\\in\\\\mathrm{specc}(\\\\gamma)$. these vectors generate a subspace of $\\\\mathbb r^{\\\\mathrm{specc}(\\\\gamma)}$. using matchings with a strong permutability property, we provide lower bounds on the dimension of this space; in particular, we show for complete graphs, complete bipartite graphs, and a few other graphs that this space is all of $\\\\mathbb r^{\\\\mathrm{specc}(\\\\gamma)}$.',\n",
       " 501: 'hyperedge replacement (hr) grammars can generate np-complete graph languages, which makes parsing hard even for fixed hr languages. therefore, we study predictive shift-reduce (psr) parsing that yields efficient parsers for a subclass of hr grammars, by generalizing the concepts of slr(1) string parsing to graphs. we formalize the construction of psr parsers and show that it is correct. psr parsers run in linear space and time, and are more efficient than the predictive top-down (ptd) parsers recently developed by the authors.',\n",
       " 502: 'it is proved that a maximal abelian subalgebra of the noncommutative torus commutes with the laplace operator on a complex torus. as a corollary, one gets an analog of the poisson summation formula for noncommutative tori.',\n",
       " 503: \"in the papers of nakaoka, he introduced the notion of hearts of (twin) cotorsion pairs on triangulated categories and showed that they have structures of (semi-) abelian categories. we study in this article a twin cotorsion pair (s,t),(u,v) on an exact category b with enough projectives and injectives and introduce a notion of the heart. first we show that its heart is preabelian. moreover we show the heart of a single cotorsion pair is abelian. these results are analog of nakaoka's results in triangulated categories. we also consider special cases where the heart has nicer structure. by our results, the heart of a special twin cotorsion pair (s,t),(t,v), is integral and almost abelian. finally we show that the gabriel-zisman localisation of the heart at the class of regular morphisms is abelian, and moreover it is equivalent to the category of finitely presented modules over a stable subcategory of b.\",\n",
       " 504: \"in this paper, we study the information-theoretic limits of learning the structure of bayesian networks (bns), on discrete as well as continuous random variables, from a finite number of samples. we show that the minimum number of samples required by any procedure to recover the correct structure grows as $\\\\omega(m)$ and $\\\\omega(k \\\\log m + (k^2/m))$ for non-sparse and sparse bns respectively, where $m$ is the number of variables and $k$ is the maximum number of parents per node. we provide a simple recipe, based on an extension of the fano's inequality, to obtain information-theoretic limits of structure recovery for any exponential family bn. we instantiate our result for specific conditional distributions in the exponential family to characterize the fundamental limits of learning various commonly used bns, such as conditional probability table based networks, gaussian bns, noisy-or networks, and logistic regression networks. en route to obtaining our main results, we obtain tight bounds on the number of sparse and non-sparse essential-dags. finally, as a byproduct, we recover the information-theoretic limits of sparse variable selection for logistic regression.\",\n",
       " 505: 'we formalize the problem of selecting the optimal set of options for planning as that of computing the smallest set of options so that planning converges in less than a given maximum of value-iteration passes. we first show that the problem is np-hard, even if the task is constrained to be deterministic---the first such complexity result for option discovery. we then present the first polynomial-time boundedly suboptimal approximation algorithm for this setting, and empirically evaluate it against both the optimal options and a representative collection of heuristic approaches in simple grid-based domains including the classic four-rooms problem.',\n",
       " 506: \"a simple scheme was proposed by knuth to generate binary balanced codewords from any information word. however, this method is limited in the sense that its redundancy is twice that of the full sets of balanced codes. the gap between knuth's algorithm's redundancy and that of the full sets of balanced codes is significantly considerable. this paper attempts to reduce that gap. furthermore, many constructions assume that a full balancing can be performed without showing the steps. a full balancing refers to the overall balancing of the encoded information together with the prefix. we propose an efficient way to perform a full balancing scheme that does not make use of lookup tables or enumerative coding.\",\n",
       " 507: 'graph coloring is one of the most famous computational problems with applications in a wide range of areas such as planning and scheduling, resource allocation, and pattern matching. so far coloring problems are mostly studied on static graphs, which often stand in stark contrast to practice where data is inherently dynamic and subject to discrete changes over time. a temporal graph is a graph whose edges are assigned a set of integer time labels, indicating at which discrete time steps the edge is active. in this paper we present a natural temporal extension of the classical graph coloring problem. given a temporal graph and a natural number $\\\\delta$, we ask for a coloring sequence for each vertex such that (i) in every sliding time window of $\\\\delta$ consecutive time steps, in which an edge is active, this edge is properly colored (i.e. its endpoints are assigned two different colors) at least once during that time window, and (ii) the total number of different colors is minimized. this sliding window temporal coloring problem abstractly captures many realistic graph coloring scenarios in which the underlying network changes over time, such as dynamically assigning communication channels to moving agents. we present a thorough investigation of the computational complexity of this temporal coloring problem. more specifically, we prove strong computational hardness results, complemented by efficient exact and approximation algorithms. some of our algorithms are linear-time fixed-parameter tractable with respect to appropriate parameters, while others are asymptotically almost optimal under the exponential time hypothesis (eth).',\n",
       " 508: 'the analytic hierarchy process (ahp) is widely used for decision making involving multiple criteria. elsner and van den driessche introduced a max-algebraic approach to the single criterion ahp. we extend this to the multi-criteria ahp, by considering multi-objective generalisations of the single objective optimisation problem solved in these earlier papers. we relate the existence of globally optimal solutions to the commutativity properties of the associated matrices; we relate min-max optimal solutions to the generalised spectral radius; and we prove that pareto optimal solutions are guaranteed to exist.',\n",
       " 509: 'electrical signaling via voltage-gated ion channels depends upon the function of a voltage sensor (vs), identified with the s1-s4 domain in voltage-gated k+ channels. here we investigate some energetic aspects of the sliding-helix model of the vs using simulations based on vs charges, linear dielectrics and whole-body motion. model electrostatics in voltage-clamped boundary conditions are solved using a boundary element method. the statistical mechanical consequences of the electrostatic configurational energy are computed to gain insight into the sliding-helix mechanism and to predict experimentally measured ensemble properties such as gating charge displaced by an applied voltage. those consequences and ensemble properties are investigated for two alternate s4 configurations, \\\\alpha- and 3(10)-helical. both forms of vs are found to have an inherent electrostatic stability. maximal charge displacement is limited by geometry, specifically the range of movement where s4 charges and counter-charges overlap in the region of weak dielectric. charge displacement responds more steeply to voltage in the \\\\alpha-helical than the 3(10)-helical sensor. this difference is due to differences on the order of 0.1 ev in the landscapes of electrostatic energy. as a step toward integrating these vs models into a full-channel model, we include a hypothetical external load in the hamiltonian of the system and analyze the energetic in/output relation of the vs.',\n",
       " 510: 'strong intelligent machines powered by deep neural networks are increasingly deployed as black boxes to make decisions in risk-sensitive domains, such as finance and medical. to reduce potential risk and build trust with users, it is critical to interpret how such machines make their decisions. existing works interpret a pre-trained neural network by analyzing hidden neurons, mimicking pre-trained models or approximating local predictions. however, these methods do not provide a guarantee on the exactness and consistency of their interpretation. in this paper, we propose an elegant closed form solution named $openbox$ to compute exact and consistent interpretations for the family of piecewise linear neural networks (plnn). the major idea is to first transform a plnn into a mathematically equivalent set of linear classifiers, then interpret each linear classifier by the features that dominate its prediction. we further apply $openbox$ to demonstrate the effectiveness of non-negative and sparse constraints on improving the interpretability of plnns. the extensive experiments on both synthetic and real world data sets clearly demonstrate the exactness and consistency of our interpretation.',\n",
       " 511: 'the auger engineering radio array (aera) is currently detecting cosmic rays of energies at and above 10^17 ev at the pierre auger observatory, by triggering on the radio emission produced in the associated air showers. the radio-detection technique must cope with a significant background of man-made radio-frequency interference, but can provide information on shower development with a high duty cycle. we discuss our techniques to handle the challenges of self-triggered radio detection in a low-power autonomous array, including triggering and filtering algorithms, data acquisition design, and communication systems.',\n",
       " 512: \"increasingly, discrimination by algorithms is perceived as a societal and legal problem. as a response, a number of criteria for implementing algorithmic fairness in machine learning have been developed in the literature. this paper proposes the continuous fairness algorithm (cfa$\\\\theta$) which enables a continuous interpolation between different fairness definitions. more specifically, we make three main contributions to the existing literature. first, our approach allows the decision maker to continuously vary between specific concepts of individual and group fairness. as a consequence, the algorithm enables the decision maker to adopt intermediate ``worldviews'' on the degree of discrimination encoded in algorithmic processes, adding nuance to the extreme cases of ``we're all equal'' (wae) and ``what you see is what you get'' (wysiwyg) proposed so far in the literature. second, we use optimal transport theory, and specifically the concept of the barycenter, to maximize decision maker utility under the chosen fairness constraints. third, the algorithm is able to handle cases of intersectionality, i.e., of multi-dimensional discrimination of certain groups on grounds of several criteria. we discuss three main examples (credit applications; college admissions; insurance contracts) and map out the legal and policy implications of our approach. the explicit formalization of the trade-off between individual and group fairness allows this post-processing approach to be tailored to different situational contexts in which one or the other fairness criterion may take precedence. finally, we evaluate our model experimentally.\",\n",
       " 513: 'there are currently over 160 known gamma-ray pulsars. while most of them are detected only from space, at least two are now seen also from the ground. magic and veritas have measured the gamma ray pulsed emission of the crab pulsar up to hundreds of gev and more recently magic has reported emission at $\\\\sim2$ tev. furthermore, in the southern hemisphere, h.e.s.s. has detected the vela pulsar above 30 gev. in addition, non-pulsed tev emission coincident with pulsars has been detected by many groups, including the milagro collaboration. these gev-tev observations open the possibility of searching for very-high-energy (vhe, > 100gev) pulsations from gamma-rays pulsars in the hawc field of view.',\n",
       " 514: 'we prove that a k\\\\\"ahler group which is cubulable, i.e. which acts properly discontinuously and cocompactly on a cat(0) cubical complex, has a finite index subgroup isomorphic to a direct product of surface groups, possibly with a free abelian factor. similarly, we prove that a closed aspherical k\\\\\"ahler manifold with a cubulable fundamental group has a finite cover which is biholomorphic to a topologically trivial principal torus bundle over a product of riemann surfaces. along the way, we prove a factorization result for essential actions of k\\\\\"ahler groups on irreducible, locally finite cat(0) cubical complexes, under the assumption that there is no fixed point in the visual boundary.',\n",
       " 515: 'the propagation of soliton waves is simulated through splices in optical fibers, in which fluctuations of dielectric parameters occur. the mathematical modeling of these local fluctuations of dielectric properties of fibers was performed by gaussian functions. by simulating soliton wave propagation in optical fibers with gaussian fluctuations in their dielectric properties, it was observed that the perturbed soliton numerical solution presented higher sensitivity to fluctuations in the dielectric parameter $\\\\beta$, a measure of the intensity of nonlinearity in the fiber. in order to verify whether the fluctuations of $\\\\beta$ parameter in the splices of the optical fiber generate unstable solitons, the propagation of a soliton wave, subject to this perturbation, was simulated for large time intervals. considering various geometric configurations and intensities of the fluctuations of parameter $\\\\beta$, it was found that the perturbed soliton wave stabilizes, i.e., the amplitude of the wave oscillations decreases for increasing values of propagation distance. it is concluded that the propagation of perturbed soliton wave presents numerical stability when subjected to local gaussian fluctuations (perturbations) of the dielectric parameters of the optical fiber.',\n",
       " 516: 'determinant codes are a class of exact-repair regenerating codes for distributed storage systems with parameters (n, k = d, d). these codes cover the entire trade-off between per-node storage and repair-bandwidth. in an earlier work of the authors, the repair data of the determinant code sent by a helper node to repair a failed node depends on the identity of the other helper nodes participating in the process, which is practically undesired. in this work, a new repair mechanism is proposed for determinant codes, which relaxes this dependency, while preserving all other properties of the code. moreover, it is shown that the determinant codes are capable of repairing multiple failures, with a per-node repair-bandwidth which scales sub-linearly with the number of failures.',\n",
       " 517: \"we consider a non-zero-sum linear quadratic gaussian (lqg) dynamic game with asymmetric information. each player observes privately a noisy version of a (hidden) state of the world $v$, resulting in dependent private observations. we study perfect bayesian equilibria (pbe) for this game with equilibrium strategies that are linear in players' private estimates of $v$. the main difficulty arises from the fact that players need to construct estimates on other players' estimate on $v$, which in turn would imply that an infinite hierarchy of estimates on estimates needs to be constructed, rendering the problem unsolvable. we show that this is not the case: each player's estimate on other players' estimates on $v$ can be summarized into her own estimate on $v$ and some appropriately defined public information. based on this finding we characterize the pbe through a backward/forward algorithm akin to dynamic programming for the standard lqg control problem. unlike the standard lqg problem, however, kalman filter covariance matrices, as well as some other required quantities, are observation-dependent and thus cannot be evaluated off-line through a forward recursion.\",\n",
       " 518: \"a complete classification of the complexity of the local and global satisfiability problems for graded modal language over traditional classes of frames has already been established. by 'traditional' classes of frames we mean those characterized by any positive combination of reflexivity, seriality, symmetry, transitivity, and the euclidean property. in this paper we fill the gaps remaining in an analogous classification of the graded modal language with graded converse modalities. in particular we show its nexptime-completeness over the class of euclidean frames, demonstrating this way that over this class the considered language is harder than the language without graded modalities or without converse modalities. we also consider its variation disallowing graded converse modalities, but still admitting basic converse modalities. our most important result for this variation is confirming an earlier conjecture that it is decidable over transitive frames. this contrasts with the undecidability of the language with graded converse modalities.\",\n",
       " 519: \"fuchsian groups with a modular embedding have the richest arithmetic properties among non-arithmetic fuchsian groups. but they are very rare, all known examples being related either to triangle groups or to teichmueller curves.   in part i of this paper we study the arithmetic properties of the modular embedding and develop from scratch a theory of twisted modular forms for fuchsian groups with a modular embedding, proving dimension formulas, coefficient growth estimates and differential equations.   in part ii we provide a modular proof for an apery-like integrality statement for solutions of picard-fuchs equations. we illustrate the theory on a worked example, giving explicit fourier expansions of twisted modular forms and the equation of a teichmueller curve in a hilbert modular surface.   in part iii we show that genus two teichmueller curves are cut out in hilbert modular surfaces by a product of theta derivatives. we rederive most of the known properties of those teichmueller curves from this viewpoint, without using the theory of flat surfaces. as a consequence we give the modular embeddings for all genus two teichmueller curves and prove that the fourier developments of their twisted modular forms are algebraic up to one transcendental scaling constant. moreover, we prove that bainbridge's compactification of hilbert modular surfaces is toroidal. the strategy to compactify can be expressed using continued fractions and resembles hirzebruch's in form, but every detail is different.\",\n",
       " 520: 'in this paper, we contrast parametric and semi-parametric representations of unobserved heterogeneity in hierarchical bayesian multinomial logit models and leverage these methods to infer distributions of willingness to pay for features of shared automated vehicle (sav) services. specifically, we compare the multivariate normal (mvn), finite mixture of normals (f-mon) and dirichlet process mixture of normals (dp-mon) mixing distributions. the latter promises to be particularly flexible in respect to the shapes it can assume and unlike other semi-parametric approaches does not require that its complexity is fixed prior to estimation. however, its properties relative to simpler mixing distributions are not well understood. in this paper, we evaluate the performance of the mvn, f-mon and dp-mon mixing distributions using simulated data and real data sourced from a stated choice study on preferences for sav services in new york city. our analysis shows that the dp-mon mixing distribution provides superior fit to the data and performs at least as well as the competing methods at out-of-sample prediction. the dp-mon mixing distribution also offers substantive behavioural insights into the adoption of savs. we find that preferences for in-vehicle travel time by sav with ride-splitting are strongly polarised. whereas one third of the sample is willing to pay between 10 and 80 usd/h to avoid sharing a vehicle with strangers, the remainder of the sample is either indifferent to ride-splitting or even desires it. moreover, we estimate that new technologies such as vehicle automation and electrification are relatively unimportant to travellers. this suggests that travellers may primarily derive indirect, rather than immediate benefits from these new technologies through increases in operational efficiency and lower operating costs.',\n",
       " 521: 'the fermi gamma-ray space telescope was launched in june 2008 and the onboard large area telescope (lat) has been collecting data since august of that same year. the lat is currently being used to study a wide range of science topics in high-energy astrophysics, one of which is the study of high-energy cosmic rays. the lat has recently demonstrated its ability to measure cosmic-ray electrons, and the fermi lat collaboration has published a measurement of the high-energy cosmic-ray electron spectrum in the 20 gev to 1 tev energy range. this talk will discuss the prospects for using the lat to perform a similar analysis to measure cosmic-ray proton events. the instrument response for cosmic-ray protons will be characterized and an assessment of the potential to measure the cosmic-ray proton energy spectrum will be presented.',\n",
       " 522: 'we show the inverse deformation problem has an affirmative answer: given a complete local noetherian ring $a$ with finite residue field $\\\\pmb{k}$, we show that there is a topologically finitely generated profinite group $\\\\gamma$ and an absolutely irreducible continuous representation $\\\\bar\\\\rho:\\\\gamma\\\\to gl_n(\\\\pmb{k})$ such that $a$ is the universal deformation ring for $\\\\gamma,\\\\bar\\\\rho$.',\n",
       " 523: 'the quest for the particle nature of dark matter is one of the big open questions of modern physics. the cresst-ii experiment, located at the gran sasso laboratory in italy, is optimised for the detection of the elastic scattering of dark matter particles with ordinary matter. we present the result obtained with an improved detector setup with increased radiopurity and enhanced background rejection. the limit obtained in the so-called low mass region between one and three gev/c2 is at the present among the best limits obtained for direct dark matter experiments. in addition we give an outlook of the future potential for direct dark matter detection using further improved cresst cawo4 cryogenic detectors.',\n",
       " 524: 'we construct minimax optimal non-asymptotic confidence sets for low rank matrix recovery algorithms such as the matrix lasso or dantzig selector. these are employed to devise adaptive sequential sampling procedures that guarantee recovery of the true matrix in frobenius norm after a data-driven stopping time $\\\\hat n$ for the number of measurements that have to be taken. with high probability, this stopping time is minimax optimal. we detail applications to quantum tomography problems where measurements arise from pauli observables. we also give a theoretical construction of a confidence set for the density matrix of a quantum state that has optimal diameter in nuclear norm. the non-asymptotic properties of our confidence sets are further investigated in a simulation study.',\n",
       " 525: 'we study the effect of long-ranged interactions on weyl semimetals. such interactions can give rise to unpaired weyl nodes, which we demonstrate by explicitly constructing a system with just a single node - a situation that is fundamentally forbidden by fermion doubling in non-interacting band structures. adding a magnetic field, we investigate the fate of the chiral anomaly. remarkably, as long as a system exhibits a single weyl node in the absence of magnetic fields, arbitrarily weak fields qualitatively restore the lowest landau level structure of a non-interacting weyl semimetal. this underlines the universality of the chiral anomaly in the context of weyl semimetals. we furthermore demonstrate how the topologically protected fermi-arc surface states are modified by long-ranged interactions.',\n",
       " 526: 'we verify new cases of the arithmetic fundamental lemma (afl) of wei zhang. this relies on a recursive algorithm which allows, under certain conditions, to reduce the afl identity in question to an afl identity in lower dimension. the main ingredient for this reduction is a comparison isomorphism between different moduli problems of pel-type for p-divisible groups. the construction of this comparison isomorphism is based on the theory of relative displays and frames, as developed by tobias ahsendorf, eike lau and thomas zink.',\n",
       " 527: \"by integrating the young-laplace equation, including the effects of gravity, we have calculated the equilibrium shape of the two-dimensional plateau borders along which a vertical soap film contacts two flat, horizontal solid substrates of given wettability. we show that the plateau borders, where most of a foam's liquid resides, can only exist if the values of the bond number ${\\\\rm bo}$ and of the liquid contact angle $\\\\theta_c$ lie within certain domains in $(\\\\theta_c,{\\\\rm bo})$ space: under these conditions the substrate is foam-philic. for values outside these domains, the substrate cannot support a soap film and is foam-phobic. in other words, on a substrate of a given wettability, only plateau borders of a certain range of sizes can form. for given $(\\\\theta_c,{\\\\rm bo})$, the top plateau border can never have greater width or cross-sectional area than the bottom one. moreover, the top plateau border cannot exist in a steady state for contact angles above 90$^\\\\circ$. our conclusions are validated by comparison with both experimental and numerical (surface evolver) data. we conjecture that these results will hold, with slight modifications, for non-planar soap films and bubbles. our results are also relevant to the motion of bubbles and foams in channels, where the friction force of the substrate on the plateau borders plays an important role.\",\n",
       " 528: 'quality data is a fundamental contributor to success in statistics and machine learning. if a statistical assessment or machine learning leads to decisions that create value, data contributors may want a share of that value. this paper presents methods to assess the value of individual data samples, and of sets of samples, to apportion value among different data contributors. we use shapley values for individual samples and owen values for combined samples, and show that these values can be computed in polynomial time in spite of their definitions having numbers of terms that are exponential in the number of samples.',\n",
       " 529: 'we prove new pinching estimate for the inverse curvature flow of strictly convex hypersurfaces in the space form $n$ of constant sectional curvature $k_n$ with speed given by $f^{-\\\\alpha}$, where $\\\\alpha\\\\in (0,1]$ for $k_n=0,-1$ and $\\\\alpha=1$ for $k_n=1$, $f$ is a smooth, symmetric homogeneous of degree one function which is inverse concave and has dual $f_*$ approaching zero on the boundary of the positive cone $\\\\gamma_+$. we show that the ratio of the largest principal curvature to the smallest principal curvature of the flow hypersurface is controlled by its initial value. this can be used to prove the smooth convergence of the flow.',\n",
       " 530: 'in this paper power allocation in a cellular network, which transmitter uses massive multiple inputs multiple outputs (mimo) system was studied. as circuit power consumption is increased by the number of antenna in transmitter and users, thus, to analyze the performance of the network, energy efficiency objective function with considering circuit power consumption was selected. an energy efficiency optimization problem under both maximum transmit power and quality of service (qos) constraints was considered. to solve this problem under cooperation between users and their base station (bs), energy efficient power allocation algorithm was proposed. in numerical result convergence of the algorithm was shown, also the appropriate number of transmit antenna and users were obtained. finally, pilot contamination effect was evaluated, where it showed energy efficiency fell down dramatically.',\n",
       " 531: 'we study the asymptotic behavior of a family of algebraic geometry codes, which we call block-transitive, that generalizes the classes of transitive and quasi-transitive codes. we prove, by using towers of algebraic function fields, that there are sequences of codes in this family attaining the tsfasman-vladut-zink bound over finite fields of square cardinality. we give the exact length of these codes as well as explicit lower bounds for their parameters.',\n",
       " 532: 'we provide requirements on effectively enumerable topological spaces which guarantee that the rice-shapiro theorem holds for the computable elements of these spaces. we show that the relaxation of these requirements leads to the classes of effectively enumerable topological spaces where the rice-shapiro theorem does not hold. we propose two constructions that generate effectively enumerable topological spaces with particular properties from wn--families and computable trees without computable infinite paths. using them we propose examples that give a flavor of this class.',\n",
       " 533: 'in this review we make the statement that hybrid models in oncology are required as a mean for enhanced data integration. in the context of systems oncology, experimental and clinical data need to be at the heart of the models developments from conception to validation to ensure a relevant use of the models in the clinical context. the main applications pursued are to improve diagnosis and to optimize therapies.we first present the successes achieved thanks to hybrid modelling approaches to advance knowledge, treatments or drug discovery. then we present the challenges than need to be addressed to allow for a better integration of the model parts and of the data into the models. and finally, the hopes with a focus towards making personalised medicine a reality. mathematics subject classification. 35q92, 68u20, 68t05, 92-08, 92b05.',\n",
       " 534: 'a mixed dominating set for a graph $g = (v,e)$ is a set $s\\\\subseteq v \\\\cup e$ such that every element $x \\\\in (v \\\\cup e) \\\\backslash s$ is either adjacent or incident to an element of $s$. the mixed domination number of a graph $g$, denoted by $\\\\gamma_m(g)$, is the minimum cardinality of mixed dominating sets of $g$. any mixed dominating set with the cardinality of $\\\\gamma_m(g)$ is called a minimum mixed dominating set. the mixed domination set (mds) problem is to find a minimum mixed dominating set for a graph $g$ and is known to be an np-complete problem. in this paper, we present a novel approach to find all of the mixed dominating sets, called the amds problem, of a graph with bounded tree-width $tw$. our new technique of assigning power values to edges and vertices, and combining with dynamic programming, leads to a fixed-parameter algorithm of time $o(3^{tw^{2}}\\\\times tw^2 \\\\times |v|)$. this shows that mds is fixed-parameter tractable with respect to tree-width. in addition, we theoretically improve the proposed algorithm to solve the mds problem in $o(6^{tw} \\\\times |v|)$ time.',\n",
       " 535: 'respiratory modulation of sympathetic nerve activity (respsna) was studied in a hypertensive rodent model of chronic kidney disease (ckd) using lewis polycystic kidney (lpk) rats and lewis controls. in adult animals under in vivo anaesthetised conditions (n=8-10/strain), respiratory modulation of splanchnic and renal nerve activity was compared under control conditions, and during peripheral (hypoxia), and central, chemoreceptor (hypercapnia) challenge. respsna was increased in the lpk vs. lewis (area under curve (auc) splanchnic and renal: 8.7$\\\\pm$1.1 vs. 3.5$\\\\pm$0.5 and 10.6$\\\\pm$1.1 vs. 7.1$\\\\pm$0.2 $\\\\mu$v.s, respectively, p<0.05). hypoxia and hypercapnia increased respsna in both strains but the magnitude of the response was greater in lpk, particularly in response to hypoxia. in juvenile animals studied using a working heart brainstem preparation (n=7-10/strain), increased respsna was evident in the lpk (thoracic sna, auc: 0.86$\\\\pm$0.1 vs. 0.42$\\\\pm$0.1 $\\\\mu$v.s, p<0.05), and activation of peripheral chemoreceptors (nacn) again drove a larger increase in respsna in the lpk with no difference in the response to hypercapnia. amplified respsna occurs in ckd and may contribute to the development of hypertension.',\n",
       " 536: 'following the work of kashiwara-rouquier and gan-ginzburg, we define a family of exact functors from category $\\\\mathcal o$ for the rational cherednik algebra in type $a$ to representations of certain \"coloured braid groups\" and calculate the dimensions of the representations thus obtained from standard modules. to show that our constructions also make sense in a more general context, we also briefly study the case of the rational cherednik algebra corresponding to complex reflection group $\\\\mathbb z/l\\\\mathbb z$.',\n",
       " 537: \"we derive the full linear-response theory for non-relativistic quantum electrodynamics in the long wavelength limit, show quantum modifications of the well-known maxwell's equation in matter and provide a practical framework to solve the resulting equations by using quantum-electrodynamical density-functional theory. we highlight how the coupling between quantized light and matter changes the usual response functions and introduces new types of cross-correlated light-matter response functions. these cross-correlation responses lead to measurable changes in maxwell's equations due to the quantum-matter-mediated photon-photon interactions. key features of treating the combined matter-photon response are that natural lifetimes of excitations become directly accessible from first principles, changes in the electronic structure due to strong light-matter coupling are treated fully non-perturbatively, and for the first time self-consistent solutions of the back-reaction of matter onto the photon vacuum and vice versa are accounted for. by introducing a straightforward extension of the random-phase approximation for the coupled matter-photon problem, we calculate the first ab-initio spectra for a real molecular system that is coupled to the quantized electromagnetic field. our approach can be solved numerically very efficiently. the presented framework leads to a shift in paradigm by highlighting how electronically excited states arise as a modification of the photon field and that experimentally observed effects are always due to a complex interplay between light and matter. at the same time the findings provide a new route to analyze as well as propose experiments at the interface between quantum chemistry, nanoplasmonics and quantum optics.\",\n",
       " 538: 'magnetization dynamics driven by an electric field could provide long-term benefits to information technologies because of its ultralow power consumption. meanwhile, the dzyaloshinskii-moriya interaction in interfacially asymmetric multilayers consisting of ferromagnetic and heavy-metal layers can stabilize topological spin textures, such as chiral domain walls, skyrmions, and skyrmion bubbles. these topological spin textures can be controlled by an electric field, and hold promise for building advanced spintronic devices. here, we present an experimental and numerical study on the electric field-induced creation and directional motion of topological spin textures in magnetic multilayer films and racetracks with thickness gradient and interfacial dzyaloshinskii-moriya interaction at room temperature. we find that the electric field-induced directional motion of chiral domain wall is accompanied with the creation of skyrmion bubbles at certain conditions. we also demonstrate that the electric field variation can induce motion of skyrmion bubbles. our findings may provide opportunities for developing skyrmion-based devices with ultralow power consumption.',\n",
       " 539: 'we show the asymptotic degree distribution of the typical vertex of a sparse inhomogeneous random intersection graph.',\n",
       " 540: 'this paper considers the problem of distributed state estimation using multi-robot systems. the robots have limited communication capabilities and, therefore, communicate their measurements intermittently only when they are physically close to each other. to decrease the distance that the robots need to travel only to communicate, we divide them into small teams that can communicate at different locations to share information and update their beliefs. then, we propose a new distributed scheme that combines (i) communication schedules that ensure that the network is intermittently connected, and (ii) sampling-based motion planning for the robots in every team with the objective to collect optimal measurements and decide a location for those robots to communicate. to the best of our knowledge, this is the first distributed state estimation framework that relaxes all network connectivity assumptions, and controls intermittent communication events so that the estimation uncertainty is minimized. we present simulation results that demonstrate significant improvement in estimation accuracy compared to methods that maintain an end-to-end connected network for all time.',\n",
       " 541: 'power laws in nature are considered to be signatures of complexity. the theory of self-organized criticality (soc) was proposed to explain their origins. a longstanding principle of soc is the \\\\emph{separation of timescales} axiom. it dictates that external input is delivered to the system at a much slower rate compared to the timescale of internal dynamics. the statistics of neural avalanches in the brain was demonstrated to follow a power law, indicating closeness to a critical state. moreover, criticality was shown to be a beneficial state for various computations leading to the hypothesis, that the brain is a soc system. however, for neuronal systems that are constantly bombarded by incoming signals, separation of timescales assumption is unnatural. recently it was experimentally demonstrated that a proper correction of the avalanche detection algorithm to account for the increased drive during task performance leads to a change of the power-law exponent from $1.5$ to approximately $1.3$, but there is so far no theoretical explanation for this change. here we investigate the importance of timescales separation, by partly abandoning it in various models. we achieve it by allowing for external input during the avalanche, without compromising the separation of avalanches. we develop an analytic treatment and provide numerical simulations of a simple neuronal model.',\n",
       " 542: 'many statistical methods require solutions to optimization problems. when the global solution is hard to attain, statisticians always use the better if there are two solutions for chosen, where the word \"better\" is understood in the sense of optimization. this seems reasonable in that the better solution is more likely to be the global solution, whose statistical properties of interest usually have been well established. from the statistical perspective, we use the better solution because we intuitively believe the principle, called better solution principle (bsp) in this paper, that a better solution to a statistical optimization problem also has better statistical properties of interest. bsp displays some concordance between optimization and statistics, and is expected to widely hold. since theoretical study on bsp seems to be neglected by statisticians, this paper aims to establish a framework for discussing bsp in various statistical optimization problems. we demonstrate several simple but effective comparison theorems as the key results of this paper, and apply them to verify bsp in commonly encountered statistical optimization problems, including maximum likelihood estimation, best subsample selection, and best subset regression. it can be seen that bsp for these problems holds under reasonable conditions, i.e., a better solution indeed has better statistical properties of interest. in addition, guided by the bsp theory, we develop a new best subsample selection method that performs well when there are clustered outliers.',\n",
       " 543: 'a formulation of \"ne\\\\v{c}iporuk\\'s lower bound method\" slightly more inclusive than the usual complexity-measure-specific formulation is presented. using this general formulation, limitations to lower bounds achievable by the method are obtained for several computation models, such as branching programs and boolean formulas having access to a sublinear number of nondeterministic bits. in particular, it is shown that any lower bound achievable by the method of ne\\\\v{c}iporuk for the size of nondeterministic and parity branching programs is at most $o(n^{3/2}/\\\\log n)$.',\n",
       " 544: 'intrinsic wavelet transforms and wavelet estimation methods are introduced for curves in the non-euclidean space of hermitian positive definite matrices, with in mind the application to fourier spectral estimation of multivariate stationary time series. the main focus is on intrinsic average-interpolation wavelet transforms in the space of positive definite matrices equipped with an affine-invariant riemannian metric, and convergence rates of linear wavelet thresholding are derived for intrinsically smooth curves of hermitian positive definite matrices. in the context of multivariate fourier spectral estimation, intrinsic wavelet thresholding is equivariant under a change of basis of the time series, and nonlinear wavelet thresholding is able to capture localized features in the spectral density matrix across frequency, always guaranteeing positive definite estimates. the finite-sample performance of intrinsic wavelet thresholding is assessed by means of simulated data and compared to several benchmark estimators in the riemannian manifold. further illustrations are provided by examining the multivariate spectra of trial-replicated brain signal time series recorded during a learning experiment.',\n",
       " 545: \"collaborative filtering (cf) is one of the most successful approaches for recommender systems. with the emergence of online social networks, social recommendation has become a popular research direction. most of these social recommendation models utilized each user's local neighbors' preferences to alleviate the data sparsity issue in cf. however, they only considered the local neighbors of each user and neglected the process that users' preferences are influenced as information diffuses in the social network. recently, graph convolutional networks~(gcn) have shown promising results by modeling the information diffusion process in graphs that leverage both graph structure and node feature information. to this end, in this paper, we propose an effective graph convolutional neural network based model for social recommendation. based on a classical cf model, the key idea of our proposed model is that we borrow the strengths of gcns to capture how users' preferences are influenced by the social diffusion process in social networks. the diffusion of users' preferences is built on a layer-wise diffusion manner, with the initial user embedding as a function of the current user's features and a free base user latent vector that is not contained in the user feature. similarly, each item's latent vector is also a combination of the item's free latent vector, as well as its feature representation. furthermore, we show that our proposed model is flexible when user and item features are not available. finally, extensive experimental results on two real-world datasets clearly show the effectiveness of our proposed model.\",\n",
       " 546: \"in this paper, we study the multiple-antenna wireless communication networks, where a large number of devices simultaneously communicate with an access point. the capacity region of multiple-input multiple-output massive multiple access channels (mimo mmac) is investigated. while joint typicality decoding is utilized to establish the achievability of capacity region for conventional mac with fixed number of users, the technique is not directly applicable for mimo mmac. instead, an information-theoretic approach based on gallager's error exponent analysis is exploited to characterize the \\\\textcolor[rgb]{0,0,0}{finite dimension region} of mimo mmac. theoretical results reveal that the finite dimension region of mimo mmac is dominated by sum rate constraint only, and the individual user rate is determined by a specific factor that corresponds to the allocation of sum rate. the rate in conventional mac is not achievable with massive multiple access, which is due to the fact that successive interference cancellation cannot guarantee an arbitrary small error decoding probability for mimo mmac. the results further imply that, asymptotically, the individual user rate is independent of the number of transmit antennas, and channel hardening makes the individual user rate close to that when only statistic knowledge of channel is available at receiver. the finite dimension region of mimo mmac is a generalization of the symmetric rate in chen \\\\emph{et al.} (2017).\",\n",
       " 547: 'in 1981 j. wahl described smoothings of surface quotient singularities with no vanishing cycles. given a smoothing of a projective surface x of this type, we construct an associated exceptional vector bundle on the nearby fiber y in the case h^{2,0}(y)=h^1(y)=0. if y is the projective plane we show that our construction establishes a bijective correspondence between the possible degenerate surfaces x and exceptional bundles on y modulo dualizing and tensoring by line bundles. if y is of general type then our construction establishes a connection between components of the boundary of the moduli space of surfaces deformation equivalent to y and exceptional bundles on y.',\n",
       " 548: 'we construct motivic invariants of a subvariety of an algebraic torus from its tropicalization and initial degenerations. more specifically, we introduce an invariant of a compactification of such a variety called the \"tropical motivic nearby fiber.\" this invariant specializes in the schon case to the hodge-deligne polynomial of the limit mixed hodge structure of a corresponding degeneration. we give purely combinatorial expressions for this hodge-deligne polynomial in the cases of schon hypersurfaces and smooth tropical varieties. we also deduce a formula for the euler characteristic of a general fiber of the degeneration.',\n",
       " 549: \"the chen groups of a group $g$ are the lower central series quotients of the maximal metabelian quotient of $g$. under certain conditions, we relate the ranks of the chen groups to the first resonance variety of $g$, a jump locus for the cohomology of $g$. in the case where $g$ is the fundamental group of the complement of a complex hyperplane arrangement, our results positively resolve suciu's chen ranks conjecture. we obtain explicit formulas for the chen ranks of a number of groups of broad interest, including pure artin groups associated to coxeter groups, and the group of basis-conjugating automorphisms of a finitely generated free group.\",\n",
       " 550: 'matrix decompositions are fundamental tools in the area of applied mathematics, statistical computing, and machine learning. in particular, low-rank matrix decompositions are vital, and widely used for data analysis, dimensionality reduction, and data compression. massive datasets, however, pose a computational challenge for traditional algorithms, placing significant constraints on both memory and processing power. recently, the powerful concept of randomness has been introduced as a strategy to ease the computational load. the essential idea of probabilistic algorithms is to employ some amount of randomness in order to derive a smaller matrix from a high-dimensional data matrix. the smaller matrix is then used to compute the desired low-rank approximation. such algorithms are shown to be computationally efficient for approximating matrices with low-rank structure. we present the \\\\proglang{r} package rsvd, and provide a tutorial introduction to randomized matrix decompositions. specifically, randomized routines for the singular value decomposition, (robust) principal component analysis, interpolative decomposition, and cur decomposition are discussed. several examples demonstrate the routines, and show the computational advantage over other methods implemented in r.',\n",
       " 551: 'following the breakthrough of croot, lev, and pach, tao introduced a symmetrized version of their argument, which is now known as the slice rank method. in this paper, we introduce a more general version of the slice rank of a tensor, which we call the partition rank. this allows us to extend the slice rank method to problems that require the variables to be distinct. using the partition rank, we generalize a recent result of ge and shangguan, and prove that any set $a\\\\subset\\\\mathbb{f}_{q}^{n}$ of size \\\\[|a|>\\\\binom{n+(k-1)q}{(k-1)(q-1)}\\\\] contains a $k$-right-corner, that is distinct vectors $x_{1},\\\\dots,x_{k},x_{k+1}$ where $x_{1}-x_{k+1},\\\\dots,x_{k}-x_{k+1}$ are mutually orthogonal, for $q=p^{r}$, a prime power with $p>k$.',\n",
       " 552: \"holomorphic chains on a riemann surface arise naturally as fixed points of the natural c*-action on the moduli space of higgs bundles. in this paper we associate a new quiver bundle to the hom-complex of two chains, and prove that stability of the chains implies stability of this new quiver bundle. our approach uses the hitchin-kobayashi correspondence for quiver bundles. moreover, we use our result to give a new proof of a key lemma on chains (due to \\\\'alvarez-c\\\\'onsul, garc\\\\'ia-prada and schmitt), which has been important in the study of higgs bundle moduli; this proof relies on stability and thus avoids the direct use of the chain vortex equations.\",\n",
       " 553: 'we exhibit a pseudoeffective r-divisor d_\\\\lambda on the blow-up of p^3 at nine very general points which lies in the closed movable cone and has negative intersections with a set of curves whose union is zariski dense. it follows that the diminished base locus b_-(d_\\\\lambda) = \\\\bigcup_{a ample}} b(d_\\\\lambda+a) is not closed and that d_\\\\lambda does not admit a zariski decomposition in even a very weak sense. by a similar method, we construct an r-divisor on the family of blow-ups of p^2 at ten distinct points, which is nef on a very general fiber but fails to be nef over countably many prime divisors in the base.',\n",
       " 554: 'this paper introduces two new burnside rings for a finite group $g$, called the slice burnside ring and the section burnside ring. they are built as grothendieck rings of the category of morphisms of $g$-sets, and of galois morphisms of $g$-sets, respectively. the well known results on the usual burnside ring, concerning ghost maps, primitive idempotents, and description of the prime spectrum, are extended to these rings. it is also shown that these two rings have a natural structure of green biset functor. the functorial structure of unit groups of these rings is also discussed.',\n",
       " 555: 'we examine spectral operator-theoretic properties of linear and nonlinear dynamical systems with globally stable attractors. using the kato decomposition we develop a spectral expansion for general linear autonomous dynamical systems with analytic observables, and define the notion of generalized eigenfunctions of the associated koopman operator. we interpret stable, unstable and center subspaces in terms of zero level sets of generalized eigenfunctions. we then utilize conjugacy properties of koopman eigenfunctions and the new notion of open eigenfunctions - defined on subsets of state space - to extend these results to nonlinear dynamical systems with an equilibrium. we provide a characterization of (global) center manifolds, center-stable and center-unstable manifolds in terms of joint zero level sets of families of koopman operator eigenfunctions associated with the nonlinear system.after defining a new class of hilbert spaces, that capture the on and off attractor properties of dissipative dynamics, and introduce the concept of modulated fock spaces}, we develop spectral expansions for a class of dynamical systems possessing globally stable limit cycles and limit tori, with observables that are square-integrable in on-attractor variables and analytic in off-attractor variables. we discuss definitions of stable, unstable and global center manifolds in such nonlinear systems with (quasi)-periodic attractors in terms of zero level sets of koopman operator eigenfunctions. we define the notion of isostables for a general class of nonlinear systems. we provide a simple example of a measure-preserving system that is not chaotic but has continuous spectrum, and discuss experimental observations of spectrum on such systems. we define the coherent principal dimension for a class of datasets based on the lattice-type principal spectrum of the associated koopman operator.',\n",
       " 556: 'the lat instrument on the fermi gamma-ray space telescope is performing an all-sky survey from 20 mev to 300 gev with unprecedented statistics and angular resolution. this is providing a wealth of new information on the non-thermal emission from the galactic interstellar medium with implications for cosmic rays and galactic structure. first results at intermediate latitudes have already shown good agreement with predictions based on direct measurements of cosmic rays, suggesting that at least the local (within about 1 kpc from the sun) gamma-ray emission is understood. we will present the first spectra from regions over the sky using the lat data, and profiles for selected energies. the aim here is to evaluate the agreement with the models and assess what we can expect to learn as this analysis matures.',\n",
       " 557: \"with the emergence of the big data age, the issue of how to obtain valuable knowledge from a dataset efficiently and accurately has attracted increasingly attention from both academia and industry. this paper presents a parallel random forest (prf) algorithm for big data on the apache spark platform. the prf algorithm is optimized based on a hybrid approach combining data-parallel and task-parallel optimization. from the perspective of data-parallel optimization, a vertical data-partitioning method is performed to reduce the data communication cost effectively, and a data-multiplexing method is performed is performed to allow the training dataset to be reused and diminish the volume of data. from the perspective of task-parallel optimization, a dual parallel approach is carried out in the training process of rf, and a task directed acyclic graph (dag) is created according to the parallel training process of prf and the dependence of the resilient distributed datasets (rdd) objects. then, different task schedulers are invoked for the tasks in the dag. moreover, to improve the algorithm's accuracy for large, high-dimensional, and noisy data, we perform a dimension-reduction approach in the training process and a weighted voting approach in the prediction process prior to parallelization. extensive experimental results indicate the superiority and notable advantages of the prf algorithm over the relevant algorithms implemented by spark mllib and other studies in terms of the classification accuracy, performance, and scalability.\",\n",
       " 558: \"when lifting the assumption of spatially-independent scattering centers in classical linear transport theory, collision rate is no longer proportional to angular flux / radiance because the macroscopic cross-section $\\\\sigma_t(s)$ depends on the distance $s$ to the previous collision or boundary. we generalize collision and track-length estimators to support unbiased estimation of either flux integrals or collision rates in generalized radiative transfer (grt). to provide benchmark solutions for the monte carlo estimators, we derive the four green's functions for the isotropic point source in infinite media with isotropic scattering. additionally, new moment-preserving diffusion approximations for these green's functions are derived, which reduce to algebraic expressions involving the first four moments of the free-path lengths between collisions.\",\n",
       " 559: 'we prove that if y\" = f(y,y\\',t) is a generic painleve equation from among the classes ii to v then any collection of distinct solutions and their derivatives are algebraically independent over c(t). (already proved by nishioka for the single painleve i equation). for generic painleve vi we prove a slightly weaker statement.',\n",
       " 560: 'since the birth of computer and networks, fuelled by pervasive computing and ubiquitous connectivity, the amount of data stored and transmitted has exponentially grown through the years. due to this demand, new solutions for storing data are needed, and one promising media is the dna. this storage solution provides numerous advantages, which includes the ability to store dense information while achieving long-term stability. however, the question as how the data can be retrieved from a dna-based archive, still remains. in this paper, we aim to address this question by proposing a new storage solution that relies upon molecular communication, and in particular bacterial nanonetworks. our solution allows digitally encoded information to be stored into non-motile bacteria, which compose an archival architecture of clusters, and to be later retrieved by engineered motile bacteria, whenever reading operations are needed. we conducted extensive simulations, in order to determine the reliability of data retrieval from non-motile storage clusters, placed at different locations. aiming to assess the feasibility of our solution, we have also conducted wet lab experiments that show how bacteria nanonetworks can effectively retrieve a simple message, such as \"hello world\", by conjugation with non-motile bacteria, and finally mobilize towards a final point.',\n",
       " 561: 'in this note we give an example of an ergodic non-singular map whose unitary operator admits a lebesgue component of multiplicity one in its spectrum.',\n",
       " 562: '3d reconstruction is a fundamental issue in many applications and the feature point matching problem is a key step while reconstructing target objects. conventional algorithms can only find a small number of feature points from two images which is quite insufficient for reconstruction. to overcome this problem, we propose sefm a sequential feature point matching algorithm. we first utilize the epipolar geometry to find the epipole of each image. rotating along the epipole, we generate a set of the epipolar lines and reserve those intersecting with the input image. next, a rough matching phase, followed by a dense matching phase, is applied to find the matching dot-pairs using dynamic programming. furthermore, we also remove wrong matching dot-pairs by calculating the validity. experimental results illustrate that sefm can achieve around 1,000 to 10,000 times matching dot-pairs, depending on individual image, compared to conventional algorithms and the object reconstruction with only two images is semantically visible. moreover, it outperforms conventional algorithms, such as sift and surf, regarding precision and recall.',\n",
       " 563: 'we present certain liouville properties of eigenfunctions of second-order elliptic operators with real coefficients, via an approach that is based on stochastic representations of positive solutions, and criticality theory of second-order elliptic operators. these extend results of y. pinchover to the case of nonsymmetric operators of schr\\\\\"odinger type. in particular, we provide an answer to an open problem posed by pinchover in [comm. math. phys. 272 (2007), no. 1, 75-84, problem 5]. in addition, we prove a lower bound on the decay of positive supersolutions of general second-order elliptic operators in any dimension, and discuss its implications to the landis conjecture.',\n",
       " 564: 'cooperation is ubiquitous across all levels of biological systems ranging from microbial communities to human societies. it, however, seemingly contradicts the evolutionary theory, since cooperators are exploited by free-riders and thus are disfavored by natural selection. many studies based on evolutionary game theory have tried to solve the puzzle and figure out the reason why cooperation exists and how it emerges. network reciprocity is one of the mechanisms to promote cooperation, where nodes refer to individuals and links refer to social relationships. the spatial arrangement of mutant individuals, which refers to the clustering of mutants, plays a key role in network reciprocity. besides, many other mechanisms supporting cooperation suggest that the clustering of mutants plays an important role in the expansion of mutants. however, the clustering of mutants and the game dynamics are typically coupled. it is still unclear how the clustering of mutants alone alters the evolutionary dynamics. to this end, we employ a minimal model with frequency independent fitness on a circle. it disentangles the clustering of mutants from game dynamics. the distance between two mutants on the circle is adopted as a natural indicator for the clustering of mutants or assortment. we find that the assortment is an amplifier of the selection for the connected mutants compared with the separated ones. nevertheless, as mutants are separated, the more dispersed mutants are, the greater the chance of invasion is. it gives rise to the non-monotonic effect of clustering, which is counterintuitive. on the other hand, we find that less assortative mutants speed up fixation. our model shows that the clustering of mutants plays a non-trivial role in fixation, which has emerged even if the game interaction is absent.',\n",
       " 565: 'why deep neural networks (dnns) capable of overfitting often generalize well in practice is a mystery [#zhang2016understanding]. to find a potential mechanism, we focus on the study of implicit biases underlying the training process of dnns. in this work, for both real and synthetic datasets, we empirically find that a dnn with common settings first quickly captures the dominant low-frequency components, and then relatively slowly captures the high-frequency ones. we call this phenomenon frequency principle (f-principle). the f-principle can be observed over dnns of various structures, activation functions, and training algorithms in our experiments. we also illustrate how the f-principle help understand the effect of early-stopping as well as the generalization of dnns. this f-principle potentially provides insights into a general principle underlying dnn optimization and generalization.',\n",
       " 566: 'let pl+(s1) be the group of order preserving piecewise linear homeomorphisms of the circle. an element in pl+(s1) is called reversible in pl+(s1) if it is conjugate to its inverse in pl+(s1). we characterize the reversible elements in pl+(s1). we also perform a sim- ilar characterisation in the full group pl(s1) of piecewise linear home- omorphisms of the circle.',\n",
       " 567: 'we prove that, for a k3 surface in characteristic p > 2, the automorphism group acts on the nef cone with a rational polyhedral fundamental domain and on the nodal classes with finitely many orbits. as a consequence, for any non-negative integer g, there are only finitely many linear systems of irreducible curves on the surface of arithmetic genus g, up to the action of the automorphism group.',\n",
       " 568: 'in this paper, we study the problem of traffic management in highways facing stochastic perturbations. to model the macroscopic traffic flow under perturbations, we use cell-transmission model with markovian capacities. the decision variables are: (i) the admissible flow through each on-ramp, and (ii) whether individual on-ramps are metered to prioritize the mainline traffic or not. the objective is to maximize the throughput while ensuring that on-ramp queues remain bounded on average. we develop a computational approach to solving this stability-constrained, throughput-maximization problem. we establish a mixed-integer linear program for throughput maximization and construct an algorithm that gives the optimal solution in particular settings. we illustrate the performance benefits of the proposed approach through a computational study on a segment of interstate 210 in california, usa.',\n",
       " 569: 'despite substantial interest in applications of neural networks to information retrieval, neural ranking models have only been applied to standard ad hoc retrieval tasks over web pages and newswire documents. this paper proposes mp-hcnn (multi-perspective hierarchical convolutional neural network) a novel neural ranking model specifically designed for ranking short social media posts. we identify document length, informal language, and heterogeneous relevance signals as features that distinguish documents in our domain, and present a model specifically designed with these characteristics in mind. our model uses hierarchical convolutional layers to learn latent semantic soft-match relevance signals at the character, word, and phrase levels. a pooling-based similarity measurement layer integrates evidence from multiple types of matches between the query, the social media post, as well as urls contained in the post. extensive experiments using twitter data from the trec microblog tracks 2011--2014 show that our model significantly outperforms prior feature-based as well and existing neural ranking models. to our best knowledge, this paper presents the first substantial work tackling search over social media posts using neural ranking models.',\n",
       " 570: 'in this paper, we develop a new necessary and sufficient condition for the vanishing of 4-massey products of elements in the mod-2 galois cohomology of a field. this new description allows us to define a splitting variety for 4-massey products, which is shown in the appendix to satisfy a local-to-global principle over number fields. as a consequence, we prove that, for a number field, all such 4-massey products vanish whenever they are defined. this provides new explicit restrictions on the structure of absolute galois groups of number fields.',\n",
       " 571: 'particle-based variational inference offers a flexible way of approximating complex posterior distributions with a set of particles. in this paper we introduce a new particle-based variational inference method based on the theory of semi-discrete optimal transport. instead of minimizing the kl divergence between the posterior and the variational approximation, we minimize a semi-discrete optimal transport divergence. the solution of the resulting optimal transport problem provides both a particle approximation and a set of optimal transportation densities that map each particle to a segment of the posterior distribution. we approximate these transportation densities by minimizing the kl divergence between a truncated distribution and the optimal transport solution. the resulting algorithm can be interpreted as a form of ensemble variational inference where each particle is associated with a local variational approximation.',\n",
       " 572: 'the human brain can effectively learn a new task from a small number of samples, which indicate that the brain can transfer its prior knowledge to solve tasks in different domains. this function is analogous to transfer learning (tl) in the field of machine learning. tl uses a well-trained feature space in a specific task domain to improve performance in new tasks with insufficient training data. tl with rich feature representations, such as features of convolutional neural networks (cnns), shows high generalization ability across different task domains. however, such tl is still insufficient in making machine learning attain generalization ability comparable to that of the human brain. to examine if the internal representation of the brain could be used to achieve more efficient tl, we introduce a method for tl mediated by human brains. our method transforms feature representations of audiovisual inputs in cnns into those in activation patterns of individual brains via their association learned ahead using measured brain responses. then, to estimate labels reflecting human cognition and behavior induced by the audiovisual inputs, the transformed representations are used for tl. we demonstrate that our brain-mediated tl (btl) shows higher performance in the label estimation than the standard tl. in addition, we illustrate that the estimations mediated by different brains vary from brain to brain, and the variability reflects the individual variability in perception. thus, our btl provides a framework to improve the generalization ability of machine-learning feature representations and enable machine learning to estimate human-like cognition and behavior, including individual variability.',\n",
       " 573: 'motivated by the study of weyl structures on conformal manifolds admitting parallel weightless forms, we define the notion of conformal product of conformal structures and study its basic properties. we obtain a classification of weyl manifolds carrying parallel forms, and we use it to investigate the holonomy of the adapted weyl connection on conformal products. as an application we describe a new class of einstein-weyl manifolds of dimension 4.',\n",
       " 574: 'this article studies the financial time series data processing for machine learning. it introduces the most frequent scaling methods, then compares the resulting stationarity and preservation of useful information for trend forecasting. it proposes an empirical test based on the capability to learn simple data relationship with simple models. it also speaks about the data split method specific to time series, avoiding unwanted overfitting and proposes various labelling for classification and regression.',\n",
       " 575: 'in the modern era where highly-commodified cultural products compete heavily for mass consumption, finding the principles behind the complex process of how successful, \"hit\" products emerge remains a vital scientific goal that requires an interdisciplinary approach. here we present a framework for tracing the cycle of prosperity-and-decline of a product to find insights into influential and potent factors that determine its success. as a rapid, high-throughput indicator of the preference of the public, popularity charts have emerged as a useful information source for finding the market performance patterns of products over time, which we call the on-chart life trajectories that show how the products enter the chart, fare inside it, and eventually exit from it. we propose quantitative parameters to characterise a life trajectory, and analyse a large-scale data set of nearly $7\\\\,000$ songs from gaon chart, a major weekly korean pop (k-pop) chart that cover a span of six years. we find that a significant role is played by non-musical extrinsic factors such as the established fan base of the artist and the might of production companies in the on-chart success of songs, strongly indicative of the commodified nature of modern cultural products. we also review a possible mathematical model of this phenomenon, and discuss several nontrivial yet intriguing trajectories that we call the \"late bloomers\" and the \"re-entrants\" that appears to be strongly driven by serendipitous exposure on mass media and the changes of seasons.',\n",
       " 576: 'polaritons are quasiparticles arising from the strong coupling of electromagnetic waves in cavities and dipolar oscillations in a material medium. in this framework, localized surface plasmon in metallic nanoparticles defining optical nanocavities have attracted increasing interests in the last decade. this interest results from their sub-diffraction mode volume, which offers access to extremely high photonic densities by exploiting strong scattering cross-sections. however, high absorption losses in metals have hindered the observation of collective coherent phenomena, such as condensation. in this work we demonstrate the formation of a non-equilibrium room temperature plasmon-exciton-polariton condensate with a long range spatial coherence, extending a hundred of microns, well over the excitation area, by coupling frenkel excitons in organic molecules to a multipolar mode in a lattice of plasmonic nanoparticles. time-resolved experiments evidence the picosecond dynamics of the condensate and a sizeable blueshift, thus measuring for the first time the effect of polariton interactions in plasmonic cavities. our results pave the way to the observation of room temperature superfluidity and novel nonlinear phenomena in plasmonic systems, challenging the common belief that absorption losses in metals prevent the realization of macroscopic quantum states.',\n",
       " 577: 'we develop a method that is based on processing gathered event related potentials (erp) signals and the use of machine learning technique for multivariate analysis (i.e. classification) that we apply in order to analyze the differences between dyslexic and skilled readers.   no human intervention is needed in the analysis process. this is the state of the art results for automatic identification of dyslexic readers using a lexical decision task. we use mathematical and machine learning based techniques to automatically discover novel complex features that (i) allow for reliable distinction between dyslexic and normal control skilled readers and (ii) to validate the assumption that the most of the differences between dyslexic and skilled readers located in the left hemisphere.   interestingly, these tools also pointed to the fact that high pass signals (typically considered as \"noise\" during erp/eeg analyses) in fact contains significant relevant information. finally, the proposed scheme can be used for analysis of any erp based studies.',\n",
       " 578: 'it is shown that the distributed chaos in the simple hamiltonian (conservative) dynamical systems, such as the nose-hoover oscillator and double oscillator, can mimic the distributed chaos in the isotropic homogeneous turbulence. direct numerical simulations with the classic toda lattice and with the nonlinear schr\\\\\"{o}dinger equation (soliton turbulence) under random initial conditions have been also discussed in this context. these properties of the distributed chaos have been related to analytical properties of the hamiltonian systems. decrease of the smoothness results in the power-law spectra instead of the stretched exponential ones characteristic to the distributed chaos, both for the dynamical systems and for turbulence.',\n",
       " 579: \"this paper finds near equilibrium prices for electricity markets with nonconvexities due to binary variables, in order to reduce the market participants' opportunity costs, such as generators' unrecovered costs. the opportunity cost is defined as the difference between the profit when the instructions of the market operator are followed and when the market participants can freely make their own decisions based on the market prices. we use the minimum complementarity approximation to the minimum total opportunity cost (mtoc) model, from previous research, with tests on a much more realistic unit commitment (uc) model than in previous research, including features such as reserve requirements, ramping constraints, and minimum up and down times. the developed model incorporates flexible price responsive demand, as in previous research, but since not all demand is price responsive, we consider the more realistic case that total demand is a mixture of fixed and flexible. another improvement over previous mtoc research is computational: whereas the previous research had nonconvex terms among the objective function's continuous variables, we convert the objective to an equivalent form that contains only linear and convex quadratic terms in the continuous variables. we compare the unit commitment model with the standard social welfare optimization version of uc, in a series of sensitivity analyses, varying flexible demand to represent varying degrees of future penetration of electric vehicles and smart appliances, different ratios of generation availability, and different values of transmission line capacities to consider possible congestion. the minimum total opportunity cost and social welfare solutions are mostly very close in different scenarios, except in some extreme cases.\",\n",
       " 580: \"the minimum cut problem for an undirected edge-weighted graph asks us to divide its set of nodes into two blocks while minimizing the weight sum of the cut edges. here, we introduce a linear-time algorithm to compute near-minimum cuts. our algorithm is based on cluster contraction using label propagation and padberg and rinaldi's contraction heuristics [siam review, 1991]. we give both sequential and shared-memory parallel implementations of our algorithm. extensive experiments on both real-world and generated instances show that our algorithm finds the optimal cut on nearly all instances significantly faster than other state-of-the-art algorithms while our error rate is lower than that of other heuristic algorithms. in addition, our parallel algorithm shows good scalability.\",\n",
       " 581: 'motivated by the classical susceptible-infected-recovered (sir) epidemic models proposed by kermack and mckendrick, we consider a class of stochastic compartmental dynamical systems with a notion of partial ordering among the compartments. we call such systems unidirectional mass transfer models (mtms). we show that there is a natural way of interpreting a uni-directional mtm as a survival dynamical system (sds) that is described in terms of survival functions instead of population counts. this sds interpretation allows us to employ tools from survival analysis to address various issues with data collection and statistical inference of unidirectional mtms. in particular, we propose and numerically validate a statistical inference procedure based on sds-likelihoods. we use the sir model as a running example throughout the paper to illustrate the ideas.',\n",
       " 582: 'radio detection of cosmic-ray air showers requires time synchronization of detectors on a nanosecond level, especially for advanced reconstruction algorithms based on the wavefront curvature and for interferometric analysis approaches. at the auger engineering radio array, the distributed, autonomous detector stations are time-synchronized via the global positioning system which, however, does not provide sufficient timing accuracy. we thus employ a dedicated beacon reference transmitter to correct for event-by-event clock drifts in our offline data analysis. in an independent cross-check of this \"beacon correction\" using radio pulses emitted by commercial airplanes, we have shown that the combined timing accuracy of the two methods is better than 2 nanoseconds.',\n",
       " 583: 'we consider the uniform random $d$-regular graph on $n$ vertices, with $d \\\\in [n^\\\\alpha, n^{2/3-\\\\alpha}]$ for arbitrary $\\\\alpha > 0$. we prove that in the bulk of the spectrum the local eigenvalue correlation functions and the distribution of the gaps between consecutive eigenvalues coincide with those of the gaussian orthogonal ensemble.',\n",
       " 584: \"situation awareness (sa) is an important constituent in human information processing and essential in pilots' decision-making processes. acquiring and maintaining appropriate levels of sa is critical in aviation environments as it affects all decisions and actions taking place in flights and air traffic control. this paper provides an overview of recent measurement models and approaches to establishing and enhancing sa in aviation environments. many aspects of sa are examined including the classification of sa techniques into six categories, and different theoretical sa models from individual, to shared or team, and to distributed or system levels. quantitative and qualitative perspectives pertaining to sa methods and issues of sa for unmanned vehicles are also addressed. furthermore, future research directions regarding sa assessment approaches are raised to deal with shortcomings of the existing state-of-the-art methods in the literature.\",\n",
       " 585: 'we suggest a possible realization of a solid-state memory capacitive (memcapacitive) system. our approach relies on the slow polarization rate of a medium between plates of a regular capacitor. to achieve this goal, we consider a multi-layer structure embedded in a capacitor. the multi-layer structure is formed by metallic layers separated by an insulator so that non-linear electronic transport (tunneling) between the layers can occur. the suggested memcapacitor shows hysteretic charge-voltage and capacitance-voltage curves, and both negative and diverging capacitance within certain ranges of the field. this proposal can be easily realized experimentally, and indicates the possibility of information storage in memcapacitive devices.',\n",
       " 586: 'designing sparse sampling strategies is one of the important components in having resilient estimation and control in networked systems as they make network design problems more cost-effective due to their reduced sampling requirements and less fragile to where and when samples are collected. it is shown that under what conditions taking coarse samples from a network will contain the same amount of information as a more finer set of samples. our goal is to estimate initial condition of linear time-invariant networks using a set of noisy measurements. the observability condition is reformulated as the frame condition, where one can easily trace location and time stamps of each sample. we compare estimation quality of various sampling strategies using estimation measures, which depend on spectrum of the corresponding frame operators. using properties of the minimal polynomial of the state matrix, deterministic and randomized methods are suggested to construct observability frames. intrinsic tradeoffs assert that collecting samples from fewer subsystems dictates taking more samples (in average) per subsystem. three scalable algorithms are developed to generate sparse space-time sampling strategies with explicit error bounds.',\n",
       " 587: \"a new certification authority authorization (caa) resource record for the domain name system (dns) was standardized in 2013. motivated by the later 2017 decision to enforce mandatory caa checking for most certificate authorities, this paper surveys the early adoption of caa by using an empirical sample collected from the alexa's top-million domains. according to the results, (i) the adoption of caa is still at a modest level; only a little below two percent of the popular domains sampled have adopted caa. among the domains that have adopted caa, (ii) authorizations dealing with wildcard certificates are rare compared to conventional certificates. interestingly, (iii) the results only partially reflect the market structure of the global certificate business. with these timely results, the paper contributes to the ongoing large-scale empirical research on the use of encryption technologies.\",\n",
       " 588: 'we say a group is finitely annihilated if it is the set-theoretic union of all its proper normal finite index subgroups. we investigate this new property, and observe that it is independent of several other well known group properties. for finitely generated groups, we show that in many cases it is equivalent to having non-cyclic abelianisation, and at the same time construct an explicit infinite family of counterexamples to this. we show for finitely presented groups that this property is neither markov nor co-markov. in the context of our work we show that the weight of a non-perfect finite group, or a non-perfect finitely generated solvable group, is the same as the weight of its abelianisation. we generalise a theorem of brodie-chamberlain-kappe on finite coverings of groups, and finish with some generalisations and variations of our new definition.',\n",
       " 589: 'extended object tracking considers the simultaneous estimation of the kinematic state and the shape parameters of a moving object based on a varying number of noisy detections. a main challenge in extended object tracking is the nonlinearity and high-dimensionality of the estimation problem. this work presents compact closed-form expressions for a recursive kalman filter that explicitly estimates the orientation and axes lengths of an extended object based on detections that are scattered over the object surface (according to a gaussian distribution). existing approaches are either based on monte carlo approximations or do not allow for explicitly maintaining all ellipse parameters. the performance of the novel approach is demonstrated with respect to the state-of-the-art by means of simulations.',\n",
       " 590: \"we propose a threshold detector for l\\\\'evy distributed fluctuations based on a josephson junction. the l\\\\'evy noise current added to a linearly ramped bias current results in clear changes in the distribution of switching currents out of the zero-voltage state of the junction. we observe that the analysis of the cumulative distribution function of the switching currents supplies information on both the characteristics shape parameter $\\\\alpha$ of the l\\\\'evy statistics and the intensity of the fluctuations. moreover, we discuss a theoretical model which allows to extract characteristic features of the l\\\\'evy fluctuations from a measured distribution of switching currents. in view of this results, this system can effectively find an application as a detector for a l\\\\'evy signal embedded in a noisy background.\",\n",
       " 591: 'enumerative algebraic geometry deals with problems of counting geometric objects defined algebraically, an important class of enumerative problems is that of counting curves: given a class of curves in some projective variety defined by fixing some algebraic or geometric invariants (such as degree, genus and types of singularities), the problem usually takes the form of \"how many curves of that class pass through a configuration of n points in general position?\" tropical geometry deals with certain piecewise-linear complexes, which arise as degeneration of families of complex algebraic varieties, and can also be described algebraically using \"max-plus\" algebra, (the tropical semi-field). the problem we solve is that of counting rational curves with one cusp and certain number of nodes on toric surfaces, passing through a configuration of sufficient points in general position. we show that that this number equals the number of certain tropical curves counted with multiplicities and we describe these curves and their multiplicities. the main tools are tropicalization and patchworking. in tropicalization we pass from an equisingular family of curves to a special limit fiber which can be described in terms of tropical data and analytic data. we then classify these possible limits, and use the patchworking theorem to reconstruct the families that correspond to them.',\n",
       " 592: 'we present a bayesian model selection approach to estimate the intrinsic dimensionality of a high-dimensional dataset. to this end, we introduce a novel formulation of the probabilisitic principal component analysis model based on a normal-gamma prior distribution. in this context, we exhibit a closed-form expression of the marginal likelihood which allows to infer an optimal number of components. we also propose a heuristic based on the expected shape of the marginal likelihood curve in order to choose the hyperparameters. in non-asymptotic frameworks, we show on simulated data that this exact dimensionality selection approach is competitive with both bayesian and frequentist state-of-the-art methods.',\n",
       " 593: \"the purpose of this short problem paper is to raise an extremal question on set systems which seems to be natural and appealing. our question is: which set systems of a given size maximise the number of $(n+1)$-element chains in the power set $\\\\mathcal{p}(\\\\{1,2,\\\\dots,n\\\\})$? we will show that for each fixed $\\\\alpha>0$ there is a family of $\\\\alpha 2^n$ sets containing $(\\\\alpha+o(1))n!$ such chains, and that this is asymptotically best possible. for smaller set systems we are unable to answer the question. we conjecture that a `tower of cubes' construction is extremal. we finish by mentioning briefly a connection to an extremal problem on posets and a variant of our question for the grid graph.\",\n",
       " 594: 'this study provides an independent, outside-in estimate of the cost and schedule risks of nuclear waste storage projects. based on a reference class of 216 past, comparable projects, risk of cost overrun was found to be 202% or less, with 80% certainty, i.e., 20% risk of an overrun above 202%. based on a reference class of 200 past, comparable projects, risk of schedule overrun was found to be 104% or less, with 80% certainty, i.e., 20% risk of overrun above 104%. cost risk and schedule risk are both substantial for nuclear waste storage projects.',\n",
       " 595: 'a linear stability analysis of a two-layer plane couette flow of two immiscible fluid layers with different densities, viscosities and thicknesses, bounded by two infinite parallel plates moving at a constant relative velocity to each other, with an insoluble surfactant along the interface and in the presence of gravity is carried out. the normal modes approach is applied to the equations governing flow disturbances. these equations, together with boundary conditions at the plates and the interface, yield a linear eigenvalue problem. when inertia is neglected velocity amplitudes are linear combinations of hyperbolic functions, and a quadratic dispersion equation for the complex growth rate is obtained where coefficients depend on the aspect ratio, the viscosity ratio, the basic velocity shear, the marangoni number ma that measures the effects of surfactant, and the bond number bo that measures the influence of gravity. an extensive investigation is carried out that examines the stabilizing or destabilizing influences of these parameters. there are two continuous branches of the normal modes: a robust branch that exists even with no surfactant, and a surfactant branch that vanishes when ma $\\\\downarrow 0$. due to the availability of the explicit forms for the growth rates, in many instances the numerical results are corroborated with analytical asymptotics. for the less unstable branch, a mid-wave interval of unstable wavenumbers (halpern and frenkel (2003)) sometimes co-exists with a long-wave one. we study the instability landscape, determined by the threshold curve of the long-wave instability and the critical curve of the mid-wave instability in the (ma, bo)-plane. the changes of the extremal points of the critical curves with the variation of the other parameters, such as the viscosity ratio, and the extrema bifurcation points are investigated.',\n",
       " 596: \"chemical evolution is essential in understanding the origins of life. we present a theory for the evolution of molecule masses and show that small molecules grow by random diffusion and large molecules by a preferential attachment process leading eventually to life's molecules. it reproduces correctly the distribution of molecules found via mass spectroscopy for the murchison meteorite and estimates the start of chemical evolution back to 12.8 billion years following the birth of stars and supernovae. from the frontier mass between the random and preferential attachment dynamics the birth time of molecule families can be estimated. amino acids emerge about 165 million years after chemical elements emerge in stars. using the scaling of reaction rates with the distance of the molecules in space we recover correctly the few days emergence time of amino acids in the miller-urey experiment. the distribution of interstellar and extragalactic molecules are both consistent with the evolutionary mass distribution, and their age is estimated to 108 and 65 million years after the start of evolution. from the model, we can determine the number of different molecule compositions at the time of the emergence of earth to be 1.6 million and the number of molecule compositions in interstellar space to a mere 719 species.\",\n",
       " 597: 'in a collectivised pension fund, investors agree that any money remaining in the fund when they die can be shared among the survivors.   we compute analytically the optimal investment-consumption strategy for a fund of $n$ identical investors with homogeneous epstein--zin preferences, investing in the black--scholes market in continuous time but consuming in discrete time. our result holds for arbitrary mortality distributions.   we also compute the optimal strategy for an infinite fund of investors, and prove the convergence of the optimal strategy as $n\\\\to \\\\infty$. the proof of convergence shows that effective strategies for inhomogeneous funds can be obtained using the optimal strategies found in this paper for homogeneous funds, using the results of [2].   we find that a constant consumption strategy is suboptimal even for infinite collectives investing in markets where assets provide no return so long as investors are \"satisfaction risk-averse.\" this suggests that annuities and defined benefit investments will always be suboptimal investments.   we present numerical results examining the importance of the fund size, $n$, and the market parameters.',\n",
       " 598: 'precision physics at future multi-tev lepton colliders such as clic requires excellent jet energy resolution. the detectors need deep calorimeter systems to limit the energy leakage also for very highly energetic particles and jets. at the same time, compact physical dimensions are mandatory to permit the installation of the complete calorimeter system inside high-field solenoidal magnets. this requires very dense absorbers, making tungsten a natural choice for hadron calorimeters at such a future collider. to study the performance of such a calorimeter, a physics prototype with tungsten absorbers and scintillator tiles with sipm readout as active elements has been constructed and has been tested in particle beams at cern over a wide energy range from 1 gev to 300 gev. we report on the construction and on the operational experience obtained with muon, electron and hadron beams.',\n",
       " 599: 'it is believed that most (perhaps all) gapped phases of matter can be described at long distances by topological quantum field theory (tqft). on the other hand, it has been rigorously established that in 1+1d ground states of gapped hamiltonians can be approximated by matrix product states (mps). we show that the state-sum construction of 2d tqft naturally leads to mps in their standard form. in the case of systems with a global symmetry $g$, this leads to a classification of gapped phases in 1+1d in terms of morita-equivalence classes of $g$-equivariant algebras. non-uniqueness of the mps representation is traced to the freedom of choosing an algebra in a particular morita class. in the case of short-range entangled phases, we recover the group cohomology classification of spt phases.',\n",
       " 600: 'given samples from an unknown multivariate distribution $p$, is it possible to distinguish whether $p$ is the product of its marginals versus $p$ being far from every product distribution? similarly, is it possible to distinguish whether $p$ equals a given distribution $q$ versus $p$ and $q$ being far from each other? these problems of testing independence and goodness-of-fit have received enormous attention in statistics, information theory, and theoretical computer science, with sample-optimal algorithms known in several interesting regimes of parameters. unfortunately, it has also been understood that these problems become intractable in large dimensions, necessitating exponential sample complexity.   motivated by the exponential lower bounds for general distributions as well as the ubiquity of markov random fields (mrfs) in the modeling of high-dimensional distributions, we initiate the study of distribution testing on structured multivariate distributions, and in particular the prototypical example of mrfs: the ising model. we demonstrate that, in this structured setting, we can avoid the curse of dimensionality, obtaining sample and time efficient testers for independence and goodness-of-fit. one of the key technical challenges we face along the way is bounding the variance of functions of the ising model.',\n",
       " 601: 'given a homogeneous k-th order differential operator $a (d)$ on $\\\\mathbb{r}^n$ between two finite dimensional spaces, we establish the hardy inequality $$\\\\int_{\\\\mathbb{r}^n} \\\\frac{\\\\lvert d^{k-1}u\\\\rvert}{\\\\lvert x \\\\rvert} \\\\,\\\\mathrm{d} x \\\\leq c \\\\int_{\\\\mathbb{r}^n} \\\\lvert a(d)u\\\\rvert $$ and the sobolev inequality $$\\\\lvert d^{k-n} u\\\\rvert_{l^{\\\\infty}(\\\\mathbb{r}^n)}\\\\leq c \\\\int_{\\\\mathbb{r}^n} \\\\lvert a(d)u\\\\rvert $$ when $a(d)$ is elliptic and satisfies a recently introduced cancellation property. we also study the necessity of these two conditions.',\n",
       " 602: 'lattice and special nonlattice multilevel constellations constructed from binary codes, such as constructions a, c, and d, have relevant applications in mathematics (sphere packing) and in communication (multi-stage decoding and efficient vector quantization). in this work, we explore some properties of construction c, in particular its geometric uniformity. we then propose a new multilevel construction, inspired by bit interleaved coded modulation (bicm), that we call construction c*. we investigate the geometric uniformity, laticeness, and minimum distance properties of construction c* and discuss its superior packing efficiency when compared to construction c.',\n",
       " 603: \"fluent and confident speech is desirable to every speaker. but professional speech delivering requires a great deal of experience and practice. in this paper, we propose a speech stream manipulation system which can help non-professional speakers to produce fluent, professional-like speech content, in turn contributing towards better listener engagement and comprehension. we propose to achieve this task by manipulating the disfluencies in human speech, like the sounds 'uh' and 'um', the filler words and awkward long silences. given any unrehearsed speech we segment and silence the filled pauses and doctor the duration of imposed silence as well as other long pauses ('disfluent') by a predictive model learned using professional speech dataset. finally, we output a audio stream in which speaker sounds more fluent, confident and practiced compared to the original speech he/she recorded. according to our quantitative evaluation, we significantly increase the fluency of speech by reducing rate of pauses and fillers.\",\n",
       " 604: 'it is not clear how to target patients who are most likely to benefit from digital care management programs ex-ante, a shortcoming of current risk score based approaches. this study focuses on defining impactability by identifying those patients most likely to benefit from technology enabled care management, delivered through a digital health platform, including a mobile app and clinician web dashboard. anonymized insurance claims data were used from a commercially insured population across several u.s. states and combined with inferred sociodemographic data and data derived from the patient-held mobile application itself. our approach involves the creation of two models and the comparative analysis of the methodologies and performances therein. we first train a cost prediction model to calculate the differences in predicted (without intervention) versus actual (with onboarding onto digital health platform) healthcare expenditure for patients (n = 1,242). this enables the classification of impactability if differences in predicted versus actual costs meet a predetermined threshold. a random forest machine learning model was then trained to accurately categorize new patients as impactable versus not impactable, reaching an overall accuracy of 71.9%. we then modify these parameters through grid search to define the parameters that deliver optimal performance. a roadmap is proposed to iteratively improve the performance of the model. as the number of newly onboarded patients and length of use continues to increase, the accuracy of predicting impactability will improve commensurately as more advanced machine learning techniques such as deep learning become relevant. this approach is generalizable to analyzing the impactability of any intervention and is a key component of realising closed loop feedback systems for continuous improvement in healthcare.',\n",
       " 605: 'd. ruelle considered a general setting where he is able to characterize equilibrium states for h\\\\\"older potentials based on properties of conjugating homeomorphism in the so called smale spaces. on this setting he also shows a relation of kms states of $c^*$-algebras and equilibrium probabilities of thermodynamic formalism. a later paper by n. haydn and d. ruelle presents a shorter proof of this equivalence.   here we consider similar problems but now on the symbolic space $\\\\omega = \\\\{1,2,...,d\\\\}^{\\\\mathbb{z} - \\\\{ 0 \\\\} }$ and the dynamics will be given by the shift $\\\\tau$. in the case of potentials depending on a finite coordinates we will present a simplified proof of the equivalence mentioned above which is the main issue of the papers by d. ruelle and n. haydn. the class of conjugating homeomorphism is explicit and reduced to a minimal set of conditions.   we also present with details (following d. ruelle) the relation of these probabilities with the kms dynamical $c^*$-state on the $c^*$-algebra associated to the groupoid defined by the homoclinic equivalence relation.   the topics presented here are not new but we believe the main ideas of the proof of the results by ruelle and haydn will be quite transparent in our exposition.',\n",
       " 606: 'the high altitude water cherenkov (hawc) gamma-ray observatory is a wide field-of-view observatory sensitive to 0.5 tev - 100 tev gamma-rays and cosmic-rays in the state of puebla, mexico at an altitude of 4100m. the hawc observatory performed an indirect search for dark matter via gev-tev photons resulting from dark matter annihilation and decay considering various sources, including dwarf spheroidal galaxies (dsphs), the m31 galaxy and the virgo cluster, as well as a combined limit using the dsphs. hawc has not seen statistically significant excess from these sources. we searched for dark matter annihilation and decay at dark matter masses above 1 tev. we will present the annihilation cross-section and decay lifetime limits.',\n",
       " 607: 'we study large-scale kinematic dynamo action of steady mirror-antisymmetric flows of incompressible fluid, that involve small spatial scales only, by asymptotic methods of the multiscale stability theory. it turns out that, due to the magnetic $\\\\alpha$-effect in such flows, the large-scale mean field experiences harmonic oscillations in time on the scale o($\\\\varepsilon t$) without growth or decay. here $\\\\varepsilon$ is the spatial scale ratio and $t$ is the fast time of the order of the flow turnover time. the interaction of the accompanying fluctuating magnetic field with the flow gives rise to an anisotropic magnetic eddy diffusivity, whose dependence on the direction of the large-scale wave vector generically exhibits a singular behaviour, and thus to negative eddy diffusivity for whichever molecular magnetic diffusivity. consequently, such flows always act as kinematic dynamos on the time scale o($\\\\varepsilon^2t$); for the directions at which eddy diffusivity is infinite, the large-scale mean-field growth rate is finite on the scale o($\\\\varepsilon^{3/2}t$). we investigate numerically this dynamo mechanism for two sample flows.',\n",
       " 608: \"we prove effective versions of algebraic and analytic lang's conjectures for product-quotient surfaces of general type with $p_g=0$ and $c_1^2=c_2$.\",\n",
       " 609: 'in this study, the majorana equation for particles with arbitrary spin is solved for a half-integer spin free particle. the solution for the fundamental state, corresponding to the reference frame in which the particle is at rest, is compared with that obtained using the dirac equation, especially as regards the approximation in the relativistic limit, in which the speed of the particle is close to that of light. furthermore, the solutions that majorana defines unphysical, proving that their occupation probability increases with the particle velocity, are taken into consideration. the anomalous behavior exhibited by these states also shows that for high-energy particles with small mass, transitions from a bradyonic state to a tachyonic state become possible.',\n",
       " 610: 'recent discovery of both gapped and gapless topological phases in weakly correlated electron systems has introduced various relativistic particles and a number of exotic phenomena in condensed matter physics. the weyl fermion is a prominent example of three dimensional (3d), gapless topological excitation, which has been experimentally identified in inversion symmetry breaking semimetals. however, their realization in spontaneously time reversal symmetry (trs) breaking magnetically ordered states of correlated materials has so far remained hypothetical. here, we report a set of experimental evidence for elusive magnetic weyl fermions in mn$_3$sn, a non-collinear antiferromagnet that exhibits a large anomalous hall effect even at room temperature. detailed comparison between our angle resolved photoemission spectroscopy (arpes) measurements and density functional theory (dft) calculations reveals significant bandwidth renormalization and damping effects due to the strong correlation among mn 3$d$ electrons. moreover, our transport measurements have unveiled strong evidence for the chiral anomaly of weyl fermions, namely, the emergence of positive magnetoconductance only in the presence of parallel electric and magnetic fields. the magnetic weyl fermions of mn$_3$sn have a significant technological potential, since a weak field ($\\\\sim$ 10 mt) is adequate for controlling the distribution of weyl points and the large fictitious field ($\\\\sim$ a few 100 t) in the momentum space. our discovery thus lays the foundation for a new field of science and technology involving the magnetic weyl excitations of strongly correlated electron systems.',\n",
       " 611: 'we propose novel ensemble calculation methods for navier-stokes equations subject to various initial conditions, forcing terms and viscosity coefficients. we establish the stability of the schemes under a cfl condition involving velocity fluctuations. similar to related works, the schemes require solution of a single system with multiple right-hand sides. moreover, we extend the ensemble calculation method to problems with open boundary conditions, with provable energy stability.',\n",
       " 612: \"we forecast the main cosmological parameter constraints achievable with the core space mission which is dedicated to mapping the polarisation of the cosmic microwave background (cmb). core was recently submitted in response to esa's fifth call for medium-sized mission proposals (m5). here we report the results from our pre-submission study of the impact of various instrumental options, in particular the telescope size and sensitivity level, and review the great, transformative potential of the mission as proposed. specifically, we assess the impact on a broad range of fundamental parameters of our universe as a function of the expected cmb characteristics, with other papers in the series focusing on controlling astrophysical and instrumental residual systematics. in this paper, we assume that only a few central core frequency channels are usable for our purpose, all others being devoted to the cleaning of astrophysical contaminants. on the theoretical side, we assume lcdm as our general framework and quantify the improvement provided by core over the current constraints from the planck 2015 release. we also study the joint sensitivity of core and of future baryon acoustic oscillation and large scale structure experiments like desi and euclid. specific constraints on the physics of inflation are presented in another paper of the series. in addition to the six parameters of the base lcdm, which describe the matter content of a spatially flat universe with adiabatic and scalar primordial fluctuations from inflation, we derive the precision achievable on parameters like those describing curvature, neutrino physics, extra light relics, primordial helium abundance, dark matter annihilation, recombination physics, variation of fundamental constants, dark energy, modified gravity, reionization and cosmic birefringence. (abridged)\",\n",
       " 613: 'this short note considers an efficient variant of the trust-region algorithm with dynamic accuracy proposed carter (1993) and conn, gould and toint (2000) as a tool for very high-performance computing, an area where it is critical to allow multi-precision computations for keeping the energy dissipation under control. numerical experiments are presented indicating that the use of the considered method can bring substantial savings in objective function\\'s and gradient\\'s evaluation \"energy costs\" by efficiently exploiting multi-precision computations.',\n",
       " 614: 'click-through rate (ctr) prediction, which aims to predict the probability of a user clicking on an ad or an item, is critical to many online applications such as online advertising and recommender systems. the problem is very challenging since (1) the input features (e.g., the user id, user age, item id, item category) are usually sparse and high-dimensional, and (2) an effective prediction relies on high-order combinatorial features (\\\\textit{a.k.a.} cross features), which are very time-consuming to hand-craft by domain experts and are impossible to be enumerated. therefore, there have been efforts in finding low-dimensional representations of the sparse and high-dimensional raw features and their meaningful combinations. in this paper, we propose an effective and efficient method called the \\\\emph{autoint} to automatically learn the high-order feature interactions of input features. our proposed algorithm is very general, which can be applied to both numerical and categorical input features. specifically, we map both the numerical and categorical features into the same low-dimensional space. afterwards, a multi-head self-attentive neural network with residual connections is proposed to explicitly model the feature interactions in the low-dimensional space. with different layers of the multi-head self-attentive neural networks, different orders of feature combinations of input features can be modeled. the whole model can be efficiently fit on large-scale raw data in an end-to-end fashion. experimental results on four real-world datasets show that our proposed approach not only outperforms existing state-of-the-art approaches for prediction but also offers good explainability. code is available at: \\\\url{https://github.com/deepgraphlearning/recommendersystems}.',\n",
       " 615: \"we investigate velocity variations inside of and surrounding a gravity driven drop impacting on and moving through a confining orifice, wherein the effects of edge geometry (round- vs. sharp-edged) and surface wettability (hydrophobic vs. hydrophilic) of the orifice are considered. using refractive index matching and time-resolved piv, we quantify the redistribution of energy in the drop and the surrounding fluid during the drop's impact and motion through a round-edged orifice. the measurements show the importance of a) drop kinetic energy transferred to and dissipated within the surrounding liquid, and b) the drop kinetic energy due to internal deformation and rotation during impact and passage through the orifice. while a rounded orifice edge prevents contact between the drop and orifice surface, a sharp edge promotes contact immediately upon impact, changing the near surface flow field as well as the drop passage dynamics. for a sharp-edged hydrophobic orifice, the contact lines remain localized near the orifice edge, but slipping and pinning strongly affect the drop propagation and outcome. for a sharp-edged hydrophilic orifice, on the other hand, the contact lines propagate away from the orifice edge, and their motion is coupled with the global velocity fields in the drop and the surrounding fluid. by examining the contact line propagation over a hydrophilic orifice surface with minimal drop penetration, we characterize two stages of drop spreading that exhibit power-law dependence with variable exponent. in the first stage, the contact line propagates under the influence of impact inertia and gravity. in the second stage, inertial influence subsides, and the contact line propagates mainly due to wettability.\",\n",
       " 616: 'in vivo measurements of muscle architecture (i.e. the spatial arrangement of muscle fascicles) are routinely included in research and clinical settings to monitor muscle structure, function and plasticity. however, in most cases such measurements are performed manually, and more reliable and time-efficient automated methods are either lacking completely, or are inaccessible to those without expertise in image analysis. in this work, we propose an imagej script to automate the entire analysis process of muscle architecture in ultrasound images: simple muscle architecture analysis (sma). images are filtered in the spatial and frequency domains with built-in commands and external plugins to highlight aponeuroses and fascicles. fascicle dominant orientation is then computed in regions of interest using the orientationj plugin. bland-altman plots of analyses performed manually or with sma indicates that the automated analysis does not induce any systematic bias and that both methods agree equally through the range of measurements. our test results illustrate the suitability of sma to analyse images from superficial muscles acquired with a broad range of ultrasound settings.',\n",
       " 617: 'fitted interatomic potentials are widely used in atomistic simulations thanks to their ability to compute the energy and forces on atoms quickly. however, the simulation results crucially depend on the quality of the potential being used. force matching is a method aimed at constructing reliable and transferable interatomic potentials by matching the forces computed by the potential as closely as possible, with those obtained from first principles calculations. the potfit program is an implementation of the force-matching method that optimizes the potential parameters using a global minimization algorithm followed by a local minimization polish. we extended potfit in two ways. first, we adapted the code to be compliant with the kim application programming interface (api) standard (part of the knowledgebase of interatomic models project). this makes it possible to use potfit to fit many kim potential models, not just those prebuilt into the potfit code. second, we incorporated the geodesic levenberg--marquardt (lm) minimization algorithm into potfit as a new local minimization algorithm. the extended potfit was tested by generating a training set using the kim environment-dependent interatomic potential (edip) model for silicon and using potfit to recover the potential parameters from different initial guesses. the results show that edip is a \"sloppy model\" in the sense that its predictions are insensitive to some of its parameters, which makes fitting more difficult. we find that the geodesic lm algorithm is particularly efficient for this case. the extended potfit code is the first step in developing a kim-based fitting framework for interatomic potentials for bulk and two dimensional materials. the code is available for download via https://www.potfit.net.',\n",
       " 618: 'simplistic estimation of neural connectivity in meeg sensor space is impossible due to volume conduction. the only viable alternative is to carry out connectivity estimation in source space. among the neuroscience community this is claimed to be impossible or misleading due to leakage: linear mixing of the reconstructed sources. to address this problematic we propose a novel solution method that caulks the leakage in meeg source activity and connectivity estimates: bc-vareta. it is based on a joint estimation of source activity and connectivity in the frequency domain representation of meeg time series. to achieve this, we go beyond current methods that assume a fixed gaussian graphical model for source connectivity. in contrast we estimate this graphical model in a bayesian framework by placing priors on it, which allows for highly optimized computations of the connectivity, via a new procedure based on the local quadratic approximation under quite general prior models. a further contribution of this paper is the rigorous definition of leakage via the spatial dispersion measure and earth movers distance based on the geodesic distances over the cortical manifold. both measures are extended for the first time to quantify connectivity leakage by defining them on the cartesian product of cortical manifolds. using these measures, we show that bc-vareta outperforms most state of the art inverse solvers by several orders of magnitude.',\n",
       " 619: 'we present herschel and xmm-newton observations of ulasj1234+0907 ($z=2.503$), the reddest broad-line type 1 quasar currently known with (i-k)>7.1. herschel observations indicate that the quasar host is a hyperluminous infrared galaxy (hylirg) with a total infrared luminosity of log10(lir/l0)=13.90+/-0.02. a greybody fit gives a dust temperature of td=60+/-3k assuming an emissivity index of beta=1.5, considerably higher than in submillimeter bright galaxies observed at similar redshifts. the star formation rate is estimated to be >2000m0/yr even accounting for a significant contribution from an agn component to the total infrared luminosity or requiring that only the far infra-red luminosity is powered by a starburst. xmm-newton observations constrain the hard x-ray luminosity to be l(2-10kev)=1.3e45 erg/s putting ulasj1234+0907 among the brightest x-ray quasars known. through very deep optical and near infra-red imaging of the field at sub-arcsecond seeing, we demonstrate that despite its extreme luminosity, it is highly unlikely that ulasj1234+0907 is being lensed. we measure a neutral hydrogen column density of nh=9e21/cm^2 corresponding to av~6 mags. the observed properties of ulasj1234+0907 - high luminosity and eddington ratio, broad lines, moderate column densities and significant infra-red emission from re-processed dust - are similar to those predicted by galaxy formation simulations for the agn blowout phase. the high eddington ratio combined with the presence of significant amounts of dust in this quasar, is expected to drive strong outflows due to the effects of radiation pressure on dust. we conclude that ulasj1234+0907 is a prototype galaxy caught at the peak epoch of galaxy formation, which is transitioning from a starburst to optical quasar via a dusty quasar phase.',\n",
       " 620: 'we study the effects of chemical bonding on raman scattering from benzenethiol chemisorbed on silver clusters using time-dependent density functional theory (tddft). raman scattering cross sections are computed using a formalism that employs analytical derivatives of frequency-dependent electronic polarizabilities, which treats both off-resonant and resonant enhancement within the same scheme. in the off-resonant regime, raman scattering into molecular vibrational modes is enhanced by one order of magnitude and shows pronounced dependence on the orientation and the local symmetry of the molecule. additional strong enhancement of the order of $10^2$ arises from resonant transitions to mixed metal--molecular electronic states. the raman enhancement is analyzed using raman excitation profiles (reps) for the range of excitation energies $1.6-3.0$ ev, in which isolated benzenethiol does not have electronic transitions. the computed vibrational frequency shifts and relative raman scattering cross sections of the metal--molecular complexes are in good agreement with experimental data on surface enhanced raman scattering (sers) for benzenethiol adsorbed on silver surfaces. characterization and understanding of these effects, associated with chemical enhancement mechanism, may be used to improve the detection sensitivity in molecular raman scattering.',\n",
       " 621: 'apparent personality and emotion analysis are both central to affective computing. existing works solve them individually. in this paper we investigate if such high-level affect traits and their relationship can be jointly learned from face images in the wild. to this end, we introduce persemon, an end-to-end trainable and deep siamese-like network. it consists of two convolutional network branches, one for emotion and the other for apparent personality. both networks share their bottom feature extraction module and are optimized within a multi-task learning framework. emotion and personality networks are dedicated to their own annotated dataset. furthermore, an adversarial-like loss function is employed to promote representation coherence among heterogeneous dataset sources. based on this, we also explore the emotion-to-apparent-personality relationship. extensive experiments demonstrate the effectiveness of persemon.',\n",
       " 622: 'steganography is collection of methods to hide secret information (\"payload\") within non-secret information \"container\"). its counterpart, steganalysis, is the practice of determining if a message contains a hidden payload, and recovering it if possible. presence of hidden payloads is typically detected by a binary classifier. in the present study, we propose a new model for generating image-like containers based on deep convolutional generative adversarial networks (dcgan). this approach allows to generate more setganalysis-secure message embedding using standard steganography algorithms. experiment results demonstrate that the new model successfully deceives the steganography analyzer, and for this reason, can be used in steganographic applications.',\n",
       " 623: 'control of blood glucose is essential for diabetes management. current digital therapeutic approaches for subjects with type 1 diabetes mellitus (t1dm) such as the artificial pancreas and insulin bolus calculators leverage machine learning techniques for predicting subcutaneous glucose for improved control. deep learning has recently been applied in healthcare and medical research to achieve state-of-the-art results in a range of tasks including disease diagnosis, and patient state prediction among others. in this work, we present a deep learning model that is capable of forecasting glucose levels with leading accuracy for simulated patient cases (rmse = 9.38$\\\\pm$0.71 [mg/dl] over a 30-minute horizon, rmse = 18.87$\\\\pm$2.25 [mg/dl] over a 60-minute horizon) and real patient cases (rmse = 21.07$\\\\pm$2.35 [mg/dl] for 30-minute, rmse = 33.27$\\\\pm$4.79\\\\% for 60-minute). in addition, the model provides competitive performance in providing effective prediction horizon ($ph_{eff}$) with minimal time lag both in a simulated patient dataset ($ph_{eff}$ = 29.0$\\\\pm$0.7 for 30-min and $ph_{eff}$ = 49.8$\\\\pm$2.9 for 60-min) and in a real patient dataset ($ph_{eff}$ = 19.3$\\\\pm$3.1 for 30-min and $ph_{eff}$ = 29.3$\\\\pm$9.4 for 60-min). this approach is evaluated on a dataset of 10 simulated cases generated from the uva/padova simulator and a clinical dataset of 10 real cases each containing glucose readings, insulin bolus, and meal (carbohydrate) data. performance of the recurrent convolutional neural network is benchmarked against four algorithms. the proposed algorithm is implemented on an android mobile phone, with an execution time of $6$ms on a phone compared to an execution time of $780$ms on a laptop.',\n",
       " 624: 'we design and implement megaphone, a data migration mechanism for stateful distributed dataflow engines with latency objectives. when compared to existing migration mechanisms, megaphone has the following differentiating characteristics: (i) migrations can be subdivided to a configurable granularity to avoid latency spikes, and (ii) migrations can be prepared ahead of time to avoid runtime coordination. megaphone is implemented as a library on an unmodified timely dataflow implementation, and provides an operator interface compatible with its existing apis. we evaluate megaphone on established benchmarks with varying amounts of state and observe that compared to na\\\\\"ive approaches megaphone reduces service latencies during reconfiguration by orders of magnitude without significantly increasing steady-state overhead.',\n",
       " 625: 'in this paper we review the theory of silicon nanowires. we focus on nanowires with diameters below 10 nm, where quantum effects become important and the properties diverge significantly from those of bulk silicon. these wires can be efficiently treated within electronic structure simulation methods and will be among the most important functional blocks of future nanoelectronic devices. firstly, we review the structural properties of silicon nanowires, emphasizing the close connection between the growth orientation, the cross-section and the bounding facets. secondly, we discuss the electronic structure of pristine and doped nanowires, which hold the ultimate key for their applicability in novel electronic devices. finally, we review transport properties where some of the most important limitations in the performances of nanowire-based devices can lay. many of the unique properties of these systems are at the same time defying challenges and opportunities for great technological advances.',\n",
       " 626: 'we prove dynamical upper bounds for discrete one-dimensional schroedinger operators in terms of various spacing properties of the eigenvalues of finite volume approximations. we demonstrate the applicability of our approach by a study of the fibonacci hamiltonian.',\n",
       " 627: \"we attempt to fit the observed radial velocities (rvs) of ${\\\\,{\\\\sim}\\\\,}30$ local group (lg) galaxies using a 3d dynamical model of it and its immediate environment within the context of the standard cosmological paradigm, $\\\\lambda$cdm. this extends and confirms the basic results of our previous axisymmetric investigation of the lg (mnras, 459, 2237). we find that there remains a tendency for observed rvs to exceed those predicted by our best-fitting model. the typical mismatch is slightly higher than in our 2d model, with a root mean square value of ${\\\\,{\\\\sim}\\\\,}50$ km/s. our main finding is that including the 3d distribution of massive perturbing dark matter halos is unlikely to help greatly with the high velocity galaxy problem. nonetheless, the 2d and 3d results differ in several other ways such as which galaxies' rvs are most problematic and the preferred values of parameters common to both models.   the anomalously high rvs of several lg dwarfs may be better explained if the milky way (mw) and andromeda (m31) were once moving much faster than in our models. this would allow lg dwarfs to gain very high rvs via gravitational slingshot encounters with a massive fast-moving galaxy. such a scenario is possible in some modified gravity theories, especially those which require the mw and m31 to have previously undergone a close flyby. in a $\\\\lambda$cdm context, however, this scenario is not feasible as the resulting dynamical friction would cause a rapid merger.\",\n",
       " 628: 'this paper discusses the connection between the local cohomology modules and the serre classes of $r$-modules. such connection provided a common language for expressing some results about the local cohomology $r$-modules, that has appeared in different papers.',\n",
       " 629: 'we like to build abelian groups (or r-modules) which on the one hand are quite free, say $\\\\aleph_{\\\\omega + 1}$-free, and on the other hand, are complicated in suitable sense. we choose as our test problem having no non-trivial homomorphism to $z$ (known classically for $\\\\aleph_1$-free, recently for $\\\\aleph_n$-free). we succeed to prove the existence of even $\\\\aleph_{\\\\omega_1 \\\\cdot n}-$free ones. this requires building n-dimensional black boxes, which are quite free. thus combinatorics is of self interest and we believe will be useful also for other purposes. on the other hand, modulo suitable large cardinals, we prove that it is consistent that every $\\\\aleph_{\\\\omega_1 \\\\cdot \\\\omega}$-free abelian group has non-trivial homomorphisms to z.',\n",
       " 630: 'superfluid currents in the boson condensate with a source and sink of particles are modelled by the pt-symmetric gross-pitaevskii equation with a complex potential. we demonstrate the existence of through-flows of the condensate --- stationary states with the asymptotically nonvanishing flux. the through-flows come in two broad varieties determined by the form of their number density distribution. one variety is described by dip-like solutions featuring a localised density depression; the other one comprises hump-like structures with a density spike in their core. we exemplify each class by exact closed-form solutions. for a fixed set of parameters of the pt-symmetric potential, stationary through-flows form continuous families parametrized by the strength of the background flux. all hump-like and some dip-like members of the family are found to be stable. we show that the through-flows can be controlled by varying the gain-and-loss amplitude of the complex potential and that these amplitude variations may produce an anomalous response of the flux across the gain-loss interface.',\n",
       " 631: 'a recent paper of totaro develops a theory of $q$-ample bundles in characteristic 0. specifically, a line bundle $l$ on $x$ is $q$-ample if for every coherent sheaf $\\\\mathcal{f}$ on $x$, there exists an integer $m_0$ such that $m\\\\geq m_0$ implies $h^i(x,\\\\mathcal{f}\\\\otimes \\\\mathcal{o}(ml))=0$ for $i>q$. we show that a line bundle $l$ on a complex projective scheme $x$ is $q$-ample if and only if the restriction of $l$ to its augmented base locus is $q$-ample. in particular, when $x$ is a variety and $l$ is big but fails to be $q$-ample, then there exists a codimension 1 subscheme $d$ of $x$ such that the restriction of $l$ to $d$ is not $q$-ample.',\n",
       " 632: 'learning using privileged information (lupi) is a powerful heterogenous feature space machine learning framework that allows a machine learning model to learn from highly informative or privileged features which are available during training only to generate test predictions using input space features which are available both during training and testing. lupi can significantly improve prediction performance in a variety of machine learning problems. however, existing large margin and neural network implementations of learning using privileged information are mostly designed for classification tasks. in this work, we have proposed a simple yet effective formulation that allows us to perform regression using privileged information through a custom loss function. apart from regression, our formulation allows general application of lupi to classification and other related problems as well. we have verified the correctness, applicability and effectiveness of our method on regression and classification problems over different synthetic and real-world problems. to test the usefulness of the proposed model in real-world problems, we have evaluated our method on the problem of protein binding affinity prediction. the proposed lupi regression-based model has shown to outperform the current state-of-the-art predictor.',\n",
       " 633: 'we construct two bases for each cluster algebra coming from a triangulated surface without punctures. we work in the context of a coefficient system coming from a full-rank exchange matrix, for example, principal coefficients.',\n",
       " 634: 'we review progress that has been made in utilizing one form of direct statistical simulation (dss) to describe geophysical and astrophysical flows that are anisotropic and inhomogeneous. we first explain the approach, which is based upon a systematic and conservative expansion of the equations of motion for low-order equal-time cumulants. we place the method into context with other statistical procedures. truncation at second order in the hierarchy of cumulants is equivalent to retaining the interaction between zonal mean flows and eddies. eddy-eddy interactions appear at higher orders, but care must be taken to keep the higher-order expansions realizable with non-negative probability distribution functions. the strengths and weaknesses of different levels of approximation are assessed with numerical experiments on the fiducial problem of a stochastically forced jet on a spherical surface. the results give an insight into the mechanisms that may control jet spacing and strength, and indicate interesting avenues for future research.',\n",
       " 635: 'in order to handle extremely-high stored energy in future proton-proton colliders, an extremely high-efficiency collimation system is required for safe operation. at lhc, the major limiting locations in terms of particle losses on superconducting (sc) magnets are the dispersion suppressors (ds) downstream of the transverse collimation insertion. these losses are due to the protons experiencing single diffractive interactions in the primary collimators. how to solve this problem is very important for future proton-proton colliders, such as the fcc-hh and sppc. in this article, a novel method is proposed, which arranges both the transverse and momentum collimation in the same long straight section. in this way, the momentum collimation system can clean those particles related to the single diffractive effect. the effectiveness of the method has been confirmed by multi-particle simulations. in addition, sc quadrupoles with special designs such as enlarged aperture and good shielding are adopted to enhance the phase advance in the transverse collimation section, so that tertiary collimators can be arranged to clean off the tertiary halo which emerges from the secondary collimators and improve the collimation efficiency. with one more collimation stage in the transverse collimation, the beam losses in both the momentum collimation section and the experimental regions can be largely reduced. multi-particle simulation results with the merlin code confirm the effectiveness of the collimation method. at last, we provide a protection scheme of the sc magnets in the collimation section. the fluka simulations show that by adding some special protective collimators in front of the magnets, the maximum power deposition in the sc coils is reduced dramatically, which is proven to be valid for protecting the sc magnets from quenching.',\n",
       " 636: 'we develop an optimal experimental design framework for adapting the covariance inflation and localization in data assimilation problems. covariance inflation and localization are ubiquitously employed to alleviate the effect of using ensembles of finite sizes in all practical data assimilation systems. the choice of both the inflation factor and the localization radius can have a significant impact on the performance of the assimilation scheme. these parameters are generally tuned by trial and error, rendering them expensive to optimize in practice. spatially and temporally varying inflation parameter and localization radii have been recently proposed and have been empirically proven to enhance the performance of the employed assimilation filter. in this study, we present a variational framework for adaptive tuning of the inflation and localization parameters. each of these parameters is optimized independently, with an objective to minimize the uncertainty in the posterior state. the proposed framework does not assume uncorrelated observations or prior errors and can in principle be applied without expert knowledge about the model and the observations. thus, it is adequate for handling dense as well as sparse observational networks. we present the mathematical formulation, algorithmic description of the approach, and numerical experiments using the two-layer lorenz-96 model.',\n",
       " 637: 'the main topic of this paper is motivated by a localization problem in cellular networks. given a graph $g$ we want to localize a walking agent by checking his distance to as few vertices as possible. the model we introduce is based on a pursuit graph game that resembles the famous cops and robbers game. it can be considered as a game theoretic variant of the \\\\emph{metric dimension} of a graph. we provide upper bounds on the related graph invariant $\\\\zeta (g)$, defined as the least number of cops needed to localize the robber on a graph $g$, for several classes of graphs (trees, bipartite graphs, etc). our main result is that, surprisingly, there exists planar graphs of treewidth $2$ and unbounded $\\\\zeta (g)$. on a positive side, we prove that $\\\\zeta (g)$ is bounded by the pathwidth of $g$. we then show that the algorithmic problem of determining $\\\\zeta (g)$ is np-hard in graphs with diameter at most $2$. finally, we show that at most one cop can approximate (arbitrary close) the location of the robber in the euclidean plane.',\n",
       " 638: \"we define new isomorphism-invariants for ergodic measure-preserving systems on standard probability spaces, called measure-theoretic chaos and measure-theoretic$^+$ chaos. these notions are analogs of the topological chaoses {\\\\rm dc2} and its slightly stronger version (which we denote by {\\\\rm dc}{\\\\small$1\\\\tfrac12$}). we prove that: 1. if a \\\\tl\\\\ system is measure-theoretically (measure-theoretically$^+$) chaotic with respect to at least one of its ergodic measures then it is \\\\tl ly {\\\\rm dc2} ({\\\\rm dc}{\\\\small$1 \\\\tfrac12$}) chaotic. 2. every ergodic system with positive kolmogorov--sinai entropy is measure-theoretically$^+$ chaotic (even in a bit stronger uniform sense). we provide an example showing that the latter statement cannot be reversed, a system of entropy zero with uniform measure-theoretic$^+$ chaos.   \\\\bigskip   \\\\centerline{\\\\bf r\\\\'esum\\\\'e}   nous introduisons de nouveaux invariants pour les syst\\\\`emes dynamiques d\\\\'efinis sur des espaces probabilis\\\\'es standards, appel\\\\'es respectivement {\\\\rm chaos mesur\\\\'e} et {\\\\rm chaos$^+$ mesur\\\\'e}. ces notions sont des analogues du chaos topologique {\\\\rm dc2} et de l'une de ses variantes, renforc\\\\'ee, que nous appelons {\\\\rm dc}{\\\\small$1 \\\\tfrac12$}. nous montrons d'une part que si un syst\\\\`eme dynamique topologique est chaotique (resp. chaotique$^+$) au sens da la mesure relativement \\\\`a\\\\ l'une de ses mesures invariantes ergodiques, alors il l'est du point de vue topologique au sens correspondant. nous montrons que tout syst\\\\`eme ergodique d'entropie m\\\\'etrique positive est chaotique$^+$ au sens de la mesure (m\\\\^eme en un sens plus fort, i.e. {\\\\rm uniform\\\\'ement}). nous donnons enfin un exemple de syst\\\\`eme dynamique topologique d'entropie nulle qui pr\\\\'esente pour l'une de ses mesures invariantes ergodiques un chaos$^+$ mesur\\\\'e uniforme.\",\n",
       " 639: 'the rapid evolution of deep neural networks is demanding deep learning (dl) frameworks not only to satisfy the requirement of quickly executing large computations, but also to support straightforward programming models for quickly implementing and experimenting with complex network structures. however, existing frameworks fail to excel in both departments simultaneously, leading to diverged efforts for optimizing performance and improving usability.   this paper presents janus, a system that combines the advantages from both sides by transparently converting an imperative dl program written in python, the de-facto scripting language for dl, into an efficiently executable symbolic dataflow graph. janus can convert various dynamic features of python, including dynamic control flow, dynamic types, and impure functions, into elements of a symbolic dataflow graph. experiments demonstrate that janus can achieve fast dl training by exploiting the techniques imposed by symbolic graph-based dl frameworks, while maintaining the simple and flexible programmability of imperative dl frameworks at the same time.',\n",
       " 640: \"this article aims to improve the performance of networked multi-agent systems, which are common representations of cyber-physical systems. the rate of convergence to consensus of multi-agent networks is critical to ensure cohesive, rapid response to external stimuli. the challenge is that increasing the rate of convergence can require changes in the network connectivity, which might not be always feasible. note that current consensus-seeking control laws can be considered as a gradient-based search over the graph's laplacian potential. the main contribution of this article is to improve the convergence to consensus, by using an accelerated gradient-based search approach. additionally, this work shows that the accelerated-consensus approach can be implemented in a distributed manner, where each agent applies a delayed self reinforcement, without the need for additional network information or changes to the network connectivity. simulation results of an example networked system are presented in this work to show that the proposed accelerated-consensus approach with dsr can substantially improve synchronization during the transition by about ten times, in addition to decreasing the transition time by about half, when compared to the case without the dsr approach. this is shown to improve formation control during transitions in networked multi-agent systems.\",\n",
       " 641: 'deep neural networks can learn complex and abstract representations, that are progressively obtained by combining simpler ones. a recent trend in speech and speaker recognition consists in discovering these representations starting from raw audio samples directly. differently from standard hand-crafted features such as mfccs or fbank, the raw waveform can potentially help neural networks discover better and more customized representations. the high-dimensional raw inputs, however, can make training significantly more challenging. this paper summarizes our recent efforts to develop a neural architecture that efficiently processes speech from audio waveforms. in particular, we propose sincnet, a novel convolutional neural network (cnn) that encourages the first layer to discover meaningful filters by exploiting parametrized sinc functions. in contrast to standard cnns, which learn all the elements of each filter, only low and high cutoff frequencies of band-pass filters are directly learned from data. this inductive bias offers a very compact way to derive a customized front-end, that only depends on some parameters with a clear physical meaning. our experiments, conducted on both speaker and speech recognition, show that the proposed architecture converges faster, performs better, and is more computationally efficient than standard cnns.',\n",
       " 642: 'we introduce and study birational invariants for foliations on projective surfaces built from the adjoint linear series of positive powers of the canonical bundle of the foliation. we apply the results in order to investigate the effective algebraic integration of foliations on the projective plane. in particular, we describe the zariski closure of the set of foliations on the projective plane of degree d admitting rational first integrals with fibers having geometric genus bounded by g.',\n",
       " 643: 'it is known that the pak-stanley labeling of the shi hyperplane arrangement provides a bijection between the regions of the arrangement and parking functions. for any graph g, we define the g-semiorder arrangement and show that the pak-stanley labeling of its regions produces all g-parking functions.',\n",
       " 644: 'we measured the impact of long-range exponentially decaying intra-areal lateral connectivity on the scaling and memory occupation of a distributed spiking neural network simulator compared to that of short-range gaussian decays. while previous studies adopted short-range connectivity, recent experimental neurosciences studies are pointing out the role of longer-range intra-areal connectivity with implications on neural simulation platforms. two-dimensional grids of cortical columns composed by up to 11 m point-like spiking neurons with spike frequency adaption were connected by up to 30 g synapses using short- and long-range connectivity models. the mpi processes composing the distributed simulator were run on up to 1024 hardware cores, hosted on a 64 nodes server platform. the hardware platform was a cluster of ibm nx360 m5 16-core compute nodes, each one containing two intel xeon haswell 8-core e5-2630 v3 processors, with a clock of 2.40 g hz, interconnected through an infiniband network, equipped with 4x qdr switches.',\n",
       " 645: 'the amount of available videos in the web has significantly increased not only for entertainment etc., but also to convey educational or scientific information in an effective way. there are several web portals that offer access to the latter kind of video material. one of them is the tib av-portal of the leibniz information centre for science and technology (tib), which hosts scientific and educational video content. in contrast to other video portals, automatic audiovisual analysis (visual concept classification, optical character recognition, speech recognition) is utilized to enhance metadata information and semantic search. in this paper, we propose to further exploit and enrich this automatically generated information by linking it to the integrated authority file (gnd) of the german national library. this information is used to derive a measure to compare the similarity of two videos which serves as a basis for recommending semantically similar videos. a user study demonstrates the feasibility of the proposed approach.',\n",
       " 646: 'we study a classical realizability model (in the sense of j.-l. krivine) arising from a model of untyped lambda calculus in coherence spaces. we show that this model validates countable choice using bar recursion and bar induction.',\n",
       " 647: 'motivated by recent prototypes of engineered atomic spin devices, we study a fully connected system of $n$ spins $1/2$, modeled by the lipkin-meshkov-glick (lmg) model of a collective spin $s=n/2$ in the presence of markovian dissipation processes. we determine and classify the different phases of the dissipative lmg model with markovian dissipation, including the properties of the steady-state and the dynamic behavior in the asymptotic long-time regime. employing variational methods and a systematic approach based on the holstein-primakoff mapping, we determine the phase diagram and the spectral and steady-state properties of the liouvillian by studying both the infinite-$s$ limit and $1/s$ corrections. our approach reveals the existence of different kinds of dynamical phases and phase transitions, multi-stability and regions where the dynamics is recurrent. we provide a classification of critical and non-critical liouvillians according to their spectral and steady-state properties.',\n",
       " 648: 'the aim of this paper is to encourage science educators and outreach groups to look appropriately at the sun and consider it as an extraordinary pedagogical tool to teach science at all education stages, what we call here as the solar educational spectrum, i.e., from k-12 to higher education, to develop informal educational projects that may lead to reach more complex material and to enlarge the experience at each stage. we review the main aspects of the sun as an appetizer of the endless source of ideas to perform informal educational projects outside of a structured curriculum. we end up our discussion by sharing our experience across the educational spectrum in colombia and how we used it as a development instrument.',\n",
       " 649: 'let $\\\\mathbf{tb}$ be the category of totally bounded, locally compact metric spaces with the $c_0$ coarse structures. we show that if $x$ and $y$ are in $\\\\mathbf{tb}$ then $x$ and $y$ are coarsely equivalent if and only if their higson coronas are homeomorphic. in fact, the higson corona functor gives an equivalence of categories $\\\\mathbf{tb}\\\\to\\\\mathbf{k}$, where $\\\\mathbf{k}$ is the category of compact metrizable spaces. we use this fact to show that the continuously controlled coarse structure on a locally compact space $x$ induced by some metrizable compactification $\\\\tilde{x}$ is determined only by the topology of the remainder $\\\\tilde{x}\\\\setminus x$.',\n",
       " 650: 'on-chip optoelectronic and all-optical information processing paradigms require compact implementation of signal transfer for which nanoscale surface plasmons circuitry offers relevant solutions. this work demonstrates the directional signal transmittance mediated by 2d plasmonic eigenmodes supported by crystalline cavities. channel devices comprising two mesoscopic triangular input and output ports and sustaining delocalized, higher-order plasmon resonances in the visible to infra-red range are shown to enable the controllable transmittance between two confined entry and exit ports coupled over a distance exceeding 2 $\\\\mu$m. the transmittance is attenuated by > 20db upon rotating the incident linear polarization, thus offering a convenient switching mechanism. the optimal transmittance for a given operating wavelength depends on the geometrical design of the device that sets the spatial and spectral characteristic of the supporting delocalized mode. our approach is highly versatile and opens the way to more complex information processing using pure plasmonic or hybrid nanophotonic architectures.',\n",
       " 651: 'in contrast to the many examples of convex divisible domains in real projective space, we prove that up to projective isomorphism there is only one convex divisible domain in the grassmannian of $p$-planes in $\\\\mathbb{r}^{2p}$ when $p > 1$. moreover, this convex divisible domain is a model of the symmetric space associated to the simple lie group so$(p, p)$.',\n",
       " 652: \"in the present work we explore a pre-stretched oscillator chain where the nodes interact via a pairwise lennard-jones potential. in addition to a homogeneous solution, we identify solutions with one or more (so-called) `breaks', i.e., jumps. as a function of the canonical parameter of the system, namely the precompression strain $d$, we find that the most fundamental one break solution changes stability when the monotonicity of the hamiltonian changes with $d$. we provide a proof for this (motivated by numerical computations) observation. this critical point separates stable and unstable segments of the one break branch of solutions. we find similar branches for 2 through 5 break branches of solutions. each of these higher `excited state' solutions possesses an additional unstable pair of eigenvalues. we thus conjecture that $k$ break solutions will possess at least $k-1$ (and at most $k$) pairs of unstable eigenvalues. our stability analysis is corroborated by direct numerical computations of the evolutionary dynamics.\",\n",
       " 653: 'detection schemes for the quantum chromodynamics axions and other axion-like particles in light-shining-through-a-wall (lsw) experiments are based on the conversion of these particles into photons in a magnetic field. an alternative scheme may involve the detection via a resonant atomic or molecular transition induced by resonant axion absorption. the signal obtained in this process is second order in the axion-electron interaction constant but may become first order if we allow interference between the axion-induced transition amplitude and the transition amplitude induced by the electromagnetic radiation that produces the axions.',\n",
       " 654: 'structured pruning is a popular method for compressing a neural network: given a large trained network, one alternates between removing channel connections and fine-tuning; reducing the overall width of the network. however, the efficacy of structured pruning has largely evaded scrutiny. in this paper, we examine resnets and densenets obtained through structured pruning-and-tuning and make two interesting observations: (i) reduced networks---smaller versions of the original network trained from scratch---consistently outperform pruned networks; (ii) if one takes the architecture of a pruned network and then trains it from scratch it is significantly more competitive. furthermore, these architectures are easy to approximate: we can prune once and obtain a family of new, scalable network architectures that can simply be trained from scratch. finally, we compare the inference speed of reduced and pruned networks on hardware, and show that reduced networks are significantly faster. code is available at https://github.com/bayeswatch/pytorch-prunes.',\n",
       " 655: 'a nice differential-geometric framework for (non-abelian) higher gauge theory is provided by principal 2-bundles, i.e. categorified principal bundles. their total spaces are lie groupoids, local trivializations are kinds of morita equivalences, and connections are lie-2-algebra-valued 1-forms. in this article, we construct explicitly the parallel transport of a connection on a principal 2-bundle. parallel transport along a path is a morita equivalence between the fibres over the end points, and parallel transport along a surface is an intertwiner between morita equivalences. we prove that our constructions fit into the general axiomatic framework for categorified parallel transport and surface holonomy.',\n",
       " 656: 'visual exploration of large multidimensional datasets has seen tremendous progress in recent years, allowing users to express rich data queries that produce informative visual summaries, all in real time. techniques based on data cubes are some of the most promising approaches. however, these techniques usually require a large memory footprint for large datasets. to tackle this problem, we present neuralcubes: neural networks that predict results for aggregate queries, similar to data cubes. neuralcubes learns a function that takes as input a given query, for instance, a geographic region and temporal interval, and outputs the result of the query. the learned function serves as a real-time, low-memory approximator for aggregation queries. neuralcubes models are small enough to be sent to the client side (e.g. the web browser for a web-based application) for evaluation, enabling data exploration of large datasets without database/network connection. we demonstrate the effectiveness of neuralcubes through extensive experiments on a variety of datasets and discuss how neuralcubes opens up opportunities for new types of visualization and interaction.',\n",
       " 657: 'let $(r, \\\\mathfrak{m}, k)$ denote a local cohen-macaulay ring such that the category of maximal cohen-macaulay $r$-modules $\\\\textbf{mcm}\\\\ r$ contains an $n$-cluster tilting object $l$. in this paper, we compute $g_1(r) := k_1(\\\\textbf{mod}\\\\ r)$ explicitly as a direct sum of a free group and a specified quotient of $\\\\text{aut}_r(l)_{\\\\text{ab}}$ when $r$ is a $k$-algebra and $k$ is algebraically closed (and $\\\\text{char}(k)\\\\neq 2$). moreover, we give some explicit computations of $\\\\text{aut}_r(l)_{\\\\text{ab}}$ and $g_1(r)$ for certain hypersurface singularities.',\n",
       " 658: 'multiple imputation (mi) inference handles missing data by first properly imputing the missing values $m$ times, and then combining the $m$ analysis results from applying a complete-data procedure to each of the completed datasets. however, the existing method for combining likelihood ratio tests has multiple defects: (i) the combined test statistic can be negative in practice when the reference null distribution is a standard $f$ distribution; (ii) it is not invariant to re-parametrization; (iii) it fails to ensure monotonic power due to its use of an inconsistent estimator of the fraction of missing information (fmi) under the alternative hypothesis; and (iv) it requires non-trivial access to the likelihood ratio test statistic as a function of estimated parameters instead of datasets. this paper shows, via both theoretical derivations and empirical investigations, that essentially all of these problems can be straightforwardly addressed if we are willing to perform an additional likelihood ratio test by stacking the $m$ completed datasets as one big completed dataset. a particularly intriguing finding is that the fmi itself can be estimated consistently by a likelihood ratio statistic for testing whether the $m$ completed datasets produced by mi can be regarded effectively as samples coming from a common model. practical guidelines are provided based on an extensive comparison of existing mi tests.',\n",
       " 659: 'we report curling self-propulsion in aqueous emulsions of common mesogenic compounds. nematic liquid crystal droplets self-propel in a surfactant solution with concentrations above the critical micelle concentration while undergoing micellar solubilization. we analyzed trajectories both in a hele-shaw geometry and in a 3d setup at variable buoyancy. the coupling between the nematic director field and the convective flow inside the droplet leads to a second symmetry breaking which gives rise to curling motion in 2d. this is demonstrated through a reversible transition to non-helical persistent swimming by heating to the isotropic phase. furthermore, auto-chemotaxis can spontaneously break the inversion symmetry, leading to helical trajectories.',\n",
       " 660: 'the $q,t$-catalan numbers can be defined using rational functions, geometry related to hilbert schemes, symmetric functions, representation theory, dyck paths, partition statistics, or dyck words. after decades of intensive study, it was eventually proved that all these definitions are equivalent. in this paper, we study the similar situation for higher $q,t$-catalan numbers, where the equivalence of the algebraic and combinatorial definitions is still conjectural. we compute the limits of several versions of the modified higher $q,t$-catalan numbers and show that these limits equal the generating function for integer partitions. we also identify certain coefficients of the higher $q,t$-catalan numbers as enumerating suitable integer partitions, and we make some conjectures on the homological significance of the bergeron-garsia nabla operator.',\n",
       " 661: 'generative adversarial networks (gans) have achieved remarkable results in the task of generating realistic natural images. in most successful applications, gan models share two common aspects: solving a challenging saddle point optimization problem, interpreted as an adversarial game between a generator and a discriminator functions; and parameterizing the generator and the discriminator as deep convolutional neural networks. the goal of this paper is to disentangle the contribution of these two factors to the success of gans. in particular, we introduce generative latent optimization (glo), a framework to train deep convolutional generators using simple reconstruction losses. throughout a variety of experiments, we show that glo enjoys many of the desirable properties of gans: synthesizing visually-appealing samples, interpolating meaningfully between samples, and performing linear arithmetic with noise vectors; all of this without the adversarial optimization scheme.',\n",
       " 662: 'mask-based pattern generation is a crucial step in microchip production. the next-generation extreme-ultraviolet- (euv) lithography instruments with a wavelength of \\\\si{13.5}{\\\\nano\\\\meter} is currently under development. in principle, this should allow patterning down to a resolution of a few nanometers in a single exposure. however, there are many technical challenges, including those due to the very high energy of the photons. lithography with metastable atoms has been suggested as a cost-effective, less-complex alternative to euv lithography. the great advantage of atom lithography is that the kinetic energy of an atom is much smaller than that of a photon for a given wavelength. however, up till now no method has been available for making masks for atom lithography that can produce arbitrary, high resolution patterns. here we present a solution to this problem. first, traditional binary holography is extended to near-field binary holography, based on fresnel diffraction. by this technique, we demonstrate that it is possible to make masks that can generate arbitrary patterns in a plane in the near field (from the mask) with a resolution down to the nanometer range using a state of the art metastable helium source. we compare the flux of this source to that of an established euv source (asml, nxe:3100) and show that patterns can potentially be produced at comparable speeds. finally, we present an extension of the grid-based holography method for a grid of hexagonally shaped subcells. our method can be used with any beam that can be modeled as a scalar wave, including other matter-wave beams such as helium ions, electrons or acoustic waves.',\n",
       " 663: 'we propose a new algorithmic framework, called \"partial rejection sampling\", to draw samples exactly from a product distribution, conditioned on none of a number of bad events occurring. our framework builds (perhaps surprising) new connections between the variable framework of the lov\\\\\\'asz local lemma and some classical sampling algorithms such as the \"cycle-popping\" algorithm for rooted spanning trees. among other applications, we discover new algorithms to sample satisfying assignments of k-cnf formulas with bounded variable occurrences.',\n",
       " 664: 'this paper outlines a methodology for semi-parametric spatio-temporal modelling of data which is dense in time but sparse in space, obtained from a split panel design, the most feasible approach to covering space and time with limited equipment. the data are hourly averaged particle number concentration (pnc) and were collected, as part of the ultrafine particles from transport emissions and child health (uptech) project. two weeks of continuous measurements were taken at each of a number of government primary schools in the brisbane metropolitan area. the monitoring equipment was taken to each school sequentially. the school data are augmented by data from long term monitoring stations at three locations in brisbane, australia.   fitting the model helps describe the spatial and temporal variability at a subset of the uptech schools and the long-term monitoring sites. the temporal variation is modelled hierarchically with penalised random walk terms, one common to all sites and a term accounting for the remaining temporal trend at each site. parameter estimates and their uncertainty are computed in a computationally efficient approximate bayesian inference environment, r-inla.   the temporal part of the model explains daily and weekly cycles in pnc at the schools, which can be used to estimate the exposure of school children to ultrafine particles (ufps) emitted by vehicles. at each school and long-term monitoring site, peaks in pnc can be attributed to the morning and afternoon rush hour traffic and new particle formation events. the spatial component of the model describes the school to school variation in mean pnc at each school and within each school ground. it is shown how the spatial model can be expanded to identify spatial patterns at the city scale with the inclusion of more spatial locations.',\n",
       " 665: 'we discuss the pricing and hedging of volatility options in some rough volatility models. first, we develop efficient monte carlo methods and asymptotic approximations for computing option prices and hedge ratios in models where log-volatility follows a gaussian volterra process. while providing a good fit for european options, these models are unable to reproduce the vix option smile observed in the market, and are thus not suitable for vix products. to accommodate these, we introduce the class of modulated volterra processes, and show that they successfully capture the vix smile.',\n",
       " 666: 'in this paper, we introduce the variational autoencoder (vae) to an end-to-end speech synthesis model, to learn the latent representation of speaking styles in an unsupervised manner. the style representation learned through vae shows good properties such as disentangling, scaling, and combination, which makes it easy for style control. style transfer can be achieved in this framework by first inferring style representation through the recognition network of vae, then feeding it into tts network to guide the style in synthesizing speech. to avoid kullback-leibler (kl) divergence collapse in training, several techniques are adopted. finally, the proposed model shows good performance of style control and outperforms global style token (gst) model in abx preference tests on style transfer.',\n",
       " 667: 'we derive a backward and forward nonlinear pdes that govern the implied volatility of a contingent claim whenever the latter is well-defined. this would include at least any contingent claim written on a positive stock price whose payoff at a possibly random time is convex. we also discuss suitable initial and boundary conditions for those pdes. finally, we demonstrate how to solve them numerically by using an iterative finite-difference approach.',\n",
       " 668: 'we study the maximum likelihood model in emission tomography and propose a new family of algorithms for its solution, called string-averaging expectation-maximization (saem). in the string-averaging algorithmic regime, the index set of all underlying equations is split into subsets, called \"strings,\" and the algorithm separately proceeds along each string, possibly in parallel. then, the end-points of all strings are averaged to form the next iterate. saem algorithms with several strings presents better practical merits than the classical row-action maximum-likelihood algorithm (ramla). we present numerical experiments showing the effectiveness of the algorithmic scheme in realistic situations. performance is evaluated from the computational cost and reconstruction quality viewpoints. a complete convergence theory is also provided.',\n",
       " 669: \"synchronization, the temporal coordination of coupled oscillators, allows fireflies to flash in unison, neurons to fire collectively and human crowds to fall in step on the london millenium bridge. here, we interpret active (or self-propelled) chiral microswimmers with a distribution of intrinsic frequencies as motile oscillators and show that they can synchronize over very large distances, even for local coupling in 2d. this opposes to canonical non-active oscillators on static or time-dependent networks, leading to synchronized domains only. a consequence of this activity-induced synchronization is the emergence of a `mutual flocking phase', where particles of opposite chirality cooperate to form superimposed flocks moving at a relative angle to each other, providing a chiral active matter analogue to the celebrated toner-tu phase. the underlying mechanism employs a positive feedback loop involving the two-way coupling between oscillators' phase and self-propulsion, and could be exploited as a design principle for synthetic active materials and chiral self-sorting techniques\",\n",
       " 670: \"the impulsive generation of two-magnon modes in antiferromagnets by femtosecond optical pulses, so-called femto-nanomagnons, leads to coherent longitudinal oscillations of the antiferromagnetic order parameter that cannot be described by a thermodynamic landau-lifshitz approach. we argue that this dynamics is triggered as a result of a laser-induced modification of the exchange interaction. in order to describe the oscillations we have formulated a quantum mechanical description in terms of magnon pair operators and coherent states. such an approach allowed us to} derive an effective macroscopic equation of motion for the temporal evolution of the antiferromagnetic order parameter. an implication of the latter is that the photo-induced spin dynamics represents a macroscopic entanglement of pairs of magnons with femtosecond period and nanometer wavelength. by performing magneto-optical pump-probe experiments with 10 femtosecond resolution in the cubic knif$_3$ and the uniaxial k$_2$nif$_4$ collinear heisenberg antiferromagnets, we observed coherent oscillations at the frequency of 22 thz and 16 thz, respectively. the detected frequencies as a function of the temperature ideally fit the two-magnon excitation up to the n\\\\'eel point. the experimental signals are described as dynamics of magnetic linear dichroism due to longitudinal oscillations of the antiferromagnetic vector.\",\n",
       " 671: \"predictive modelling and supervised learning are central to modern data science. with predictions from an ever-expanding number of supervised black-box strategies - e.g., kernel methods, random forests, deep learning aka neural networks - being employed as a basis for decision making processes, it is crucial to understand the statistical uncertainty associated with these predictions.   as a general means to approach the issue, we present an overarching framework for black-box prediction strategies that not only predict the target but also their own predictions' uncertainty. moreover, the framework allows for fair assessment and comparison of disparate prediction strategies. for this, we formally consider strategies capable of predicting full distributions from feature variables, so-called probabilistic supervised learning strategies.   our work draws from prior work including bayesian statistics, information theory, and modern supervised machine learning, and in a novel synthesis leads to (a) new theoretical insights such as a probabilistic bias-variance decomposition and an entropic formulation of prediction, as well as to (b) new algorithms and meta-algorithms, such as composite prediction strategies, probabilistic boosting and bagging, and a probabilistic predictive independence test.   our black-box formulation also leads (c) to a new modular interface view on probabilistic supervised learning and a modelling workflow api design, which we have implemented in the newly released skpro machine learning toolbox, extending the familiar modelling interface and meta-modelling functionality of sklearn. the skpro package provides interfaces for construction, composition, and tuning of probabilistic supervised learning strategies, together with orchestration features for validation and comparison of any such strategy - be it frequentist, bayesian, or other.\",\n",
       " 672: 'this work is at the interface of graph theory and quantum mechanics. quantum correlations epitomize the usefulness of quantum mechanics. quantum discord is an interesting facet of bipartite quantum correlations. earlier, it was shown that every combinatorial graph corresponds to quantum states whose characteristics are reflected in the structure of the underlined graph. a number of combinatorial relations between quantum discord and simple graphs were studied. to extend the scope of these studies, we need to generalize the earlier concepts applicable to simple graphs to weighted graphs, corresponding to a diverse class of quantum states. to this effect, we determine the class of quantum states whose density matrix representation can be derived from graph laplacian matrices associated with a weighted directed graph and call them graph laplacian quantum states. we find the graph-theoretic conditions for zero and non-zero quantum discord for these states. we apply these results on some important pure two qubit states, as well as a number of mixed quantum states, such as the werner, isotropic, and $x$-states. we also consider graph laplacian states corresponding to simple graphs as a special case.',\n",
       " 673: 'the purpose of this paper is to introduce liouville hypersurfaces in contact manifolds, which generalize ribbons of legendrian graphs and pages of supporting open books. liouville hypersurfaces are used to define a gluing operation for contact manifolds called the liouville connect sum. performing this operation on a contact manifold $\\\\mxi$ gives an exact -- and in many cases, stein - cobordism from $\\\\mxi$ to the surgered manifold. these cobordisms are used to establish the existence of \"fillability\" and \"non-vanishing contact homology\" monoids in symplectomorphism groups of liouville domains, study the symplectic fillability of a family of contact manifolds which fiber over the circle, associate cobordisms to certain branched coverings of contact manifolds, and construct exact symplectic cobordisms that do not admit stein structures. the liouville connect sum generalizes the weinstein handle attachment and is used to extend the definition of contact $(1/k)$-surgery along legendrian knots in contact 3-manifolds to contact $(1/k)$-surgery along legendrian spheres in contact manifolds of arbitrary dimension. this is used to construct exotic contact structures on 5- and 13-dimensional spheres after establishing that $s^{2}$ and $s^{6}$ are the only spheres along which generalized dehn twists smoothly square to the identity mapping. the exoticity of these contact structures implies that dehn twists along $s^{2}$ and $s^{6}$ do not symplectically square to the identity.',\n",
       " 674: 'we study the holographic hydrodynamics in the einstein-gauss-bonnet(egb) gravity in the framework of the large $d$ expansion. we find that the large $d$ egb equations can be interpreted as the hydrodynamic equations describing the conformal fluid. these fluid equations are truncated at the second order of the derivative expansion, similar to the einstein gravity at large $d$. from the analysis of the fluid flows, we find that the fluid equations can be taken as a variant of the compressible version of the non-relativistic navier-stokes equations. particularly, in the limit of small mach number, these equations could be cast into the form of the incompressible navier-stokes equations with redefined reynolds number and mach number. by using numerical simulation, we find that the egb holographic turbulence shares similar qualitative feature as the turbulence from the einstein gravity, despite the presence of two extra terms in the equations of motion. we analyze the effect of the gb term on the holographic turbulence in detail.',\n",
       " 675: 'we address the curse of dimensionality in dynamic covariance estimation by modeling the underlying co-volatility dynamics of a time series vector through latent time-varying stochastic factors. the use of a global-local shrinkage prior for the elements of the factor loadings matrix pulls loadings on superfluous factors towards zero. to demonstrate the merits of the proposed framework, the model is applied to simulated data as well as to daily log-returns of 300 s&p 500 members. our approach yields precise correlation estimates, strong implied minimum variance portfolio performance and superior forecasting accuracy in terms of log predictive scores when compared to typical benchmarks.',\n",
       " 676: \"we tackle the change-point problem with data belonging to a general set. we build a penalty for choosing the number of change-points in the kernel-based method of harchaoui and capp{\\\\'e} (2007). this penalty generalizes the one proposed by lebarbier (2005) for one-dimensional signals. we prove a non-asymptotic oracle inequality for the proposed method, thanks to a new concentration result for some function of hilbert-space valued random variables. experiments on synthetic data illustrate the accuracy of our method, showing that it can detect changes in the whole distribution of data, even when the mean and variance are constant.\",\n",
       " 677: 'we propose a greedy and supervised learning approach for visibility-based exploration, reconstruction and surveillance. using a level set representation, we train a convolutional neural network to determine vantage points that maximize visibility. we show that this method drastically reduces the on-line computational cost and determines a small set of vantage points that solve the problem. this enables us to efficiently produce highly-resolved and topologically accurate maps of complex 3d environments. unlike traditional next-best-view and frontier-based strategies, the proposed method accounts for geometric priors while evaluating potential vantage points. while existing deep learning approaches focus on obstacle avoidance and local navigation, our method aims at finding near-optimal solutions to the more global exploration problem. we present realistic simulations on 2d and 3d urban environments.',\n",
       " 678: 'this tutorial teaches parts of the finite element method (fem), and solves a stochastic partial differential equation (spde). the contents herein are considered \"known\" in the numerics literature, but for statisticians it is very difficult to find a resource for learning these ideas in a timely manner (without doing a year\\'s worth of courses in numerics). the goal of this tutorial is to be pedagogical and explain the computations/theory to a statistician. this is not a practical tutorial, there is little computer code, and no data analysis.',\n",
       " 679: 'many real-world vision problems suffer from inherent ambiguities. in clinical applications for example, it might not be clear from a ct scan alone which particular region is cancer tissue. therefore a group of graders typically produces a set of diverse but plausible segmentations. we consider the task of learning a distribution over segmentations given an input. to this end we propose a generative segmentation model based on a combination of a u-net with a conditional variational autoencoder that is capable of efficiently producing an unlimited number of plausible hypotheses. we show on a lung abnormalities segmentation task and on a cityscapes segmentation task that our model reproduces the possible segmentation variants as well as the frequencies with which they occur, doing so significantly better than published approaches. these models could have a high impact in real-world applications, such as being used as clinical decision-making algorithms accounting for multiple plausible semantic segmentation hypotheses to provide possible diagnoses and recommend further actions to resolve the present ambiguities.',\n",
       " 680: \"we consider the issue of a market maker acting at the same time in the lit and dark pools of an exchange. the exchange wishes to establish a suitable make-take fees policy to attract transactions on its venues. we first solve the stochastic control problem of the market maker without the intervention of the exchange. then we derive the equations defining the optimal contract to be set between the market maker and the exchange. this contract depends on the trading flows generated by the market maker's activity on the two venues. in both cases, we show existence and uniqueness, in the viscosity sense, of the solutions of the hamilton-jacobi-bellman equations associated to the market maker and exchange's problems. we finally design deep reinforcement learning algorithms enabling us to approximate efficiently the optimal controls of the market maker and the optimal incentives to be provided by the exchange.\",\n",
       " 681: \"the batalin-vilkovisky formalism in quantum field theory was originally invented to address the difficult problem of finding diagrammatic descriptions of oscillating integrals with degenerate critical points. but since then, bv algebras have become interesting objects of study in their own right, and mathematicians sometimes have good understanding of the homological aspects of the story without any access to the diagrammatics. in this note we reverse the usual direction of argument: we begin by asking for an explicit calculation of the homology of a bv algebra, and from it derive wick's theorem and the other feynman rules for finite-dimensional integrals.\",\n",
       " 682: 'the on-going h.e.s.s. galactic plane survey continues to reveal new sources of vhe gamma-rays. in particular, recent re-observations of the region around the shell-type supernova remnant (snr) g318.2+0.1 have resulted in the discovery of statistically-significant very-high-energy (vhe) gamma-ray emission from an extended region. although the source remains unidentified, archival observations of co12 in the region provide an opportunity to investigate a potential snr/molecular cloud interaction. the morphological properties of this newly-discovered vhe gamma-ray source hessj1457-593 are presented and discussed in light of the multi-wavelength data available.',\n",
       " 683: 'generative adversarial networks (gans) have been promising for many computer vision problems due to their powerful capabilities to enhance the data for training and test. in this paper, we leveraged gans and proposed a new architecture with a cascaded single shot detector (ssd) for pedestrian detection at distance, which is yet a challenge due to the varied sizes of pedestrians in videos at distance. to overcome the low-resolution issues in pedestrian detection at distance, dcgan is employed to improve the resolution first to reconstruct more discriminative features for a ssd to detect objects in images or videos. a crucial advantage of our method is that it learns a multi-scale metric to distinguish multiple objects at different distances under one image, while dcgan serves as an encoder-decoder platform to generate parts of an image that contain better discriminative information. to measure the effectiveness of our proposed method, experiments were carried out on the canadian institute for advanced research (cifar) dataset, and it was demonstrated that the proposed new architecture achieved a much better detection rate, particularly on vehicles and pedestrians at distance, making it highly suitable for smart cities applications that need to discover key objects or pedestrians at distance.',\n",
       " 684: 'topological semimetals, extending the topological classification from insulators to metals, have greatly enriched our understanding of topological states in condensed matter. this is particularly true for topological nodal-line semimetals (tnlss). in the present paper, we identify layered materials as promising candidates for hosting tnlss. based on first-principles calculations and effective model analysis, we propose that layered ferromagnetic rare-earth-metal monohalides lnx (ln=la, gd; x=cl, br) exhibit long pursued topological phases. specifically, single-layer lax and single-layer gdx are ideal two-dimensional (2d) weyl semimetals and large-gap 2d quantum anomalous hall insulators (qahis), with band gaps up to 61 mev, respectively. in addition, 3d lax and 3d gdx are tnlss with a pair of mirror-symmetry protected nodal lines and 3d weak qahis, respectively. the nodal lines in 3d lax extending through the whole brillouin zone (bz) are fairly robust against strong spin-orbit coupling (soc) and located close to the fermi level, providing a novel platform toward exploring the exotic properties in nodal-line fermions as well as related device designs.',\n",
       " 685: 'in this paper, we define the geometric median of a probability measure on a riemannian manifold, give its characterization and a natural condition to ensure its uniqueness. in order to calculate the median in practical cases, we also propose a subgradient algorithm and prove its convergence as well as estimating the error of approximation and the rate of convergence. the convergence property of this subgradient algorithm, which is a generalization of the classical weiszfeld algorithm in euclidean spaces to the context of riemannian manifolds, also answers a recent question in p. t. fletcher et al. [13]',\n",
       " 686: 'analyzing massive complex networks yields promising insights about our everyday lives. building scalable algorithms to do so is a challenging task that requires a careful analysis and an extensive evaluation. however, engineering such algorithms is often hindered by the scarcity of publicly~available~datasets.   network generators serve as a tool to alleviate this problem by providing synthetic instances with controllable parameters. however, many network generators fail to provide instances on a massive scale due to their sequential nature or resource constraints. additionally, truly scalable network generators are few and often limited in their realism.   in this work, we present novel generators for a variety of network models that are frequently used as benchmarks. by making use of pseudorandomization and divide-and-conquer schemes, our generators follow a communication-free paradigm. the resulting generators are thus embarrassingly parallel and have a near optimal scaling behavior. this allows us to generate instances of up to $2^{43}$ vertices and $2^{47}$ edges in less than 22 minutes on 32768 cores. therefore, our generators allow new graph families to be used on an unprecedented scale.',\n",
       " 687: 'let $g$ be a connected semisimple algebraic group and let $h \\\\subset g$ be a connected reductive subgroup. given a flag variety $x$ of $g$, a result of vinberg and kimelfeld asserts that $h$ acts spherically on $x$ if and only if for every irreducible representation $r$ of $g$ realized in the space of sections of a homogeneous line bundle on $x$ the restriction of $r$ to $h$ is multiplicity free. in this case, the information on restrictions to $h$ of all such irreducible representations of $g$ is encoded in a monoid, which we call the restricted branching monoid. in this paper, we review the cases of spherical actions on flag varieties of simple groups for which the restricted branching monoids are known (this includes the case where $h$ is a levi subgroup of $g$) and compute the restricted branching monoids for all spherical actions on flag varieties that correspond to triples $(g,h,x)$ satisfying one of the following two conditions: (1) $g$ is simple and $h$ is a symmetric subgroup of $g$; (2) $g = \\\\mathrm{sl}_n$.',\n",
       " 688: \"this document describes the minimum interface that a (soap- or rest-based) web service requires to participate in the ivoa. note that this is not required of standard vo services developed prior to this specification, although uptake is strongly encouraged on any subsequent revision. all new standard vo services, however, must feature a vosi-compliant interface.   this document has been produced by the grid and web services working group. it has been reviewed by ivoa members and other interested parties, and has been endorsed by the ivoa executive committee as an ivoa recommendation. it is a stable document and may be used as reference material or cited as a normative reference from another document. ivoa's role in making the recommendation is to draw attention to the specification and to promote its widespread deployment. this enhances the functionality and interoperability inside the astronomical community.\",\n",
       " 689: 'the existence of a quantum butterfly effect in the form of exponential sensitivity to small perturbations has been under debate for a long time. lately, this question gained increased interest due to the proposal to probe chaotic dynamics and scrambling using out-of-time-order correlators. in this work we study echo dynamics in the sachdev-ye-kitaev model under effective time reversal in a semiclassical approach. we demonstrate that small imperfections introduced in the time-reversal procedure result in an exponential divergence from the perfect echo, which allows to identify a lyapunov exponent $\\\\lambda_l$. in particular, we find that $\\\\lambda_l$ is twice the lyapunov exponent of the semiclassical equations of motion. this behavior is attributed to the growth of an out-of-time-order double commutator that resembles an out-of-time-order correlator.',\n",
       " 690: 'most blind deconvolution methods usually pre-define a large kernel size to guarantee the support domain. blur kernel estimation error is likely to be introduced, yielding severe artifacts in deblurring results. in this paper, we first theoretically and experimentally analyze the mechanism to estimation error in oversized kernel, and show that it holds even on blurry images without noises. then to suppress this adverse effect, we propose a low rank-based regularization on blur kernel to exploit the structural information in degraded kernels, by which larger-kernel effect can be effectively suppressed. and we propose an efficient optimization algorithm to solve it. experimental results on benchmark datasets show that the proposed method is comparable with the state-of-the-arts by accordingly setting proper kernel size, and performs much better in handling larger-size kernels quantitatively and qualitatively. the deblurring results on real-world blurry images further validate the effectiveness of the proposed method.',\n",
       " 691: 'we extend the group theoretic construction of local models of pappas and zhu to the case of groups obtained by weil restriction along a possibly wildly ramified extension. this completes the construction of local models for all reductive groups when $p \\\\geq 5$. we show that the local models are normal with special fiber reduced and study the monodromy action on the sheaves of nearby cycles. as a consequence, we prove a conjecture of kottwitz that the semi-simple trace of frobenius gives a central function in the parahoric hecke algebra. we also introduce a notion of splitting model and use this to study the inertial action in the case of an unramified group.',\n",
       " 692: 'the alice (a large ion collider experiment) detector yields a huge sample of data from different sub-detectors. on-line data processing is applied to select and reduce the volume of the stored data. alice applies a multi-level hardware trigger scheme where fast detectors are used to feed a three-level (l0, l1, and l2) deep chain. the high-level trigger (hlt) is a fourth filtering stage sitting logically between the l2 trigger and the data acquisition event building. the emcal detector comprises a large area electromagnetic calorimeter that extends the momentum measurement of photons and neutral mesons up to $p_t=250$ gev/c, which improves the alice capability to perform jet reconstruction with measurement of the neutral energy component of jets. an online reconstruction and trigger chain has been developed within the hlt framework to sharpen the emcal hardware triggers, by combining the central barrel tracking information with the shower reconstruction (clusters) in the calorimeter. in the present report the status and the functionality of the software components developed for the emcal hlt online reconstruction and trigger chain will be discussed, as well as preliminary results from their commissioning performed during the 2011 lhc running period.',\n",
       " 693: 'as the human, we can recognize the places across a wide range of changing environmental conditions such as those caused by weathers, seasons, and day-night cycles. we excavate and memorize the stable semantic structure of different places and scenes. for example, we can recognize tree whether the bare tree in winter or lush tree in summer. therefore, the intrinsic features that are corresponding to specific semantic contents and condition-invariant of appearance changes can be employed to improve the performance of long-term place recognition significantly.   in this paper, we propose a novel intrinsic encoder that excavates the condition-invariant latent space of different places under drastic appearance changes. our method excavates the space of intrinsic structure and semantic information by proposed self-supervised encoder loss. different from previous learning based place recognition methods that need paired training data of each place with appearance changes, we employ the weakly-supervised strategy to utilize unpaired set-based training data of different environmental conditions.   we conduct comprehensive experiments and show that our semi-supervised intrinsic encoder achieves remarkable performance for place recognition under drastic appearance changes. the proposed intrinsic encoder outperforms the state-of-the-art image-level place recognition methods on standard benchmark nordland.',\n",
       " 694: 'we provide adaptive inference methods, based on l1 regularization methods, for regular (semi-parametric) and non-regular (nonparametric) linear functionals of the conditional expectation function. examples of regular functionals include average treatment effects, policy effects from covariate distribution shifts and stochastic transformations, and average derivatives. examples of non-regular functionals include the local linear functionals defined as local averages that approximate perfectly localized quantities: average treatment, average policy effects, and average derivatives, conditional on a covariate subvector fixed at a point. our construction relies on building neyman orthogonal equations for the target parameter that are approximately invariant to small perturbations of the nuisance parameters. to achieve this property we include the linear riesz representer for the functionals in the equations as the additional nuisance parameter. we use l1-regularized methods to learn approximations to the regression function and the linear representer, in settings where dimension of (possibly overcomplete) dictionary of basis functions p is much larger than n. we then estimate the linear functional by the solution to the empirical analog of the orthogonal equations. our key result is that under weak assumptions the estimator of the functional concentrates in a l/root(n) neighborhood of the target with deviations controlled by the gaussian law, provided l/root(n) \\\\to 0; l is the operator norm of the functional, measuring the degree of its non-regularity, with l diverging for local functionals (or under weak identification of the global functionals).',\n",
       " 695: 'despite citation counts from google scholar (gs), web of science (wos), and scopus being widely consulted by researchers and sometimes used in research evaluations, there is no recent or systematic evidence about the differences between them. in response, this paper investigates 2,448,055 citations to 2,299 english-language highly-cited documents from 252 gs subject categories published in 2006, comparing gs, the wos core collection, and scopus. gs consistently found the largest percentage of citations across all areas (93%-96%), far ahead of scopus (35%-77%) and wos (27%-73%). gs found nearly all the wos (95%) and scopus (92%) citations. most citations found only by gs were from non-journal sources (48%-65%), including theses, books, conference papers, and unpublished materials. many were non-english (19%-38%), and they tended to be much less cited than citing sources that were also in scopus or wos. despite the many unique gs citing sources, spearman correlations between citation counts in gs and wos or scopus are high (0.78-0.99). they are lower in the humanities, and lower between gs and wos than between gs and scopus. the results suggest that in all areas gs citation data is essentially a superset of wos and scopus, with substantial extra coverage.',\n",
       " 696: \"the lack of comprehensive, high-quality health data in developing nations creates a roadblock for combating the impacts of disease. one key challenge is understanding the health information needs of people in these nations. without understanding people's everyday needs, concerns, and misconceptions, health organizations and policymakers lack the ability to effectively target education and programming efforts. in this paper, we propose a bottom-up approach that uses search data from individuals to uncover and gain insight into health information needs in africa. we analyze bing searches related to hiv/aids, malaria, and tuberculosis from all 54 african nations. for each disease, we automatically derive a set of common search themes or topics, revealing a wide-spread interest in various types of information, including disease symptoms, drugs, concerns about breastfeeding, as well as stigma, beliefs in natural cures, and other topics that may be hard to uncover through traditional surveys. we expose the different patterns that emerge in health information needs by demographic groups (age and sex) and country. we also uncover discrepancies in the quality of content returned by search engines to users by topic. combined, our results suggest that search data can help illuminate health information needs in africa and inform discussions on health policy and targeted education efforts both on- and offline.\",\n",
       " 697: 'we complete classification of mutation-finite cluster algebras by extending the technique derived by fomin, shapiro, and thurston to skew-symmetrizable case. we show that for every mutation-finite skew-symmetrizable matrix a diagram characterizing the matrix admits an unfolding which embeds its mutation class to the mutation class of some mutation-finite skew-symmetric matrix. in particular, this establishes a correspondence between a large class of skew-symmetrizable mutation-finite cluster algebras and triangulated marked bordered surfaces.',\n",
       " 698: 'the quadratic travelling salesman problem (qtsp) is to find a least-cost hamiltonian cycle in an edge-weighted graph, where costs are defined on all pairs of edges such that each edge in the pair is contained in the hamiltonian cycle. this is a more general version than the one that appears in the literature as the qtsp, denoted here as the \\\\emph{adjacent quadratic} tsp, which only considers costs for pairs of adjacent edges. major directions of research work on the linear tsp include exact algorithms, heuristics, approximation algorithms, polynomially solvable special cases and exponential neighbourhoods among others. in this paper we explore the complexity of searching exponential neighbourhoods for qtsp, the fixed-rank qtsp, and the adjacent quadratic tsp. the fixed-rank qtsp is introduced as a restricted version of the qtsp where the cost matrix has fixed rank $p$. it is shown that fixed-rank qtsp is solvable in pseudopolynomial time and admits an fptas for each of the special cases studied, except for the case of matching edge ejection tours. the adjacent quadratic tsp is shown to be polynomially-solvable in many of the cases for which the linear tsp is polynomially-solvable. interestingly, optimizing over the matching edge ejection tour neighbourhood is shown to be pseudopolynomial for the rank 1 case without a linear term in the objective function, but np-hard for the adjacent quadratic tsp case.   we also show that the quadratic shortest path problem on an acyclic digraph can be solved in pseudopolynomial time and by an fptas when the rank of the associated cost matrix is fixed.',\n",
       " 699: 'we introduce meta-f*, a tactics and metaprogramming framework for the f* program verifier. the main novelty of meta-f* is allowing the use of tactics and metaprogramming to discharge assertions not solvable by smt, or to just simplify them into well-behaved smt fragments. plus, meta-f* can be used to generate verified code automatically.   meta-f* is implemented as an f* effect, which, given the powerful effect system of f*, heavily increases code reuse and even enables the lightweight verification of metaprograms. metaprograms can be either interpreted, or compiled to efficient native code that can be dynamically loaded into the f* type-checker and can interoperate with interpreted code. evaluation on realistic case studies shows that meta-f* provides substantial gains in proof development, efficiency, and robustness.',\n",
       " 700: 'when multiple firms are simultaneously running experiments on a platform, the treatment effects for one firm may depend on the experimentation policies of others. this paper presents a set of causal estimands that are relevant to such an environment. we also present an experimental design that is suitable for facilitating experimentation across multiple competitors in such an environment. together, these can be used by a platform to run experiments \"as a service,\" on behalf of its participating firms. we show that the causal estimands we develop are identified nonparametrically by the variation induced by the design, and present two scalable estimators that help measure them in typical high-dimensional situations. we implement the design on the advertising platform of jd.com, an ecommerce company, which is also a publisher of digital ads in china. we discuss how the design is engineered within the platform\\'s auction-driven ad-allocation system, which is typical of modern, digital advertising marketplaces. finally, we present results from a parallel experiment involving 16 advertisers and millions of jd.com users. these results showcase the importance of accommodating a role for interactions across experimenters and demonstrates the viability of the framework.',\n",
       " 701: 'in this work, we study the problem of learning a single model for multiple domains. unlike the conventional machine learning scenario where each domain can have the corresponding model, multiple domains (i.e., applications/users) may share the same machine learning model due to maintenance loads in cloud computing services. for example, a digit-recognition model should be applicable to hand-written digits, house numbers, car plates, etc. therefore, an ideal model for cloud computing has to perform well at each applicable domain. to address this new challenge from cloud computing, we develop a framework of robust optimization over multiple domains. in lieu of minimizing the empirical risk, we aim to learn a model optimized to the adversarial distribution over multiple domains. hence, we propose to learn the model and the adversarial distribution simultaneously with the stochastic algorithm for efficiency. theoretically, we analyze the convergence rate for convex and non-convex models. to our best knowledge, we first study the convergence rate of learning a robust non-convex model with a practical algorithm. furthermore, we demonstrate that the robustness of the framework and the convergence rate can be further enhanced by appropriate regularizers over the adversarial distribution. the empirical study on real-world fine-grained visual categorization and digits recognition tasks verifies the effectiveness and efficiency of the proposed framework.',\n",
       " 702: \"in random walks, the path representation of the green's function is an infinite sum over the length of path probability density functions (pdfs). here we derive and solve, in laplace space, the recursion relation for the n order path pdf for any arbitrarily inhomogeneous semi-markovian random walk in a one-dimensional (1d) chain of l states. the recursion relation relates the n order path pdf to l/2 (round towards zero for an odd l) shorter path pdfs, and has n independent coefficients that obey a universal formula. the z transform of the recursion relation straightforwardly gives the generating function for path pdfs, from which we obtain the green's function of the random walk, and derive an explicit expression for any path pdf of the random walk. these expressions give the most detailed description of arbitrarily inhomogeneous semi-markovian random walks in 1d.\",\n",
       " 703: 'we study the furstenberg-entropy realization problem for stationary actions. it is shown that for finitely supported probability measures on free groups, any a-priori possible entropy value can be realized as the entropy of an ergodic stationary action. this generalizes results of bowen. the stationary actions we construct arise via invariant random subgroups (irss), based on ideas of bowen and kaimanovich. we provide a general framework for constructing a continuum of ergodic irss for a discrete group under some algebraic conditions, which gives a continuum of entropy values. our tools apply for example, for certain extensions of the group of finitely supported permutations and lamplighter groups, hence establishing full realization results for these groups. for the free group, we construct the irss via a geometric construction of subgroups, by describing their schreier graphs. the analysis of the entropy of these spaces is obtained by studying the random walk on the appropriate schreier graphs.',\n",
       " 704: 'this study illustrates how to use \"spmoran,\" which is an r package for moran\\'s eigenvector-based spatial regression analysis for up to millions of observations. this package estimates fixed or random effects eigenvector spatial filtering models and their extensions including a spatially varying coefficient model, a spatial unconditional quantile regression model, and low rank spatial econometric models. these models are estimated computationally efficiently.',\n",
       " 705: 'we study a simple run-and-tumble random walk whose switching frequency from run mode to tumble mode and the reverse depend on a stochastic signal. we consider a particularly sharp, step-like dependence, where the run to tumble switching probability jumps from zero to one as the signal crosses a particular value (say y_1 ) from below. similarly, tumble to run switching probability also shows a jump like this as the signal crosses another value (y_2 < y_1 ) from above. we are interested in characterizing the effect of signaling noise on the long time behavior of the random walker. we consider two different time-evolutions of the stochastic signal. in one case, the signal dynamics is an independent stochastic process and does not depend on the run-and-tumble motion. in this case we can analytically calculate the mean value and the complete distribution function of the run duration and tumble duration. in the second case, we assume that the signal dynamics is influenced by the spatial location of the random walker. for this system, we numerically measure the steady state position distribution of the random walker. we discuss some similarities and differences between our system and e.coli chemotaxis, which is another well-known run-and-tumble motion encountered in nature.',\n",
       " 706: 'bayesian optimisation is a popular technique for hyperparameter learning but typically requires initial exploration even in cases where similar prior tasks have been solved. we propose to transfer information across tasks using learnt representations of training datasets used in those tasks. this results in a joint gaussian process model on hyperparameters and data representations. representations make use of the framework of distribution embeddings into reproducing kernel hilbert spaces. the developed method has a faster convergence compared to existing baselines, in some cases requiring only a few evaluations of the target objective.',\n",
       " 707: 'we investigate topological phase transitions driven by interaction and identify a novel topological mott insulator state in one-dimensional fermionic optical superlattices through numerical density matrix renormalization group (dmrg) method. remarkably, the low-energy edge excitations change from spin-1/2 fermionic single-particle modes to spin-1 bosonic collective modes across the phase transition. due to spin-charge separation, the low-energy theory is governed by an effective spin superexchange model, whereas the charge degree of freedom is fully gapped out. such topological mott state can be characterized by a spin chern number and gapless magnon modes protected by a finite spin gap. the proposed experimental setup is simple and may pave the way for the experimental observation of exotic topological mott states.',\n",
       " 708: 'hannan consistency, or no external regret, is a~key concept for learning in games. an action selection algorithm is hannan consistent (hc) if its performance is eventually as good as selecting the~best fixed action in hindsight. if both players in a~zero-sum normal form game use a~hannan consistent algorithm, their average behavior converges to a~nash equilibrium (ne) of the~game. a similar result is known about extensive form games, but the~played strategies need to be hannan consistent with respect to the~counterfactual values, which are often difficult to obtain. we study zero-sum extensive form games with simultaneous moves, but otherwise perfect information. these games generalize normal form games and they are a special case of extensive form games. we study whether applying hc algorithms in each decision point of these games directly to the~observed payoffs leads to convergence to a~nash equilibrium. this learning process corresponds to a~class of monte carlo tree search algorithms, which are popular for playing simultaneous-move games but do not have any known performance guarantees. we show that using hc algorithms directly on the~observed payoffs is not sufficient to guarantee the~convergence. with an~additional averaging over joint actions, the~convergence is guaranteed, but empirically slower. we further define an~additional property of hc algorithms, which is sufficient to guarantee the~convergence without the~averaging and we empirically show that commonly used hc algorithms have this property.',\n",
       " 709: \"in relation extraction with distant supervision, noisy labels make it difficult to train quality models. previous neural models addressed this problem using an attention mechanism that attends to sentences that are likely to express the relations. we improve such models by combining the distant supervision data with an additional directly-supervised data, which we use as supervision for the attention weights. we find that joint training on both types of supervision leads to a better model because it improves the model's ability to identify noisy sentences. in addition, we find that sigmoidal attention weights with max pooling achieves better performance over the commonly used weighted average attention in this setup. our proposed method achieves a new state-of-the-art result on the widely used fb-nyt dataset.\",\n",
       " 710: 'we propose a recurrent rl agent with an episodic exploration mechanism that helps discovering good policies in text-based game environments. we show promising results on a set of generated text-based games of varying difficulty where the goal is to collect a coin located at the end of a chain of rooms. in contrast to previous text-based rl approaches, we observe that our agent learns policies that generalize to unseen games of greater difficulty.',\n",
       " 711: 'software engineers can find vulnerabilities with less effort if they are directed towards code that might contain more vulnerabilities. harmless is an incremental support vector machine tool that builds a vulnerability prediction model from the sourcecode inspected to date, then suggests what source code files should be inspected next. in this way, harmless can reduce the time and effort required to achieve some desired level of recall for finding vulnerabilities. the tool also provides feedback on when to stop (at that desired level of recall) while at the same time, correcting human errors by double-checking suspicious files.   this paper evaluates harmless on mozilla firefox vulnerability data. harmless found 80, 90, 95, 99% of the vulnerabilities by inspecting 10, 16, 20, 34% of the source code files. when targeting 90, 95, 99% recall, harmless could stop after inspecting 23, 30, 47% of the source code files. even when human reviewers fail to identify half of the vulnerabilities (50% false negative rate), harmlesscould detect 96% of the missing vulnerabilities by double-checking half of the inspected files.   our results serve to highlight the very steep cost of protecting software from vulnerabilities (in our case study that cost is, for example, the human effort of inspecting 28,750$\\\\times$20% = 5,750 source code files to identify 95% of the vulnerabilities). while this result could benefit the mission-critical projects where human resources are available for inspecting thousands of source code files, the research challenge for future work is how to further reduce that cost. the conclusion of this paper discusses various ways that goal might be achieved.',\n",
       " 712: \"we report on the challenges and limitations of direct coupling of the magnetic field from a circuit resonator to an electron spin bound to a donor potential. we propose a device consisting of a trilayer lumped-element superconducting resonator and a single donor implanted in enriched $^{28}$si. the resonator impedance is significantly smaller than the practically achievable limit using prevalent coplanar resonators. furthermore, the resonator includes a nano-scale spiral inductor to spatially focus the magnetic field from the photons at the location of the implanted donor. the design promises approximately two orders of magnitude increase in the local magnetic field, and thus the spin to photon coupling rate $g$, compared to the estimated coupling rate to the magnetic field of coplanar transmission-line resonators. we show that by using niobium (aluminum) as the resonator's superconductor and a single phosphorous (bismuth) atom as the donor, a coupling rate of $g/2\\\\pi$=0.24 mhz (0.39 mhz) can be achieved in the single photon regime. for this hybrid cavity quantum electrodynamic system, such enhancement in $g$ is sufficient to enter the strong coupling regime.\",\n",
       " 713: 'cellular automata (ca) are dynamical systems on symbolic configurations on the lattice. they are also used as models of massively parallel computers. as dynamical systems, one would like to understand the effect of small random perturbations on the dynamics of ca. as models of computation, they can be used to study the reliability of computation against noise.   we consider various families of ca (nilpotent, permutive, gliders, ca with a spreading symbol, surjective, algebraic) and prove that they are highly unstable against noise, meaning that they forget their initial conditions under slightest positive noise. this is manifested as the ergodicity of the resulting probabilistic ca. the proofs involve a collection of different techniques (couplings, entropy, fourier analysis), depending on the dynamical properties of the underlying deterministic ca and the type of noise.',\n",
       " 714: 'the tweedie compound poisson-gamma model is routinely used for modeling non-negative continuous data with a discrete probability mass at zero. mixed models with random effects account for the covariance structure related to the grouping hierarchy in the data. an important application of tweedie mixed models is pricing the insurance policies, e.g. car insurance. however, the intractable likelihood function, the unknown variance function, and the hierarchical structure of mixed effects have presented considerable challenges for drawing inferences on tweedie. in this study, we tackle the bayesian tweedie mixed-effects models via variational inference approaches. in particular, we empower the posterior approximation by implicit models trained in an adversarial setting. to reduce the variance of gradients, we reparameterize random effects, and integrate out one local latent variable of tweedie. we also employ a flexible hyper prior to ensure the richness of the approximation. our method is evaluated on both simulated and real-world data. results show that the proposed method has smaller estimation bias on the random effects compared to traditional inference methods including mcmc; it also achieves a state-of-the-art predictive performance, meanwhile offering a richer estimation of the variance function.',\n",
       " 715: \"reinforcement learning in multiagent systems has been studied in the fields of economic game theory, artificial intelligence and statistical physics by developing an analytical understanding of the learning dynamics (often in relation to the replicator dynamics of evolutionary game theory). however, the majority of these analytical studies focuses on repeated normal form games, which only have a single environmental state. environmental dynamics, i.e., changes in the state of an environment affecting the agents' payoffs has received less attention, lacking a universal method to obtain deterministic equations from established multistate reinforcement learning algorithms.   in this work we present a novel methodological extension, separating the interaction from the adaptation time scale, to derive the deterministic limit of a general class of reinforcement learning algorithms, called temporal difference learning. this form of learning is equipped to function in more realistic multistate environments by using the estimated value of future environmental states to adapt the agent's behavior. we demonstrate the potential of our method with the three well established learning algorithms q learning, sarsa learning and actor-critic learning. illustrations of their dynamics on two multiagent, multistate environments reveal a wide range of different dynamical regimes, such as convergence to fixed points, limit cycles, and even deterministic chaos.\",\n",
       " 716: '(1) we show that if a presentation of the trivial group is \"hard to trivialize\", in the sense that lots of tietze moves are necessary to transform it into the trivial presentation, then the associated presentation complex (which is a contractible 2-dimensional cell complex) is \"hard to embed in $\\\\mathbb{r}^3$\", in the sense that lots of linear subdivisions are necessary.   (2) for any d, we show that all collapsible d-complexes with n facets linearly embed in $\\\\mathbb{r}^{2d}$ after less than n barycentric subdivisions. this is best possible, as cones over non-planar graphs do not topologically embed in $\\\\mathbb{r}^{3}$.',\n",
       " 717: 'we classify simple heteroclinic networks for a $\\\\gamma$-equivariant system in ${\\\\mathbb r}^4$ with finite $\\\\gamma \\\\subset {\\\\rm o}(4)$, proceeding as follows: we define a graph associated with a given $\\\\gamma \\\\subset {\\\\rm o}(n)$ and identify all so-called simple graphs associated with subgroups of ${\\\\rm o}(4)$. then, knowing the graph associated with a given $\\\\gamma$, we determine the types of heteroclinic networks that the group admits. our study is restricted to networks that are maximal in the sense that they have the highest possible number of connections -- any non-maximal network can then be derived by deleting one or more connections. finally, for networks of type a, i.e., admitted by $\\\\gamma \\\\subset {\\\\rm so}(4)$, we give necessary and sufficient conditions for fragmentary and essential asymptotic stability. (for other simple heteroclinic networks the conditions for stability are known.) the results are illustrated by a numerical example of a simple heteroclinic network that involves two subcycles that can be essentially asymptotically stable simultaneously.',\n",
       " 718: \"the main result of this paper is a quantified version of ingham's tauberian theorem for bounded vector-valued sequences rather than functions. it gives an estimate on the rate of decay of such a sequence in terms of the behaviour of a certain boundary function, with the quality of the estimate depending on the degree of smoothness this boundary function is assumed to possess. the result is then used to give a new proof of the quantified katznelson-tzafriri theorem recently obtained in [21].\",\n",
       " 719: 'the cuntz semigroup of a c*-algebra is an important invariant in the structure and classification theory of c*-algebras. it captures more information than k-theory but is often more delicate to handle. we systematically study the lattice and category theoretic aspects of cuntz semigroups.   given a c*-algebra $a$, its (concrete) cuntz semigroup $cu(a)$ is an object in the category $cu$ of (abstract) cuntz semigroups, as introduced by coward, elliott and ivanescu. to clarify the distinction between concrete and abstract cuntz semigroups, we will call the latter $cu$-semigroups.   we establish the existence of tensor products in the category $cu$ and study the basic properties of this construction. we show that $cu$ is a symmetric, monoidal category and relate $cu(a\\\\otimes b)$ with $cu(a)\\\\otimes_{cu}cu(b)$ for certain classes of c*-algebras.   as a main tool for our approach we introduce the category $w$ of pre-completed cuntz semigroups. we show that $cu$ is a full, reflective subcategory of $w$. one can then easily deduce properties of $cu$ from respective properties of $w$, e.g. the existence of tensor products and inductive limits. the advantage is that constructions in $w$ are much easier since the objects are purely algebraic.   we also develop a theory of $cu$-semirings and their semimodules. the cuntz semigroup of a strongly self-absorbing c*-algebra has a natural product giving it the structure of a $cu$-semiring. we give explicit characterizations of $cu$-semimodules over such $cu$-semirings. for instance, we show that a $cu$-semigroup $s$ tensorially absorbs the $cu$-semiring of the jiang-su algebra if and only if $s$ is almost unperforated and almost divisible, thus establishing a semigroup version of the toms-winter conjecture.',\n",
       " 720: 'the extremely high carrier mobility and the unique band structure, make graphene very useful for field-effect transistor applications. according to several works, the primary limitation to graphene based transistor performance is not related to the material quality, but to extrinsic factors that affect the electronic transport properties. one of the most important parasitic element is the contact resistance appearing between graphene and the metal electrodes functioning as the source and the drain. ohmic contacts to graphene, with low contact resistances, are necessary for injection and extraction of majority charge carriers to prevent transistor parameter fluctuations caused by variations of the contact resistance. the international technology roadmap for semiconductors, toward integration and down-scaling of graphene electronic devices, identifies as a challenge the development of a cmos compatible process that enables reproducible formation of low contact resistance. however, the contact resistance is still not well understood despite it is a crucial barrier towards further improvements. in this paper, we review the experimental and theoretical activity that in the last decade has been focusing on the reduction of the contact resistance in graphene transistors. we will summarize the specific properties of graphene-metal contacts with particular attention to the nature of metals, impact of fabrication process, fermi level pinning, interface modifications induced through surface processes, charge transport mechanism, and edge contact formation.',\n",
       " 721: 'we present the bayesian case model (bcm), a general framework for bayesian case-based reasoning (cbr) and prototype classification and clustering. bcm brings the intuitive power of cbr to a bayesian generative framework. the bcm learns prototypes, the \"quintessential\" observations that best represent clusters in a dataset, by performing joint inference on cluster labels, prototypes and important features. simultaneously, bcm pursues sparsity by learning subspaces, the sets of features that play important roles in the characterization of the prototypes. the prototype and subspace representation provides quantitative benefits in interpretability while preserving classification accuracy. human subject experiments verify statistically significant improvements to participants\\' understanding when using explanations produced by bcm, compared to those given by prior art.',\n",
       " 722: 'we forecast s&p 500 excess returns using a flexible bayesian econometric state space model with non-gaussian features at several levels. more precisely, we control for overparameterization via novel global-local shrinkage priors on the state innovation variances as well as the time-invariant part of the state space model. the shrinkage priors are complemented by heavy tailed state innovations that cater for potential large breaks in the latent states. moreover, we allow for leptokurtic stochastic volatility in the observation equation. the empirical findings indicate that several variants of the proposed approach outperform typical competitors frequently used in the literature, both in terms of point and density forecasts.',\n",
       " 723: \"we use young's raising operators to introduce and study double theta polynomials, which specialize to both the theta polynomials of buch, kresch, and tamvakis, and to double (or factorial) schur s-polynomials and q-polynomials. these double theta polynomials give giambelli formulas which represent the equivariant schubert classes in the torus-equivariant cohomology ring of symplectic grassmannians, and we employ them to obtain a new presentation of this ring in terms of intrinsic generators and relations.\",\n",
       " 724: \"we construct examples of smooth 4-dimensional manifolds m supporting a locally cat(0)-metric, whose universal cover x satisfy hruska's isolated flats condition, and contain 2-dimensional flats f with the property that the boundary at infinity of f defines a nontrivial knot in the boundary at infinity of x. as a consequence, we obtain that the fundamental group of m cannot be isomorphic to the fundamental group of any riemannian manifold of nonpositive sectional curvature. in particular, m is a locally cat(0)-manifold which does not support any riemannian metric of nonpositive sectional curvature.\",\n",
       " 725: 'the portfolio optimisation problem, first raised by harry markowitz in 1952, has been a fundamental and central topic to understanding the stock market and making decisions. there has been plenty of works contributing to development of the mean-variance optimisation (mvo) so far. in this paper, one kind of them, namely, dynamic mean-variance optimisation (dmvo) is mainly discussed. one can apply either precommitment or game-theoritical approach to address time-inconsistency in dmvo. we use the second approach to seek for a time-consistent strategy. after obtaining the optimal strategy, we extend the result to a cev-driven economy. in order to prove the usefulness of them, strategies are fit into both real market data and simulated data. it turns out that the strategy whose assumptions are close to market conditions generally gives a better result. lastly, a selected strategy is chosen to compare with another strategy came up by deep learning technique.',\n",
       " 726: 'in this article we consider a convex feasible set described by inequality constraints that are continuous and not necessarily lipschitz or convex. we show that if the slater constraint qualification and a non-degeneracy condition are satisfied, then the karush-kuhn-tucker type optimality condition is both necessary and sufficient. in this way we extend previous results which are proved for lipschitz and differentiable inequalities.',\n",
       " 727: 'when an extended system is coupled at its opposite boundaries to two reservoirs at different temperatures or chemical potentials, it cannot achieve a global thermal equilibrium and is instead driven to a set of current-carrying nonequilibrium states. despite the broad relevance of such a scenario to metallic systems, there have been limited investigations of the entanglement structure of the resulting long-time states, in part, due to the fundamental difficulty in solving realistic models for disordered, interacting electrons. we investigate this problem by carefully analyzing two \"toy\" models for coherent quantum transport of diffusive fermions: the celebrated three-dimensional, noninteracting anderson model and a class of random quantum circuits acting on a chain of qubits, which exactly maps to a diffusive, interacting fermion problem. crucially, the random circuit model can also be tuned to have no interactions between the fermions, similar to the anderson model. we show that the long-time states of driven noninteracting fermions exhibit volume-law mutual information and entanglement, both for our random circuit model and for the nonequilibrium steady-state of the anderson model. with interactions, the random circuit model is quantum chaotic and approaches local equilibrium, with only short-range entanglement. these results provide a generic picture for the emergence of local equilibrium in current-driven quantum-chaotic systems, and also provide examples of stable, highly-entangled many-body states out of equilibrium. we discuss experimental techniques to probe these effects in low-temperature mesoscopic wires or ultracold atomic gases.',\n",
       " 728: 'although symmetry has been discussed in terms of a major law of perceptual organization since the early conceptual efforts of the gestalt school (wertheimer, metzger, koffka and others), the first quantitative measurements testing for effects of symmetry on processes of gestalt formation have seen the day only recently. in this study, a psychophysical rating study and a \"foreground\" versus \"background\" choice response time experiment were run with human observers to test for effects of bilateral symmetry on the perceived strength of figure against ground in triangular kanizsa configurations. displays with and without bilateral symmetry, identical physically specified to total contour ratio and constant local contrast intensity within and across conditions, but variable local contrast polarity and variable orientation in the plane were presented in a random order to human observers. configurations with bilateral symmetry produced significantly stronger figure against ground percepts reflected by greater subjective magnitudes and consistently higher percentages of \"foreground\" judgments accompanied by significantly shorter response times. these effects of symmetry depend neither on the orientation of the axis of symmetry, nor on the contrast polarity of the physical inducers. it is concluded that bilateral symmetry, irrespective of orientation, significantly contributes to the, largely sign invariant, visual mechanisms of shape segregation that determine the salience of figure against ground in perceptually ambiguous image configurations.',\n",
       " 729: 'model sets are always meyer sets but the converse is generally not true. in this work we show that for a repetitive meyer multiple sets of $\\\\mathbb{r}^d$ with associated dynamical system $(\\\\mathbb{x}, \\\\mathbb{r}^d)$, the property of being a model multiple set is equivalent for $(\\\\mathbb{x}, \\\\mathbb{r}^d)$ to be almost automorphic. we deduce this by showing that a repetitive meyer multiple set can always be embedded into a repetitive model multiple set having a smaller group of topological eigenvalues.',\n",
       " 730: \"recent high-energy cosmic $e^\\\\pm$ measurement from the dark matter particle explorer (dampe) satellite confirms the deviation of total cosmic ray electron spectrum above 700-900 gev from a simple power law. in this paper we demonstrate that the cascade decay of dark matter (dm) can account for dampe's tev $e^+e^-$ spectrum. we select the least constraint dm decay channel into four muons as the benchmark scenario, and perform an analysis with propagation variance in both dm signal and the milky way's electron background. the best-fit of the model is obtained for joint dampe, fermi-large area telescope (fermi-lat), high energy stereoscopic system (hess), high energy electron data sets, and with an $\\\\mathcal{o}(10^{26})$ second decay lifetime, which is consistent with existing gamma ray and cosmic microwave background limits. we compare the spectral difference between the cascade decay of typical final-state channels. the least constrained $4\\\\mu$ channels give good fits to the electron spectrum's tev scale down-turn, yet their low energy spectrum has tension with sub-tev positron data from ams02. we also consider a three-step cascade decay into eight muons, and also a gamma-ray constrained $4\\\\mu,4b$ mixed channel, to demonstrate that a further softened cascade decay signal would be required for the agreement with all the data sets.\",\n",
       " 731: 'finding optimal correction of errors in generic stabilizer codes is a computationally hard problem, even for simple noise models. while this task can be simplified for codes with some structure, such as topological stabilizer codes, developing good and efficient decoders still remains a challenge. in our work, we systematically study a very versatile class of decoders based on feedforward neural networks. to demonstrate adaptability, we apply neural decoders to the triangular color and toric codes under various noise models with realistic features, such as spatially-correlated errors. we report that neural decoders provide significant improvement over leading efficient decoders in terms of the error-correction threshold. using neural networks simplifies the process of designing well-performing decoders, and does not require prior knowledge of the underlying noise model.',\n",
       " 732: 'we describe the relationship between intersection cohomology with twisted coefficients and the perverse sheaves which play the role of the eigenspaces for the milnor monodromy of an affine hypersurface.',\n",
       " 733: 'cell migration in fibreous extracellular matrix (ecm) is crucial to many physiological and pathological processes such as tissue regeneration, immune response and cancer progression. during migration, individual cells can generate active pulling forces via actin filament contraction, which are transmitted to the ecm fibers through focal adhesion complexes, remodel the ecm, and eventually propagate to and can be sensed by other cells in the system. the microstructure and physical properties of the ecm can also significantly influence cell migration, e.g., via durotaxis and contact guidance. here, we develop a computational model for cell migration regulated by cell-ecm micro-mechanical coupling. our model explicitly takes into account a variety of cellular level processes including focal adhesion formation and disassembly, active traction force generation and cell locomotion due to actin filament contraction, transmission and propagation of tensile forces in the ecm, as well as the resulting ecm remodeling. we validate our model by accurately reproducing single-cell dynamics of mcf-10a breast cancer cells migrating on collagen gels and show that the durotaxis and contact guidance effects naturally arise as a consequence of the cell-ecm micro-mechanical interactions considered in the model. moreover, our model predicts strongly correlated multi-cellular migration dynamics, which are resulted from the ecm-mediated mechanical coupling among the migrating cell and are subsequently verified in {\\\\it in vitro} experiments using mcf-10a cells. our computational model provides a robust tool to investigate emergent collective dynamics of multi-cellular systems in complex {\\\\it in vivo} micro-environment and can be utilized to design {\\\\it in vitro} micro-environments to guide collective behaviors and self-organization of cells.',\n",
       " 734: \"a diversity of animals that run on solid, level, flat, non-slip surfaces appear to bounce on their legs; elastic elements in the limbs can store and return energy during each step. the mechanics and energetics of running in natural terrain, particularly on surfaces that can yield and flow under stress, is less understood. the zebra-tailed lizard (callisaurus draconoides), a small desert generalist with a large, elongate, tendinous hind foot, runs rapidly across a variety of natural substrates. we use high speed video to obtain detailed three-dimensional running kinematics on solid and granular surfaces to reveal how leg, foot, and substrate mechanics contribute to its high locomotor performance. running at ~10 body length/s (~1 m/s), the center of mass oscillates like a spring-mass system on both substrates, with only 15% reduction in stride length on the granular surface. on the solid surface, a strut-spring model of the hind limb reveals that the hind foot saves about 40% of the mechanical work needed per step, significant for the lizard's small size. on the granular surface, a penetration force model and hypothesized subsurface foot rotation indicates that the hind foot paddles through fluidized granular medium, and that the energy lost per step during irreversible deformation of the substrate does not differ from the reduction in the mechanical energy of the center of mass. the upper hind leg muscles must perform three times as much mechanical work on the granular surface as on the solid surface to compensate for the greater energy lost within the foot and to the substrate.\",\n",
       " 735: 'let $\\\\mathcal b\\\\subseteq\\\\mathbb n$ be a primitive set. we complement results on heredity of the $\\\\mathcal b$-free subshift $x_\\\\eta$ from [arxiv:1509.08010] in two directions: in the proximal case we prove that a subshift $x_\\\\varphi$, which micht be slightly larger than the subshift $x_\\\\eta$, is always hereditary. (there is no need to assume that the set $\\\\mathcal b$ is taut or even has light tails, but if $\\\\mathcal b$ is taut, then $x_\\\\varphi=x_\\\\eta$.) we also generalize the the concept of heredity to the non-proximal (and hence non-hereditary) case by proving that $x_\\\\varphi$ is always \"hereditary away from its unique minimal subsystem\" (which is always toeplitz). finally we characterize regularity of this toeplitz subsystem equivalently by the condition $m_h(\\\\overline{\\\\operatorname{int}(w)})=0$, where $w$ (\"the window\") is a subset of a compact abelian group $h$ canonically associated with the set $\\\\mathcal b$, and $m_h$ denotes haar measure on $h$. throughout, results from [arxiv:1702.02375] are heavily used.',\n",
       " 736: \"the tight coupling between neuronal activity and the local increase of blood flow termed neurovascular coupling is essential for normal brain function. this mechanism of regulation is compromised in alzheimer's disease (ad). in order to determine whether a purely vascular dysfunction or a neuronal alteration of blood vessels diameter control could be responsible for the impaired neurovascular coupling observed in ad, blood vessels reactivity in response to different pharmacological stimulations was examined in double transgenic appxps1 mice model of ad. blood vessels movements were monitored using infrared videomicroscopy ex vivo, in cortical slices of 8 month-old appxps1 and wild type (wt) mice. we quantified vasomotor responses induced either by direct blood vessel stimulation with a thromboxane a 2 analogue, the u46619 (9,11-dideoxy-11a,9a-epoxymethanoprostaglandin f2) or via the stimulation of interneurons with the nicotinic acetylcholine receptor (nachrs) agonist dmpp (1,1-dimethyl-4-phenylpiperazinium iodide). using both types of stimulation, no significant differences were detected for the amplitude of blood vessel diameter changes between the transgenic appxps1 mice model of ad and wt mice, although the kinetics of recovery were slower in appxps1 mice. we find that activation of neocortical interneurons with dmpp induced both vasodilation via nitric oxide (no) release and constriction via neuropeptide y (npy) release. however, we observed a smaller proportion of reactive blood vessels following a neuronal activation in transgenic mice compared with wt mice. altogether, these results suggest that in this mouse model of ad, deficiency in the cortical neurovascular coupling essentially results from a neuronal rather than a vascular dysfunction.\",\n",
       " 737: 'algorithms for acoustic source localization and tracking provide estimates of the positional information about active sound sources in acoustic environments and are essential for a wide range of applications such as personal assistants, smart homes, tele-conferencing systems, hearing aids, or autonomous systems. the aim of the ieee-aasp challenge on sound source localization and tracking (locata) was to objectively benchmark state-of-the-art localization and tracking algorithms using an open-access data corpus of recordings for scenarios typically encountered in audio and acoustic signal processing applications. the challenge tasks ranged from the localization of a single source with a static microphone array to the tracking of multiple moving sources with a moving microphone array.',\n",
       " 738: 'we consider decision problems for relations over finite and infinite words defined by finite automata. we prove that the equivalence problem for binary deterministic rational relations over infinite words is undecidable in contrast to the case of finite words, where the problem is decidable. furthermore, we show that it is decidable in doubly exponential time for an automatic relation over infinite words whether it is a recognizable relation. we also revisit this problem in the context of finite words and improve the complexity of the decision procedure to single exponential time. the procedure is based on a polynomial time regularity test for deterministic visibly pushdown automata, which is a result of independent interest.',\n",
       " 739: \"this paper investigates whether learning contingency-awareness and controllable aspects of an environment can lead to better exploration in reinforcement learning. to investigate this question, we consider an instantiation of this hypothesis evaluated on the arcade learning element (ale). in this study, we develop an attentive dynamics model (adm) that discovers controllable elements of the observations, which are often associated with the location of the character in atari games. the adm is trained in a self-supervised fashion to predict the actions taken by the agent. the learned contingency information is used as a part of the state representation for exploration purposes. we demonstrate that combining actor-critic algorithm with count-based exploration using our representation achieves impressive results on a set of notoriously challenging atari games due to sparse rewards. for example, we report a state-of-the-art score of >11,000 points on montezuma's revenge without using expert demonstrations, explicit high-level information (e.g., ram states), or supervisory data. our experiments confirm that contingency-awareness is indeed an extremely powerful concept for tackling exploration problems in reinforcement learning and opens up interesting research questions for further investigations.\",\n",
       " 740: 'knowing the symmetries of a polyhedron can be very useful for the analysis of its structure as well as for practical polyhedral computations. in this note, we study symmetry groups preserving the linear, projective and combinatorial structure of a polyhedron. in each case we give algorithmic methods to compute the corresponding group and discuss some practical experiences. for practical purposes the linear symmetry group is the most important, as its computation can be directly translated into a graph automorphism problem. we indicate how to compute integral subgroups of the linear symmetry group that are used for instance in integer linear programming.',\n",
       " 741: 'we demonstrate that the tail dependence should always be taken into account as a proxy for systematic risk of loss for investments. we provide the clear statistical evidence of that the structure of investment portfolios on a regulated market should be adjusted to the price of gold. our finding suggests that the active bartering of oil for goods would prevent collapsing the national market facing international sanctions.',\n",
       " 742: 'we introduce the problem of git stability for syzygy points of canonical curves with a view toward a git construction of the canonical model of the moduli space of stable curves. as the first step in this direction, we prove semi-stability of the first syzygy point for a general canonical curve of odd genus.',\n",
       " 743: \"the celebrated hook-length formula gives a product formula for the number of standard young tableaux of a straight shape. in 2014, naruse announced a more general formula for the number of standard young tableaux of skew shapes as a positive sum over excited diagrams of products of hook-lengths. we give an algebraic and a combinatorial proof of naruse's formula, by using factorial schur functions and a generalization of the hillman--grassl correspondence, respectively.   the main new results are two different $q$-analogues of naruse's formula: for the skew schur functions, and for counting reverse plane partitions of skew shapes. we establish explicit bijections between these objects and families of integer arrays with certain nonzero entries, which also proves the second formula.\",\n",
       " 744: 'we apply the atom-atom potentials to molecular crystals of iron (ii) complexes with bulky organic ligands. the crystals under study are formed by low-spin or high-spin molecules of fe(phen)$_{2}$(ncs)$_{2}$ (phen = 1,10-phenanthroline), fe(btz)$_{2}$(ncs)$_{2}$ (btz = 5,5$^{\\\\prime }$,6,6$^{\\\\prime}$-tetrahydro-4\\\\textit{h},4$^{\\\\prime}$\\\\textit{h}-2,2$^{\\\\prime }$-bi-1,3-thiazine), and fe(bpz)$_{2}$(bipy) (bpz = dihydrobis(1-pyrazolil)borate, and bipy = 2,2$^{\\\\prime}$-bipyridine). all molecular geometries are taken from the x-ray experimental data and assumed to be frozen. the unit cell dimensions and angles, positions of the centers of masses of molecules, and the orientations of molecules corresponding to the minimum energy at 1 atm and 1 gpa are calculated. the optimized crystal structures are in a good agreement with the experimental data. sources of the residual discrepancies between the calculated and experimental structures are discussed. the intermolecular contributions to the enthalpy of the spin transitions are found to be comparable with its total experimental values. it demonstrates that the method of atom-atom potentials is very useful for modeling organometalic crystals undergoing the spin transitions.',\n",
       " 745: \"the pentagram map was introduced by r. schwartz in 1992 for convex planar polygons. recently, v. ovsienko, r. schwartz, and s. tabachnikov proved liouville integrability of the pentagram map for generic monodromies by providing a poisson structure and the sufficient number of integrals in involution on the space of twisted polygons. in this paper we prove algebraic-geometric integrability for any monodromy, i.e., for both twisted and closed polygons. for that purpose we show that the pentagram map can be written as a discrete zero-curvature equation with a spectral parameter, study the corresponding spectral curve, and the dynamics on its jacobian. we also prove that on the symplectic leaves poisson brackets discovered for twisted polygons coincide with the symplectic structure obtained from krichever-phong's universal formula.\",\n",
       " 746: 'a large distance propagation in turbulent atmosphere results in disintegration of laser beam into speckles. we find that the most intense speckle approximately preserves both the gaussian shape and the diameter of the initial collimated beam while loosing energy during propagation.   one per 1000 of atmospheric realizations produces at 7km distance an intense speckle above 20\\\\% of the initial power. such optimal realizations create effective extended lenses focusing the intense speckle beyond the diffraction limit of vacuum propagation.   atmospheric realizations change every several milliseconds. we propose to use intense speckles to greatly increase the time-averaged power delivery to the target plane by triggering the pulsed laser operations only at times of optimal realizations. resulting power delivery and laser irradiance at the intense speckles well exceeds both intensity of diffraction-limited beam and intensity averaged over typical realizations.',\n",
       " 747: \"we present a sequential monte carlo algorithm for markov chain trajectories with proposals constructed in reverse time, which is advantageous when paths are conditioned to end in a rare set. the reverse time proposal distribution is constructed by approximating the ratio of green's functions in nagasawa's formula. conditioning arguments can be used to interpret these ratios as low-dimensional conditional sampling distributions of some coordinates of the process given the others. hence the difficulty in designing smc proposals in high dimension is greatly reduced. we illustrate our method on estimating an overflow probability in a queueing model, the probability that a diffusion follows a narrowing corridor, and the initial location of an infection in an epidemic model on a network.\",\n",
       " 748: 'we present a novel, purely affinity-based natural image matting algorithm. our method relies on carefully defined pixel-to-pixel connections that enable effective use of information available in the image. we control the information flow from the known-opacity regions into the unknown region, as well as within the unknown region itself, by utilizing multiple definitions of pixel affinities. among other forms of information flow, we introduce color-mixture flow, which builds upon local linear embedding and effectively encapsulates the relation between different pixel opacities. our resulting novel linear system formulation can be solved in closed-form and is robust against several fundamental challenges of natural matting such as holes and remote intricate structures. while our method is primarily designed as a standalone matting tool, we show that it can also be used for regularizing mattes obtained by sampling-based methods. the formulation is also extended to layer color estimation and we show that the use of multiple channels of flow increases the layer color quality. we also demonstrate our performance in green-screen keying and analyze the characteristics of the utilized affinities.',\n",
       " 749: 'we consider the expected value for the total curvature of a random closed polygon. numerical experiments have suggested that as the number of edges becomes large, the difference between the expected total curvature of a random closed polygon and a random open polygon with the same number of turning angles approaches a positive constant. we show that this is true for a natural class of probability measures on polygons, and give a formula for the constant in terms of the moments of the edgelength distribution.   we then consider the symmetric measure on closed polygons of fixed total length constructed by cantarella, deguchi, and shonkwiler. for this measure, we are able to prove that the expected value of total curvature for a closed n-gon is exactly \\\\pi/2 n + (\\\\pi/4) 2n/(2n-3). as a consequence, we show that at least 1/3 of fixed-length hexagons and 1/11 of fixed-length heptagons in 3-space are unknotted.',\n",
       " 750: 'we introduce the concept of forward rank-dependent performance processes, extending the original notion to forward criteria that incorporate probability distortions. a fundamental challenge is how to reconcile the time-consistent nature of forward performance criteria with the time-inconsistency stemming from probability distortions. for this, we first propose two distinct definitions, one based on the preservation of performance value and the other on the time-consistency of policies and, in turn, establish their equivalence. we then fully characterize the viable class of probability distortion processes, providing a bifurcation-type result. specifically, it is either the case that the probability distortions are degenerate in the sense that the investor would never invest in the risky assets, or the marginal probability distortion equals to a normalized power of the quantile function of the pricing kernel. we also characterize the optimal wealth process, whose structure motivates the introduction of a new, distorted measure and a related market. we then build a striking correspondence between the forward rank-dependent criteria in the original market and forward criteria without probability distortions in the auxiliary market. this connection also provides a direct construction method for forward rank-dependent criteria. a byproduct of our work are some new results on the so-called dynamic utilities and on time-inconsistent problems in the classical (backward) setting.',\n",
       " 751: 'community detection is a key data analysis problem across different fields. during the past decades, numerous algorithms have been proposed to address this issue. however, most work on community detection does not address the issue of statistical significance. although some research efforts have been made towards mining statistically significant communities, deriving an analytical solution of p-value for one community under the configuration model is still a challenging mission that remains unsolved. the configuration model is a widely used random graph model in community detection, in which the degree of each node is preserved in the generated random networks. to partially fulfill this void, we present a tight upper bound on the p-value of a single community under the configuration model, which can be used for quantifying the statistical significance of each community analytically. meanwhile, we present a local search method to detect statistically significant communities in an iterative manner. experimental results demonstrate that our method is comparable with the competing methods on detecting statistically significant communities.',\n",
       " 752: 'collective learning in economic development has been revealed by recent empirical studies, however, investigations on how to benefit most from its effects remain still lacking. in this paper, we explore the maximization of the collective learning effects using a simple propagation model to study the diversification of industries on real networks built on brazilian labor data. for the inter-regional learning, we find an optimal strategy that makes a balance between core and periphery industries in the initial activation, considering the core-periphery structure of the industry space--a network representation of the relatedness between industries. for the inter-regional learning, we find an optimal strategy that makes a balance between nearby and distant regions in establishing new spatial connections, considering the spatial structure of the integrated adjacent network that connects all regions. our findings suggest that the near to by random strategies are likely to make the best use of the collective learning effects in advancing regional economic development practices.',\n",
       " 753: \"the performance of face detectors has been largely improved with the development of convolutional neural network. however, it remains challenging for face detectors to detect tiny, occluded or blurry faces. besides, most face detectors can't locate face's position precisely and can't achieve high intersection-over-union (iou) scores. we assume that problems inside are inadequate use of supervision information and imbalance between semantics and details at all level feature maps in cnn even with feature pyramid networks (fpn). in this paper, we present a novel single-shot face detection network, named df$^2$s$^2$ (detection with feature fusion and segmentation supervision), which introduces a more effective feature fusion pyramid and a more efficient segmentation branch on resnet-50 to handle mentioned problems. specifically, inspired by fpn and senet, we apply semantic information from higher-level feature maps as contextual cues to augment low-level feature maps via a spatial and channel-wise attention style, preventing details from being covered by too much semantics and making semantics and details complement each other. we further propose a semantic segmentation branch to best utilize detection supervision information meanwhile applying attention mechanism in a self-supervised manner. the segmentation branch is supervised by weak segmentation ground-truth (no extra annotation is required) in a hierarchical manner, deprecated in the inference time so it wouldn't compromise the inference speed. we evaluate our model on wider face dataset and achieved state-of-art results.\",\n",
       " 754: 'we show that the polynomial s_{m,k}(a,b), that is the sum of all words in noncommuting variables a and b having length m and exactly k letters equal to b, is not equal to a sum of commutators and hermitian squares in the algebra r<x,y> where x^2=a and y^2=b, for all even values of m and k with 6 <= k <= m-10, and also for (m,k)=(12,6). this leaves only the case (m,k)=(16,8) open. this topic is of interest in connection with the lieb--seiringer formulation of the bessis--moussa--villani conjecture, which asks whether the trace of s_{m,k}(a,b)) is nonnegative for all positive semidefinite matrices a and b. these results eliminate the possibility of using \"descent + sum-of-squares\" to prove the bmv conjecture.   we also show that s_{m,4}(a,b) is equal to a sum of commutators and hermitian squares in r<a,b> when m is even and not a multiple of 4, which implies that the trace of s_{m,4}(a,b) is nonnegative for all hermitian matrices a and b, for these values of m.',\n",
       " 755: 'the bi-lipschitz geometry is one of the main subjects in the modern approach of singularity theory. however, it rises from works of important mathematicians of the last century, especially zariski. in this work we investigate the bi-lipschitz equisingularity of families of essentially isolated determinantal singularities inspired by the approach of mostowski and gaffney.',\n",
       " 756: 'we propose a new point of view for regularizing deep neural networks by using the norm of a reproducing kernel hilbert space (rkhs). even though this norm cannot be computed, it admits upper and lower approximations leading to various practical strategies. specifically, this perspective (i) provides a common umbrella for many existing regularization principles, including spectral norm and gradient penalties, or adversarial training, (ii) leads to new effective regularization penalties, and (iii) suggests hybrid strategies combining lower and upper bounds to get better approximations of the rkhs norm. we experimentally show this approach to be effective when learning on small datasets, or to obtain adversarially robust models.',\n",
       " 757: 'central galaxies (cgs) in massive halos live in unique environments with formation histories closely linked to that of the host halo. in local clusters they have larger sizes ($r_e$) and lower velocity dispersions (sigma) at fixed stellar mass m_star, and much larger r_e at a fixed $\\\\sigma$ than field and satellite galaxies (non-cgs). using spectroscopic observations of group galaxies selected from the cosmos survey, we compare the dynamical scaling relations of early-type cgs and non-cgs at z~0.6, to distinguish possible mechanisms that produce the required evolution. cgs are systematically offset towards larger r_e at fixed $\\\\sigma$ compared to non-cgs with similar m_star. the cg r_e-m_star relation also shows differences, primarily driven by a sub-population (~15%) of galaxies with large $r_e$, while the m_star-sigma relations are indistinguishable. these results are accentuated when double sersic profiles, which better fit light in the outer regions of galaxies, are adopted. they suggest that even group-scale cgs can develop extended components by these redshifts that can increase total $r_e$ and m_star estimates by factors of ~2. to probe the evolutionary link between our sample and cluster cgs, we also analyze two cluster samples at z~0.6 and z~0. we find similar results for the more massive halos at comparable z, but much more distinct cg scaling relations at low-z. thus, the rapid, late-time accretion of outer components, perhaps via the stripping and accretion of satellites, would appear to be a key feature that distinguishes the evolutionary history of cgs.',\n",
       " 758: 'we reanalyse the prospects for upcoming ultra-high energy cosmic ray experiments in connection with the phenomenology of super-heavy dark matter. we identify a set of observables well suited to reveal a possible anisotropy in the high energy cosmic ray flux induced by the decays of these particles, and quantify their performance via monte carlo simulations that mimic the outcome of near-future and next-generation experiments. the spherical and circular dipoles are able to tell isotropic and anisotropic fluxes apart at a confidence level as large as $4\\\\sigma$ or $5\\\\sigma$, depending on the dark matter profile. the forward-to-backward flux ratio yields a comparable result for relatively large opening angles of about 40~deg, but it is less performing once a very large number of events is considered. we also find that an actual experiment employing these observables and collecting 300~events at 60~eev would have a $50\\\\%$ chance of excluding isotropy against super-heavy dark matter at a significance of at least $3\\\\sigma$',\n",
       " 759: 'many applications donot have the benefit of the laws of physics to derive succinct descriptive models for observed data. in alternative, interdependencies among $n$ time series $\\\\{ x_{nk}, k>0 \\\\}_{n=1}^{n}$ are nowadays often captured by a graph or network $g$ that in practice may be very large. the network itself may change over time as well (i.e., as $g_k$). tracking brute force the changes of time varying networks presents major challenges, including the associated computational problems. further, a large set of networks may not lend itself to useful analysis. this paper approximates the time varying networks $\\\\left\\\\{g_k\\\\right\\\\}$ as weighted linear combinations of eigennetworks. the eigennetworks are fixed building blocks that are estimated by first learning the time series of graphs $g_k$ from the data $\\\\{ x_{nk}, k>0 \\\\}_{n=1}^{n}$, followed by a principal network analysis procedure. the weights of the eigennetwork representation are eigenfeatures and the time varying networks $\\\\left\\\\{g_k\\\\right\\\\}$ describe a trajectory in eigennetwork space. these eigentrajectories should be smooth since the networks $g_k$ vary at a much slower rate than the data $x_{nk}$, except when structural network shifts occur reflecting potentially an abrupt change in the underlying application and sources of the data. algorithms for learning the time series of graphs $\\\\left\\\\{g_k\\\\right\\\\}$, deriving the eigennetworks, eigenfeatures and eigentrajectories, and detecting changepoints are presented. experiments on simulated data and with two real time series data (a voting record of the us senate and genetic expression data for the \\\\textit{drosophila melanogaster} as it goes through its life cycle) demonstrate the performance of the learning and provide interesting interpretations of the eigennetworks.',\n",
       " 760: 'for every metric space $x$ we introduce two cardinal characteristics $\\\\mathrm{cov}^\\\\flat(x)$ and $\\\\mathrm{cov}^\\\\sharp(x)$ describing the capacity of balls in $x$. we prove that these cardinal characteristics are invariant under coarse equivalence and prove that two ultrametric spaces $x,y$ are coarsely equivalent if $\\\\mathrm{cov}^\\\\flat(x)=\\\\mathrm{cov}^\\\\sharp(x)=\\\\mathrm{cov}^\\\\flat(y)=\\\\mathrm{cov}^\\\\sharp(y)$. this result implies that an ultrametric space $x$ is coarsely equivalent to an isometrically homogeneous ultrametric space if and only if $\\\\mathrm{cov}^\\\\flat(x)=\\\\mathrm{cov}^\\\\sharp(x)$. moreover, two isometrically homogeneous ultrametric spaces $x,y$ are coarsely equivalent if and only if $\\\\mathrm{cov}^\\\\sharp(x)=\\\\mathrm{cov}^\\\\sharp(y)$ if and only if each of these spaces coarsely embeds into the other space. this means that the coarse structure of an isometrically homogeneous ultrametric space $x$ is completely determined by the value of the cardinal $\\\\mathrm{cov}^\\\\sharp(x)=\\\\mathrm{cov}^\\\\flat(x)$.',\n",
       " 761: 'a recent approach based on bayesian inverse planning for the \"theory of mind\" has shown good performance in modeling human cognition. however, perfect inverse planning differs from human cognition during one kind of complex tasks due to human bounded rationality. one example is an environment in which there are many available plans for achieving a specific goal. we propose a \"plan predictability oriented model\" as a model of inferring other peoples\\' goals in complex environments. this model adds the bias that people prefer predictable plans. this bias is calculated with simple plan prediction. we tested this model with a behavioral experiment in which humans observed the partial path of goal-directed actions. our model had a higher correlation with human inference. we also confirmed the robustness of our model with complex tasks and determined that it can be improved by taking account of individual differences in \"bounded rationality\".',\n",
       " 762: 'besides its predicted promising high electron mobilities at room temperature, ptse2 bandgap sensitively depends on the number of monolayers combined by van der waals interaction according to our calculations. we understand this by using bandstructure calculations based on the density functional theory. it was found that the front orbitals of vbm and cbm are contributed mainly from pz and px+y orbitals of se which are sensitive to the out-plane and in-plane lattice constants, respectively. the van der waals force enhances the bonding out-of-plane, which in-turn influences the bonding in-plane. we found that the thickness dependent bandgap has the same origin as the strain dependent bandgap, which is from the change of the front orbital interactions. the work shows the flexibilities of tuning the electronic and optical properties of this compound in a wide range.',\n",
       " 763: 'let $m$ be a simply connected spin manifold of dimension at least six which admits a metric of positive scalar curvature. we show that the observer moduli space of positive scalar curvature metrics on $m$ has non-trivial higher homotopy groups.   moreover, denote by $\\\\mathcal{m}_0^+(m)$ the moduli space of positive scalar cuvature metrics on $m$ associated to the group of orientation-preserving diffeomorphisms of $m$. we show that if $m$ belongs to a certain class of manifolds which includes $(2n-2)$-connected $(4n-2)$-dimensional manifolds, then the fundamental group of $\\\\mathcal{m}_0^+(m)$ is non-trivial.',\n",
       " 764: 'the cryogenic dark matter search (cdms) utilizes large mass, 3\" diameter $\\\\times$ 1\" thick target masses as particle detectors. the target is instrumented with both phonon and ionization sensors and comparison of energy in each channel provides event-by-event classification of electron and nuclear recoils. fiducial volume is determined by the ability to obtain good phonon and ionization signal at a particular location. due to electronic band structure in germanium, electron mass is described by an anisotropic tensor with heavy mass aligned along the symmetry axis defined by the [111] miller index (l valley), resulting in large lateral component to the transport. the spatial distribution of electrons varies significantly for detectors which have their longitudinal axis orientations described by either the [100] or [111] miller indices. electric fields with large fringing component at high detector radius also affect the spatial distribution of electrons and holes. both effects are studied in a 3 dimensional monte carlo and the impact on fiducial volume is discussed.',\n",
       " 765: 'let $f(a,b,c,d)=\\\\sqrt{a^2+b^2}+\\\\sqrt{c^2+d^2}-\\\\sqrt{(a+c)^2+(b+d)^2}$, let $(a,b,c,d)$ stand for $a,b,c,d\\\\in\\\\mathbb z_{\\\\geq 0}$ such that $ad-bc=1$. define \\\\begin{equation} \\\\label{eq_main} f(s) = \\\\sum_{(a,b,c,d)} f(a,b,c,d)^s. \\\\end{equation} in other words, we consider the sum of the powers of the triangle inequality defects for the lattice parallelograms (in the first quadrant) of area one.   we prove that $f(s)$ converges when $s>1$ and diverges at $s=1/2$. (this papers differs from its published version: fedor petrov showed us how to easily prove that $f(s)$ converges for $s>2/3$ and diverges for $s\\\\leq 2/3$, see below.) we also prove $$\\\\sum\\\\limits_{\\\\substack{(a,b,c,d), 1\\\\leq a\\\\leq b, 1\\\\leq c\\\\leq d}} \\\\frac{1}{(a+b)^2(c+d)^2(a+b+c+d)^2} = 1/24,$$ and show a general method to obtain such formulae. the method comes from the consideration of the tropical analogue of the caustic curves, whose moduli give a complete set of continuous invariants on the space of convex domains.',\n",
       " 766: 'subdiffusive motion takes place at a much slower timescale than diffusive motion. as a preliminary step to studying reaction-subdiffusion pulled fronts, we consider here the hyperbolic limit $(t,x) \\\\to (t/\\\\varepsilon, x/\\\\varepsilon)$ of an age-structured equation describing the subdiffusive motion of, e.g., some protein inside a biological cell. solutions of the rescaled equations are known to satisfy a hamilton-jacobi equation in the formal limit $\\\\varepsilon \\\\to 0$. in this work we derive uniform lipschitz estimates, and establish the convergence towards the viscosity solution of the limiting hamilton-jacobi equation. the two main obstacles overcome in this work are the non-existence of an integrable stationary measure, and the importance of memory terms in subdiffusion.',\n",
       " 767: 'little by little, newspapers are revealing the bright future that artificial intelligence (ai) is building. intelligent machines will help everywhere. however, this bright future has a dark side: a dramatic job market contraction before its unpredictable transformation. hence, in a near future, large numbers of job seekers will need financial support while catching up with these novel unpredictable jobs. this possible job market crisis has an antidote inside. in fact, the rise of ai is sustained by the biggest knowledge theft of the recent years. learning ai machines are extracting knowledge from unaware skilled or unskilled workers by analyzing their interactions. by passionately doing their jobs, these workers are digging their own graves.   in this paper, we propose human-in-the-loop artificial intelligence (hit-ai) as a fairer paradigm for artificial intelligence systems. hit-ai will reward aware and unaware knowledge producers with a different scheme: decisions of ai systems generating revenues will repay the legitimate owners of the knowledge used for taking those decisions. as modern robin hoods, hit-ai researchers should fight for a fairer artificial intelligence that gives back what it steals.',\n",
       " 768: 'sequence-to-sequence attention-based models on subword units allow simple open-vocabulary end-to-end speech recognition. in this work, we show that such models can achieve competitive results on the switchboard 300h and librispeech 1000h tasks. in particular, we report the state-of-the-art word error rates (wer) of 3.54% on the dev-clean and 3.82% on the test-clean evaluation subsets of librispeech. we introduce a new pretraining scheme by starting with a high time reduction factor and lowering it during training, which is crucial both for convergence and final performance. in some experiments, we also use an auxiliary ctc loss function to help the convergence. in addition, we train long short-term memory (lstm) language models on subword units. by shallow fusion, we report up to 27% relative improvements in wer over the attention baseline without a language model.',\n",
       " 769: 'we develop variational matrix product state (mps) methods with symmetries to determine dispersion relations of one dimensional quantum lattices as a function of momentum and preset quantum number. we test our methods on the xxz spin chain, the hubbard model and a non-integrable extended hubbard model, and determine the excitation spectra with a precision similar to the one of the ground state. the formulation in terms of quantum numbers makes the topological nature of spinons and holons very explicit. in addition, the method also enables an easy and efficient direct calculation of the necessary magnetic field or chemical potential required for a certain ground state magnetization or particle density.',\n",
       " 770: 'lindel{\\\\\"o}f\\'s hypothesis, one of the most important open problems in the history of mathematics, states that for large $t$, riemann\\'s zeta function $\\\\zeta(1/2+it)$ is of order $o(t^{\\\\varepsilon})$ for any $\\\\varepsilon>0$ . it is well known that for large $t$, the leading order asymptotics of the riemann zeta function can be expressed in terms of a transcendental exponential sum. the usual approach to the lindel\\\\\"of hypothesis involves the use of ingenious techniques for the estimation of this sum. however, since such estimates can not yield an asymptotic formula for the above sum, it appears that this strategy cannot lead to the proof of lindel\\\\\"of\\'s hypothesis. here, a completely different approach is introduced. in particular, a novel linear integral equation is derived for $|\\\\zeta(\\\\sigma+it)|^2, \\\\ 0<\\\\sigma<1$ whose asymptotic analysis yields asymptotic results for a certain riemann zeta-type double exponential sum. this sum has the same structure as the sum describing the leading asymptotics of $|\\\\zeta(\\\\sigma+it)|^2$, namely it involves $m_1^{-\\\\sigma-it}m_2^{-\\\\sigma-it}$, but its summation limits are different than those of the sum corresponding to $|\\\\zeta(\\\\sigma+it)|^2$. the analysis of the above integral equation requires the asymptotic estimation of four different integrals denoted by $i_1,i_2,\\\\tilde{i}_3,\\\\tilde{i}_4$, as well as the derivation of an exact relation between certain double exponential sums. here, the latter relation is derived, and also the rigorous analysis of the first two integrals $i_1$ and $i_2$ is presented. for the remaining two integrals, formal results are only derived that suggest a possible roadmap for the derivation of rigorous asymptotic results of the above double exponential sum, as well as for other sums associated with $|\\\\zeta(\\\\sigma+it)|^2$. additional developments suggested by the above novel approach are also discussed.',\n",
       " 771: 'we investigate a decomposition of a unital lindblad dynamical map of an open quantum system into two distinct types of mapping on the hilbert-schmidt space of quantum states. one component of the decomposed map corresponds to reversible behaviours, while the other to irreversible characteristics. for a finite dimensional system, we employ real vectors or bloch representations and express a dynamical map on the state space as a real matrix acting on the representation. it is found that rotation and scaling transformations on the real vector space, obtained from the real-polar decomposition, form building blocks for the dynamical map. consequently, the change of the linear entropy or purity, which indicates dissipative behaviours, depends only on the scaling part of the dynamical matrix. the rate of change of the entropy depends on the structure of the scaling part of the dynamical matrix, such as eigensubspace partitioning, and its relationship with the initial state. in particular, the linear entropy is expressed as a weighted sum of the exponential-decay functions in each scaling component, where the weight is equal to $\\\\vert\\\\vec{x}_k(\\\\rho)\\\\vert^2$ of the initial state $\\\\rho$ in the subspace. the dissipative behaviours and the partition of eigensubspaces in the decomposition are discussed and illustrated for qubit systems.',\n",
       " 772: 'in the most works which deal with eas the cr energy spectrum is deduced by means of the model defined dependence $e_0=a\\\\cdot{n_e}^{\\\\alpha}$. an electron total number $n_e$ is evaluated by integration of the nkg-function f(r). this algorithm breaks down for young eas with age parameter $s\\\\sim0$. this work shows, that part of the young eas becomes large in the range $n_e\\\\geq10^7$, it cause to divergency of the $n_e$ integral for them and distorts the shape of eas (cr) spectrum. a final analysis of the experimental data permits to conclude that eas spectrum has local maximum at $n_e\\\\sim10^9$, which results in a decrease of the eas spectrum slope for $n_e\\\\geq10^7$ (inverse break or \"knee\"). a local maximum can arise because of the additional cr component in the range $e_0\\\\geq10$ pev.',\n",
       " 773: 'we study the behavior of bivariate empirical copula process $\\\\mathbb{g}_n(\\\\cdot,\\\\cdot)$ on pavements $[0,k_n/n]^2$ of $[0,1]^2,$ where $k_n$ is a sequence of positive constants fulfilling some conditions. we provide a upper bound for the strong approximation of $\\\\mathbb{g}_n(\\\\cdot,\\\\cdot)$ by a gaussian process when $k_n/n \\\\searrow \\\\gamma$ as $n\\\\rightarrow \\\\infty,$ where $0 \\\\leq \\\\gamma \\\\leq 1.$',\n",
       " 774: 'scanning tunnelling microscopy and low energy electron diffraction show a dimerization-like reconstruction in the one-dimensional atomic chains on bi(114) at low temperatures. while one-dimensional systems are generally unstable against such a distortion, its observation is not expected for this particular surface, since there are several factors that should prevent it: one is the particular spin texture of the fermi surface, which resembles a one-dimensional topological state, and spin protection should hence prevent the formation of the reconstruction. the second is the very short nesting vector $2 k_f$, which is inconsistent with the observed lattice distortion. a nesting-driven mechanism of the reconstruction is indeed excluded by the absence of any changes in the electronic structure near the fermi surface, as observed by angle-resolved photoemission spectroscopy. however, distinct changes in the electronic structure at higher binding energies are found to accompany the structural phase transition. this, as well as the observed short correlation length of the pairing distortion, suggest that the transition is of the strong coupling type and driven by phonon entropy rather than electronic entropy.',\n",
       " 775: 'accurate beam alignment is essential for beam-based millimeter wave communications. conventional beam sweeping solutions often have large overhead, which is unacceptable for mobile applications like vehicle-to-everything. learning-based solutions that leverage sensor data like position to identify good beam directions are one approach to reduce the overhead. most existing solutions, though, are supervised-learning where the training data is collected beforehand. in this paper, we use a multi-armed bandit framework to develop online learning algorithms for beam pair selection and refinement. the beam pair selection algorithm learns coarse beam directions in some predefined beam codebook, e.g., in discrete angles separated by the 3db beamwidths. the beam refinement fine-tunes the identified directions to match the peak of the power angular spectrum at that position. the beam pair selection uses the upper confidence bound (ucb) with a newly proposed risk-aware feature, while the beam refinement uses a modified optimistic optimization algorithm. the proposed algorithms learn to recommend good beam pairs quickly. when using 16x16 arrays at both the transmitter and receiver, it can achieve on average 1db gain over the exhaustive search (over 271x271 beam pairs) on the unrefined codebook within 100 time-steps with a training budget of only 30 beam pairs.',\n",
       " 776: 'the eros-2 project has been designed to search for microlensing events towards any dense stellar field. the densest parts of the galactic spiral arms have been monitored to maximize the microlensing signal expected from the stars of the galactic disk and bulge. 12.9 million stars have been monitored during 7 seasons towards 4 directions in the galactic plane, away from the galactic center. a total of 27 microlensing event candidates have been found. estimates of the optical depths from the 22 best events are provided. a first order interpretation shows that simple galactic models with a standard disk and an elongated bulge are in agreement with our observations. we find that the average microlensing optical depth towards the complete eros-cataloged stars of the spiral arms is $\\\\bar{\\\\tau} =0.51\\\\pm .13\\\\times 10^{-6}$, a number that is stable when the selection criteria are moderately varied. as the eros catalog is almost complete up to $i_c=18.5$, the optical depth estimated for the sub-sample of bright target stars with $i_c<18.5$ ($\\\\bar{\\\\tau}=0.39\\\\pm >.11\\\\times 10^{-6}$) is easier to interpret. the set of microlensing events that we have observed is consistent with a simple galactic model. a more precise interpretation would require either a better knowledge of the distance distribution of the target stars, or a simulation based on a galactic model. for this purpose, we define and discuss the concept of optical depth for a given catalog or for a limiting magnitude.',\n",
       " 777: 'one challenge with neural ranking is the need for a large amount of manually-labeled relevance judgments for training. in contrast with prior work, we examine the use of weak supervision sources for training that yield pseudo query-document pairs that already exhibit relevance (e.g., newswire headline-content pairs and encyclopedic heading-paragraph pairs). we also propose filtering techniques to eliminate training samples that are too far out of domain using two techniques: a heuristic-based approach and novel supervised filter that re-purposes a neural ranker. using several leading neural ranking architectures and multiple weak supervision datasets, we show that these sources of training pairs are effective on their own (outperforming prior weak supervision techniques), and that filtering can further improve performance.',\n",
       " 778: 'the dynamics and influence of fake news on twitter during the 2016 us presidential election remains to be clarified. here, we use a dataset of 171 million tweets in the five months preceding the election day to identify 30 million tweets, from 2.2 million users, which contain a link to news outlets. based on a classification of news outlets curated by www.opensources.co, we find that 25% of these tweets spread either fake or extremely biased news. we characterize the networks of information flow to find the most influential spreaders of fake and traditional news and use causal modeling to uncover how fake news influenced the presidential election. we find that, while top influencers spreading traditional center and left leaning news largely influence the activity of clinton supporters, this causality is reversed for the fake news: the activity of trump supporters influences the dynamics of the top fake news spreaders.',\n",
       " 779: 'elliptic curve cryptography (ecc) is used in many security systems due to its small key size and high security as compared to the other cryptosystems. in many well-known security systems substitution box (s-box) is the only non-linear component. recently, it is shown that the security of a cryptosystem can be improved by using dynamic s-boxes instead of a static s-box. this fact necessitates the construction of new secure s-boxes. in this paper, we propose an efficient method for the generation of s-boxes based on a class of mordell elliptic curves (mecs) over prime fields by defining different total orders. the proposed scheme is developed in such a way that for each input it outputs an s-box in linear time and constant space. due to this property, our method takes less time and space as compared to all existing s-box construction methods over elliptic curve. furthermore, it is shown by the computational results that the proposed method is capable of generating cryptographically strong s-boxes with comparable security to some of the existing s-boxes constructed over different mathematical structures.',\n",
       " 780: 'we construct a minimal generating set of the level 2 mapping class group of a nonorientable surface of genus $g$, and determine its abelianization for $g\\\\ge4$.',\n",
       " 781: 'the theoretical explanation for deep neural network (dnn) is still an open problem. in this paper dnn is considered as a discrete-time dynamical system due to its layered structure. the complexity provided by the nonlinearity in the dynamics is analyzed in terms of topological entropy and chaos characterized by lyapunov exponents. the properties revealed for the dynamics of dnn are applied to analyze the corresponding capabilities of classification and generalization.',\n",
       " 782: 'we complete our recent classification of compact inner symmetric spaces with weakly complex tangent bundle by filling up a case which was left open, and extend this classification to the larger category of compact homogeneous spaces with positive euler characteristic. we show that a simply connected compact equal rank homogeneous space has weakly complex tangent bundle if and only if it is a product of compact equal rank homogeneous spaces which either carry an invariant almost complex structure (and are classified by hermann), or have stably trivial tangent bundle (and are classified by singhof and wemmer), or belong to an explicit list of weakly complex spaces which have neither stably trivial tangent bundle, nor carry invariant almost complex structures.',\n",
       " 783: 'this paper introduces a theoretical framework for the analysis and control of the stochastic susceptible-infected-removed (sir) spreading process over a network of heterogeneous agents. in our analysis, we analyze the exact networked markov process describing the sir model, without resorting to mean-field approximations, and introduce a convex optimization framework to find an efficient allocation of resources to contain the expected number of accumulated infections over time. numerical simulations are presented to illustrate the effectiveness of the obtained results.',\n",
       " 784: 'the transcription of handwritten text on images is one task in machine learning and one solution to solve it is using multi-dimensional recurrent neural networks (mdrnn) with connectionist temporal classification (ctc). the rnns can contain special units, the long short-term memory (lstm) cells. they are able to learn long term dependencies but they get unstable when the dimension is chosen greater than one. we defined some useful and necessary properties for the one-dimensional lstm cell and extend them in the multi-dimensional case. thereby we introduce several new cells with better stability. we present a method to design cells using the theory of linear shift invariant systems. the new cells are compared to the lstm cell on the ifn/enit and rimes database, where we can improve the recognition rate compared to the lstm cell. so each application where the lstm cells in mdrnns are used could be improved by substituting them by the new developed cells.',\n",
       " 785: \"automatic feature extraction using neural networks has accomplished remarkable success for images, but for sound recognition, these models are usually modified to fit the nature of the multi-dimensional temporal representation of the audio signal in spectrograms. this may not efficiently harness the time-frequency representation of the signal. the conditional neural network (clnn) takes into consideration the interrelation between the temporal frames, and the masked conditional neural network (mclnn) extends upon the clnn by forcing a systematic sparseness over the network's weights using a binary mask. the masking allows the network to learn about frequency bands rather than bins, mimicking a filterbank used in signal transformations such as mfcc. additionally, the mask is designed to consider various combinations of features, which automates the feature hand-crafting process. we applied the mclnn for the environmental sound recognition problem using the urbansound8k, yornoise, esc-10 and esc-50 datasets. the mclnn have achieved competitive performance compared to state-of-the-art convolutional neural networks and hand-crafted attempts.\",\n",
       " 786: 'we consider the phase diagram of hadronic matter as a function of temperature, t , and baryon chemical potential, mu. currently the dominant paradigm is a line of first order transitions which ends at a critical endpoint.   in this work we suggest that spatially inhomogenous phases are a generic feature of the hadronic phase diagram at nonzero mu and low t . familiar examples are pion and kaon condensates. at higher densities, we argue that these condensates connect onto chiral spirals in a quarkyonic regime. both of these phases exhibit the spontaneous breaking of a global u(1) symmetry and quasi-long range order, analogous to smectic liquid crystals. we argue that there is a continuous line of first order transitions which separate spatially inhomogenous from homogenous phases, where the latter can be either a hadronic phase or a quark-gluon plasma.   while mean field theory predicts that there is a lifshitz point along this line of first order transitions, in three spatial dimensions strong infrared fluctuations wash out any lifshitz point. using known results from inhomogenous polymers, we suggest that instead there is a lifshitz regime. non-perturbative effects are large in this regime, where the momentum dependent terms for the propagators of pions and associated modes are dominated not by terms quadratic in momenta, but quartic. fluctuations in a lifshitz regime may be directly relevant to the collisions of heavy ions at (relatively) low energies, sqrt(s)/a : 1 to 20 gev.',\n",
       " 787: 'although multiplier bimonoids in general are not known to correspond to comonoids in any monoidal category, we classify them in terms of maps from the catalan simplicial set to another suitable simplicial set; thus they can be regarded as (co)monoids in something more general than a monoidal category (namely, the simplicial set itself). we analyze the particular simplicial maps corresponding to that class of multiplier bimonoids which can be regarded as comonoids.',\n",
       " 788: \"in a classical work of the 1950's, lee and yang proved that for fixed nonnegative temperature, the zeros of the partition functions of a ferromagnetic ising model always lie on the unit circle in the complex magnetic field. zeros of the partition function in the complex temperature were then considered by fisher, when the magnetic field is set to zero. limiting distributions of lee-yang and of fisher zeros are physically important as they control phase transitions in the model. one can also consider the zeros of the partition function simultaneously in both complex magnetic field and complex temperature. they form an algebraic curve called the lee-yang-fisher (lyf) zeros. in this paper we continue studying their limiting distribution for the diamond hierarchical lattice (dhl). in this case, it can be described in terms of the dynamics of an explicit rational function r in two variables (the migdal-kadanoff renormalization transformation). we study properties of the fatou and julia sets of this transformation and then we prove that the lee-yang-fisher zeros are equidistributed with respect to a dynamical (1,1)-current in the projective space. the free energy of the lattice gets interpreted as the pluripotential of this current. we also prove a more general equidistribution theorem which applies to rational mappings having indeterminate points, including the migdal-kadanoff renormalization transformation of various other hierarchical lattices.\",\n",
       " 789: 'a new algorithm has been developed for delineation of significant points of various electrocardiographic signal (ecg) waves, taking into account information from all available leads and providing similar or higher accuracy in comparison with other modern technologies. the test results for the qt database show a sensitivity above 97% when detecting ecg wave peaks and 96% for their onsets and offsets, as well as better positive predictive value compared to the previously known algorithms. in contrast to the previously published algorithms, the proposed approach also allows one to determine the morphology of waves. the segmentation mean errors of all significant points are below the tolerances defined by the committee of general standards for electrocardiography (cse).',\n",
       " 790: 'a theory usually comprises assumptions and deduced predictions from them. in this paper, empirical evidences corroborate with assumptions about time for a decision making facing known probabilities and outcomes.',\n",
       " 791: 'loft is one of the four medium mission candidates (m3), selected by esa in the framework of the cosmic vision programme (2015-2025), for feasibility study. if approved by esa in 2014, its launch is foreseen in 2022-2024. loft is being designed to observe x-ray sources with excellent temporal resolution and very good spectral capability. its main objectives are to directly probe the motion of matter in the very close vicinity of black holes (strong field gravity), as well as to study the physics of ultra dense matter (neutron stars). the payload includes a large area detector (lad) and a wide field monitor (wfm). the lad is a collimated (< 1 degree field of view) experiment operating in the energy range 2-30 kev, with a 10 m2 peak effective area and an energy resolution of 260 ev at 6 kev. the wfm will operate in almost the same energy range than the lad, 2-50 kev, enabling simultaneous monitoring of a few-steradian wide field of view, with an angular resolution of < 5 arcmin. in addition to its main scientific objectives, loft will also do a complete plan of observatory science, studying with unprecedented detail in the 2-80 kev range several transient phenomena, like accreting white dwarfs in cataclysmic variables, novae in outburst (internal and external shocks in the ejecta in classical novae, and shocks with the wind of the companion in symbiotic recurrent novae) and post-outburst novae (once accretion is re established).',\n",
       " 792: 'electrical signaling via voltage-gated ion channels depends upon the function of a voltage sensor (vs), identified with the s1-s4 domain in voltage-gated k+ channels. here we investigate some energetic aspects of the sliding-helix model of the vs using simulations based on vs charges, linear dielectrics and whole-body motion. model electrostatics in voltage-clamped boundary conditions are solved using a boundary element method. the statistical mechanical consequences of the electrostatic configurational energy are computed to gain insight into the sliding-helix mechanism and to predict experimentally measured ensemble properties such as gating charge displaced by an applied voltage. those consequences and ensemble properties are investigated for two alternate s4 configurations, \\\\alpha- and 3(10)-helical. both forms of vs are found to have an inherent electrostatic stability. maximal charge displacement is limited by geometry, specifically the range of movement where s4 charges and counter-charges overlap in the region of weak dielectric. charge displacement responds more steeply to voltage in the \\\\alpha-helical than the 3(10)-helical sensor. this difference is due to differences on the order of 0.1 ev in the landscapes of electrostatic energy. as a step toward integrating these vs models into a full-channel model, we include a hypothetical external load in the hamiltonian of the system and analyze the energetic in/output relation of the vs.',\n",
       " 793: 'magnetic insulators are a key resource for next-generation spintronic and topological devices. the family of layered metal halides promises ultrathin insulating multiferroics, spin liquids, and ferromagnets, but new characterization methods are required to unlock their potential. here, we report tunneling through the layered magnetic insulator cri3 as a function of temperature and applied magnetic field. we electrically detect the magnetic ground state and inter-layer coupling and observe a field-induced metamagnetic transition. the metamagnetic transition results in magnetoresistances of 95%, 300%, and 550% for bilayer, trilayer, and tetralayer cri3 barriers, respectively. we further measure inelastic tunneling spectra for our junctions, unveiling a rich spectrum of collective magnetic excitations (magnons) in cri3. our results establish vertical tunneling as a versatile probe of magnetism in atomically thin insulators.',\n",
       " 794: 'the riemann-hilbert correspondence embeds the triangulated category of (not necessarily regular) holonomic d-modules into that of $\\\\mathbb r$-constructible enhanced ind-sheaves. the source category has a standard t-structure. here, we provide the target category with a middle perversity t-structure, and prove that the embedding is exact.',\n",
       " 795: \"a quantitative understanding of organism-level behavior requires predictive models that can capture the richness of behavioral phenotypes, yet are simple enough to connect with underlying mechanistic processes. here we investigate the motile behavior of nematodes at the level of their translational motion on surfaces driven by undulatory propulsion. we broadly sample the nematode behavioral repertoire by measuring motile trajectories of the canonical lab strain $c. elegans$ n2 as well as wild strains and distant species. we focus on trajectory dynamics over timescales spanning the transition from ballistic (straight) to diffusive (random) movement and find that salient features of the motility statistics are captured by a random walk model with independent dynamics in the speed, bearing and reversal events. we show that the model parameters vary among species in a correlated, low-dimensional manner suggestive of a common mode of behavioral control and a trade-off between exploration and exploitation. the distribution of phenotypes along this primary mode of variation reveals that not only the mean but also the variance varies considerably across strains, suggesting that these nematode lineages employ contrasting ``bet-hedging'' strategies for foraging.\",\n",
       " 796: \"esnault asked whether every smooth complex projective variety with infinite fundamental group has a nonzero symmetric differential (a section of a symmetric power of the cotangent bundle). in a sense, this would mean that every variety with infinite fundamental group has some nonpositive curvature.   we show that the answer to esnault's question is positive when the fundamental group has a finite-dimensional representation over some field with infinite image. this applies to all known varieties with infinite fundamental group. along the way, we produce many symmetric differentials on the base of a variation of hodge structures.   one interest of these results is that symmetric differentials give information in the direction of kobayashi hyperbolicity. for example, they limit how many rational curves the variety can contain.\",\n",
       " 797: 'this paper initiates the study of energy-efficiency gains provided by caching. we focus on the cache-aided gaussian interference channel in the low-snr regime. we propose a strategy that creates content overlaps at the transmitter caches to allow for co-operation between the transmitters. this co-operation yields a beamforming gain, which has to be traded off against a multicasting gain. we evaluate the performance of this strategy and show its approximate optimality in both the single-receiver case and the single-transmitter case.',\n",
       " 798: 'cloud computing is becoming an essential component of modern computer and communication systems. the available resources at the cloud such as computing nodes, storage, databases, etc. are often packaged in the form of virtual machines (vms) to be used by remotely located client applications for computational tasks. however, the cloud has a limited number of vms available, which have to be efficiently utilized to generate higher productivity and subsequently generate maximum revenue. client applications generate requests with computational tasks at random times with random complexity to be processed by the cloud. the cloud service provider (csp) has to decide whether to allocate a vm to a task at hand or to wait for a higher complexity task in the future. we propose a threshold-based mechanism to optimally decide the allocation and pricing of vms to sequentially arriving requests in order to maximize the revenue of the csp over a finite time horizon. moreover, we develop an adaptive and resilient framework based that can counter the effect of realtime changes in the number of available vms at the cloud server, the frequency and nature of arriving tasks on the revenue of the csp.',\n",
       " 799: 'we use the terms \"$\\\\infty$-categories\" and \"$\\\\infty$-functors\" to mean the objects and morphisms in an \"$\\\\infty$-cosmos.\" quasi-categories, segal categories, complete segal spaces, naturally marked simplicial sets, iterated complete segal spaces, $\\\\theta_n$-spaces, and fibered versions of each of these are all $\\\\infty$-categories in this sense. we show that the basic category theory of $\\\\infty$-categories and $\\\\infty$-functors can be developed from the axioms of an $\\\\infty$-cosmos; indeed, most of the work is internal to a strict 2-category of $\\\\infty$-categories, $\\\\infty$-functors, and natural transformations. in the $\\\\infty$-cosmos of quasi-categories, we recapture precisely the same theory developed by joyal and lurie, although in most cases our definitions, which are 2-categorical rather than combinatorial in nature, present a new incarnation of the standard concepts.   in the first lecture, we define an $\\\\infty$-cosmos and introduce its \"homotopy 2-category,\" using formal category theory to define and study equivalences and adjunctions between $\\\\infty$-categories. in the second lecture, we study (co)limits of diagrams taking values in an $\\\\infty$-category and the relationship between (co)limits and adjunctions. in the third lecture, we introduce comma $\\\\infty$-categories, which are used to encode the universal properties of (co)limits and adjointness and prove \"model independence\" results. in the fourth lecture, we introduce (co)cartesian fibrations, describe the calculus of \"modules\" between $\\\\infty$-categories, and use this framework to prove the yoneda lemma and develop the theory of pointwise kan extensions of $\\\\infty$-functors.',\n",
       " 800: 'we study some constructions on distributions in a uniform $p$-adic context, and also in large positive characteristic, using model theoretic methods. we introduce a class of distributions which we call distributions of ${\\\\mathscr c}^{\\\\mathrm{exp}}$-class and which is based on the notion of ${\\\\mathscr c}^{\\\\mathrm{exp}}$-class functions from [6]. this class of distributions is stable under fourier transformation and has various forms of uniform behavior across non-archimedean local fields. we study wave front sets, pull-backs and push-forwards of distributions of this class. in particular we show that the wave front set is always equal to the complement of the zero locus of a ${\\\\mathscr c}^{\\\\mathrm{exp}}$-class function. we first revise and generalize some of the results of heifetz that he developed in the $p$-adic context by analogy to results about real wave front sets by h\\\\\"ormander. in the final section, we study sizes of neighborhoods of local constancy of schwartz-bruhat functions and their push forwards in relation to discriminants.',\n",
       " 801: 'active learning is a type of sequential design for supervised machine learning, in which the learning algorithm sequentially requests the labels of selected instances from a large pool of unlabeled data points. the objective is to produce a classifier of relatively low risk, as measured under the 0-1 loss, ideally using fewer label requests than the number of random labeled data points sufficient to achieve the same. this work investigates the potential uses of surrogate loss functions in the context of active learning. specifically, it presents an active learning algorithm based on an arbitrary classification-calibrated surrogate loss function, along with an analysis of the number of label requests sufficient for the classifier returned by the algorithm to achieve a given risk under the 0-1 loss. interestingly, these results cannot be obtained by simply optimizing the surrogate risk via active learning to an extent sufficient to provide a guarantee on the 0-1 loss, as is common practice in the analysis of surrogate losses for passive learning. some of the results have additional implications for the use of surrogate losses in passive learning.',\n",
       " 802: 'an adaptive agent predicting the future state of an environment must weigh trust in new observations against prior experiences. in this light, we propose a view of the adaptive immune system as a dynamic bayesian machinery that updates its memory repertoire by balancing evidence from new pathogen encounters against past experience of infection to predict and prepare for future threats. this framework links the observed initial rapid increase of the memory pool early in life followed by a mid-life plateau to the ease of learning salient features of sparse environments. we also derive a modulated memory pool update rule in agreement with current vaccine response experiments. our results suggest that pathogenic environments are sparse and that memory repertoires significantly decrease infection costs even with moderate sampling. the predicted optimal update scheme maps onto commonly considered competitive dynamics for antigen receptors.',\n",
       " 803: 'audio tagging aims to assign one or several tags to an audio clip. most of the datasets are weakly labelled, which means only the tags of the clip are known, without knowing the occurrence time of the tags. the labeling of an audio clip is often based on the audio events in the clip and no event level label is provided to the user. previous works have used the bag of frames model assume the tags occur all the time, which is not the case in practice. we propose a joint detection-classification (jdc) model to detect and classify the audio clip simultaneously. the jdc model has the ability to attend to informative and ignore uninformative sounds. then only informative regions are used for classification. experimental results on the \"chime home\" dataset show that the jdc model reduces the equal error rate (eer) from 19.0% to 16.9%. more interestingly, the audio event detector is trained successfully without needing the event level label.',\n",
       " 804: 'in this paper, we explore the nature of central idempotents of schur rings over finite groups. we introduce the concept of a lattice schur ring and explore properties of these kinds of schur rings. in particular, the primitive, central idempotents of lattice schur rings are completely determined. for a general schur ring $s$, $s$ contains a maximal lattice schur ring, whose central, primitive idempotents form a system of pairwise orthogonal, central idempotents in $s$. we show that if $s$ is a schur ring with rational coefficients over a cyclic group, then these idempotents are always primitive and are spanned by the normal subgroups contained in $s$. furthermore, a wedderburn decomposition of schur rings over cyclic groups is given. some examples of schur rings over non-cyclic groups will also be explored.',\n",
       " 805: 'we study a discrete time self interacting random process on graphs, which we call greedy random walk. the walker is located initially at some vertex. as time evolves, each vertex maintains the set of adjacent edges touching it that have not been crossed yet by the walker. at each step, the walker being at some vertex, picks an adjacent edge among the edges that have not traversed thus far according to some (deterministic or randomized) rule. if all the adjacent edges have already been traversed, then an adjacent edge is chosen uniformly at random. after picking an edge the walk jumps along it to the neighboring vertex. we show that the expected edge cover time of the greedy random walk is linear in the number of edges for certain natural families of graphs. examples of such graphs include the complete graph, even degree expanders of logarithmic girth, and the hypercube graph. we also show that grw is transient in $\\\\z^d$ for all $d \\\\geq 3$.',\n",
       " 806: 'the adaptive immune system of vertebrates can detect, respond to, and memorize diverse pathogens from past experience. while the clonal selection of t helper (th) cells is the simple and established mechanism to better recognize new pathogens, the question that still remains unexplored is how the th cells can acquire better ways to bias the responses of immune cells for eliminating pathogens more efficiently by translating the recognized antigen information into regulatory signals. in this work, we address this problem by associating the adaptive immune network organized by the th cells with reinforcement learning (rl). by employing recent advancements of network-based rl, we show that the th immune network can acquire the association between antigen patterns of and the effective responses to pathogens. moreover, the clonal selection as well as other inter-cellular interactions are derived as a learning rule of the network. we also demonstrate that the stationary clone-size distribution after learning shares characteristic features with those observed experimentally. our theoretical framework may contribute to revising and renewing our understanding of adaptive immunity as a learning system.',\n",
       " 807: \"the square kilometre array (ska), which will be the world's largest radio telescope, will enhance and boost a large number of science projects, including the search for pulsars. the frequency domain acceleration search is an efficient approach to search for binary pulsars. a significant part of it is the harmonic-summing module, which is the research subject of this paper. most of the operations in the harmonic-summing module are relatively cheap operations for fpgas. the main challenge is the large number of point accesses to off-chip memory which are not consecutive but irregular. although harmonic-summing alone might not be targeted for fpga acceleration, it is a part of the pulsar search pipeline that contains many other compute-intensive modules, which are efficiently executed on fpga. hence having the harmonic-summing also on the fpga will avoid off-board communication, which could destroy other acceleration benefits. two types of harmonic-summing approaches are investigated in this paper: 1) storing intermediate data in off-chip memory and 2) processing the input signals directly without storing. for the second type, two approaches of caching data are proposed and evaluated: 1) preloading points that are frequently touched 2) preloading all necessary points that are used to generate a chunk of output points. opencl is adopted to implement the proposed approaches. in an extensive experimental evaluation, the same opencl kernel codes are evaluated on fpga boards and gpu cards. regarding the proposed preloading methods, preloading all necessary points method while reordering the input signals is faster than all the other methods. while in raw performance a single fpga board cannot compete with a gpu, in terms of energy dissipation, gpu costs up to 2.6x times more energy than that of fpgas in executing the same ndrange kernels.\",\n",
       " 808: 'in this paper, we study the linear systems $|-mk_x|$ on fano varieties $x$ with klt singularities. in a given dimension $d$, we prove $|-mk_x|$ is non-empty and contains an element with \"good singularities\" for some natural number $m$ depending only on $d$; if in addition $x$ is $\\\\epsilon$-lc for some $\\\\epsilon>0$, then we show that we can choose $m$ depending only on $d$ and $\\\\epsilon$ so that $|-mk_x|$ defines a birational map. further, we prove shokurov\\'s conjecture on boundedness of complements, and show that certain classes of fano varieties form bounded families.',\n",
       " 809: \"astrophysical bow shocks are a common result of the interaction between two supersonic plasma flows, such as winds or jets from stars or active galaxies, or streams due to the relative motion between a star and the interstellar medium. for cylindrically symmetric bow shocks, we develop a general theory for the effects of inclination angle on the apparent shape. we propose a new two-dimensional classification scheme for bow shapes, which is based on dimensionless geometric ratios that can be estimated from observational images. the two ratios are related to the flatness of the bow's apex, which we term planitude and the openness of its wings, which we term alatude. we calculate the expected distribution in the planitude-alatude plane for a variety of simple geometrical and physical models: quadrics of revolution, wilkinoids, cantoids, and ancantoids. we further test our methods against numerical magnetohydrodynamical simulations of stellar bow shocks and find that the apparent planitude and alatude measured from infrared dust continuum maps serve as accurate diagnostics of the shape of the contact discontinuity, which can be used to discriminate between different physical models. we present an algorithm that can determine the planitude and alatude from observed bow shock emission maps with a precision of 10 to 20%.\",\n",
       " 810: \"bilingual word embeddings have been widely used to capture the similarity of lexical semantics in different human languages. however, many applications, such as cross-lingual semantic search and question answering, can be largely benefited from the cross-lingual correspondence between sentences and lexicons. to bridge this gap, we propose a neural embedding model that leverages bilingual dictionaries. the proposed model is trained to map the literal word definitions to the cross-lingual target words, for which we explore with different sentence encoding techniques. to enhance the learning process on limited resources, our model adopts several critical learning strategies, including multi-task learning on different bridges of languages, and joint learning of the dictionary model with a bilingual word embedding model. experimental evaluation focuses on two applications. the results of the cross-lingual reverse dictionary retrieval task show our model's promising ability of comprehending bilingual concepts based on descriptions, and highlight the effectiveness of proposed learning strategies in improving performance. meanwhile, our model effectively addresses the bilingual paraphrase identification problem and significantly outperforms previous approaches.\",\n",
       " 811: 'flexible barriers are increasingly used for the protection from debris flow in mountainous terrain due to their low cost and environmental impact. however, a numerical tool for rational design of such structures is still missing. in this work, a hybrid computational framework is presented, using a total lagrangian formulation of the finite element method (fem) to represent a flexible barrier. the actions exerted on the structure by a debris flow are obtained from simultaneous simulations of the flow of a fluid-grain mixture, using two conveniently coupled solvers: the discrete element method (dem) governs the motion of the grains, while the free-surface non-newtonian fluid phase is solved using the lattice-boltzmann method (lbm). simulations on realistic geometries show the dependence of the momentum transfer on the barrier on the composition of the debris flow, challenging typical assumptions made during the design process today. in particular, we demonstrate that both grains and fluid contribute in a non-negligible way to the momentum transfer. moreover, we show how the flexibility of the barrier reduces its vulnerability to structural collapse, and how the stress is distributed on its fabric, highlighting potential weak points.',\n",
       " 812: 'aim: to evaluate a flow cytometry protocol that uses reference beads for the enumeration of live and dead bacteria present in a mixture. methods and results: mixtures of live and dead escherichia coli with live:dead concentration ratios varying from 0 to 100% were prepared. these samples were stained using syto 9 and propidium iodide and 6 {\\\\mu}m reference beads were added. bacteria present in live samples were enumerated by agar plate counting. bacteria present in dead samples were enumerated by agar plate counting before treatment with isopropanol. there is a linear relationship between the presented flow cytometry method and agar plate counts for live (r2 = 0.99) and dead e. coli (r2 = 0.93) concentrations of ca. 104 to 108 bacteria ml-1 within mixtures of live and dead bacteria. conclusions: reliable enumeration of live e. coli within a mixture of both live and dead was possible for concentration ratios of above 2.5% live and for the enumeration of dead e. coli the lower limit was ca. 20% dead. significance and impact of the study: the ability to obtain absolute cell concentrations is only available for selected flow cytometers, this study describes a method for accurate enumeration that is applicable to basic flow cytometers without specialised counting features. by demonstrating the application of the method to count e. coli, we raised points of consideration for using this fcm counting method and aim to lay the foundation for future work that uses similar methods for different bacterial strains.',\n",
       " 813: 'deep neural network models have been proven to be very successful in image classification tasks, also for medical diagnosis, but their main concern is its lack of interpretability. they use to work as intuition machines with high statistical confidence but unable to give interpretable explanations about the reported results. the vast amount of parameters of these models make difficult to infer a rationale interpretation from them. in this paper we present a diabetic retinopathy interpretable classifier able to classify retine images into the different levels of disease severity and of explaining its results by assigning a score for every point in the hidden and input space, evaluating its contribution to the final classification in a linear way. the generated visual maps can be interpreted by an expert in order to compare its own knowledge with the interpretation given by the model.',\n",
       " 814: \"in this article, global stabilization results for the two dimensional viscous burgers' equation, that is, convergence of unsteady solution to its constant steady state solution with any initial data, are established using a nonlinear neumann boundary feedback control law. then, using $c^0$-conforming finite element method in spatial direction, global stabilization results for the semidiscrete solution are shown. moreover, optimal error estimates in $l^\\\\infty(l^2)$ and in $l^\\\\infty(h^1)$-norms for the state variable and convergence result for the boundary feedback control law are derived. all the results preserve exponential stabilization property. finally, several numerical experiments are conducted to confirm our theoretical findings.\",\n",
       " 815: \"social networks influence health-related behaviors, such as obesity and smoking. while researchers have studied social networks as a driver for diffusion of influences and behaviors, it is less understood how the structure or topology of the network, in itself, impacts an individual's health behaviors and wellness state. in this paper, we investigate whether the structure or topology of a social network offers additional insight and predictability on an individual's health and wellness. we develop a model called the network-driven health predictor (netcare) that leverages features representative of social network structure. using a large longitudinal data set of students enrolled in the nethealth study at the university of notre dame, we show that the netcare model improves the overall prediction performance over the baseline models -- that use demographics and physical attributes -- by 38%, 65%, 55%, and 54% for the wellness states -- stress, happiness, positive attitude, and self-assessed health -- considered in this paper.\",\n",
       " 816: 'we study the stable pairs theory of local curves in 3-folds with descendent insertions. the rationality of the partition function of descendent invariants is established for the full local curve geometry (equivariant with respect to the scaling 2-torus) including relative conditions and odd degree insertions for higher genus curves. the capped 1-leg descendent vertex (equivariant with respect to the 3-torus) is also proven to be rational. the results are obtained by combining geometric constraints with a detailed analysis of the poles of the descendent vertex.',\n",
       " 817: \"as the decade turns, we reflect on nearly thirty years of successful manipulation of the world's public equity markets. this reflection highlights a few of the key enabling ingredients and lessons learned along the way. a quantitative understanding of market impact and its decay, which we cover briefly, lets you move long-term market prices to your advantage at acceptable cost. hiding your footprints turns out to be less important than moving prices in the direction most people want them to move. widespread (if misplaced) trust of market prices -- buttressed by overestimates of the cost of manipulation and underestimates of the benefits to certain market participants -- makes price manipulation a particularly valuable and profitable tool. of the many recent stories heralding the dawn of the present golden age of misinformation, the manipulation leading to the remarkable increase in the market capitalization of the world's publicly traded companies over the past three decades is among the best.\",\n",
       " 818: 'in this paper, we study the generative models of sequential discrete data. to tackle the exposure bias problem inherent in maximum likelihood estimation (mle), generative adversarial networks (gans) are introduced to penalize the unrealistic generated samples. to exploit the supervision signal from the discriminator, most previous models leverage reinforce to address the non-differentiable problem of sequential discrete data. however, because of the unstable property of the training signal during the dynamic process of adversarial training, the effectiveness of reinforce, in this case, is hardly guaranteed. to deal with such a problem, we propose a novel approach called cooperative training (cot) to improve the training of sequence generative models. cot transforms the min-max game of gans into a joint maximization framework and manages to explicitly estimate and optimize jensen-shannon divergence. moreover, cot works without the necessity of pre-training via mle, which is crucial to the success of previous methods. in the experiments, compared to existing state-of-the-art methods, cot shows superior or at least competitive performance on sample quality, diversity, as well as training stability.',\n",
       " 819: 'activity-based models appeared as an answer to the limitations of the traditional trip-based and tour-based four-stage models. the fundamental assumption of activity-based models is that travel demand is originated from people performing their daily activities. this is why they include a consistent representation of time, of the persons and households, time-dependent routing, and microsimulation of travel demand and traffic. in spite of their potential to simulate traffic demand management policies, their practical application is still limited. one of the main reasons is that these models require a huge amount of very detailed input data hard to get with surveys. however, the pervasive use of mobile devices has brought a valuable new source of data. the work presented here has a twofold objective: first, to demonstrate the capability of mobile phone records to feed activity-based transport models, and, second, to assert the advantages of using activity-based models to estimate the effects of traffic demand management policies. activity diaries for the metropolitan area of barcelona are reconstructed from mobile phone records. this information is then employed as input for building a transport matsim model of the city. the model calibration and validation process proves the quality of the activity diaries obtained. the possible impacts of a cordon toll policy applied to two different areas of the city and at different times of the day is then studied. our results show the way in which the modal share is modified in each of the considered scenario. the possibility of evaluating the effects of the policy at both aggregated and traveller level, together with the ability of the model to capture policy impacts beyond the cordon toll area confirm the advantages of activity-based models for the evaluation of traffic demand management policies.',\n",
       " 820: 'in this paper we modify the model of itkin, shcherbakov and veygman, (2019) (isv2019), proposed for pricing quanto credit default swaps (cds) and risky bonds, in several ways. first, it is known since the lehman brothers bankruptcy that the recovery rate could significantly vary right before or at default, therefore, in this paper we consider it to be stochastic. second, to reduce complexity of the model, we treat the domestic interest rate as deterministic, because, as shown in isv2019, volatility of the domestic interest rate does not contribute much to the value of the quanto cds spread. finally, to solve the corresponding systems of 4d partial differential equations we use a different flavor of the radial basis function (rbf) method which is a combination of localized rbf and finite-difference methods, and is known in the literature as rbf-fd. results of our numerical experiments presented in the paper demonstrate that the influence of volatility of the recovery rate is significant if the correlation between the recovery rate and the log-intensity of the default is non-zero. also, the impact of the recovery mean-reversion rate on the quanto cds spread could be comparable with the impact due to jump-at-default in the fx rate.',\n",
       " 821: 'health care is one of the most exciting frontiers in data mining and machine learning. successful adoption of electronic health records (ehrs) created an explosion in digital clinical data available for analysis, but progress in machine learning for healthcare research has been difficult to measure because of the absence of publicly available benchmark data sets. to address this problem, we propose four clinical prediction benchmarks using data derived from the publicly available medical information mart for intensive care (mimic-iii) database. these tasks cover a range of clinical problems including modeling risk of mortality, forecasting length of stay, detecting physiologic decline, and phenotype classification. we propose strong linear and neural baselines for all four tasks and evaluate the effect of deep supervision, multitask training and data-specific architectural modifications on the performance of neural models.',\n",
       " 822: 'we give a new simple and short (\"one-line\") analysis for the runtime of the well-known euclidean algorithm. while very short simple, the obtained upper bound in near-optimal.',\n",
       " 823: 'kalman filtering is a classic state estimation technique used in application areas such as signal processing and autonomous control of vehicles. it is now being used to solve problems in computer systems such as controlling the voltage and frequency of processors.   although there are many presentations of kalman filtering in the literature, they usually deal with particular systems like autonomous robots or linear systems with gaussian noise, which makes it difficult to understand the general principles behind kalman filtering. in this paper, we first present the abstract ideas behind kalman filtering at a level accessible to anyone with a basic knowledge of probability theory and calculus, and then show how these concepts can be applied to the particular problem of state estimation in linear systems. this separation of concepts from applications should make it easier to understand kalman filtering and to apply it to other problems in computer systems.',\n",
       " 824: 'we propose a novel encoding/transmission scheme called continuous chain (cc) transmission that is able to improve the finite-length performance of a system using spatially-coupled low-density parity-check (sc-ldpc) codes. in cc transmission, instead of transmitting a sequence of independent codewords from a terminated sc-ldpc code chain, we connect multiple chains in a layered format, where encoding, transmission, and decoding are now performed in a continuous fashion. the connections between chains are created at specific points, chosen to improve the finite-length performance of the code structure under iterative decoding. we describe the design of cc schemes for different sc-ldpc code ensembles constructed from protographs: a (j,k)-regular sc-ldpc code chain, a spatially-coupled repeat-accumulate (sc-ra) code, and a spatially-coupled accumulate-repeat-jagged-accumulate (sc- arja) code. in all cases, significant performance improvements are reported and, in addition, it is shown that using cc transmission only requires a small increase in decoding complexity and decoding delay with respect to a system employing a single sc-ldpc code chain for transmission.',\n",
       " 825: 'this paper provides analysis to a generalized version of the coupon collector problem, in which the collector gets $d$ distinct coupons each run and she chooses the one that she has the least so far. on the asymptotic case when the number of coupons $n$ goes to infinity, we show that on average $\\\\frac{n\\\\log n}{d} + \\\\frac{n}{d}(m-1)\\\\log\\\\log{n}+o(mn)$ runs are needed to collect $m$ sets of coupons. an efficient exact algorithm is also developed for any finite case to compute the average needed runs exactly. numerical examples are provided to verify our theoretical predictions.',\n",
       " 826: 'recommender systems often operate on item catalogs clustered by genres, and user bases that have natural clusterings into user types by demographic or psychographic attributes. prior work on system-wide diversity has mainly focused on defining intent-aware metrics among such categories and maximizing relevance of the resulting recommendations, but has not combined the notions of diversity from the two point of views of items and users. in this work, (1) we introduce two new system-wide diversity metrics to simultaneously address the problems of diversifying the categories of items that each user sees, diversifying the types of users that each item is shown, and maintaining high recommendation quality. we model this as a subgraph selection problem on the bipartite graph of candidate recommendations between users and items. (2) in the case of disjoint item categories and user types, we show that the resulting problems can be solved exactly in polynomial time, by a reduction to a minimum cost flow problem. (3) in the case of non-disjoint categories and user types, we prove np-completeness of the objective and present efficient approximation algorithms using the submodularity of the objective. (4) finally, we validate the effectiveness of our algorithms on the movielens-1m and netflix datasets, and show that algorithms designed for our objective also perform well on sales diversity metrics, and even some intent-aware diversity metrics. our experimental results justify the validity of our new composite diversity metrics.',\n",
       " 827: \"the continuous observation of the financial markets has identified some stylized facts which challenge the conventional assumptions, promoting the born of new approaches. on the one hand, the long-range dependence has been faced replacing the traditional gauss-wiener process (brownian motion), characterized by stationary independent increments, by a fractional version. on the other hand, the cev model addresses the leverage effect and smile-skew phenomena, efficiently. in this paper, these two insights are merging and both the fractional and mixed-fractional extensions for the cev model, are developed. using the fractional versions of both the ito's calculus and the fokker-planck equation, the transition probability density function of the asset price is obtained as the solution of a non-stationary feller process with time-varying coefficients, getting an analytical valuation formula for a european call option. besides, the greeks are computed and compared with the standard case.\",\n",
       " 828: 'large scale visual understanding is challenging, as it requires a model to handle the widely-spread and imbalanced distribution of <subject, relation, object> triples. in real-world scenarios with large numbers of objects and relations, some are seen very commonly while others are barely seen. we develop a new relationship detection model that embeds objects and relations into two vector spaces where both discriminative capability and semantic affinity are preserved. we learn both a visual and a semantic module that map features from the two modalities into a shared space, where matched pairs of features have to discriminate against those unmatched, but also maintain close distances to semantically similar ones. benefiting from that, our model can achieve superior performance even when the visual entity categories scale up to more than 80,000, with extremely skewed class distribution. we demonstrate the efficacy of our model on a large and imbalanced benchmark based of visual genome that comprises 53,000+ objects and 29,000+ relations, a scale at which no previous work has ever been evaluated at. we show superiority of our model over carefully designed baselines on the original visual genome dataset with 80,000+ categories. we also show state-of-the-art performance on the vrd dataset and the scene graph dataset which is a subset of visual genome with 200 categories.',\n",
       " 829: \"recently conlon, fox, and the author gave a new proof of a relative szemer\\\\'edi theorem, which was the main novel ingredient in the proof of the celebrated green-tao theorem that the primes contain arbitrarily long arithmetic progressions. roughly speaking, a relative szemer\\\\'edi theorem says that if s is a set of integers satisfying certain conditions, and a is a subset of s with positive relative density, then a contains long arithmetic progressions, and our recent results show that s only needs to satisfy a so-called linear forms condition.   this note contains an alternative proof of the new relative szemer\\\\'edi theorem, where we directly transfer szemer\\\\'edi's theorem, instead of going through the hypergraph removal lemma. this approach provides a somewhat more direct route to establishing the result, and it gives better quantitative bounds.   the proof has three main ingredients: (1) a transference principle/dense model theorem of green-tao and tao-ziegler (with simplified proofs given later by gowers, and independently, reingold-trevisan-tulsiani-vadhan) applied with a discrepancy/cut-type norm (instead of a gowers uniformity norm as it was applied in earlier works), (2) a counting lemma established by conlon, fox, and the author, and (3) szemer\\\\'edi's theorem as a black box.\",\n",
       " 830: 'a unified metric is given for the evaluation of object tracking systems. the metric is inspired by kl-divergence or relative entropy, which is commonly used to evaluate clustering techniques. since tracking problems are fundamentally different from clustering, the components of kl-divergence are recast to handle various types of tracking errors (i.e., false alarms, missed detections, merges, splits). scoring results are given on a standard tracking dataset (oxford town centre dataset), as well as several simulated scenarios. also, this new metric is compared with several other metrics including the commonly used multiple object tracking accuracy metric. in the final section, advantages of this metric are given including the fact that it is continuous, parameter-less and comprehensive.',\n",
       " 831: 'qr bar codes are prototypical images for which part of the image is a priori known (required patterns). open source bar code readers, such as zbar, are readily available. we exploit both these facts to provide and assess purely regularization-based methods for blind deblurring of qr bar codes in the presence of noise.',\n",
       " 832: 'with the success of modern internet based platform, such as amazon mechanical turk, it is now normal to collect a large number of hand labeled samples from non-experts. the dawid- skene algorithm, which is based on expectation- maximization update, has been widely used for inferring the true labels from noisy crowdsourced labels. however, dawid-skene scheme requires all the data to perform each em iteration, and can be infeasible for streaming data or large scale data. in this paper, we provide an online version of dawid- skene algorithm that only requires one data frame for each iteration. further, we prove that under mild conditions, the online dawid-skene scheme with projection converges to a stationary point of the marginal log-likelihood of the observed data. our experiments demonstrate that the online dawid- skene scheme achieves state of the art performance comparing with other methods based on the dawid- skene scheme.',\n",
       " 833: 'in multi-server distributed queueing systems, the access of stochastically arriving jobs to resources is often regulated by a dispatcher, also known as load balancer. a fundamental problem consists in designing a load balancing algorithm that minimizes the delays experienced by jobs. during the last two decades, the power-of-$d$-choice algorithm, based on the idea of dispatching each job to the least loaded server out of $d$ servers randomly sampled at the arrival of the job itself, has emerged as a breakthrough in the foundations of this area due to its versatility and appealing asymptotic properties. in this paper, we consider the power-of-$d$-choice algorithm with the addition of a local memory that keeps track of the latest observations collected over time on the sampled servers. then, each job is sent to a server with the lowest observation. we show that this algorithm is asymptotically optimal in the sense that the load balancer can always assign each job to an idle server in the large-system limit. this holds true if and only if the system load $\\\\lambda$ is less than $1-\\\\frac{1}{d}$. if this condition is not satisfied, we show that queue lengths are tightly bounded by $\\\\left\\\\lceil - \\\\frac{ \\\\log (1-\\\\lambda)}{\\\\log (\\\\lambda d +1)} \\\\right\\\\rceil$. this is in contrast with the classic version of the power-of-$d$-choice algorithm, where at the fluid scale a strictly positive proportion of servers containing $i$ jobs exists for all $i\\\\ge 0$, in equilibrium. our results quantify and highlight the importance of using memory as a means to enhance performance in randomized load balancing.',\n",
       " 834: 'we stratify intuitionistic first-order logic over $(\\\\forall,\\\\to)$ into fragments determined by the alternation of positive and negative occurrences of quantifiers (mints hierarchy).   we study the decidability and complexity of these fragments. we prove that even the $\\\\delta_2$ level is undecidable and that $\\\\sigma_1$ is expspace-complete. we also prove that the arity-bounded fragment of $\\\\sigma_1$ is complete for co-nexptime.',\n",
       " 835: \"let $\\\\mathscr{f}$ be a singular holomorphic foliation, of codimension $k$, on a complex compact manifold such that its singular set has codimension $\\\\geq k+1$. in this work we determinate baum-bott residues for $\\\\mathscr{f}$ with respect to homogeneous symmetric polynomials of degree $k+1$. we drop the baum-bott's generic hypothesis and we show that the residues can be expressed in terms of the grothendieck residue of an one-dimensional foliation on a $(k+1)$-dimensional disc transversal to a $(k+1)$-codimensional component of the singular set of $\\\\mathscr{f}$. also, we show that cenkl's algorithm for non-expected dimensional singularities holds dropping the cenkl's regularity assumption.\",\n",
       " 836: 'we show that a single particle distribution for the d2q13 lattice boltzmann scheme can simulate coupled effects involving advection and diffusion of velocity and temperature. we consider various test cases: non-linear waves with periodic boundary conditions, a test case with buoyancy, propagation of transverse waves, couette and poiseuille flows. we test various boundary conditions and propose to mix bounce-back and anti-bounce-back numerical boundary conditions to take into account velocity and temperature dirichlet conditions. we present also first results for the de vahl davis heated cavity. our results are compared with the coupled d2q9-d2q5 lattice boltzmann approach for the boussinesq system and with an elementary finite differences solver for the compressible navier-stokes equations.',\n",
       " 837: 'despite excellent performance on stationary test sets, deep neural networks (dnns) can fail to generalize to out-of-distribution (ood) inputs, including natural, non-adversarial ones, which are common in real-world settings. in this paper, we present a framework for discovering dnn failures that harnesses 3d renderers and 3d models. that is, we estimate the parameters of a 3d renderer that cause a target dnn to misbehave in response to the rendered image. using our framework and a self-assembled dataset of 3d objects, we investigate the vulnerability of dnns to ood poses of well-known objects in imagenet. for objects that are readily recognized by dnns in their canonical poses, dnns incorrectly classify 97% of their pose space. in addition, dnns are highly sensitive to slight pose perturbations. importantly, adversarial poses transfer across models and datasets. we find that 99.9% and 99.4% of the poses misclassified by inception-v3 also transfer to the alexnet and resnet-50 image classifiers trained on the same imagenet dataset, respectively, and 75.5% transfer to the yolov3 object detector trained on ms coco.',\n",
       " 838: 'generative adversarial networks (gans) are an expressive class of neural generative models with tremendous success in modeling high-dimensional continuous measures. in this paper, we present a scalable method for unbalanced optimal transport (ot) based on the generative-adversarial framework. we formulate unbalanced ot as a problem of simultaneously learning a transport map and a scaling factor that push a source measure to a target measure in a cost-optimal manner. in addition, we propose an algorithm for solving this problem based on stochastic alternating gradient updates, similar in practice to gans. we also provide theoretical justification for this formulation, showing that it is closely related to an existing static formulation by liero et al. (2018), and perform numerical experiments demonstrating how this methodology can be applied to population modeling.',\n",
       " 839: 'we propose to execute deep neural networks (dnns) with dynamic and sparse graph (dsg) structure for compressive memory and accelerative execution during both training and inference. the great success of dnns motivates the pursuing of lightweight models for the deployment onto embedded devices. however, most of the previous studies optimize for inference while neglect training or even complicate it. training is far more intractable, since (i) the neurons dominate the memory cost rather than the weights in inference; (ii) the dynamic activation makes previous sparse acceleration via one-off optimization on fixed weight invalid; (iii) batch normalization (bn) is critical for maintaining accuracy while its activation reorganization damages the sparsity. to address these issues, dsg activates only a small amount of neurons with high selectivity at each iteration via a dimension-reduction search (drs) and obtains the bn compatibility via a double-mask selection (dms). experiments show significant memory saving (1.7-4.5x) and operation reduction (2.3-4.4x) with little accuracy loss on various benchmarks.',\n",
       " 840: \"a user's data is represented by a finite-valued random variable. given a function of the data, a querier is required to recover, with at least a prescribed probability, the value of the function based on a query response provided by the user. the user devises the query response, subject to the recoverability requirement, so as to maximize privacy of the data from the querier. privacy is measured by the probability of error incurred by the querier in estimating the data from the query response. we analyze single and multiple independent query responses, with each response satisfying the recoverability requirement, that provide maximum privacy to the user. in the former setting, we also consider privacy for a predicate of the user's data. achievability schemes with explicit randomization mechanisms for query responses are given and their privacy compared with converse upper bounds.\",\n",
       " 841: 'covariates are factors that have a debilitating influence on face verification performance. in this paper, we comprehensively study two covariate related problems for unconstrained face verification: first, how covariates affect the performance of deep neural networks on the large-scale unconstrained face verification problem; second, how to utilize covariates to improve verification performance. to study the first problem, we implement five state-of-the-art deep convolutional networks (dcnns) for face verification and evaluate them on three challenging covariates datasets. in total, seven covariates are considered: pose (yaw and roll), age, facial hair, gender, indoor/outdoor, occlusion (nose and mouth visibility, eyes visibility, and forehead visibility), and skin tone. these covariates cover both intrinsic subject-specific characteristics and extrinsic factors of faces. some of the results confirm and extend the findings of previous studies, others are new findings that were rarely mentioned previously or did not show consistent trends. for the second problem, we demonstrate that with the assistance of gender information, the quality of a pre-curated noisy large-scale face dataset for face recognition can be further improved. after retraining the face recognition model using the curated data, performance improvement is observed at low false acceptance rates (fars) (far=$10^{-5}$, $10^{-6}$, $10^{-7}$).',\n",
       " 842: 'we study the convergence of nash equilibria in a game of optimal stopping. if the associated mean field game has a unique equilibrium, any sequence of $n$-player equilibria converges to it as $n\\\\to\\\\infty$. however, both the finite and infinite player versions of the game often admit multiple equilibria. we show that mean field equilibria satisfying a transversality condition are limit points of $n$-player equilibria, but we also exhibit a remarkable class of mean field equilibria that are not limits, thus questioning their interpretation as \"large $n$\" equilibria.',\n",
       " 843: 'this paper proposes an alternative to the synthetic control method (scm) for estimating the effect of a policy intervention on an outcome over time. recurrent neural networks (rnns) are used to predict the counterfactual outcomes of treated units using only the outcomes of control units as predictors. this approach is less susceptible to $p$-hacking because it does not require the researcher to choose predictors or pre-intervention covariates to construct the synthetic control. rnns do not assume a functional form, can learn nonconvex combinations of control units, and are specifically structured to exploit temporal dependencies in sequential data. i apply the approach to the problem of estimating the long-run impacts of u.s. homestead policy on public school spending.',\n",
       " 844: 'we consider a class of participation rights, i.e. obligations issued by a company to investors who are interested in performance-based compensation. albeit having desirable economic properties equity-based debt obligations (ebdo) pose challenges in accounting and contract pricing. we formulate and solve the associated mathematical problem in a discrete time, as well as a continuous time setting. in the latter case the problem is reduced to a forward-backward stochastic differential equation (fbsde) and solved using the method of decoupling fields.',\n",
       " 845: 'the fpga/nios fir filter based on linear prediction (lp) to suppress radio frequency interference (rfi) has been installed in several radio stations in the auger engineering radio array (aera) experiment. aera observes coherent radio emission from extensive air showers induced by ultra-high-energy cosmic rays to make a detailed study of the development of the electromagnetic part of air showers. radio signals provide complementary information to that obtained from auger surface detectors, which are predominantly sensitive to the particle content of an air shower at the surface. the radio signals from air showers are caused by the coherent emission due to geomagnetic and charge-excess processes. these emissions can be observed in the frequency band between 10 - 100 mhz. however, this frequency range is significantly contaminated by narrow-band rfi and other human-made distortions. a fir filter implemented in the fpga logic segment of the front-end electronics of a radio sensor significantly improves the signal-to-noise ratio.   in this paper we present first results of the efficiency of the adaptive lp fir filter, deployed in real aera station on pampas, with a comparison to the currently used iir notch filter with constant coefficients. the laboratory tests confirms the stability of the filter. using constant lp coefficients the suppression efficiency remains the same for hours, which corresponds to more than $\\\\bf 10^{12}$ clock cycles. we compared in real conditions several variants of the lp fir filter with various lengths and various coefficients widths (due to fixed-point representations in the fpga logic) with the aim to minimize the power consumption for the radio station while keeping sufficient accuracy for noise reduction.',\n",
       " 846: 'this paper studies the eigenvalue problem on $\\\\mathbb{r}^d$ for a class of second order, elliptic operators of the form $\\\\mathscr{l} = a^{ij}\\\\partial_{x_i}\\\\partial_{x_j} + b^{i}\\\\partial_{x_i} + f$, associated with non-degenerate diffusions. we show that strict monotonicity of the principal eigenvalue of the operator with respect to the potential function $f$ fully characterizes the ergodic properties of the associated ground state diffusion, and the unicity of the ground state, and we present a comprehensive study of the eigenvalue problem from this point of view. this allows us to extend or strengthen various results in the literature for a class of viscous hamilton-jacobi equations of ergodic type with smooth coefficients to equations with measurable drift and potential. in addition, we establish the strong duality for the equivalent infinite dimensional linear programming formulation of these ergodic control problems. we also apply these results to the study of the infinite horizon risk-sensitive control problem for diffusions, and establish existence of optimal markov controls, verification of optimality results, and the continuity of the controlled principal eigenvalue with respect to stationary markov controls.',\n",
       " 847: 'weight pruning methods of dnns have been demonstrated to achieve a good model pruning rate without loss of accuracy, thereby alleviating the significant computation/storage requirements of large-scale dnns. structured weight pruning methods have been proposed to overcome the limitation of irregular network structure and demonstrated actual gpu acceleration. however, in prior work the pruning rate (degree of sparsity) and gpu acceleration are limited (to less than 50%) when accuracy needs to be maintained. in this work,we overcome these limitations by proposing a unified, systematic framework of structured weight pruning for dnns. it is a framework that can be used to induce different types of structured sparsity, such as filter-wise, channel-wise, and shape-wise sparsity, as well non-structured sparsity. the proposed framework incorporates stochastic gradient descent with admm, and can be understood as a dynamic regularization method in which the regularization target is analytically updated in each iteration. without loss of accuracy on the alexnet model, we achieve 2.58x and 3.65x average measured speedup on two gpus, clearly outperforming the prior work. the average speedups reach 3.15x and 8.52x when allowing a moderate ac-curacy loss of 2%. in this case the model compression for convolutional layers is 15.0x, corresponding to 11.93x measured cpu speedup. our experiments on resnet model and on other data sets like ucf101 and cifar-10 demonstrate the consistently higher performance of our framework.',\n",
       " 848: 'in this paper, we study the efficiency of egoistic and altruistic strategies within the model of social dynamics determined by voting in a stochastic environment (the vise model) using two criteria: maximizing the average capital increment and minimizing the number of bankrupt participants. the proposals are generated stochastically; three families of the corresponding distributions are considered: normal distributions, symmetrized pareto distributions, and student\\'s $t$-distributions. it is found that the \"pit of losses\" paradox described earlier does not occur in the case of heavy-tailed distributions. the egoistic strategy better protects agents from extinction in aggressive environments than the altruistic ones, however, the efficiency of altruism is higher in more favorable environments. a comparison of altruistic strategies with each other shows that in aggressive environments, everyone should be supported to minimize extinction, while under more favorable conditions, it is more efficient to support the weakest participants. studying the dynamics of participants\\' capitals we identify situations where the two considered criteria contradict each other. at the next stage of the study, combined voting strategies and societies involving participants with selfish and altruistic strategies will be explored.',\n",
       " 849: 'this paper investigates calculations of robust funding valuation adjustment (fva) for over the counter (otc) derivatives under distributional uncertainty using wasserstein distance as the ambiguity measure. wrong way funding risk can be characterized via the robust fva formulation. the simpler dual formulation of the robust fva optimization is derived. next, some computational experiments are conducted to measure the additional fva charge due to distributional uncertainty under a variety of portfolio and market configurations. finally some suggestions for future work, such as robust capital valuation adjustment (kva) and margin valuation adjustment (mva), are discussed.',\n",
       " 850: 'in systems of programmable matter, we are given a collection of simple computation elements (or particles) with limited (constant-size) memory. we are interested in when they can self-organize to solve system-wide problems of movement, configuration and coordination. here, we initiate a stochastic approach to developing robust distributed algorithms for programmable matter systems using markov chains. we are able to leverage the wealth of prior work in markov chains and related areas to design and rigorously analyze our distributed algorithms and show that they have several desirable properties.   we study the compression problem, in which a particle system must gather as tightly together as possible, as in a sphere or its equivalent in the presence of some underlying geometry. more specifically, we seek fully distributed, local, and asynchronous algorithms that lead the system to converge to a configuration with small boundary. we present a markov chain-based algorithm that solves the compression problem under the geometric amoebot model, for particle systems that begin in a connected configuration. the algorithm takes as input a bias parameter $\\\\lambda$, where $\\\\lambda > 1$ corresponds to particles favoring having more neighbors. we show that for all $\\\\lambda > 2+\\\\sqrt{2}$, there is a constant $\\\\alpha > 1$ such that eventually with all but exponentially small probability the particles are $\\\\alpha$-compressed, meaning the perimeter of the system configuration is at most $\\\\alpha \\\\cdot p_{min}$, where $p_{min}$ is the minimum possible perimeter of the particle system. surprisingly, the same algorithm can also be used for expansion when $0 < \\\\lambda < 2.17$, and we prove similar results about expansion for values of $\\\\lambda$ in this range. this is counterintuitive as it shows that particles preferring to be next to each other ($\\\\lambda > 1$) is not sufficient to guarantee compression.',\n",
       " 851: 'we study classes of right-angled coxeter groups with respect to the strong submodel relation of parabolic subgroup. we show that the class of all right-angled coxeter group is not smooth, and establish some general combinatorial criteria for such classes to be abstract elementary classes, for them to be finitary, and for them to be tame. we further prove two combinatorial conditions ensuring the strong rigidity of a right-angled coxeter group of arbitrary rank. the combination of these results translate into a machinery to build concrete examples of $\\\\mathrm{aecs}$ satisfying given model-theoretic properties. we exhibit the power of our method constructing three concrete examples of finitary classes. we show that the first and third class are non-homogeneous, and that the last two are tame, uncountably categorical and axiomatizable by a single $l_{\\\\omega_{1}, \\\\omega}$-sentence. we also observe that the isomorphism relation of any countable complete first-order theory is $\\\\kappa$-borel reducible (in the sense of generalized descriptive set theory) to the isomorphism relation of the theory of right-angled coxeter groups whose coxeter graph is an infinite random graph.',\n",
       " 852: 'in a recent paper jones introduced a correspondence between elements of the thompson group $f$ and certain graphs/links. it follows from his work that several polynomial invariants of links, such as the kauffman bracket, can be reinterpreted as coefficients of certain unitary representations of $f$. we give a somewhat different and elementary proof of this fact for the kauffman bracket evaluated at certain roots of unity by means of a statistical mechanics model interpretation. moreover, by similar methods we show that, for some particular specializations of the variables, other familiar link invariants and graph polynomials, namely the number of $n$-colourings and the tutte polynomial, can be viewed as positive definite functions on $f$.',\n",
       " 853: 'walking speed estimation is an essential component of mobile apps in various fields such as fitness, transportation, navigation, and health-care. most existing solutions are focused on specialized medical applications that utilize body-worn motion sensors. these approaches do not serve effectively the general use case of numerous apps where the user holding a smartphone tries to find his or her walking speed solely based on smartphone sensors. however, existing smartphone-based approaches fail to provide acceptable precision for walking speed estimation. this leads to a question: is it possible to achieve comparable speed estimation accuracy using a smartphone over wearable sensor based obtrusive solutions?   we find the answer from advanced neural networks. in this paper, we present deepwalking, the first deep learning-based walking speed estimation scheme for smartphone. a deep convolutional neural network (dcnn) is applied to automatically identify and extract the most effective features from the accelerometer and gyroscope data of smartphone and to train the network model for accurate speed estimation. experiments are performed with 10 participants using a treadmill. the average root-mean-squared-error (rmse) of estimated walking speed is 0.16m/s which is comparable to the results obtained by state-of-the-art approaches based on a number of body-worn sensors (i.e., rmse of 0.11m/s). the results indicate that a smartphone can be a strong tool for walking speed estimation if the sensor data are effectively calibrated and supported by advanced deep learning techniques.',\n",
       " 854: \"suppose one has found a non-empty sub-category $\\\\mathcal{a}$ of the fukaya category of a compact calabi-yau manifold $x$ which is homologically smooth in the sense of non-commutative geometry, a condition intrinsic to $\\\\mathcal{a}$. then, we show $\\\\mathcal{a}$ split-generates the fukaya category and moreoever, that our hypothesis implies (and is therefore equivalent to the assertion that) $\\\\mathcal{a}$ satisfies abouzaid's geometric generation criterion [abo]. an immediate consequence of earlier work [g1, gps1, gps2] is that the open-closed and closed-open maps, relating quantum cohomology to the hochschild invariants of the fukaya category, are also isomorphisms. our result continues to hold when $c_1(x) \\\\neq 0$ (for instance, when $x$ is monotone fano), under a further hypothesis: the 0th hochschild cohomology of $\\\\mathcal{a}$ $\\\\mathrm{hh}^0(\\\\mathcal{a})$ should have sufficiently large rank: $\\\\mathrm{rk}\\\\ \\\\mathrm{hh}^0(\\\\mathcal{a}) \\\\geq \\\\mathrm{rk}\\\\ \\\\mathrm{qh}^0(x)$. our proof depends only on formal properties of fukaya categories and open-closed maps, the most recent and crucial of which, compatibility of the open-closed map with pairings, was observed independently in ongoing joint work of the author with perutz and sheridan [gps2] and by abouzaid-fukaya-oh-ohta-ono [afo+]; a proof in the simplest settings appears here in an appendix. because categories morita equivalent to categories of coherent sheaves or matrix factorizations are homologically smooth, our result applies to resolve the split-generation question in homological mirror symmetry for compact symplectic manifolds (generalizing a result of perutz-sheridan [ps2] proven in the case $c_1(x) = 0$): any embedding of coherent sheaves or matrix factorizations into the split-closed derived fukaya category is automatically a morita equivalence when it has large enough $\\\\mathrm{hh}^0$ (which it always does if $c_1(x)=0$).\",\n",
       " 855: 'we report the detection of the lunar gamma-ray emission during the first year of fermi-lat observations. such emission is produced by cosmic ray nuclei interacting with the lunar surface. thanks to the solar minimum conditions and the reduced effects of heliospheric modulation, the lunar flux was at its maximum due to the increased flux of galactic cosmic rays hitting the lunar surface. fermi-lat instrument has a superior sensitivity, angular resolution, and observes the whole sky every two orbits. it is the only gamma-ray mission capable of detecting the lunar emission with high confidence and to monitor it over the full 24th solar cycle. we also report the status of a search of the gamma-ray emission from major planets and asteroid populations in the ecliptic plane.',\n",
       " 856: 'resource allocation systems provide the fundamental support for the normal functioning and well being of the modern society, and can be modeled as minority games. a ubiquitous dynamical phenomenon is the emergence of herding, where a vast majority of the users concentrate on a small number of resources, leading to a low efficiency in resource allocation. to devise strategies to prevent herding is thus of high interest. previous works focused on control strategies that rely on external interventions, such as pinning control where a fraction of users are forced to choose a certain action. is it possible to eliminate herding without any external control? the main point of this paper is to provide an affirmative answer through exploiting artificial intelligence (ai). in particular, we demonstrate that, when agents are empowered with reinforced learning in that they get familiar with the unknown game environment gradually and attempt to deliver the optimal actions to maximize the payoff, herding can effectively be eliminated. computations reveal the striking phenomenon that, regardless of the initial state, the system evolves persistently and relentlessly toward the optimal state in which all resources are used efficiently. however, the evolution process is not without interruptions: there are large fluctuations that occur but only intermittently in time. the statistical distribution of the time between two successive fluctuating events is found to depend on the parity of the evolution, i.e., whether the number of time steps in between is odd or even. we develop a physical analysis and derive mean-field equations to gain an understanding of these phenomena. as minority game dynamics and the phenomenon of herding are common in social, economic, and political systems, and since ai is becoming increasingly widespread, we expect our ai empowered minority game system to have broad applications.',\n",
       " 857: 'joint image filters leverage the guidance image as a prior and transfer the structural details from the guidance image to the target image for suppressing noise or enhancing spatial resolution. existing methods either rely on various explicit filter constructions or hand-designed objective functions, thereby making it difficult to understand, improve, and accelerate these filters in a coherent framework. in this paper, we propose a learning-based approach for constructing joint filters based on convolutional neural networks. in contrast to existing methods that consider only the guidance image, the proposed algorithm can selectively transfer salient structures that are consistent with both guidance and target images. we show that the model trained on a certain type of data, e.g., rgb and depth images, generalizes well to other modalities, e.g., flash/non-flash and rgb/nir images. we validate the effectiveness of the proposed joint filter through extensive experimental evaluations with state-of-the-art methods.',\n",
       " 858: 'i sketch a line of thought about consciousness and physics that gives some motivation for the hypothesis that conscious observers deviate - perhaps only very subtly and slightly - from quantum dynamics. although it is hard to know just how much credence to give this line of thought, it does motivate a stronger and more comprehensive programme of quantum experiments involving quantum observers.',\n",
       " 859: 'randomly censored survival data are frequently encountered in applied sciences including biomedical or reliability applications and clinical trial analyses. testing the significance of statistical hypotheses is crucial in such analyses to get conclusive inference but the existing likelihood based tests, under a fully parametric model, are extremely non-robust against outliers in the data. although, there exists a few robust parameter estimators (e.g., m-estimators and minimum density power divergence estimators) given randomly censored data, there is hardly any robust testing procedure available in the literature in this context. one of the major difficulties in this context is the construction of a suitable consistent estimator of the asymptotic variance of m estimators; the latter is a function of the unknown censoring distribution. in this paper, we take the first step in this direction by proposing a consistent estimator of asymptotic variance of the m-estimators based on randomly censored data without any assumption on the form of the censoring scheme. we then describe and study a class of robust wald-type tests for parametric statistical hypothesis, both simple as well as composite, under such set-up, along with their general asymptotic and robustness properties. robust tests for comparing two independent randomly censored samples and robust tests against one sided alternatives are also discussed. their advantages and usefulness are demonstrated for the tests based on the minimum density power divergence estimators with specific attention to clinical trial analyses.',\n",
       " 860: 'planning robust robot manipulation requires good forward models that enable robust plans to be found. this work shows how to achieve this using a forward model learned from robot data to plan push manipulations. we explore learning methods (gaussian process regression, and an ensemble of mixture density networks) that give estimates of the uncertainty in their predictions. these learned models are utilised by a model predictive path integral (mppi) controller to plan how to push the box to a goal location. the planner avoids regions of high predictive uncertainty in the forward model. this includes both inherent uncertainty in dynamics, and meta uncertainty due to limited data. thus, pushing tasks are completed in a robust fashion with respect to estimated uncertainty in the forward model and without the need of differentiable cost functions. we demonstrate the method on a real robot, and show that learning can outperform physics simulation. using simulation, we also show the ability to plan uncertainty averse paths.',\n",
       " 861: 'we study local and global properties of positive solutions of $-{\\\\delta}u=u^p]{\\\\left |{\\\\nabla u}\\\\right |}^q$ in a domain ${\\\\omega}$ of ${\\\\mathbb r}^n$, in the range $1\\\\<p+q$, $p\\\\geq 0$, $0\\\\leq q\\\\< 2$. we first prove a local harnack inequality and nonexistence of positive solutions in ${\\\\mathbb r}^n$ when $p(n-2)+q(n-1) \\\\<n$ or in an exterior domain if $p(n-2)+q(n-1)\\\\<n$ and $0\\\\leq q\\\\<1$. using a direct bernstein method we obtain a first range of values of $p$ and $q$ in which $u(x)\\\\leq c({\\\\mathrm dist\\\\,}(x,\\\\partial\\\\omega)^{\\\\frac{q-2}{p+q-1}}$ this holds in particular if $p+q\\\\<1+\\\\frac{4}{n-1}$. using an integral bernstein method we obtain a wider range of values of $p$ and $q$ in which all the global solutions are constants. our result contains gidas and spruck nonexistence result as a particular case. we also study solutions under the form $u(x)=r^{\\\\frac{q-2}{p+q-1}}\\\\omega(\\\\sigma)$. we prove existence, nonexistence and rigidity of the spherical component $\\\\omega$ in some range of values of $n$, $p$ and $q$.',\n",
       " 862: 'we show that there cannot be more than 64 lines on a quartic surface admitting isolated rational double points over an algebraically closed field of characteristic $p \\\\neq 2,\\\\,3$, thus extending segre--rams--sch\\\\\"utt theorem. our proof offers a deeper insight into the triangle-free case and takes advantage of a special configuration of lines, thereby avoiding the technique of the flecnodal divisor. we provide several examples of non-smooth k3 quartic surfaces with many lines.',\n",
       " 863: \"quantum and noncommutative corrections to the newtonian law of inertia are considered in the general setting of verlinde's entropic force postulate. we demonstrate that the form for the modified newtonian dynamics (mond) emerges in a classical setting by seeking appropriate corrections in the entropy.we estimate the correction term by using concrete coherent states in the standard and generalized versions of heisenberg's uncertainty principle. using jackiw's direct and analytic method we compute the explicit wavefunctions for these states producing minimal length as well as minimal products. subsequently we derive a further selection criterion restricting the free parameters in the model in providing a canonical formulation of the quantum corrected newtonian law by setting up the lagrangian and hamiltonian for the system.\",\n",
       " 864: \"recent high-profile cyber attacks exemplify why organizations need better cyber defenses. cyber threats are hard to accurately predict because attackers usually try to mask their traces. however, they often discuss exploits and techniques on hacking forums. the community behavior of the hackers may provide insights into groups' collective malicious activity. we propose a novel approach to predict cyber events using sentiment analysis. we test our approach using cyber attack data from 2 major business organizations. we consider 3 types of events: malicious software installation, malicious destination visits, and malicious emails that surpassed the target organizations' defenses. we construct predictive signals by applying sentiment analysis on hacker forum posts to better understand hacker behavior. we analyze over 400k posts generated between january 2016 and january 2018 on over 100 hacking forums both on surface and dark web. we find that some forums have significantly more predictive power than others. sentiment-based models that leverage specific forums can outperform state-of-the-art deep learning and time-series models on forecasting cyber attacks weeks ahead of the events.\",\n",
       " 865: 'in the paper, we study the three-dimensional prandtl equations without any monotonicity condition on the velocity field. we prove that when one tangential component of the velocity field has a single curve of non-degenerate critical points with respect to the normal variable, the system is locally well-posed in the gevrey function space with gevrey index in $]1, 2].$ the proof is based on some new observation of cancellation mechanism in the three space dimensional system in addition to those in the two-dimensional setting obtained in [1,7,19,22].',\n",
       " 866: \"automation driving techniques have seen tremendous progresses these last years, particularly due to a better perception of the environment. in order to provide safe yet not too conservative driving in complex urban environment, data fusion should not only consider redundant sensing to characterize the surrounding obstacles, but also be able to describe the uncertainties and errors beyond presence/absence (be it binary or probabilistic). this paper introduces an enriched representation of the world, more precisely of the potential existence of obstacles through an evidential grid map. a method to create this representation from 2 very different sensors, laser scanner and stereo camera, is presented along with algorithms for data fusion and temporal updates. this work allows a better handling of the dynamic aspects of the urban environment and a proper management of errors in order to create a more reliable map. we use the evidential framework based on the dempster-shafer theory to model the environment perception by the sensors. a new combination operator is proposed to merge the different sensor grids considering their distinct uncertainties. in addition, we introduce a new long-life layer with high level states that allows the maintenance of a global map of the entire vehicle's trajectory and distinguish between static and dynamic obstacles. results on a real road dataset show that the environment mapping data can be improved by adding relevant information that could be missed without the proposed approach.\",\n",
       " 867: 'current best local descriptors are learned on a large dataset of matching and non-matching keypoint pairs. however, data of this kind is not always available since detailed keypoint correspondences can be hard to establish. on the other hand, we can often obtain labels for pairs of keypoint bags. for example, keypoint bags extracted from two images of the same object under different views form a matching pair, and keypoint bags extracted from images of different objects form a non-matching pair. on average, matching pairs should contain more corresponding keypoints than non-matching pairs. we describe an end-to-end differentiable architecture that enables the learning of local keypoint descriptors from such weakly-labeled data. additionally, we discuss how to improve the method by incorporating the procedure of mining hard negatives. we also show how can our approach be used to learn convolutional features from unlabeled video signals and 3d models.   our implementation is available at https://github.com/nenadmarkus/wlrn',\n",
       " 868: 'an information-theoretic development is given for the problem of compound poisson approximation, which parallels earlier treatments for gaussian and poisson approximation. let $p_{s_n}$ be the distribution of a sum $s_n=\\\\sumn y_i$ of independent integer-valued random variables $y_i$. nonasymptotic bounds are derived for the distance between $p_{s_n}$ and an appropriately chosen compound poisson law. in the case where all $y_i$ have the same conditional distribution given $\\\\{y_i\\\\neq 0\\\\}$, a bound on the relative entropy distance between $p_{s_n}$ and the compound poisson distribution is derived, based on the data-processing property of relative entropy and earlier poisson approximation results. when the $y_i$ have arbitrary distributions, corresponding bounds are derived in terms of the total variation distance. the main technical ingredient is the introduction of two \"information functionals,\" and the analysis of their properties. these information functionals play a role analogous to that of the classical fisher information in normal approximation. detailed comparisons are made between the resulting inequalities and related bounds.',\n",
       " 869: 'a review of modernization and growth of ground based optical and near-infrared astrophysical observational facilities in the globe attributed to the recent technological developments in optomechanical, electronics and computer science areas is presented. hubble space telescope (hst) and speckle and adaptive ground based imaging have obtained images better than 0.1 arc sec angular resolution bringing the celestial objects closer to us at least by a factor of 10 during the last two decades. from the light gathering point of view, building of large size (more than 5 meter aperture) ground based optical and nearinfrared telescopes based on latest technology have become economical in recent years. consequently, in the world, a few 8-10 meter size ground-based optical and near-infrared telescopes are being used for observations of the celestial objects, three 25-40 meter size are under design stage and making of a ~ 100 meter size telescope is under planning stage. in india, the largest sized optical and near-infrared telescope is the modern 3.6-meter located at devasthal, nainital. however, the existing indian moderate size telescopes equipped with modern backend instruments have global importance due to their geographical location. recently, participation of india in the thirty meter telescope (tmt) project has been approved by the government of india.',\n",
       " 870: \"the thermodynamics of the inhomogeneous one-dimensional repulsive fermionic hubbard model with parabolic confinement is studied by a density-functional theory approach, based on mermin's generalization to finite temperatures. a local-density approximation (lda), based on exact results for the homogeneous model, is used to approximate the correlation part in the helmholtz free-energy, comprising the thermodynamic bethe ansatz lda (tbalda). the general presentation of the method is given and some properties of the homogeneous model that are relevant to the dft approach are analyzed. extensive comparison between tbalda and numerical exact diagonalization results for thermodynamic properties of small inhomogeneous chains is discussed. in the remaining, a classical thermodynamic treatment of the confined system is developed with the focus on global properties of large systems. a unusual behavior under isentropic expansion is found and discussed.\",\n",
       " 871: 'we examine the cosmological constraints that can be achieved with a galaxy cluster survey with the future core space mission. using realistic simulations of the millimeter sky, produced with the latest version of the planck sky model, we characterize the core cluster catalogues as a function of the main mission performance parameters. we pay particular attention to telescope size, key to improved angular resolution, and discuss the comparison and the complementarity of core with ambitious future ground-based cmb experiments that could be deployed in the next decade. a possible core mission concept with a 150 cm diameter primary mirror can detect of the order of 50,000 clusters through the thermal sunyaev-zeldovich effect (sze). the total yield increases (decreases) by 25% when increasing (decreasing) the mirror diameter by 30 cm. the 150 cm telescope configuration will detect the most massive clusters ($>10^{14}\\\\, m_\\\\odot$) at redshift $z>1.5$ over the whole sky, although the exact number above this redshift is tied to the uncertain evolution of the cluster sze flux-mass relation; assuming self-similar evolution, core will detect $\\\\sim 500$ clusters at redshift $z>1.5$. this changes to 800 (200) when increasing (decreasing) the mirror size by 30 cm. core will be able to measure individual cluster halo masses through lensing of the cosmic microwave background anisotropies with a 1-$\\\\sigma$ sensitivity of $4\\\\times10^{14} m_\\\\odot$, for a 120 cm aperture telescope, and $10^{14} m_\\\\odot$ for a 180 cm one. [abridged]',\n",
       " 872: 'the magic telescopes are two imaging atmospheric cherenkov telescopes (iacts) located on the canary island of la palma. with 17m diameter mirror dishes and ultra-fast electronics, they provide an energy threshold as low as 50 gev for observations at low zenith angles. the first magic telescope was taken in operation in 2004 whereas the second one joined in 2009. in 2011 we started a major upgrade program to improve and to unify the stereoscopic system of the two similar but at that time different telescopes. here we report on the upgrade of the readout electronics and digital trigger of the two telescopes, the upgrade of the camera of the magic i telescope as well as the commissioning of the system after this major upgrade.',\n",
       " 873: 'vulnerabilities of complex networks have became a trend topic in complex systems recently due to its real world applications. most real networks tend to be very fragile to high betweenness adaptive attacks. however, recent contributions have shown the importance of interconnected nodes in the integrity of networks and module-based attacks have appeared promising when compared to traditional malicious non-adaptive attacks. in the present work we deeply explore the trade-off associated with attack procedures, introducing a generalized robustness measure and presenting an attack performance index that takes into account both robustness of the network against the attack and the run-time needed to obtained the list of targeted nodes for the attack. besides, we introduce the concept of deactivation point aimed to mark the point at which the network stops to function properly. we then show empirically that non-adaptive module-based attacks perform better than high degree and betweenness adaptive attacks in networks with well defined community structures and consequent high modularity.',\n",
       " 874: 'since the commissioning of the array in spring 2007, the veritas array (sensitive in the 0.1-50 tev energy range) has acquired over 300 hours of observations investigating the tev emission from x-ray binary star systems, in particular focusing on the known tev binary targets ls i +61 303 and hess j0632+057. both tev binaries have been monitored by veritas for several years and the resulting dataset is continuing to yield important results in the characterization of these poorly understood systems. we present these results, as well as the contemporaneous observations of these sources taken with fermi-lat and swift-xrt. in the case of ls i +61 303, simultaneous observations taken with veritas and fermi-lat reveal a break in emission in the 10-200 gev range. for hess j0632 057, the extended veritas observations have allowed for the first identification of a binary system through tev gamma-ray observations.',\n",
       " 875: \"data compression is a popular technique for improving the efficiency of data processing workloads such as sql queries and more recently, machine learning (ml) with classical batch gradient methods. but the efficacy of such ideas for mini-batch stochastic gradient descent (mgd), arguably the workhorse algorithm of modern ml, is an open question. mgd's unique data access pattern renders prior art, including those designed for batch gradient methods, less effective. we fill this crucial research gap by proposing a new lossless compression scheme we call tuple-oriented compression (toc) that is inspired by an unlikely source, the string/text compression scheme lempel-ziv-welch, but tailored to mgd in a way that preserves tuple boundaries within mini-batches. we then present a suite of novel compressed matrix operation execution techniques tailored to the toc compression scheme that operate directly over the compressed data representation and avoid decompression overheads. an extensive empirical evaluation with real-world datasets shows that toc consistently achieves substantial compression ratios by up to 51x and reduces runtimes for mgd workloads by up to 10.2x in popular ml systems.\",\n",
       " 876: 'the mallows measure is a probability measure on $s_n$ where the probability of a permutation $\\\\pi$ is proportional to $q^{l(\\\\pi)}$ with $q > 0$ being a parameter and $l(\\\\pi)$ the number of inversions in $\\\\pi$. we prove a weak law of large numbers for the length of the longest common subsequences of two independent permutations drawn from the mallows measure, when $q$ is a function of $n$ and $n(1-q)$ has limit in $\\\\mathbb{r}$ as $n \\\\to \\\\infty$.',\n",
       " 877: 'we investigate metric learning in the context of dynamic time warping (dtw), the by far most popular dissimilarity measure used for the comparison and analysis of motion capture data. while metric learning enables a problem-adapted representation of data, the majority of methods has been proposed for vectorial data only. in this contribution, we extend the popular principle offered by the large margin nearest neighbors learner (lmnn) to dtw by treating the resulting component-wise dissimilarity values as features. we demonstrate that this principle greatly enhances the classification accuracy in several benchmarks. further, we show that recent auxiliary concepts such as metric regularization can be transferred from the vectorial case to component-wise dtw in a similar way. we illustrate that metric regularization constitutes a crucial prerequisite for the interpretation of the resulting relevance profiles.',\n",
       " 878: 'we utilize a combination of vector magnetic field and scanning tunneling microscopy to elucidate the 3d field-based electronic phase diagram of a correlated iron-based superconductor, lifeas. we observe, under a zero-field-cooled method, an ordered hexagonal vortex lattice ground-state in contrast to the disordered lattice observed under a field-cooled method. it transforms into a four-fold-symmetric state by increasing c-axis field and distorts elliptically upon tilting the field in-plane. the vortex lattice transformations correlate with the field dependent superconducting gap that characterizes the cooper pairing strength. the anisotropy of the vortex lattice agrees with the field enhanced bogoliubov quasiparticle scattering channel that is determined by the pairing symmetry with respect to its fermi surface structure. our systematic tuning of the vortex lattice symmetry and study of its correlation with cooper pairing demonstrates the many-body interplay between the superconducting order parameter and emergent vortex matter.',\n",
       " 879: \"the goal of this paper is to generalise alex rennet's proof of the non-axiomatizability of the class of pseudo-o-minimal structures. rennet showed that if l is an expansion of the language of ordered fields and k is the class of pseudo-o-minimal l-structures (l-structures elementarily equivalent to an ultraproduct of o-minimal structures) then k is not computably axiomatizable. we give a general version of this theorem, and apply it to several classes of topological structures.\",\n",
       " 880: 'explainability and interpretability are two critical aspects of decision support systems. within computer vision, they are critical in certain tasks related to human behavior analysis such as in health care applications. despite their importance, it is only recently that researchers are starting to explore these aspects. this paper provides an introduction to explainability and interpretability in the context of computer vision with an emphasis on looking at people tasks. specifically, we review and study those mechanisms in the context of first impressions analysis. to the best of our knowledge, this is the first effort in this direction. additionally, we describe a challenge we organized on explainability in first impressions analysis from video. we analyze in detail the newly introduced data set, the evaluation protocol, and summarize the results of the challenge. finally, derived from our study, we outline research opportunities that we foresee will be decisive in the near future for the development of the explainable computer vision field.',\n",
       " 881: 'fermi-lat is performing an all-sky gamma-ray survey from 20 mev to >300 gev with unprecedented sensitivity and angular resolution. fermi is the only mission able to detect high energy (>20 mev) emission from the sun during the new solar cycle 24. fermi was launched on june 2008, since then high energy emission from the sun was continuously monitored searching for flare events. upper limits were derived for all the solar flares detected by other missions and experiments (rhessi, fermi-gbm, goes). we present the analysis techniques used for this study and the preliminary results obtained so far.',\n",
       " 882: 'the high-frequency-peaked bl lac (hbl) 1es 0806+524 (z = 0.138) was discovered in vhe $\\\\gamma$ rays in 2008. until now, the broad-band spectrum of 1es 0806+524 has been only poorly characterized, in particular at high energies. we analysed multiwavelength observations from $\\\\gamma$ rays to radio performed from 2011 january to march, which were triggered by the high activity detected at optical frequencies. these observations constitute the most precise determination of the broad-band emission of 1es 0806+524 to date. the stereoscopic magic observations yielded a $\\\\gamma$-ray signal above 250 gev of $(3.7 \\\\pm 0.7)$ per cent of the crab nebula flux with a statistical significance of 9.9 $\\\\sigma$. the multiwavelength observations showed significant variability in essentially all energy bands, including a vhe $\\\\gamma$-ray flare that lasted less than one night, which provided unprecedented evidence for short-term variability in 1es 0806+524. the spectrum of this flare is well described by a power law with a photon index of $2.97 \\\\pm 0.29$ between $\\\\sim$150 gev and 1 tev and an integral flux of $(9.3 \\\\pm 1.9)$ per cent of the crab nebula flux above 250 gev. the spectrum during the non-flaring vhe activity is compatible with the only available vhe observation performed in 2008 with veritas when the source was in a low optical state. the broad-band spectral energy distribution can be described with a one-zone synchrotron self compton model with parameters typical for hbls, indicating that 1es 0806+524 is not substantially different from the hbls previously detected.',\n",
       " 883: 'transparency is often deemed critical to enable effective real-world deployment of intelligent systems. yet the motivations for and benefits of different types of transparency can vary significantly depending on context, and objective measurement criteria are difficult to identify. we provide a brief survey, suggesting challenges and related concerns. we highlight and review settings where transparency may cause harm, discussing connections across privacy, multi-agent game theory, economics, fairness and trust.',\n",
       " 884: 'we report direct observation of charge accumulation effect on magnetization reversal in a pt/co(0.5 nm)/pt(0.5 nm)/al2o3 structure with perpendicular anisotropy. by imaging magnetic domain with polar kerr microscopy, we evidence that positive charges accumulating at the pt/al2o3 interface result in favoring magnetic domain wall propagation, while negative charges hinder domain wall nucleation and propagation. our results suggest that magnetic properties in co layer can be strongly influenced by 5d electron accumulation/depletion in an ultrathin pt layer.',\n",
       " 885: 'we show that the space in which scientific, technological and economic developments interplay with each other can be mathematically shaped using pioneering multilayer network and complexity techniques. we build the tri-layered network of human activities (scientific production, patenting, and industrial production) and study the interactions among them, also taking into account the possible time delays. within this construction we can identify which capabilities and prerequisites are needed to be competitive in a given activity, and even measure how much time is needed to transform, for instance, the technological know-how into economic wealth and scientific innovation, being able to make predictions with a very long time horizon. quite unexpectedly, we find empirical evidence that the naive knowledge flow from science, to patents, to products is not supported by data, being instead technology the best predictor for industrial and scientific production for the next decades.',\n",
       " 886: 'this paper presents a direct numerical scheme to approximate the solution of all classes of nonlinear volterra integral equations of the first kind. this computational method is based on operational matrices and vectors. the operational vector for hybrid block pulse functions and chebyshev polynomials is constructed. the scheme transforms the integral equation to a matrix equation and solves it with a careful estimate of the error involved. the main characteristic of the scheme is the low cost of setting up the equations without using any projection method which is the consequence of using operational vectors. simple structure to implement, low computational cost and perfect approximate solutions are the major points of the presented method.   error analysis and comparisons with other existing schemes demonstrate the efficiency and the superiority of our scheme.',\n",
       " 887: 'the segal conjecture describes stable maps between classifying spaces in terms of (virtual) bisets for the finite groups in question. along these lines, we give an algebraic formula for the p-completion functor applied to stable maps between classifying spaces purely in terms of fusion data and burnside modules.',\n",
       " 888: 'in axisymmetric fusion reactors, the equilibrium magnetic configuration can be expressed in terms of the solution to a semi-linear elliptic equation known as the grad-shafranov equation, the solution of which determines the poloidal component of the magnetic field. when the geometry of the confinement region is known, the problem becomes an interior dirichlet boundary value problem. we propose a high order solver based on the hybridizable discontinuous galerkin method. the resulting algorithm (1) provides high order of convergence for the flux function and its gradient, (2) incorporates a novel method for handling piecewise smooth geometries by extension from polygonal meshes, (3) can handle geometries with non-smooth boundaries and x-points, and (4) deals with the semi-linearity through an accelerated two-grid fixed-point iteration. the effectiveness of the algorithm is verified with computations for cases where analytic solutions are known on configurations similar to those of actual devices (iter with single null and double null divertor, nstx, asdex upgrade, and field reversed configurations).',\n",
       " 889: 'let $g$ be a finite group, let $\\\\pi(g)$ be the set of prime divisors of $|g|$ and let $\\\\gamma(g)$ be the prime graph of $g$. this graph has vertex set $\\\\pi(g)$, and two vertices $r$ and $s$ are adjacent if and only if $g$ contains an element of order $rs$. many properties of these graphs have been studied in recent years, with a particular focus on the prime graphs of finite simple groups. in this note, we determine the pairs $(g,h)$, where $g$ is simple and $h$ is a proper subgroup of $g$ such that $\\\\gamma(g) = \\\\gamma(h)$.',\n",
       " 890: 'we show that self-conformal subsets of $\\\\mathbb{r}$ that do not satisfy the weak separation condition have full assouad dimension. combining this with a recent results by k\\\\\"aenm\\\\\"aki and rossi we conclude that an interesting dichotomy applies to self-conformal and not just self-similar sets: if $f\\\\subset\\\\mathbb{r}$ is self-conformal with hausdorff dimension strictly less than $1$, either the hausdorff dimension and assouad dimension agree or the assouad dimension is $1$. we conclude that the weak separation property is in this case equivalent to assouad and hausdorff dimension coinciding. (this manuscript contains errors, see comment below.)',\n",
       " 891: 'in this note, we discuss the possible existence of finite critical trajectories connecting two zeros a(t) and b(t) of a family of quadratic differentials satisfying some properties. we treat the cases of holomorphic and meromorphic quadratic differentials, and we give new proofs concerning the supports of limit measures of the root-counting measures of the generalized laguerre and jacobi polynomials with varying parameters.',\n",
       " 892: 'process mining consists of techniques where logs created by operative systems are transformed into process models. in process mining tools it is often desired to be able to classify ongoing process instances, e.g., to predict how long the process will still require to complete, or to classify process instances to different classes based only on the activities that have occurred in the process instance thus far. recurrent neural networks and its subclasses, such as gated recurrent unit (gru) and long short-term memory (lstm), have been demonstrated to be able to learn relevant temporal features for subsequent classification tasks. in this paper we apply recurrent neural networks to classifying process instances. the proposed model is trained in a supervised fashion using labeled process instances extracted from event log traces. this is the first time we know of gru having been used in classifying business process instances. our main experimental results shows that gru outperforms lstm remarkably in training time while giving almost identical accuracies to lstm models. additional contributions of our paper are improving the classification model training time by filtering infrequent activities, which is a technique commonly used, e.g., in natural language processing (nlp).',\n",
       " 893: 'we study the kondo physics of a quantum magnetic impurity in two-dimensional topological superconductors (tscs), either intrinsic or induced on the surface of a bulk topological insulator, using a numerical renormalization group technique. we show that, despite sharing the p + ip pairing symmetry, intrinsic and extrinsic tscs host different physical processes that produce distinct kondo signatures. extrinsic tscs harbor an unusual screening mechanism involving both electron and orbital degrees of freedom that produces rich and prominent kondo phenomena, especially an intriguing pseudospin kondo singlet state in the superconducting gap and a spatially anisotropic spin correlation. in sharp contrast, intrinsic tscs support a robust impurity spin doublet ground state and an isotropic spin correlation. these findings advance fundamental knowledge of novel kondo phenomena in tscs and suggest experimental avenues for their detection and distinction.',\n",
       " 894: 'as a continuation of [14], we study new pattern formations of ground states $(u_1,u_2)$ for two-component bose-einstein condensates (bec) with homogeneous trapping potentials in $r^2$, where the intraspecies interaction $(-a,-b)$ and the interspecies interaction $-\\\\beta$ are both attractive, $i.e,$ $a$, $b$ and $\\\\beta$ are all positive. if $0<b<a^*:=\\\\|w\\\\|^2_2$ and $0<\\\\beta <a^*$ are fixed, where $w$ is the unique positive solution of $\\\\delta w-w+w^3=0$ in $r^2$, the semi-trivial behavior of $(u_1,u_2)$ as $a\\\\nearrow a^*$ is proved in the sense that $u_1$ concentrates at a unique point and while $u_2\\\\equiv 0$ in $r^2$. however, if $0<b<a^*$ and $a^*\\\\le\\\\beta <\\\\beta ^*=a^*+\\\\sqrt{(a^*-a)(a^*-b)}$, the refined spike profile and the uniqueness of $(u_1,u_2)$ as $a\\\\nearrow a^*$ are analyzed, where $(u_1,u_2)$ must be unique, $u_1$ concentrates at a unique point, and meanwhile $u_2$ can either blow up or vanish, depending on how $\\\\beta$ approaches to $a^*$.',\n",
       " 895: \"we address the homotopy theory of 2-crossed modules of commutative algebras. in particular, we define the concept of a 2-fold homotopy between a pair of 1-fold homotopies connecting 2-crossed module maps $\\\\a \\\\to \\\\a'$. we also prove that if the domain 2-crossed module $\\\\a$ is free up to order one (i.e. if the bottom algebra is a polynomial algebra) then we have a 2-groupoid of 2-crossed module maps $\\\\a \\\\to \\\\a'$ and their homotopies and 2-fold homotopies.\",\n",
       " 896: 'the gamma-ray cherenkov telescope (gct) is one of the small size telescopes (ssts) proposed for the cherenkov telescope array (cta) aimed at the 1 tev to 300 tev energy range. gct will be equipped with a compact high-energy camera (chec) containing 2048 pixels of physical size about 6$\\\\times$6~mm$^2$, leading to a field of view of over 8 degrees. electronics based on custom target asics and fpgas sample incoming signals at a gigasample per second and provide a flexible triggering scheme. waveforms for every pixel in every event are read out are on demand without loss at over 600 events per second. a gct prototype in meudon, paris saw first cherenkov light from air showers in late 2015, using the first chec prototype, chec-m. this contribution presents results from lab and field tests with chec-m and the progress made to a robust camera design for deployment within cta.',\n",
       " 897: 'surface plasma waves (spws) are usually discussed in the context of a metal in contact with a dielectric. however, they can also exist between two metals. in this work we study these bimetallic waves. we find that their dispersion curve always cuts the light line, which allows direct optical coupling without surface grating structures. we propose practical schemes to excite them and the excitation efficiency is estimated. we also show that these waves can be much less lossy than conventional spws and their losses can be systematically controlled, a highly desirable attribute in applications. conducting metal oxides are apt for experimental studies.',\n",
       " 898: 'we consider the conjugacy problem for the automorphism groups of a number of countable homogeneous structures. in each case we find the precise complexity of the conjugacy relation in the sense of borel reducibility.',\n",
       " 899: \"full-duplex self-backhauling is promising to provide cost-effective and flexible backhaul connectivity for ultra-dense wireless networks, but also poses a great challenge to resource management between the access and backhaul links. in this paper, we propose a user-centric joint access-backhaul transmission framework for full-duplex self-backhauled wireless networks. in the access link, user-centric clustering is adopted so that each user is cooperatively served by multiple small base stations (sbss). in the backhaul link, user-centric multicast transmission is proposed so that each user's message is treated as a common message and multicast to its serving sbs cluster. we first formulate an optimization problem to maximize the network weighted sum rate through joint access-backhaul beamforming and sbs clustering when global channel state information (csi) is available. this problem is efficiently solved via the successive lower-bound maximization approach with a novel approximate objective function and the iterative link removal technique. we then extend the study to the stochastic joint access-backhaul beamforming optimization with partial csi. simulation results demonstrate the effectiveness of the proposed algorithms for both full csi and partial csi scenarios. they also show that the transmission design with partial csi can greatly reduce the csi overhead with little performance degradation.\",\n",
       " 900: 'in the last few years, the fermi-lat telescope has discovered over a 100 pulsars at energies above 100 mev, increasing the number of known gamma-ray pulsars by an order of magnitude. in parallel, imaging cherenkov telescopes, such as magic and veritas, have detected for the first time vhe pulsed gamma-rays from the crab pulsar. such detections have revealed that the crab vhe spectrum follows a power-law up to at least 400 gev, challenging most theoretical models, and opening wide possibilities of detecting more pulsars from the ground with the future cherenkov telescope array (cta). in this contribution, we study the capabilities of cta for detecting fermi pulsars. for this, we extrapolate their spectra with \"crab-like\" power-law tails in the vhe range, as suggested by the latest magic and veritas results.',\n",
       " 901: 'we have analysed optical spectra of bl lacertae, the prototype of its class, to verify the presence and possible flux variations of its broad ha line. we used the spectroscopic information also to investigate the question of its parent population. four spectra were acquired at the tng in 2007-2008, when the source was in a relatively faint state. in three cases we were able to measure the broad ha and several narrow emission lines. a comparison with previous results suggests that the broad ha has increased by ~50% in ten years, a change not unusual for broad lined agn. we estimated a black hole mass for bl lac of 4-6 10^8 solar masses from its relation with the bulge luminosity. the virial mass estimated from the spectroscopic data is instead 20-30 times smaller. we suggest that this discrepancy is due to the bl lac blr being underluminous. finally, we addressed the problem of the bl lac parent population, comparing its isotropic quantities with those of other agn classes. from the point of view of the narrow emission line spectrum, the source locates close to low-excitation radio galaxies. when also considering its diffuse radio power, an association with fri radio galaxies is severely questioned due to the lower radio luminosity (at give line luminosity) of bl lac. the narrow line and radio luminosities of bl lac instead match those of a sample of miniature radio galaxies, which however do not show a blr. yet, if existing, \"misaligned bl lac\" objects should have entered that sample. we also rule out the possibility that they have been excluded because of a qso optical appearance. the observational constraints suggest that bl lac is caught in a short term transient stage, which does not leave a detectable evolutionary \"trace\" in the agn population. we speculate on a scenario that can account for the observed properties. [abridged]',\n",
       " 902: 'we assume one site measures without a boundary $e^{-\\\\phi(x)}dx/z$ that satisfy a log-sobolev inequality. we prove that if these measures are perturbed with quadratic interactions, then the associated infinite dimensional gibbs measure on the lattice always satisfies a log-sobolev inequality. furthermore, we present examples of measures that satisfy the inequality with a phase that goes beyond convexity at infinity.',\n",
       " 903: 'non-convex optimization is ubiquitous in machine learning. majorization-minimization (mm) is a powerful iterative procedure for optimizing non-convex functions that works by optimizing a sequence of bounds on the function. in mm, the bound at each iteration is required to \\\\emph{touch} the objective function at the optimizer of the previous bound. we show that this touching constraint is unnecessary and overly restrictive. we generalize mm by relaxing this constraint, and propose a new optimization framework, named generalized majorization-minimization (g-mm), that is more flexible. for instance, g-mm can incorporate application-specific biases into the optimization procedure without changing the objective function. we derive g-mm algorithms for several latent variable models and show empirically that they consistently outperform their mm counterparts in optimizing non-convex objectives. in particular, g-mm algorithms appear to be less sensitive to initialization.',\n",
       " 904: 'starcraft (sc) is one of the most popular and successful real time strategy (rts) games. in recent years, sc is also widely accepted as a challenging testbed for ai research because of its enormous state space, partially observed information, multi-agent collaboration, and so on. with the help of annual aiide and cig competitions, a growing number of sc bots are proposed and continuously improved. however, a large gap remains between the top-level bot and the professional human player. one vital reason is that current sc bots mainly rely on predefined rules to select macro actions during their games. these rules are not scalable and efficient enough to cope with the enormous yet partially observed state space in the game. in this paper, we propose a deep reinforcement learning (drl) framework to improve the selection of macro actions. our framework is based on the combination of the ape-x dqn and the long-short-term-memory (lstm). we use this framework to build our bot, named as lastorder. our evaluation, based on training against all bots from the aiide 2017 starcraft ai competition set, shows that lastorder achieves an 83% winning rate, outperforming 26 bots in total 28 entrants.',\n",
       " 905: 'existing deep learning models may encounter great challenges in handling graph structured data. in this paper, we introduce a new deep learning model for graph data specifically, namely the deep loopy neural network. significantly different from the previous deep models, inside the deep loopy neural network, there exist a large number of loops created by the extensive connections among nodes in the input graph data, which makes model learning an infeasible task. to resolve such a problem, in this paper, we will introduce a new learning algorithm for the deep loopy neural network specifically. instead of learning the model variables based on the original model, in the proposed learning algorithm, errors will be back-propagated through the edges in a group of extracted spanning trees. extensive numerical experiments have been done on several real-world graph datasets, and the experimental results demonstrate the effectiveness of both the proposed model and the learning algorithm in handling graph data.',\n",
       " 906: 'fracterms are introduced as a proxy for fractions. a precise definition of fracterms is formulated and on that basis reasonably precise definitions of various classes of fracterms are given. in the context of the meadow of rational numbers viewing fractions as fracterms provides an adequate theory of fractions. a very different view on fractions is that fractions are values, i.e. rational numbers. fracterms are used to provide a range of intermediate definitions between these two definitions of fractions',\n",
       " 907: 'a family of permutations $a \\\\subset s_n$ is said to be \\\\emph{$t$-set-intersecting} if for any two permutations $\\\\sigma, \\\\pi \\\\in a$, there exists a $t$-set $x$ whose image is the same under both permutations, i.e. $\\\\sigma(x)=\\\\pi(x)$. we prove that if $n$ is sufficiently large depending on $t$, the largest $t$-set-intersecting families of permutations in $s_n$ are cosets of stabilizers of $t$-sets. the $t=2$ case of this was conjectured by j\\\\\\'anos k\\\\\"orner. it can be seen as a variant of the deza-frankl conjecture, proved in [4]. our proof uses similar techniques to those of [4], namely, eigenvalue methods, together with the representation theory of the symmetric group, but the combinatorial part of the proof is harder.',\n",
       " 908: \"the elemental energy spectra of cosmic rays play an important role in understanding their acceleration and propagation. most current results are obtained either from direct measurements by balloon or satellite detectors, or from indirect measurements by air shower detector arrays on the earth's surface. imaging air cherenkov telescopes (iacts), used primarily for gamma-ray astronomy, can also be used for cosmic-ray physics. they are able to measure cherenkov light emitted both by heavy nuclei and by secondary particles produced in their air showers, and are thus sensitive to the charge and energy of cosmic ray particles with energies of tens to hundreds of tev.   a measurement of the energy spectrum of iron nuclei, based on 71 hours of data taken by the veritas array of iacts between 2009 and 2012, will be presented. the energy and other properties of the primary particle are reconstructed using a template-based likelihood fit. the event selection makes use of direct cherenkov light, which is emitted by the primary particle before starting the air shower. a multivariate method is used to estimate the remaining background. using these methods, the iron spectrum was measured in the energy range from 20 tev to 500 tev.\",\n",
       " 909: 'we derive a priori estimates for the compressible free-boundary euler equations with surface tension in three spatial dimensions in the case of a liquid. these are estimates for local existence in lagrangian coordinates when the initial velocity and initial density belong to $h^3$, with an extra regularity condition on the moving boundary, thus lowering the regularity of the initial data. our methods are direct and involve two key elements: the boundary regularity provided by the mean curvature, and a new compressible cauchy invariance.',\n",
       " 910: 'the r package stochvol provides a fully bayesian implementation of heteroskedasticity modeling within the framework of stochastic volatility. it utilizes markov chain monte carlo (mcmc) samplers to conduct inference by obtaining draws from the posterior distribution of parameters and latent variables which can then be used for predicting future volatilities. the package can straightforwardly be employed as a stand-alone tool; moreover, it allows for easy incorporation into other mcmc samplers. the main focus of this paper is to show the functionality of stochvol. in addition, it provides a brief mathematical description of the model, an overview of the sampling schemes used, and several illustrative examples using exchange rate data.',\n",
       " 911: 'we prove several abstract versions of the lojasiewicz-simon gradient inequality for an analytic functional on a banach space that generalize previous abstract versions of this inequality, weakening their hypotheses and, in particular, the well-known infinite-dimensional version of the gradient inequality due to lojasiewicz proved by simon (1983). we also prove that the optimal exponent of the lojasiewicz-simon gradient inequality is obtained when the functional is morse-bott, improving on similar results due to chill (2003, 2006), haraux and jendoubi (2007), and simon (1996). in our article arxiv:1903.01953, we apply our abstract lojasiewicz-simon gradient inequalities to prove a lojasiewicz-simon gradient inequalities for the harmonic map energy functional using sobolev spaces which impose minimal regularity requirements on maps between closed, riemannian manifolds. those inequalities for the harmonic map energy functional generalize those of kwon (2002), liu and yang (2010), simon (1983, 1985), and topping (1997). in our monograph arxiv:1510.03815, we prove lojasiewicz--simon gradient inequalities for coupled yang--mills energy functions using sobolev spaces which impose minimal regularity requirements on pairs of connections and sections. those inequalities generalize that of the pure yang--mills energy function due to the first author (theorems 23.1 and 23.17 in arxiv:1409.1525) for base manifolds of arbitrary dimension and due to rade (1992) for dimensions two and three.',\n",
       " 912: 'this paper presents an approximate reinforcement learning (rl) methodology for bi-level power management of networked microgrids (mg) in electric distribution systems. in practice, the cooperative agent can have limited or no knowledge of the mg asset behavior and detailed models behind the point of common coupling (pcc). this makes the distribution systems unobservable and impedes conventional optimization solutions for the constrained mg power management problem. to tackle this challenge, we have proposed a bi-level rl framework in a price-based environment. at the higher level, a cooperative agent performs function approximation to predict the behavior of entities under incomplete information of mg parametric models; while at the lower level, each mg provides power-flow-constrained optimal response to price signals. the function approximation scheme is then used within an adaptive rl framework to optimize the price signal as the system load and solar generation change over time. numerical experiments have verified that, compared to previous works in the literature, the proposed privacy-preserving learning model has better adaptability and enhanced computational speed.',\n",
       " 913: \"we give upper bounds for the dimension of the set of hypersurfaces of $\\\\mathbb{p}^n$ whose intersection with a fixed integral projective variety is not integral. our upper bounds are optimal. as an application, we construct, when possible, hypersurfaces whose intersections with all the varieties of a family of integral projective varieties are integral. the degree of the hypersurfaces we construct is explicit.   -----   on majore la dimension de l'ensemble des hypersurfaces de $\\\\mathbb{p}^n$ dont l'intersection avec une vari\\\\'et\\\\'e projective int\\\\`egre fix\\\\'ee n'est pas int\\\\`egre. les majorations obtenues sont optimales. comme application, on construit, quand c'est possible, des hypersurfaces dont les intersections avec toutes les vari\\\\'et\\\\'es d'une famille de vari\\\\'et\\\\'es projectives int\\\\`egres sont int\\\\`egres. le degr\\\\'e des hypersurfaces construites est explicite.\",\n",
       " 914: 'this work investigated the stability and asymptotic behavior of some lotka volterra type models. we used the liapunov method which consists in analyzing the stability of systems of ordinary differential equations (odes) around the equilibrium when they submitted to perturbations in the initial conditions',\n",
       " 915: 'supersymmetry plays a crucial role in superstring theory and high-energy physics, but has never been observed in experiments. recently, an effective space-time supersymmetry was argued to emerge in the low-energy region by tuning dirac or weyl semimetal to approach a superconducting quantum critical point, at which the dirac or weyl fermion and the bosonic order parameter are both massless. here, we study under what circumstances can space-time supersymmetry be realized at a quantum critical point. we demonstrate that the yukawa-type coupling between the massless fermion and massless boson can dynamically generate an infinite number of non-supersymmetric terms in the effective field theory of the boson. owing to these terms, no space-time supersymmetry emerges at the superconducting quantum critical points. the results provide important constraint on the exploration of emergent space-time supersymmetry in condensed matter systems.',\n",
       " 916: 'critical transitions (or tipping points) are drastic sudden changes observed in many dynamical systems. large classes of critical transitions are associated to systems, which drift slowly towards a bifurcation point. in the context of stochastic ordinary differential equations (sodes), there are results on growth of variance and autocorrelation before a transition, which can be used as possible warning signs in applications. a similar theory has recently been developed in the simplest setting also for stochastic partial differential equations (spdes) for self-adjoint operators in the drift term. this setting leads to real discrete spectrum and growth of the covariance operator via a certain scaling law. in this paper, we develop this theory substantially further. we cover the cases of complex eigenvalues, degenerate eigenvalues as well as continuous spectrum. this provides a fairly comprehensive theory for most practical applications of warning signs for spde bifurcations.',\n",
       " 917: 'hebbian learning of excitatory synapses plays a central role in storing activity patterns in associative memory models. furthermore, interstimulus hebbian learning associates multiple items in the brain by converting temporal correlation to spatial correlation between attractors. however, growing experimental evidence suggests that learning of inhibitory synapses creates \"inhibitory engrams\", which presumably balance with the patterns encoded in the excitatory network. controlling inhibitory engrams may modify the behavior of associative memory in neural networks, but the consequence of such control has not been theoretically understood. noting that hebbian learning of inhibitory synapses yields an anti-hebbian effect, we show that the combination of hebbian and anti-hebbian learning can increase the span of temporal association between the correlated attractors. the balance of targetted and global inhibition regulates this span of association in the network. our results suggest a nontrivial role of anti-hebbian learning and inhibitory engrams in associative memory.',\n",
       " 918: 'we prove that, for 3 < m < n-1, the grassmannian of m-dimensional subspaces of the space of skew-symmetric forms over a vector space of dimension n is birational to the hilbert scheme of the degeneracy loci of m global sections of omega(2), the twisted cotangent bundle on p^{n-1}. for 3=m<n-1 and n odd, this grassmannian is proved to be birational to the set of veronese surfaces parametrized by the pfaffians of linear skew-symmetric matrices of order n.',\n",
       " 919: 'we study precursors of failure in hierarchical random fuse network models which can be considered as idealizations of hierarchical (bio)materials where fibrous assemblies are held together by multi-level (hierarchical) cross-links. when such structures are loaded towards failure, the patterns of precursory avalanche activity exhibit generic scale invariance: irrespective of load, precursor activity is characterized by power-law avalanche size distributions without apparent cut-off, with power-law exponents that decrease continuously with increasing load. this failure behavior and the ensuing super-rough crack morphology differ significantly from the findings in non-hierarchical structures.',\n",
       " 920: 'primordial black holes (pbhs) have long been suggested as a viable candidate for the elusive dark matter (dm). the abundance of such pbhs has been constrained using a number of astrophysical observations, except for a hitherto unexplored mass window of $m_{\\\\rm pbh}=[10^{-14},10^{-9}]m_\\\\odot$. here we carry out a dense-cadence (2~min sampling rate), 7 hour-long observation of the andromeda galaxy (m31) with the subaru hyper suprime-cam to search for microlensing of stars in m31 by pbhs lying in the halo regions of the milky way (mw) and m31. given our simultaneous monitoring of tens of millions of stars in m31, if such light pbhs make up a significant fraction of dm, we expect to find many microlensing events for the pbh dm scenario. however, we identify only a single candidate event, which translates into the most stringent upper bounds on the abundance of pbhs in the mass range $m_{\\\\rm pbh}\\\\simeq [10^{-11}, 10^{-6}]m_\\\\odot$.',\n",
       " 921: 'unsupervised image-to-image translation techniques are able to map local texture between two domains, but they are typically unsuccessful when the domains require larger shape change. inspired by semantic segmentation, we introduce a discriminator with dilated convolutions that is able to use information from across the entire image to train a more context-aware generator. this is coupled with a multi-scale perceptual loss that is better able to represent error in the underlying shape of objects. we demonstrate that this design is more capable of representing shape deformation in a challenging toy dataset, plus in complex mappings with significant dataset variation between humans, dolls, and anime faces, and between cats and dogs.',\n",
       " 922: 'we investigate the problem of multi-agent coordination under rationality constraints. specifically, role allocation, task assignment, resource allocation, etc. inspired by human behavior, we propose a framework (ca^3nony) that enables fast convergence to efficient and fair allocations based on a simple convention of courtesy. we prove that following such convention induces a strategy which constitutes an $\\\\epsilon$-subgame-perfect equilibrium of the repeated allocation game with discounting. simulation results highlight the effectiveness of ca^3nony as compared to state-of-the-art bandit algorithms, since it achieves more than two orders of magnitude faster convergence, higher efficiency, fairness, and average payoff.',\n",
       " 923: 'in many chemical reactions, reaction rate fluctuation is inevitable. reaction rates are different whenever chemical reaction occurs due to their dependence on the number of reaction events or the product number. as such, understanding the impact of rate fluctuation on product number counting statistics is of the utmost importance when developing a quantitative explanation of chemical reactions. in this work, we present a master equation that describes reaction rates as a function of product number and time. our equal reveals the relationship between the reaction rate and product number fluctuation. product number counting statistics uncovers a stochastic property of the product number; product number directly manipulates the reaction rate. specifically, we find that product number shows super-poisson characteristics when the product number increases, inducing an increase in the reaction rate. while, on the other hand, when the product number shows sub-poisson characteristics with an increase in the product number, this is induced by a decrease in the reaction rate. furthermore, our analysis exploits reaction rate fluctuation, enabling the quantification of the deviation of an elementary reaction process from a renewal process.',\n",
       " 924: \"computational galois theory, in particular the problem of computing the galois group of a given polynomial is a very old problem. currently, the best algorithmic solution is stauduhar's method. computationally, one of the key challenges in the application of stauduhar's method is to find, for a given pair of groups h<g a g-relative h-invariant, that is a multivariate polynomial f that is h-invariant, but not g-invariant. while generic, theoretical methods are known to find such f, in general they yield impractical answers. we give a general method for computing invariants of large degree which improves on previous known methods, as well as various special invariants that are derived from the structure of the groups. we then apply our new invariants to the task of computing the galois groups of polynomials over the rational numbers, resulting in the first practical degree independent algorithm.\",\n",
       " 925: 'deep neural networks are vulnerable to adversarial examples, even in the black-box setting, where the attacker is restricted solely to query access. existing black-box approaches to generating adversarial examples typically require a significant number of queries, either for training a substitute network or performing gradient estimation. we introduce genattack, a gradient-free optimization technique that uses genetic algorithms for synthesizing adversarial examples in the black-box setting. our experiments on different datasets (mnist, cifar-10, and imagenet) show that genattack can successfully generate visually imperceptible adversarial examples against state-of-the-art image recognition models with orders of magnitude fewer queries than previous approaches. against mnist and cifar-10 models, genattack required roughly 2,126 and 2,568 times fewer queries respectively, than zoo, the prior state-of-the-art black-box attack. in order to scale up the attack to large-scale high-dimensional imagenet models, we perform a series of optimizations that further improve the query efficiency of our attack leading to 237 times fewer queries against the inception-v3 model than zoo. furthermore, we show that genattack can successfully attack some state-of-the-art imagenet defenses, including ensemble adversarial training and non-differentiable or randomized input transformations. our results suggest that evolutionary algorithms open up a promising area of research into effective black-box attacks.',\n",
       " 926: 'we study spaces of vector-valued quasianalytic functions and solve the first cousin problem in these spaces.',\n",
       " 927: 'factor analysis has proven to be a relevant tool for extracting tissue time-activity curves (tacs) in dynamic pet images, since it allows for an unsupervised analysis of the data. reliable and interpretable results are possible only if considered with respect to suitable noise statistics. however, the noise in reconstructed dynamic pet images is very difficult to characterize, despite the poissonian nature of the count-rates. rather than explicitly modeling the noise distribution, this work proposes to study the relevance of several divergence measures to be used within a factor analysis framework. to this end, the $\\\\beta$-divergence, widely used in other applicative domains, is considered to design the data-fitting term involved in three different factor models. the performances of the resulting algorithms are evaluated for different values of $\\\\beta$, in a range covering gaussian, poissonian and gamma-distributed noises. the results obtained on two different types of synthetic images and one real image show the interest of applying non-standard values of $\\\\beta$ to improve factor analysis.',\n",
       " 928: 'we give three identities involving multiple zeta values of height one and of maximal height; an explicit formula for the height-one multiple zeta values, a regularized sum formula, and a sum formula for the multiple zeta values of maximal height.',\n",
       " 929: \"the aim of this paper is to reveal the discrete convexity of the minimum-cost packings of arborescences and branchings. we first prove that the minimum-cost packings of disjoint $k$ branchings (minimum-cost $k$-branchings) induce an $\\\\mathrm{m}^\\\\natural$-convex function defined on the integer vectors on the vertex set. the proof is based on a theorem on packing disjoint $k$-branchings, which extends edmonds' disjoint branchings theorem and is of independent interest. we then show the $\\\\mathrm{m}$-convexity of the minimum-cost $k$-arborescences, which provides a short proof for a theorem of bern\\\\'ath and kir\\\\'aly (soda 2016) stating that the root vectors of the minimum-cost $k$-arborescences form a base polyhedron of a submodular function. finally, building upon the $\\\\mathrm{m}^\\\\natural$-convexity of $k$-branchings, we present a new problem of minimum-cost root location of a $k$-branching, and show that it can be solved in polynomial time if the opening cost function is $\\\\mathrm{m}^\\\\natural$-convex.\",\n",
       " 930: 'we propose a neural information processing system which is obtained by re-purposing the function of a biological neural circuit model, to govern simulated and real-world control tasks. inspired by the structure of the nervous system of the soil-worm, c. elegans, we introduce neuronal circuit policies (ncps), defined as the model of biological neural circuits reparameterized for the control of an alternative task. we learn instances of ncps to control a series of robotic tasks, including the autonomous parking of a real-world rover robot. for reconfiguration of the purpose of the neural circuit, we adopt a search-based optimization algorithm. neuronal circuit policies perform on par and in some cases surpass the performance of contemporary deep learning models with the advantage leveraging significantly fewer learnable parameters and realizing interpretable dynamics at the cell-level.',\n",
       " 931: \"we present a system that allows users to visualize complex human motion via 3d motion sculptures---a representation that conveys the 3d structure swept by a human body as it moves through space. given an input video, our system computes the motion sculptures and provides a user interface for rendering it in different styles, including the options to insert the sculpture back into the original video, render it in a synthetic scene or physically print it.   to provide this end-to-end workflow, we introduce an algorithm that estimates that human's 3d geometry over time from a set of 2d images and develop a 3d-aware image-based rendering approach that embeds the sculpture back into the scene. by automating the process, our system takes motion sculpture creation out of the realm of professional artists, and makes it applicable to a wide range of existing video material.   by providing viewers with 3d information, motion sculptures reveal space-time motion information that is difficult to perceive with the naked eye, and allow viewers to interpret how different parts of the object interact over time. we validate the effectiveness of this approach with user studies, finding that our motion sculpture visualizations are significantly more informative about motion than existing stroboscopic and space-time visualization methods.\",\n",
       " 932: 'we introduce the notion of tropical defects, certificates that a system of polynomial equations is not a tropical basis, and provide two algorithms for finding them in affine spaces of complementary dimension to the zero set. we use these techniques to solve open problems regarding del pezzo surfaces of degree 3 and realizability of valuated gaussoids on 4 elements.',\n",
       " 933: 'currently the standard light sensors for imaging atmospheric cherenkov telescopes are the classical photo multiplier tubes that are using bialkali photo cathodes. about eight years ago we initiated an improvement program with the photo multiplier tube (pmt) manufacturers hamamatsu (japan), electron tubes enterprises (england) and photonis (france) for the needs of imaging atmospheric cherenkov telescopes. as a result, after about 40 years of stagnation of the peak quantum efficiency (qe) on the level of 25-27%, new pmts appeared with a peak qe of 35%. these have got the name super-bialkali. the second significant upgrade has happened very recently, as a result of a dedicated improvement program for the candidate pmt for cherenkov telescope array. the latter is going to be the next generation major instrument in the field of very high energy gamma astrophysics and will consist of over 100 telescopes of three different sizes of 23m, 12m and 4-7m, located both in southern and northern hemispheres. now pmts with average peak qe of approximately 40% became available. also, the photo electron collection efficiency of the previous generation pmts of 80- 90% has been enhanced towards 95-98% for the new ones. the after-pulsing of novel pmts has been reduced towards the level of 0.02% for the set threshold of 4 photo electrons. we will report on the pmt development work by the companies electron tubes enterprises and hamamatsu photonics k.k. show the achieved results and the current status.',\n",
       " 934: 'let m denote the total space of a lefschetz fibration, obtained by blowing up a lefschetz pencil on an algebraic surface. we consider the n-fold fibre sum m(n), generalizing the construction of the elliptic surfaces e(n). for a lefschetz pencil on a simply-connected minimal surface of general type we partially calculate the seiberg-witten invariants of the fibre sum m(n) using a formula of morgan-szabo-taubes. as an application we derive an obstruction for self-diffeomorphisms of the boundary of the tubular neighbourhood of a general fibre in m(n) to extend over the complement of the neighbourhood. similar obstructions are known in the case of elliptic surfaces.',\n",
       " 935: 'fix $\\\\lambda>0$. consider the bessel operator $\\\\delta_\\\\lambda:=-\\\\frac{d^2}{dx^2}-\\\\frac{2\\\\lambda}{x}\\\\frac d{dx}$ on $\\\\mathbb{r}_+:=(0,\\\\infty)$ and the harmonic conjugacy introduced by muckenhoupt and stein. we provide the two-weight inequality for the poisson operator $\\\\mathsf{p}^{[\\\\lambda]}_t=e^{-t\\\\sqrt{\\\\delta_\\\\lambda}}$ in this bessel setting. in particular, we prove that for a measure $\\\\mu$ on $\\\\mathbb{r}^2_{+,+}:=(0,\\\\infty)\\\\times (0,\\\\infty)$ and $\\\\sigma$ on $\\\\mathbb{r}_+$: $$ \\\\|\\\\mathsf{p}^{[\\\\lambda]}_\\\\sigma(f)\\\\|_{l^2(\\\\mathbb{r}^2_{+,+};\\\\mu)} \\\\lesssim \\\\|f\\\\|_{l^2(\\\\mathbb{r}_+;\\\\sigma)}, $$ if and only if testing conditions hold for the the poisson operator and its adjoint. further, the norm of the operator is shown to be equivalent to the best constant in the testing conditions.',\n",
       " 936: 'we study intersection cohomology of moduli spaces of semistable vector bundles on a complex algebraic surface. our main result relates intersection poincare polynomials of the moduli spaces to donaldson-thomas invariants of the surface. in support of this result, we compute explicitly intersection poincare polynomials for sheaves with rank two and three on ruled surfaces.',\n",
       " 937: 'for distributions p and q with different supports, the divergence d(p|q) may not exist. we define a spread divergence on modified p and q and describe sufficient conditions for the existence of such a divergence. we demonstrate how to maximize the discriminatory power of a given divergence by parameterizing and learning the spread. we also give examples of using a spread divergence to train and improve implicit generative models, including linear models (independent components analysis) and non-linear models (deep generative networks).',\n",
       " 938: 'despite the large volume of face recognition datasets, there is a significant portion of subjects, of which the samples are insufficient and thus under-represented. ignoring such significant portion results in insufficient training data. training with under-represented data leads to biased classifiers in conventionally-trained deep networks. in this paper, we propose a center-based feature transfer framework to augment the feature space of under-represented subjects from the regular subjects that have sufficiently diverse samples. a gaussian prior of the variance is assumed across all subjects and the variance from regular ones are transferred to the under-represented ones. this encourages the under-represented distribution to be closer to the regular distribution. further, an alternating training regimen is proposed to simultaneously achieve less biased classifiers and a more discriminative feature representation. we conduct ablative study to mimic the under-represented datasets by varying the portion of under-represented classes on the ms-celeb-1m dataset. advantageous results on lfw, ijb-a and ms-celeb-1m demonstrate the effectiveness of our feature transfer and training strategy, compared to both general baselines and state-of-the-art methods. moreover, our feature transfer successfully presents smooth visual interpolation, which conducts disentanglement to preserve identity of a class while augmenting its feature space with non-identity variations such as pose and lighting.',\n",
       " 939: 'end-to-end trained neural networks (nns) are a compelling approach to autonomous vehicle control because of their ability to learn complex tasks without manual engineering of rule-based decisions. however, challenging road conditions, ambiguous navigation situations, and safety considerations require reliable uncertainty estimation for the eventual adoption of full-scale autonomous vehicles. bayesian deep learning approaches provide a way to estimate uncertainty by approximating the posterior distribution of weights given a set of training data. dropout training in deep nns approximates bayesian inference in a deep gaussian process and can thus be used to estimate model uncertainty. in this paper, we propose a bayesian nn for end-to-end control that estimates uncertainty by exploiting feature map correlation during training. this approach achieves improved model fits, as well as tighter uncertainty estimates, than traditional element-wise dropout. we evaluate our algorithms on a challenging dataset collected over many different road types, times of day, and weather conditions, and demonstrate how uncertainties can be used in conjunction with a human controller in a parallel autonomous setting.',\n",
       " 940: 'a new type of integrated polarizer based on bent coupled optical waveguides is proposed. the simplicity of the device geometry permits its realization using only basic standard fabrication steps. a deep etched waveguide silicon nitride te-pass implementation has been studied using a full vector 3d mode solver and beam propagation techniques. the characteristics of the underlying physical mechanism bring in flexibility to the design of broadband devices robust against fabrication tolerances. the possibility of incorporating almost design-transparent polarizers in photonic integrated circuits is also discussed.',\n",
       " 941: 'the gseagen code is a genie based application to generate neutrino-induced events in an underwater neutrino detector. the gseagen code is able to generate events induced by all neutrino flavours, taking into account topological differences between track-type and shower-like events. the neutrino interaction is simulated taking into account the density and the composition of the media surrounding the detector. the main features of gseagen will be presented together with some examples of its application within antares and km3net.',\n",
       " 942: 'detecting objects in a video is a compute-intensive task. in this paper we propose catdet, a system to speedup object detection by leveraging the temporal correlation in video. catdet consists of two dnn models that form a cascaded detector, and an additional tracker to predict regions of interests based on historic detections. we also propose a new metric, mean delay(md), which is designed for latency-critical video applications. experiments on the kitti dataset show that catdet reduces operation count by 5.1-8.7x with the same mean average precision(map) as the single-model faster r-cnn detector and incurs additional delay of 0.3 frame. on citypersons dataset, catdet achieves 13.0x reduction in operations with 0.8% map loss.',\n",
       " 943: 'we have obtained a \"hierarchical regionalization\" of 3,107 county-level units of the united states based upon census-recorded 1995-2000 intercounty migration flows. the methodology employed was the two-stage (double-standardization and strong component [directed graph] hierarchical clustering) algorithm described in the 2009 pnas (106 [26], e66) letter (arxiv:0904.4863). various features (e. g., cosmopolitan vs. provincial aspects, and indices of isolation) of the regionalization have been previously discussed in arxiv:0907.2393, arxiv:0903.3623 and arxiv:0809.2768. however, due to the lengthy (38-page) nature of the associated dendrogram, the detailed tree structure itself was not readily available for inspection. here, we do present this (county-searchable) dendrogram--and invite readers to explore it, based on their particular interests/locations. an ordinal scale--rather than the originally-derived cardinal scale of the doubly-standardized values--in which groupings/features were more immediately apparent, was originally presented. now, we append the cardinal-scale dendrogram.',\n",
       " 944: \"we consider the interplay of point counts, singular cohomology, \\\\'etale cohomology, eigenvalues of the frobenius and the grothendieck ring of varieties for two families of varieties: spaces of rational maps and moduli spaces of marked, degree $d$ rational curves in $\\\\mathbb{p}^n$. we deduce as special cases algebro-geometric and arithmetic refinements of topological computations of segal, cohen--cohen--mann--milgram, vassiliev and others.\",\n",
       " 945: 'we investigate the spin evolution of dark matter haloes and their dependence on the number of connected filaments from the cosmic web at high redshift (spin-filament relation hereafter). to this purpose, we have simulated $5000$ haloes in the mass range $5\\\\times10^{9}h^{-1}m_{\\\\odot}$ to $5\\\\times10^{11}h^{-1}m_{\\\\odot}$ at $z=3$ in cosmological n-body simulations. we confirm the relation found by prieto et al. 2015 where haloes with fewer filaments have larger spin. we also found that this relation is more significant for higher halo masses, and for haloes with a passive (no major mergers) assembly history. another finding is that haloes with larger spin or with fewer filaments have their filaments more perpendicularly aligned with the spin vector. our results point to a picture in which the initial spin of haloes is well described by tidal torque theory and then gets subsequently modified in a predictable way because of the topology of the cosmic web, which in turn is given by the currently favoured lcdm model. our spin-filament relation is a prediction from lcdm that could be tested with observations.',\n",
       " 946: 'observations and detections of active galactic nuclei (agn) by cherenkov telescopes are often triggered by information about high flux states in other wavelength bands. to overcome this bias, the vhe gamma-ray telescope magic has conducted dedicated monitoring observations of nearby agn since 2006. three well established, tev-bright blazars were selected to be observed regularly: mrk 421, mrk 501, and 1es1959+650. the goals of these observations are to obtain an unbiased distribution of flux states shedding light on the duty cycle of agn, to investigate potential spectral changes during periods of different source activity, and to correlate the results with multiwavelength observations. also clues on a potential periodic behavior of the sources might be drawn from a study of the obtained lightcurves. by testing predictions of theoretical models, like, e.g., the correlation between the tev flux level and the peak frequency predicted in ssc models, monitoring deepens our knowledge about the acceleration and emission processes in agn. the status and results of the magic agn monitoring program will be presented.',\n",
       " 947: 'in this paper, we introduce a novel type of rectified linear unit (relu), called a dual rectified linear unit (drelu). a drelu, which comes with an unbounded positive and negative image, can be used as a drop-in replacement for a tanh activation function in the recurrent step of quasi-recurrent neural networks (qrnns) (bradbury et al. (2017)). similar to relus, drelus are less prone to the vanishing gradient problem, they are noise robust, and they induce sparse activations.   we independently reproduce the qrnn experiments of bradbury et al. (2017) and compare our drelu-based qrnns with the original tanh-based qrnns and long short-term memory networks (lstms) on sentiment classification and word-level language modeling. additionally, we evaluate on character-level language modeling, showing that we are able to stack up to eight qrnn layers with drelus, thus making it possible to improve the current state-of-the-art in character-level language modeling over shallow architectures based on lstms.',\n",
       " 948: 'in timeline-based planning, domains are described as sets of independent, but interacting, components, whose behaviour over time (the set of timelines) is governed by a set of temporal constraints. a distinguishing feature of timeline-based planning systems is the ability to integrate planning with execution by synthesising control strategies for flexible plans. however, flexible plans can only represent temporal uncertainty, while more complex forms of nondeterminism are needed to deal with a wider range of realistic problems. in this paper, we propose a novel game-theoretic approach to timeline-based planning problems, generalising the state of the art while uniformly handling temporal uncertainty and nondeterminism. we define a general concept of timeline-based game and we show that the notion of winning strategy for these games is strictly more general than that of control strategy for dynamically controllable flexible plans. moreover, we show that the problem of establishing the existence of such winning strategies is decidable using a doubly exponential amount of space.',\n",
       " 949: \"let $\\\\{g_m\\\\}_{m\\\\geq 0}$ be the random graph process, where $g_0$ is the empty graph on $n$ vertices and subsequent graphs in the sequence are obtained by adding a new edge uniformly at random. for each $\\\\varepsilon>0$, we show that, almost surely, any graph $g_m$ with minimum degree at least 2 is not only hamiltonian (as shown by bollob\\\\'as), but remains hamiltonian despite the removal of any set of edges, as long as at most $(1/2-\\\\varepsilon)$ of the edges incident to each vertex are removed. we say that such a graph is $(1/2-\\\\varepsilon)$-resiliently hamiltonian. furthermore, for each $\\\\epsilon>0$, we show that, almost surely, each graph $g_m$ is not $(1/2+\\\\varepsilon)$-resiliently hamiltonian. these results strengthen those by lee and sudakov on the likely resilience of hamiltonicity in the binomial random graph.   for each $k$, we denote by $g^{(k)}$ the (possibly empty) maximal subgraph with minimum degree at least $k$ of a graph $g$. that is, the $k$-core of $g$. krivelevich, lubetzky and sudakov have shown that, for each $k\\\\geq 15$, in almost every random graph process $\\\\{g_m\\\\}_{m\\\\geq 0}$, every non-empty $k$-core is hamiltonian. we show that, for each $\\\\varepsilon>0$ and $k\\\\geq k_0(\\\\varepsilon)$, in almost every random graph process $\\\\{g_m\\\\}_{m\\\\geq 0}$, every non-empty $k$-core is $(1/2-\\\\varepsilon)$-resiliently hamiltonian, but not $(1/2+\\\\varepsilon)$-resiliently hamiltonian.\",\n",
       " 950: \"in this paper, we reconstruct kuperberg's $g_2$ web space. we introduce a new web (a trivalent diagram) and new relations between kuperberg's web diagrams and the new diagram. using the $g_2$ webs, we define crossing formulas corresponding to r-matrices associated to some $g_2$ irreducible representations and calculate $g_2$ quantum link invariant for some torus links.\",\n",
       " 951: 'the abundances of dark matter halos in the universe are described by the halo mass function (hmf). it enters most cosmological analyses and parametrizes how the linear growth of primordial perturbations is connected to these abundances. interestingly, this connection can be made approximately cosmology independent. this made it possible to map in detail its near-universal behavior through large-scale simulations. however, such simulations may suffer from systematic effects, especially if baryonic physics is included. in this paper we ask how well observations can constrain directly the hmf. the observables we consider are galaxy cluster number counts, galaxy cluster power spectrum and lensing of type ia supernovae. our results show that des is capable of putting the first meaningful constraints on the hmf, while both euclid and j-pas can give stronger constraints, comparable to the ones from state-of-the-art simulations. we also find that an independent measurement of cluster masses is even more important for measuring the hmf than for constraining the cosmological parameters, and can vastly improve the determination of the halo mass function. measuring the hmf could thus be used to cross-check simulations and their implementation of baryon physics. it could even, if deviations cannot be accounted for, hint at new physics.',\n",
       " 952: 'we give a protocol for producing certifiable randomness from a single untrusted quantum device that is polynomial-time bounded. the randomness is certified to be statistically close to uniform from the point of view of any computationally unbounded quantum adversary, that may share entanglement with the quantum device. the protocol relies on the existence of post-quantum secure trapdoor claw-free functions, and introduces a new primitive for constraining the power of an untrusted quantum device. we show how to construct this primitive based on the hardness of the learning with errors (lwe) problem, and prove that it has a crucial adaptive hardcore bit property. the randomness protocol can be used as the basis for an efficiently verifiable \"test of quantumness\", thus answering an outstanding challenge in the field.',\n",
       " 953: 'for a strict lie 2-group, we develop a notion of lie 2-algebra-valued differential forms on lie groupoids, furnishing a differential graded-commutative lie algebra equipped with an adjoint action of the lie 2-group and a pullback operation along morita equivalences between lie groupoids. using this notion, we define connections on principal 2-bundles as lie 2-algebra-valued 1-forms on the total space lie groupoid of the 2-bundle, satisfying a condition in complete analogy to connections on ordinary principal bundles. we carefully treat various notions of curvature, and prove a classification result by the non-abelian differential cohomology of breen-messing. this provides a consistent, global perspective to higher gauge theory.',\n",
       " 954: 'we study the closure of the cubic principal hyperbolic domain and its intersection $\\\\mathcal{p}_\\\\lambda$ with the slice $\\\\mathcal{f}_\\\\lambda$ of the space of all cubic polynomials with fixed point $0$ defined by the multiplier $\\\\lambda$ at $0$. we show that any bounded domain $\\\\mathcal{w}$ of $\\\\mathcal{f}_\\\\lambda\\\\setminus\\\\mathcal{p}_\\\\lambda$ consists of $j$-stable polynomials $f$ with connected julia sets $j(f)$ and is either of \\\\emph{siegel capture} type (then $f\\\\in \\\\mathcal{w}$ has an invariant siegel domain $u$ around $0$ and another fatou domain $v$ such that $f|_v$ is two-to-one and $f^k(v)=u$ for some $k>0$) or of \\\\emph{queer} type (then at least one critical point of $f\\\\in \\\\mathcal{w}$ belongs to $j(f)$, the set $j(f)$ has positive lebesgue measure, and carries an invariant line field).',\n",
       " 955: 'in this paper we present tools for applied researchers that re-purpose off-the-shelf methods from the computer-science field of machine learning to create a \"discovery engine\" for data from randomized controlled trials (rcts). the applied problem we seek to solve is that economists invest vast resources into carrying out rcts, including the collection of a rich set of candidate outcome measures. but given concerns about inference in the presence of multiple testing, economists usually wind up exploring just a small subset of the hypotheses that the available data could be used to test. this prevents us from extracting as much information as possible from each rct, which in turn impairs our ability to develop new theories or strengthen the design of policy interventions. our proposed solution combines the basic intuition of reverse regression, where the dependent variable of interest now becomes treatment assignment itself, with methods from machine learning that use the data themselves to flexibly identify whether there is any function of the outcomes that predicts (or has signal about) treatment group status. this leads to correctly-sized tests with appropriate $p$-values, which also have the important virtue of being easy to implement in practice. one open challenge that remains with our work is how to meaningfully interpret the signal that these methods find.',\n",
       " 956: 'we give necessary and sufficient conditions on a presentable infinity-category c so that families of objects of c form an infinity-topos. in particular, we prove a conjecture of joyal that this is the case whenever c is stable.',\n",
       " 957: 'for massive data, the family of subsampling algorithms is popular to downsize the data volume and reduce computational burden. existing studies focus on approximating the ordinary least squares estimate in linear regression, where statistical leverage scores are often used to define subsampling probabilities. in this paper, we propose fast subsampling algorithms to efficiently approximate the maximum likelihood estimate in logistic regression. we first establish consistency and asymptotic normality of the estimator from a general subsampling algorithm, and then derive optimal subsampling probabilities that minimize the asymptotic mean squared error of the resultant estimator. an alternative minimization criterion is also proposed to further reduce the computational cost. the optimal subsampling probabilities depend on the full data estimate, so we develop a two-step algorithm to approximate the optimal subsampling procedure. this algorithm is computationally efficient and has a significant reduction in computing time compared to the full data approach. consistency and asymptotic normality of the estimator from a two-step algorithm are also established. synthetic and real data sets are used to evaluate the practical performance of the proposed method.',\n",
       " 958: \"grebinski and kucherov (1998) and alon et al. (2004-2005) study the problem of learning a hidden graph for some especial cases, such as hamiltonian cycle, cliques, stars, and matchings. this problem is motivated by problems in chemical reactions, molecular biology and genome sequencing.   in this paper, we present a generalization of this problem. precisely, we consider a graph g and a subgraph h of g and we assume that g contains exactly one defective subgraph isomorphic to h. the goal is to find the defective subgraph by testing whether an induced subgraph contains an edge of the defective subgraph, with the minimum number of tests. we present an upper bound for the number of tests to find the defective subgraph by using the symmetric and high probability variation of lov\\\\'asz local lemma.\",\n",
       " 959: 'the nature of the superconducting (sc) precursor in the cuprates has been the subject of intense interest, with profound implications for both the normal and the sc states. different experimental probes have led to vastly disparate conclusions on the temperature range of superconducting fluctuations. the main challenges have been to separate the sc response from complex normal-state behavior, and to distinguish the underlying behavior of the quintessential cuo$_{2}$ layers from compound-specific properties. here we reveal remarkably simple and universal behavior of the sc precursor using torque magnetometry, a unique thermodynamic probe with extremely high sensitivity to sc diamagnetism. we comprehensively study four distinct cuprate compounds: single-cuo$_{2}$-layer la$_{2-x}$sr$_{x}$cuo$_{4}$ (lsco), bi$_{2}$(sr,la)$_{2}$cuo$_{6+\\\\delta}$ (bi2201) and hgba$_{2}$cuo$_{4+\\\\delta}$ (hg1201), and double-layer bi$_{2}$sr$_{2}$ca$_{0.95}$y$_{0.05}$cuo$_{8+\\\\delta}$ (bi2212). our approach, which focuses on the nonlinear diamagnetic response, completely removes normal-state contributions and thus allows us to trace the diamagnetic signal above tc with great precision. we find that sc diamagnetism vanishes in an unusual, yet surprisingly simple exponential manner, marked by a universal temperature scale that is independent of compound and tc. we discuss the distinct possibility that this unusual behavior signifies the proliferation of sc clusters as a result of the intrinsic inhomogeneity known to be an inherent property of the cuprates.',\n",
       " 960: 'this paper addresses the problem of speech separation and enhancement from multichannel convolutive and noisy mixtures, \\\\emph{assuming known mixing filters}. we propose to perform the speech separation and enhancement task in the short-time fourier transform domain, using the convolutive transfer function (ctf) approximation. compared to time-domain filters, ctf has much less taps, consequently it has less near-common zeros among channels and less computational complexity. the work proposes three speech-source recovery methods, namely: i) the multichannel inverse filtering method, i.e. the multiple input/output inverse theorem (mint), is exploited in the ctf domain, and for the multi-source case, ii) a beamforming-like multichannel inverse filtering method applying single source mint and using power minimization, which is suitable whenever the source ctfs are not all known, and iii) a constrained lasso method, where the sources are recovered by minimizing the $\\\\ell_1$-norm to impose their spectral sparsity, with the constraint that the $\\\\ell_2$-norm fitting cost, between the microphone signals and the mixing model involving the unknown source signals, is less than a tolerance. the noise can be reduced by setting a tolerance onto the noise power. experiments under various acoustic conditions are carried out to evaluate the three proposed methods. the comparison between them as well as with the baseline methods is presented.',\n",
       " 961: 'collective motion is an intriguing phenomenon, especially considering that it arises from a set of simple rules governing local interactions between individuals. in theoretical models, these rules are normally \\\\emph{assumed} to take a particular form, possibly constrained by heuristic arguments. we propose a new class of models, which describe the individuals as \\\\emph{agents}, capable of deciding for themselves how to act and learning from their experiences. the local interaction rules do not need to be postulated in this model, since they \\\\emph{emerge} from the learning process. we apply this ansatz to a concrete scenario involving marching locusts, in order to model the phenomenon of density-dependent alignment. we show that our learning agent-based model can account for a fokker-planck equation that describes the collective motion and, most notably, that the agents can learn the appropriate local interactions, requiring no strong previous assumptions on their form. these results suggest that learning agent-based models are a powerful tool for studying a broader class of problems involving collective motion and animal agency in general.',\n",
       " 962: 'we describe a quaternionic-based ansatz generalizing the gibbons-hawking ansatz to a class of hyperk\\\\\"ahler metrics with hidden symmetries. we then apply it to obtain explicit expressions for gravitational instanton metrics of type $d_k$.',\n",
       " 963: 'there is a heated debate on how to interpret the decisions provided by deep learning models (dlm), where the main approaches rely on the visualization of salient regions to interpret the dlm classification process. however, these approaches generally fail to satisfy three conditions for the problem of lesion detection from medical images: 1) for images with lesions, all salient regions should represent lesions, 2) for images containing no lesions, no salient region should be produced,and 3) lesions are generally small with relatively smooth borders. we propose a new model-agnostic paradigm to interpret dlm classification decisions supported by a novel definition of saliency that incorporates the conditions above. our model-agnostic 1-class saliency detector (masd) is tested on weakly supervised breast lesion detection from dce-mri, achieving state-of-the-art detection accuracy when compared to current visualization methods.',\n",
       " 964: 'we consider the problem of designing a derivatives exchange aiming at addressing clients needs in terms of listed options and providing suitable liquidity. we proceed into two steps. first we use a quantization method to select the options that should be displayed by the exchange. then, using a principal-agent approach, we design a make take fees contract between the exchange and the market maker. the role of this contract is to provide incentives to the market maker so that he offers small spreads for the whole range of listed options, hence attracting transactions and meeting the commercial requirements of the exchange.',\n",
       " 965: 'we study completeness of the spaces $\\\\mathcal{p}_s^=$ of probability measures in $\\\\mathbb{r}^n$ which have equal (prescribed) moments up to order $s \\\\in \\\\mathbb{n}$, endowed with the metric $d_s(\\\\mu,\\\\nu)=\\\\sup_{x \\\\in \\\\mathbb{r}^n\\\\setminus 0}\\\\frac{|\\\\hat \\\\mu(x)-\\\\hat \\\\nu(x)|}{|x|^s}$, where $\\\\hat \\\\mu$ is the characteristic function of $\\\\mu$. we prove that the spaces $(\\\\mathcal{p}_s^=,d_s)$ are complete if $s$ is even and construct suitable counterexamples to completeness for all odd $s$. this solves an open problem formulated by j. carrillo and g. toscani in 2007.',\n",
       " 966: 'this survey discusses how recent developments in multimodal processing facilitate conceptual grounding of language. we categorize the information flow in multimodal processing with respect to cognitive models of human information processing and analyze different methods for combining multimodal representations. based on this methodological inventory, we discuss the benefit of multimodal grounding for a variety of language processing tasks and the challenges that arise. we particularly focus on multimodal grounding of verbs which play a crucial role for the compositional power of language.',\n",
       " 967: 'multi-view clustering attracts much attention recently, which aims to take advantage of multi-view information to improve the performance of clustering. however, most recent work mainly focus on self-representation based subspace clustering, which is of high computation complexity. in this paper, we focus on the markov chain based spectral clustering method and propose a novel essential tensor learning method to explore the high order correlations for multi-view representation. we first construct a tensor based on multi-view transition probability matrices of the markov chain. by incorporating the idea from robust principle component analysis, tensor singular value decomposition (t-svd) based tensor nuclear norm is imposed to preserve the low-rank property of the essential tensor, which can well capture the principle information from multiple views. we also employ the tensor rotation operator for this task to better investigate the relationship among views as well as reduce the computation complexity. the proposed method can be efficiently optimized by the alternating direction method of multipliers~(admm). extensive experiments on six real world datasets corresponding to five different applications show that our method achieves superior performance over other state-of-the-art methods.',\n",
       " 968: 'gaussian stochastic process emulation is a powerful tool for approximating computationally intensive computer models. however, estimation of parameters in the gasp emulator is a challenging task. no closed-form estimator is available and many numerical problems arise with standard estimates, e.g., the maximum likelihood estimator. in this package, we implement a marginal posterior mode estimator, for special priors and parameterizations, an estimation method that meets the robust parameter estimation criteria discussed in \\\\cite{gu2018robustness}; mathematical reasons are provided therein to explain why robust parameter estimation can greatly improve predictive performance of the emulator. in addition, inert inputs (inputs that almost have no effect on the variability of a function) can be identified from the marginal posterior mode estimation, at no extra computational cost. the package also implements the parallel partial gaussian stochastic process (pp gasp) emulator (\\\\cite{gu2016parallel}) for the scenario where the computer model has multiple outputs on e.g. spatial-temporal coordinates. the package can be operated in a default mode, but also allows numerous user specifications, such as the capability of specifying trend functions and noise terms. examples are studied herein to highlight the performance of the package in terms of out-of-sample prediction.}',\n",
       " 969: 'a cremona transformation is a birational self-map of the projective space $ \\\\mathbb{p}^{n} $. cremona transformations of $ \\\\mathbb{p}^{n} $ form a group and this group has a rational action on subvarieties of $ \\\\mathbb{p}^{n} $ and hence on its hilbert scheme. we study this action on the family of rational curves of $ \\\\mathbb{p}^{3} $ and we prove the rectifiability of any one dimensional family. this shows that any uniruled surface is cremona equivalent to a scroll and it answers a question of bogomolov-b\\\\\"ohning related to the study of uniformly rational varieties. we provide examples of infinitely many scrolls in the same cremona orbit and we show that a \"general\" scroll is not in the cremona orbit of a \"general\" rational surface.',\n",
       " 970: 'the fundamental group $\\\\pi$ of a kodaira fibration is, by definition, the extension of a surface group $\\\\pi_b$ by another surface group $\\\\pi_g$, i.e. \\\\[ 1 \\\\rightarrow \\\\pi_g \\\\rightarrow \\\\pi \\\\rightarrow \\\\pi_b \\\\rightarrow 1. \\\\] conversely, we can inquire about what conditions need to be satisfied by a group of that sort in order to be the fundamental group of a kodaira fibration. in this short note we collect some restriction on the image of the classifying map $m \\\\colon \\\\pi_b \\\\to \\\\gamma_g$ in terms of the coinvariant homology of $\\\\pi_g$. in particular, we observe that if $\\\\pi$ is the fundamental group of a kodaira fibration with relative irregularity $g-s$, then $g \\\\leq 1+ 6s$, and we show that this effectively constrains the possible choices for $\\\\pi$, namely that there are group extensions as above that fail to satisfy this bound, hence cannot be the fundamental group of a kodaira fibration. in particular this provides examples of symplectic $4$--manifolds that fail to admit a k\\\\\"ahler structure for reasons that eschew the usual obstructions.',\n",
       " 971: \"we prove that supersingular k3 surfaces over algebraically closed fields of characteristic at least $5$ are unirational, following a simplified form of liedtke's strategy.\",\n",
       " 972: 'the success of blockchain as the underlying technology for cryptocurrencies has opened up possibilities for its use in other application domains as well. the main advantages of blockchain for its potential use in other domains are its inherent security mechanisms and immunity to different attacks. a blockchain relies on a consensus method for agreeing on any new data. most of the consensus methods which are currently used for the blockchain of different cryptocurrencies require high computational power and thus are not apt for resource-constrained systems.   in this article, we discuss and survey the various blockchain based consensus methods that are applicable to resource constrained iot devices and networks. a typical iot network consists of several devices which have limited computational and communications capabilities. most often, these devices cannot perform intensive computations and are starved for bandwidth. therefore, we discuss the possible measures that can be taken to reduce the computational power and convergence time for the underlying consensus methods. we also talk about some of the alternatives to the public blockchain like private blockchain and tangle, along with their potential adoption for iot networks. furthermore, we review the existing consensus methods that have been implemented and explore the possibility of utilizing them to realize a blockchain based iot network. some of the open research challenges are also put forward.',\n",
       " 973: \"we consider some classical maps from the theory of abelian varieties and their moduli spaces and prove their definability, on restricted domains, in the o-minimal structure $\\\\rae$. in particular, we prove that the embedding of moduli space of principally polarized ableian varierty, $sp(2g,\\\\z)\\\\backslash \\\\ch_g$, is definable in $\\\\rae$, when restricted to siegel's fundamental set $\\\\ff_g$. we also prove the definability, on appropriate domains, of embeddings of families of abelian varieties into projective space.\",\n",
       " 974: \"taking a functional approach, we derive a general expression for the gradient of the mutual information (mi) with respect to the system parameters in the stochastic systems. this expression covers the cases in which the system input depends on the system parameters. as an application, we consider the k-user multiple access channels (mac) with feedback and utilize the obtained results to explore the behavior of these systems in terms of the mi. specializing the results to the additive gaussian noise mac, we extend the mi and minimum mean square error (mmse) relationship, i.e., i-mmse to the k-user gaussian mac with feedback. in this derivation, we show that the gradient of mi can be decomposed into three distinct parts, where the first part is the mmse term originated from noise, and the second and third parts reflect the effects of the interference and feedback, respectively. then, considering the capacity achieving fourier-modulated estimate correction (f-mec) strategy of kramer, we show how feedback compensates the destructive effects of the users' interference in the k-user symmetric gaussian mac.\",\n",
       " 975: 'with its unprecedented light-collecting area for night-sky observations, the cherenkov telescope array (cta) holds great potential for also optical stellar astronomy, in particular as a multi-element intensity interferometer for realizing imaging with sub-milliarcsecond angular resolution. such an order-of-magnitude increase of the spatial resolution achieved in optical astronomy will reveal the surfaces of rotationally flattened stars with structures in their circumstellar disks and winds, or the gas flows between close binaries. image reconstruction is feasible from the second-order coherence of light, measured as the temporal correlations of arrival times between photons recorded in different telescopes. this technique (once pioneered by hanbury brown and twiss) connects telescopes only with electronic signals and is practically insensitive to atmospheric turbulence and to imperfections in telescope optics. detector and telescope requirements are very similar to those for imaging air cherenkov observatories, the main difference being the signal processing (calculating cross correlations between single camera pixels in pairs of telescopes). observations of brighter stars are not limited by sky brightness, permitting efficient cta use during also bright-moon periods. while other concepts have been proposed to realize kilometer-scale optical interferometers of conventional amplitude (phase-) type, both in space and on the ground, their complexity places them much further into the future than cta, which thus could become the first kilometer-scale optical imager in astronomy.',\n",
       " 976: \"the prophet and secretary problems demonstrate online scenarios involving the optimal stopping theory. in a typical prophet or secretary problem, selection decisions are assumed to be immediate and irrevocable. however, many online settings accommodate some degree of revocability. to study such scenarios, we introduce the $\\\\ell-out-of-k$ setting, where the decision maker can select up to $k$ elements immediately and irrevocably, but her performance is measured by the top $\\\\ell$ elements in the selected set. equivalently, the decision makes can hold up to $\\\\ell$ elements at any given point in time, but can make up to $k-\\\\ell$ returns as new elements arrive.   we give upper and lower bounds on the competitive ratio of $\\\\ell$-out-of-$k$ prophet and secretary scenarios. these include a single-sample prophet algorithm that gives a competitive ratio of $1-\\\\ell\\\\cdot e^{-\\\\theta\\\\left(\\\\frac{\\\\left(k-\\\\ell\\\\right)^2}{k}\\\\right)}$, which is asymptotically tight for $k-\\\\ell=\\\\theta(\\\\ell)$. for secretary settings, we devise an algorithm that obtains a competitive ratio of $1-\\\\ell e^{-\\\\frac{k-8\\\\ell}{2+2\\\\ln \\\\ell}} - e^{-k/6}$, and show that no secretary algorithm obtains a better ratio than $1-e^{-k}$ (up to negligible terms). in passing, our results lead to an improvement of the results of assaf et al. [2000] for $1-out-of-k$ prophet scenarios.   beyond the contribution to online algorithms and optimal stopping theory, our results have implications to mechanism design. in particular, we use our prophet algorithms to derive {\\\\em overbooking} mechanisms with good welfare and revenue guarantees; these are mechanisms that sell more items than the seller's capacity, then allocate to the agents with the highest values among the selected agents.\",\n",
       " 977: 'reversible, diffusionless, first-order solid-solid phase transitions accompanied by caloric effects are critical for applications in the solid-state cooling and heat-pumping devices. accelerated discovery of caloric materials requires reliable but faster estimators for predictions and high-throughput screening of system-specific dominant caloric contributions. we assess reliability of the computational methods that provide thermodynamic properties in relevant solid phases at or near a phase transition. we test the methods using the well-studied b2 ferh alloy as a \"fruit fly\" in such a materials genome discovery, as it exhibits a metamagnetic transition which generates multicaloric (magneto-, elasto-, and baro-caloric) responses. for lattice entropy contributions, we find that the commonly-used linear-response and small-displacement phonon methods are invalid near instabilities that arise from the anharmonicity of atomic potentials, and we offer a more reliable and precise method for calculating lattice entropy at a fixed temperature. then, we apply a set of reliable methods and estimators to the metamagnetic transition in ferh (predicted $346 \\\\pm 12$ k, observed $353 \\\\pm 1$ k) and calculate the associated caloric properties, such as isothermal entropy and isentropic temperature changes.',\n",
       " 978: \"we have studied the quasi-simultaneous spectral energy distributions (sed) of 48 lbas blazars, detected within the three months of the lat bright agn sample (lbas) data taking period, combining fermi and swift data with radio nir-optical and hard-x/gamma-ray data. using these quasi-simultaneous seds, sampling both the low and the high energy peak of the blazars broad band emission, we were able to apply a diagnostic tool based on the estimate of the peak frequencies of the synchrotron (s) and inverse compton (ic) components. our analysis shows a fermi blazars' divide based on the peak frequencies of the sed. the robust result is that the synchrotron self compton (ssc) region divides in two the plane were we plot the peak frequency of the synchrotron sed vs the typical lorentz factor of the electrons most contributing to the synchrotron emission and to the inverse compton process. objects within or below this region, radiating likely via the ssc process, are high-frequency-peaked bl lac object (hbl), or low/intermediate-frequency peaked bl lac object (lbl/ibl). all of the ibls/lbls within or below the ssc region are not compton dominated. the objects lying above the ssc region, radiating likely via the external radiation compton (erc) process, are flat spectrum radio quasars and ibls/lbls. all of the ibls/lbls in the erc region show a significant compton dominance.\",\n",
       " 979: 'cervical cancer is the leading gynecological malignancy worldwide. this paper presents diverse classification techniques and shows the advantage of feature selection approaches to the best predicting of cervical cancer disease. there are thirty-two attributes with eight hundred and fifty-eight samples. besides, this data suffers from missing values and imbalance data. therefore, over-sampling, under-sampling and embedded over and under sampling have been used. furthermore, dimensionality reduction techniques are required for improving the accuracy of the classifier. therefore, feature selection methods have been studied as they divided into two distinct categories, filters and wrappers. the results show that age, first sexual intercourse, number of pregnancies, smokes, hormonal contraceptives, and stds: genital herpes are the main predictive features with high accuracy with 97.5%. decision tree classifier is shown to be advantageous in handling classification assignment with excellent performance.',\n",
       " 980: 'a major challenge in understanding the generalization of deep learning is to explain why (stochastic) gradient descent can exploit the network architecture to find solutions that have good generalization performance when using high capacity models. we find simple but realistic examples showing that this phenomenon exists even when learning linear classifiers --- between two linear networks with the same capacity, the one with a convolutional layer can generalize better than the other when the data distribution has some underlying spatial structure. we argue that this difference results from a combination of the convolution architecture, data distribution and gradient descent, all of which are necessary to be included in a meaningful analysis. we provide a general analysis of the generalization performance as a function of data distribution and convolutional filter size, given gradient descent as the optimization algorithm, then interpret the results using concrete examples. experimental results show that our analysis is able to explain what happens in our introduced examples.',\n",
       " 981: 'in this paper, we present a discrete-type approximation scheme to solve continuous-time optimal stopping problems based on fully non-markovian continuous processes adapted to the brownian motion filtration. the approximations satisfy suitable variational inequalities which allow us to construct $\\\\epsilon$-optimal stopping times and optimal values in full generality. explicit rates of convergence are presented for optimal values based on reward functionals of path-dependent sdes driven by fractional brownian motion. in particular, the methodology allows us to design concrete monte-carlo schemes for non-markovian optimal stopping time problems as demonstrated in the companion paper by bezerra, ohashi and russo.',\n",
       " 982: 'the $n$-cube is the poset obtained by ordering all subsets of $\\\\{1,\\\\ldots,n\\\\}$ by inclusion, and it can be partitioned into $\\\\binom{n}{\\\\lfloor n/2\\\\rfloor}$ chains, which is the minimum possible number. two such decompositions of the $n$-cube are called orthogonal if any two chains of the decompositions share at most a single element. shearer and kleitman conjectured in 1979 that the $n$-cube has $\\\\lfloor n/2\\\\rfloor+1$ pairwise orthogonal decompositions into the minimum number of chains, and they constructed two such decompositions. spink recently improved this by showing that the $n$-cube has three pairwise orthogonal chain decompositions for $n\\\\geq 24$. in this paper, we construct four pairwise orthogonal chain decompositions of the $n$-cube for $n\\\\geq 60$. we also construct five pairwise edge-disjoint chain decompositions of the $n$-cube for $n\\\\geq 90$, where edge-disjointness is a slightly weaker notion than orthogonality.',\n",
       " 983: 'chimera states are spatiotemporal patterns in which coherence and incoherence coexist. we observe the coexistence of synchronous (coherent) and desynchronous (incoherent) domains in a neuronal network. the network is composed of coupled adaptive exponential integrate-and-fire neurons that are connected by means of chemical synapses. in our neuronal network, the chimera states exhibit spatial structures both with spikes and bursts activities. furthermore, those desynchronised domains not only have either spike or burst activity, but we show that the structures switch between spikes and bursts as the time evolves. moreover, we verify the existence of multicluster chimera states.',\n",
       " 984: 'we present a computational study of the hydrodynamic coarsening in 3d of a critical mixture using the cahn-hilliard/navier-stokes model. the topology of the resulting intricate bicontinuous microstructure is analyzed through the principal curvatures to prove self-similar morphological evolution. we find that the self similarity exists for both systems: iso-viscous and with variable viscosity. however the two system have distinct topological character. our simulations confirm that the predicted viscous growth regime exists in both cases. moreover the coarsening rate is inversely proportional to an \\\\textit{effective viscosity} that is the geometrical average of the viscosities of the two phases.',\n",
       " 985: 'many classical social preference (multiwinner social choice) correspondences are resolute only when two alternatives and an odd number of individuals are considered. thus, they generally admit several resolute refinements, each of them naturally interpreted as a tie-breaking rule. in this paper we find out conditions which make a social preference (multiwinner social choice) correspondence admit a resolute refinement fulfilling suitable weak versions of the anonymity and neutrality principles, as well as reversal symmetry (immunity to the reversal bias).',\n",
       " 986: 'in this paper, we present necessary and sufficient conditions for some types of linear combination of frame elements (wave packet) to be a frame for $l^2(\\\\mathbb{k})$, where $\\\\mathbb{k}$ is a local field of positive characteristic.',\n",
       " 987: 'we study the connectedness locus n for the family of iterated function systems of pairs of affine-linear maps in the plane (the non-self-similar case). first results on the set n were obtained in joint work with p. shmerkin (2006). here we establish rigorous bounds for the set n based on the study of power series of special form. we also derive some bounds for the region of \"*-transversality\" which have applications to the computation of hausdorff measure of the self-affine attractor. we prove that a large portion of the set n is connected and locally connected, and conjecture that the entire connectedness locus is connected. we also prove that the set n has many zero angle \"cusp corners,\" at certain points with algebraic coordinates.',\n",
       " 988: \"there are two standard ways of classifying transport behavior of systems. the first is via time scaling of spread of correlations in the isolated system in thermodynamic limit. the second is via system size scaling of conductance in the steady state of the open system. we show here that these correspond to taking the thermodynamic limit and the long time limit of the integrated equilibrium current-current correlations of the open system in different order. in general, the limits may not commute leading to a conflict between the two standard ways of transport classification. nevertheless, the full information is contained in the equilibrium current-current correlations of the open system. we show this analytically by rigorously deriving the open-system current fluctuation dissipation relations (ocfdr) starting from an extremely general open quantum set-up and then carefully taking the proper limits. we test our theory numerically on the non-trivial example of the critical aubry-andr\\\\'e-harper (aah) model, where, it has been recently shown that, the two standard classifications indeed give different results. we find that both the total current autocorrelation and the long-range local current correlations of the open system in equilibrium show signatures of diffusive transport up to a time scale. this time scale grows as square of system size. beyond this time scale a steady state value is reached. the steady state value is conductance, which shows sub-diffusive scaling with system size.\",\n",
       " 989: 'this paper deals with subsampled spectral gradient methods for minimizing finite sum. subsample function and gradient approximations are employed in order to reduce the overall computational cost of the classical spectral gradient methods. the global convergence is enforced by a nonmonotone line search procedure. global convergence is proved when functions and gradients are approximated with increasing accuracy. r-linear convergence and worst-case iteration complexity is investigated in case of strongly convex objective function. numerical results on well known binary classification problems are given to show the effectiveness of this framework and analyze the effect of different spectral coefficient approximations arising from variable sample nature of this procedure.',\n",
       " 990: \"the resampling algorithm of moser \\\\& tardos is a powerful approach to develop constructive versions of the lov\\\\'{a}sz local lemma (lll). we generalize this to partial resampling: when a bad event holds, we resample an appropriately-random subset of the variables that define this event, rather than the entire set as in moser & tardos. this is particularly useful when the bad events are determined by sums of random variables. this leads to several improved algorithmic applications in scheduling, graph transversals, packet routing etc. for instance, we settle a conjecture of szab\\\\'{o} & tardos (2006) on graph transversals asymptotically, and obtain improved approximation ratios for a packet routing problem of leighton, maggs, & rao (1994).\",\n",
       " 991: 'a variant of coupled-cluster theory is described here, wherein the degrees of freedom are fluctuations of fragments between internally correlated states. the effects of intra-fragment correlation on the inter-fragment interaction are pre-computed and permanently folded into an effective hamiltonian, thus avoiding redundant evaluations of local relaxations associated with coupled fluctuations. a companion article shows that a low-scaling step may be used to cast the electronic hamiltonians of real systems into the form required. two proof-of-principle demonstrations are presented here for non-covalent interactions. one uses harmonic oscillators, for which accuracy and algorithm structure can be carefully controlled in comparisons. the other uses small electronic systems (be atoms) to demonstrate compelling accuracy and efficiency, also when inter-fragment electron exchange and charge transfer must be handled. since the cost of the global calculation does not depend directly on the correlation models used for the fragments, this should provide a way to incorporate difficult electronic structure problems into large systems. this framework opens a promising path for building tunable, systematically improvable methods to capture properties of systems interacting with a large number of other systems. the extension to excited states is also straightforward.',\n",
       " 992: 'we prove that stochastic gradient descent efficiently converges to the global optimizer of the maximum likelihood objective of an unknown linear time-invariant dynamical system from a sequence of noisy observations generated by the system. even though the objective function is non-convex, we provide polynomial running time and sample complexity bounds under strong but natural assumptions. linear systems identification has been studied for many decades, yet, to the best of our knowledge, these are the first polynomial guarantees for the problem we consider.',\n",
       " 993: 'we define chern-schwartz-macpherson (csm) cycles of an arbitrary matroid. these are balanced weighted fans supported on the skeleta of the corresponding bergman fan. in the case that the matroid arises from a complex hyperplane arrangement a, we show that these cycles represent the csm class of the complement of a. we also prove that for any matroid, the degrees of its csm cycles are given by the coefficients of (a shift of) the reduced characteristic polynomial, and that csm cycles are valuations under matroid polytope subdivisions.',\n",
       " 994: 'in this work we introduce a novel approach to train bidirectional generative adversarial model (bigan) in a semi-supervised manner. the presented method utilizes triplet loss function as an additional component of the objective function used to train discriminative data representation in the latent space of the bigan model. this representation can be further used as a seed for generating artificial images, but also as a good feature embedding for classification and image retrieval tasks. we evaluate the quality of the proposed method in the two mentioned challenging tasks using two benchmark datasets: cifar10 and svhn.',\n",
       " 995: 'in this paper, we present a method for the accurate estimation of the derivative (aka.~sensitivity) of expectations of functions involving an indicator function by combining a stochastic algorithmic differentiation and a regression.   the method is an improvement of the approach presented in [risk magazine april 2018].   the finite difference approximation of a partial derivative of a monte-carlo integral of a discontinuous function is known to exhibit a high monte-carlo error. the issue is evident since the monte-carlo approximation of a discontinuous function is just a finite sum of discontinuous functions and as such, not even differentiable.   the algorithmic differentiation of a discontinuous function is problematic. a natural approach is to replace the discontinuity by continuous functions. this is equivalent to replacing a path-wise automatic differentiation by a (local) finite difference approximation.   we present an improvement (in terms of variance reduction) by decoupling the integration of the dirac delta and the remaining conditional expectation and estimating the two parts by separate regressions. for the algorithmic differentiation, we derive an operator that can be injected seamlessly - with minimal code changes - into the algorithm resulting in the exact result.',\n",
       " 996: 'societies are complex systems which tend to polarize into sub-groups of individuals with dramatically opposite perspectives. this phenomenon is reflected -- and often amplified -- in online social networks where, however, humans are no more the only players, and co-exist alongside with social bots, i.e., software-controlled accounts. analyzing large-scale social data collected during the catalan referendum for independence on october 1, 2017, consisting of nearly 4 millions twitter posts generated by almost 1 million users, we identify the two polarized groups of independentists and constitutionalists and quantify the structural and emotional roles played by social bots. we show that bots act from peripheral areas of the social system to target influential humans of both groups, bombarding independentists with violent contents, increasing their exposure to negative and inflammatory narratives and exacerbating social conflict online. our findings stress the importance of developing countermeasures to unmask these forms of automated social manipulation.',\n",
       " 997: 'non-linear kernel methods can be approximated by fast linear ones using suitable explicit feature maps allowing their application to large scale problems. we investigate how convolution kernels for structured data are composed from base kernels and construct corresponding feature maps. on this basis we propose exact and approximative feature maps for widely used graph kernels based on the kernel trick. we analyze for which kernels and graph properties computation by explicit feature maps is feasible and actually more efficient. in particular, we derive approximative, explicit feature maps for state-of-the-art kernels supporting real-valued attributes including the graphhopper and graph invariant kernels. in extensive experiments we show that our approaches often achieve a classification accuracy close to the exact methods based on the kernel trick, but require only a fraction of their running time. moreover, we propose and analyze algorithms for computing random walk, shortest-path and subgraph matching kernels by explicit and implicit feature maps. our theoretical results are confirmed experimentally by observing a phase transition when comparing running time with respect to label diversity, walk lengths and subgraph size, respectively.',\n",
       " 998: \"tumors are extremely heterogeneous and comprise of a number of intratumor microenvironments or sub-regions. these tumor microenvironments may interact with eac based on complex high-level relationships, which could provide important insight into the organizational structure of the tumor network. to that end, we developed a tumor connectomics framework (tcf) to understand and model the complex functional and morphological interactions within the tumor. then, we demonstrate the tcf's potential in predicting treatment response in breast cancer patients being treated with neoadjuvant chemotherapy. the tcf was implemented on a breast cancer patient cohort of thirty-four patients with dynamic contrast enhanced (dce) magnetic resonance imaging (mri) undergoing neodjuvant chemotherapy treatment. the intra-tumor network connections (tumor connectome) before and after treatment were modeled using advanced graph theoretic centrality, path length and clustering metrics from the dce-mri. the percentage change of the graph metrics between two time-points (baseline and 1st cycle) was computed to predict the patient's final response to treatment. the tcf visualized the inter-voxel network connections across multiple time-points and was able to evaluate specific changes in the tumor connectome with treatment. degree centrality was identified as the most significant predictor of treatment response with an auc of 0.83 for classifying responders from non-responders. in conclusion, the tcf graph metrics produced excellent biomarkers for prediction of breast cancer treatment response with improved visualization and interpretability of changes both locally and globally in the tumor.\",\n",
       " 999: 'upgrades to the j-parc accelerators and the neutrino experimental facility are of vital importance to the tokai to hyper-kamiokande project (t2hk), which aims to explore cp asymmetry by the $\\\\nu_e$ appearance. in this talk i present overview of the t2hk project, current status of the beam operation at j-parc, and prospect to realize the rated 750 kw operation in coming years.',\n",
       " 1000: \"robust real-world learning should benefit from both demonstrations and interactions with the environment. current approaches to learning from demonstration and reward perform supervised learning on expert demonstration data and use reinforcement learning to further improve performance based on the reward received from the environment. these tasks have divergent losses which are difficult to jointly optimize and such methods can be very sensitive to noisy demonstrations. we propose a unified reinforcement learning algorithm, normalized actor-critic (nac), that effectively normalizes the q-function, reducing the q-values of actions unseen in the demonstration data. nac learns an initial policy network from demonstrations and refines the policy in the environment, surpassing the demonstrator's performance. crucially, both learning from demonstration and interactive refinement use the same objective, unlike prior approaches that combine distinct supervised and reinforcement losses. this makes nac robust to suboptimal demonstration data since the method is not forced to mimic all of the examples in the dataset. we show that our unified reinforcement learning algorithm can learn robustly and outperform existing baselines when evaluated on several realistic driving games.\",\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict=train_data.set_index('train_id')['abstract'].to_dict() \n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to tokenize the document \n",
    "def tokenizeRawData(id_):\n",
    "    sentences = sent_detector.tokenize(''.join(data_dict[id_])) #Sentence tokenize\n",
    "    tokenised_file = []\n",
    "    tokenizer = RegexpTokenizer(r\"[a-zA-Z$0-9]+(?:[-'_.][a-zA-Z]+)?(?:[-'_.][a-zA-Z]+)?\") \n",
    "#     tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "\n",
    "   #tokenizer=TweetTokenizer()\n",
    "   #tokenizer=word_tokenize()\n",
    "    \n",
    "    for sent in sentences:        \n",
    "        tokens = tokenizer.tokenize(sent)\n",
    "        if (len(tokens) > 0):\n",
    "            tokens[0] = tokens[0].lower() # Only normalize the first word in the sentence \n",
    "#             tokens = tokens.lower()\n",
    "            tokenised_file.append(tokens)\n",
    "    \n",
    "    tokenised_file = [item for tokens in tokenised_file for item in tokens]\n",
    "    return (id_, tokenised_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the bigram \n",
    "def bigram(input_dict):\n",
    "    #Get the all the words in our corpus \n",
    "    words=list(chain.from_iterable([set(value) for value in input_dict.values()]))\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    bigram_finder = nltk.collocations.BigramCollocationFinder.from_words(words)\n",
    "    bigram_finder.apply_freq_filter(100) # Filter only bigrams with atleast 20 frequent \n",
    "    bigram_finder.apply_word_filter(lambda w: (w in stopwords_list) or (len(w) < 3)) # Don't consider stopwords\n",
    "    #top_300_bigrams = bigram_finder.nbest(bigram_measures.pmi, 300) # top 300 bigrams\n",
    "#     top_300_bigrams = bigram_finder.nbest(bigram_measures.chi_sq, 500)\n",
    "\n",
    "    #trying out pmi measure\n",
    "    top_300_bigrams = bigram_finder.nbest(bigram_measures.pmi, 500)\n",
    "    \n",
    "    mwetokenizer = MWETokenizer(top_300_bigrams) #Bigram tokenizer \n",
    "    output_dict =  dict((doc_id, mwetokenizer.tokenize(body)) for doc_id,body in input_dict.items())\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Remove Short Words\n",
    "def removeShortTokens(input_dict):\n",
    "\n",
    "    output_dict = {} # initate dictionary for the tokens in their final form\n",
    "    for k, tokens in input_dict.items():\n",
    "        output_dict[k] = [token for token in tokens if (len(token) >= 3)] #Remove words less 3 char length\n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "\n",
    "#Function to Remove Stop Words\n",
    "def removeStopWords(input_dict):\n",
    "    output_dict = {}\n",
    "    \n",
    "    for k, tokens in input_dict.items():\n",
    "        output_dict[k] = [token for token in tokens if token.lower() not in stopwords_list]\n",
    "    return output_dict\n",
    "\n",
    "#Function to remove the Least frequent and most frequenct word\n",
    "#We have a thresold of 5% and 95%\n",
    "def removeRareToken(input_dict):\n",
    "\n",
    "    lower_limit=round(len(input_dict)*0.05)\n",
    "    upper_limit=round(len(input_dict)*0.95)\n",
    "    # The thresold of 5% and 95% \n",
    "    words = list(chain.from_iterable([set(value) for value in input_dict.values()]))\n",
    "    fd = FreqDist(words) #Document Frq Dist\n",
    "    lessFreqWords = set([k for k, v in fd.items() if v < lower_limit])\n",
    "    mostFreqWords = set([k for k, v in fd.items() if v > upper_limit])\n",
    "    \n",
    "    #Append the result to the output Dictionary\n",
    "    output_dict={}\n",
    "    for k, tokens in input_dict.items():\n",
    "        output_dict[k] = [token for token in tokens if token not in lessFreqWords   and token not in mostFreqWords]\n",
    "        \n",
    "    return output_dict\n",
    "\n",
    "# Function to stemm tokens\n",
    "def stemTokens(id_,input_dict):    \n",
    "    stemmed_words = []\n",
    "    for w in input_dict[id_]:\n",
    "        # Unigram tokens with lowercase\n",
    "        if w.islower() and '__' not in w:\n",
    "            stemmed_words.append(stemmer.stem(w))\n",
    "        # Unigram tokens with first letter capitalized\n",
    "        elif w == w.title() and '__' not in w:\n",
    "            stemmed_words.append(stemmer.stem(w).capitalize())\n",
    "        # Bigram tokens\n",
    "        else:\n",
    "            stemmed_words.append(w)\n",
    "    return stemmed_words\n",
    "\n",
    "\n",
    "#Function to lementize \n",
    "def lemTokens(id_,input_dict):    \n",
    "    stemmed_words = []\n",
    "    for w in input_dict[id_]:\n",
    "        #print(w,id_)\n",
    "        # Unigram tokens with lowercase\n",
    "        if w.islower() and '__' not in w:\n",
    "            stemmed_words.append(Word(w).lemmatize(pos='v'))\n",
    "        # Unigram tokens with first letter capitalized\n",
    "        elif w == w.title() and '__' not in w:\n",
    "            stemmed_words.append((Word(w).lemmatize(pos='v')).capitalize())\n",
    "        # Bigram tokens\n",
    "        else:\n",
    "            stemmed_words.append(w)\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dict =  dict(tokenizeRawData(id_) for id_ in data_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokensWithBigram=bigram(tokenized_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict={}\n",
    "count=0\n",
    "for k, tokens in tokensWithBigram.items():\n",
    "    output_dict[k]=stemTokens(k,tokensWithBigram) #stemming\n",
    "    output_dict[k]=lemTokens(k,output_dict) #lemmatization\n",
    "    #print(output_dict)\n",
    "    count=count+1\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words \n",
    "remove_stop=removeStopWords(output_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### not implementing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Remove the short tokens\n",
    "# tokens_dict=removeShortTokens(remove_stop)\n",
    "tokens_dict = remove_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Remove the rare tokens\n",
    "# output_dict=removeRareToken(tokens_dict)\n",
    "output_dict = tokens_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>save special case current train method gener a...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>consid dynam system finit mani equilibria pert...</td>\n",
       "      <td>math.DS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>consid discret dynam system ant-lik agent enga...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>retrofit techniqu inject extern resourc word r...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>approach decision-mak uncertainti belief funct...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29633</th>\n",
       "      <td>29634</td>\n",
       "      <td>power deep network architectur gener adversari...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29634</th>\n",
       "      <td>29635</td>\n",
       "      <td>develop mixed-characterist version mori-mukai ...</td>\n",
       "      <td>math.AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29635</th>\n",
       "      <td>29636</td>\n",
       "      <td>complex analysi wind number measur number time...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29636</th>\n",
       "      <td>29637</td>\n",
       "      <td>discuss secur comput modular sum multipl acces...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29637</th>\n",
       "      <td>29638</td>\n",
       "      <td>thi paper defin notion graph trace kernel gene...</td>\n",
       "      <td>math.AG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29638 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_id                                           abstract    label\n",
       "0             1  save special case current train method gener a...       cs\n",
       "1             2  consid dynam system finit mani equilibria pert...  math.DS\n",
       "2             3  consid discret dynam system ant-lik agent enga...       cs\n",
       "3             4  retrofit techniqu inject extern resourc word r...       cs\n",
       "4             5  approach decision-mak uncertainti belief funct...       cs\n",
       "...         ...                                                ...      ...\n",
       "29633     29634  power deep network architectur gener adversari...       cs\n",
       "29634     29635  develop mixed-characterist version mori-mukai ...  math.AG\n",
       "29635     29636  complex analysi wind number measur number time...       cs\n",
       "29636     29637  discuss secur comput modular sum multipl acces...       cs\n",
       "29637     29638  thi paper defin notion graph trace kernel gene...  math.AG\n",
       "\n",
       "[29638 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the words in each document back to senctences \n",
    "pharse=[]\n",
    "for value in output_dict.values():\n",
    "    pharse.append(' '.join(value))\n",
    "train_data['abstract']=pharse\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dict=test_data.set_index('test_id')['abstract'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to tokenize the document \n",
    "def tokenizeRawData(id_):\n",
    "    sentences = sent_detector.tokenize(''.join(test_data_dict[id_])) #Sentence tokenize\n",
    "    tokenised_file = []\n",
    "    tokenizer = RegexpTokenizer(r\"[a-zA-Z$0-9]+(?:[-'_.][a-zA-Z]+)?(?:[-'_.][a-zA-Z]+)?\") \n",
    "#     tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    \n",
    "    for sent in sentences:        \n",
    "        tokens = tokenizer.tokenize(sent)\n",
    "        if (len(tokens) > 0):\n",
    "            tokens[0] = tokens[0].lower() # Only normalize the first word in the sentence \n",
    "#             tokens = tokens.lower()\n",
    "            tokenised_file.append(tokens)\n",
    "    \n",
    "    tokenised_file = [item for tokens in tokenised_file for item in tokens]\n",
    "    return (id_, tokenised_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the bigram \n",
    "def bigram(input_dict):\n",
    "    #Get the all the words in our corpus \n",
    "    words=list(chain.from_iterable([set(value) for value in input_dict.values()]))\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    bigram_finder = nltk.collocations.BigramCollocationFinder.from_words(words)\n",
    "    bigram_finder.apply_freq_filter(100) # Filter only bigrams with atleast 20 frequent \n",
    "    bigram_finder.apply_word_filter(lambda w: (w in stopwords_list) or (len(w) < 3)) # Don't consider stopwords\n",
    "    #top_300_bigrams = bigram_finder.nbest(bigram_measures.pmi, 300) # top 300 bigrams\n",
    "    \n",
    "#     top_300_bigrams = bigram_finder.nbest(bigram_measures.chi_sq, 500)\n",
    "    \n",
    "    \n",
    "    # trying out pmi\n",
    "    top_300_bigrams = bigram_finder.nbest(bigram_measures.pmi, 500)\n",
    "    mwetokenizer = MWETokenizer(top_300_bigrams) #Bigram tokenizer \n",
    "    output_dict =  dict((doc_id, mwetokenizer.tokenize(body)) for doc_id,body in input_dict.items())\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Remove Short Words\n",
    "def removeShortTokens(input_dict):\n",
    "\n",
    "    output_dict = {} # initate dictionary for the tokens in their final form\n",
    "    for k, tokens in input_dict.items():\n",
    "        output_dict[k] = [token for token in tokens if (len(token) >= 3)] #Remove words less 3 char length\n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "\n",
    "#Function to Remove Stop Words\n",
    "def removeStopWords(input_dict):\n",
    "    output_dict = {}\n",
    "    \n",
    "    for k, tokens in input_dict.items():\n",
    "        output_dict[k] = [token for token in tokens if token.lower() not in stopwords_list]\n",
    "    return output_dict\n",
    "\n",
    "#Function to remove the Least frequent and most frequenct word\n",
    "#We have a thresold of 5% and 95%\n",
    "def removeRareToken(input_dict):\n",
    "\n",
    "    lower_limit=round(len(input_dict)*0.05)\n",
    "    upper_limit=round(len(input_dict)*0.95)\n",
    "    # The thresold of 5% and 95% \n",
    "    words = list(chain.from_iterable([set(value) for value in input_dict.values()]))\n",
    "    fd = FreqDist(words) #Document Frq Dist\n",
    "    lessFreqWords = set([k for k, v in fd.items() if v < lower_limit])\n",
    "    mostFreqWords = set([k for k, v in fd.items() if v > upper_limit])\n",
    "    \n",
    "    #Append the result to the output Dictionary\n",
    "    output_dict={}\n",
    "    for k, tokens in input_dict.items():\n",
    "        output_dict[k] = [token for token in tokens if token not in lessFreqWords   and token not in mostFreqWords]\n",
    "        \n",
    "    return output_dict\n",
    "\n",
    "# Function to stemm tokens\n",
    "def stemTokens(id_,input_dict):    \n",
    "    stemmed_words = []\n",
    "    for w in input_dict[id_]:\n",
    "        # Unigram tokens with lowercase\n",
    "        if w.islower() and '__' not in w:\n",
    "            stemmed_words.append(stemmer.stem(w))\n",
    "        # Unigram tokens with first letter capitalized\n",
    "        elif w == w.title() and '__' not in w:\n",
    "            stemmed_words.append(stemmer.stem(w).capitalize())\n",
    "        # Bigram tokens\n",
    "        else:\n",
    "            stemmed_words.append(w)\n",
    "    return stemmed_words\n",
    "\n",
    "\n",
    "#Function to lementize \n",
    "def lemTokens(id_,input_dict):    \n",
    "    stemmed_words = []\n",
    "    for w in input_dict[id_]:\n",
    "        #print(w,id_)\n",
    "        # Unigram tokens with lowercase\n",
    "        if w.islower() and '__' not in w:\n",
    "            stemmed_words.append(Word(w).lemmatize(pos='v'))\n",
    "        # Unigram tokens with first letter capitalized\n",
    "        elif w == w.title() and '__' not in w:\n",
    "            stemmed_words.append((Word(w).lemmatize(pos='v')).capitalize())\n",
    "        # Bigram tokens\n",
    "        else:\n",
    "            stemmed_words.append(w)\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenized_dict =  dict(tokenizeRawData(id_) for id_ in test_data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokensWithBigram=bigram(test_tokenized_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_dict={}\n",
    "test_count=0\n",
    "for k, tokens in test_tokensWithBigram.items():\n",
    "    test_output_dict[k]=stemTokens(k,test_tokensWithBigram) #stemming\n",
    "    test_output_dict[k]=lemTokens(k,test_output_dict) #lemmatization\n",
    "    #print(output_dict)\n",
    "    test_count=test_count+1\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words \n",
    "test_remove_stop=removeStopWords(test_output_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Remove the short tokens\n",
    "# test_tokens_dict=removeShortTokens(test_remove_stop)\n",
    "test_tokens_dict = test_remove_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Remove the rare tokens\n",
    "# test_output_dict=removeRareToken(test_tokens_dict)\n",
    "\n",
    "test_output_dict = test_tokens_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the words in each document back to senctences \n",
    "test_pharse=[]\n",
    "for value in test_output_dict.values():\n",
    "    test_pharse.append(' '.join(value))\n",
    "test_data['abstract']=test_pharse\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['abstract'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data['abstract']\n",
    "test_x = test_data['abstract']\n",
    "train_y = train_data['label']\n",
    "test_data['label'] =\"\" # our test data doesnt have label\n",
    "test_y = test_data['label']\n",
    "# merge the train_x and test_x \n",
    "merged_text = pd.concat([train_x,test_x])\n",
    "merged_text\n",
    "# create tf-idf features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=50000)\n",
    "tf_vect = TfidfVectorizer(analyzer='word', max_features=50000)\n",
    "tf_vect.fit(train_x)\n",
    "#tf_vect.fit(merged_text)\n",
    "\n",
    "# transform train_x and test_x to tf-idf vectors\n",
    "#tf_vect.fit(train_x)\n",
    "train_tf =  tf_vect.transform(train_x)\n",
    "#tf_vect.fit(test_x)\n",
    "test_tf =  tf_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create count Vector method\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(train_x)\n",
    "\n",
    "train_count =  count_vect.transform(train_x)\n",
    "valid_count =  count_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticR = LogisticRegression(max_iter=1000,random_state=1234).fit(train_tf, train_y)\n",
    "#logisticR = LogisticRegression().fit(train_count, train_y)\n",
    "\n",
    "#Let's predict the test labels\n",
    "predictions_lr = logisticR.predict(test_tf)\n",
    "#predictions_lr = logisticR.predict(valid_count)\n",
    "\n",
    "#let's check the accuracy score of the Logistic Regression model on the test set\n",
    "accuracy_score(test_y,predictions_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = predictions_lr.tolist()\n",
    "k = test_data\n",
    "k['label'] = a\n",
    "k = k.drop(columns=['abstract'])\n",
    "k.to_csv(r'logistic_test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# decision_tree = DecisionTreeClassifier(random_state=1234).fit(train_tf, train_y)\n",
    "\n",
    "# predictions_dt = decision_tree.predict(test_tf)\n",
    "\n",
    "# accuracy_score(test_y,predictions_dt)\n",
    "\n",
    "\n",
    "# a = predictions_dt.tolist()\n",
    "# k = test_data\n",
    "# k['label'] = a\n",
    "# k = k.drop(columns=['abstract'])\n",
    "# k.to_csv(r'decisionTree_test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# random_forest = RandomForestClassifier(random_state=1234).fit(train_tf, train_y)\n",
    "\n",
    "# predictions_rf = random_forest.predict(test_tf)\n",
    "\n",
    "# accuracy_score(test_y,predictions_rf)\n",
    "\n",
    "\n",
    "# a = predictions_rf.tolist()\n",
    "# k = test_data\n",
    "# k['label'] = a\n",
    "# k = k.drop(columns=['abstract'])\n",
    "# k.to_csv(r'random_forest_test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Deep learning with H20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h2o\n",
    "# h2o.init(nthreads=-1)\n",
    "# from h2o.estimators import  H2OWord2vecEstimator,H2OGradientBoostingEstimator\n",
    "# from h2o.estimators.deeplearning import H2ODeepLearningEstimator,H2OAutoEncoderEstimator\n",
    "# from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# h20_train_df = h2o.H2OFrame(train_data)\n",
    "# h20_test_df = h2o.H2OFrame(test_data)\n",
    "# # train_x = h20_train_df['Data']\n",
    "# # test_x = h20_test_df['Data']\n",
    "# # train_y = h20_train_df['gender']\n",
    "# # test_y = h20_test_df['gender']\n",
    "\n",
    "# h20_train_df['abstract'] = h20_train_df['abstract'].ascharacter()\n",
    "# h20_test_df['abstract'] = h20_test_df['abstract'].ascharacter()\n",
    "\n",
    "# def tokenize(sentences):\n",
    "#     tokenized = sentences.tokenize(\"\\\\W+\")\n",
    "#     tokenized_lower = tokenized.tolower()\n",
    "#     tokenized_filtered = tokenized_lower[(tokenized_lower.nchar() >= 2) | (tokenized_lower.isna()),:]\n",
    "#     tokenized_words = tokenized_filtered[tokenized_filtered.grep(\"[0-9]\",invert=True,output_logical=True),:]\n",
    "#     #tokenized_words = tokenized_words[(tokenized_words.isna()),:]\n",
    "#     return tokenized_words\n",
    "\n",
    "# words = tokenize(h20_train_df['abstract']) #Tokenize the training data\n",
    "\n",
    "# words_test=tokenize(h20_test_df['abstract'])#Tokenize the testing data\n",
    "\n",
    "# #Call the word to Vector model\n",
    "# w2v_model = H2OWord2vecEstimator(vec_size = 1800)\n",
    "# w2v_model.train(training_frame=words )\n",
    "\n",
    "# train_vecs = w2v_model.transform(words, aggregate_method = \"AVERAGE\")\n",
    "# test_vecs = w2v_model.transform(words_test, aggregate_method = \"AVERAGE\")\n",
    "\n",
    "# h20_train_df_vec=h20_train_df.cbind(train_vecs) #Bind the Train Vec to the Train Frame\n",
    "# h20_test_df_vec=h20_test_df.cbind(test_vecs) #Bind the Test Vec to the Test Frame\n",
    "\n",
    "\n",
    "# #Convert the output as factor \n",
    "# h20_train_df_vec['label']=h20_train_df_vec['label'].asfactor()\n",
    "# h20_test_df_vec['label']=h20_test_df_vec['label'].asfactor()\n",
    "\n",
    "# x=train_vecs.names\n",
    "# y = 'label'\n",
    "\n",
    "# #model\n",
    "\n",
    "# model1 = H2ODeepLearningEstimator(\n",
    "#     hidden=[32,32,32],l1=1e-5,epochs=10,seed=1234)\n",
    "\n",
    "# model1.train( x=x, y=y,training_frame=h20_train_df_vec)\n",
    "\n",
    "# prediction=model1.predict(h20_test_df_vec).as_data_frame()['predict']\n",
    "# prediction\n",
    "\n",
    "# # h2o = prediction.tolist()\n",
    "\n",
    "# # k = test_data\n",
    "# # k['label'] = h2o\n",
    "# # k = k.drop(columns=['abstract'])\n",
    "# # k.to_csv(r'h2o_test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for H20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implemeting Bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import os, json, gc, re, random\n",
    "# from tqdm.notebook import tqdm\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import torch, transformers, tokenizers\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import plotly.express as px\n",
    "# import seaborn as sns\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# transformers_logger = logging.getLogger(\"transformers\")\n",
    "# transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26674, 3) (2964, 3)\n"
     ]
    }
   ],
   "source": [
    "# split a dataset into train and test sets\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train test sets\n",
    "_train,_test = train_test_split(train_data, test_size=0.1,random_state=1234)\n",
    "print(_train.shape, _test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>5292</td>\n",
       "      <td>consid cycl grade $c $-algebra real $c $-algeb...</td>\n",
       "      <td>cond-mat.other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10329</th>\n",
       "      <td>10330</td>\n",
       "      <td>robust princip compon analysi rpca recov low-r...</td>\n",
       "      <td>stat.ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26654</th>\n",
       "      <td>26655</td>\n",
       "      <td>thi paper consid tensor robust princip compon ...</td>\n",
       "      <td>stat.ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27856</th>\n",
       "      <td>27857</td>\n",
       "      <td>show hamiltonian electron system write exactli...</td>\n",
       "      <td>physics.atm-clus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11894</th>\n",
       "      <td>11895</td>\n",
       "      <td>resolv conjectur li ramo relat regular fi-modu...</td>\n",
       "      <td>math.AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27852</th>\n",
       "      <td>27853</td>\n",
       "      <td>hess j1731 347 shell-typ supernova remnant emi...</td>\n",
       "      <td>astro-ph.HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23605</th>\n",
       "      <td>23606</td>\n",
       "      <td>charg transfer effect import compon physic des...</td>\n",
       "      <td>cond-mat.dis-nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>1319</td>\n",
       "      <td>smooth schubert varieti ration homogen manifol...</td>\n",
       "      <td>math.DG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25299</th>\n",
       "      <td>25300</td>\n",
       "      <td>prove number iter weisfeiler-leman algorithm c...</td>\n",
       "      <td>math.CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27439</th>\n",
       "      <td>27440</td>\n",
       "      <td>studi relat ground-stat energi quantum graph h...</td>\n",
       "      <td>math.MP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26674 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_id                                           abstract  \\\n",
       "5291       5292  consid cycl grade $c $-algebra real $c $-algeb...   \n",
       "10329     10330  robust princip compon analysi rpca recov low-r...   \n",
       "26654     26655  thi paper consid tensor robust princip compon ...   \n",
       "27856     27857  show hamiltonian electron system write exactli...   \n",
       "11894     11895  resolv conjectur li ramo relat regular fi-modu...   \n",
       "...         ...                                                ...   \n",
       "27852     27853  hess j1731 347 shell-typ supernova remnant emi...   \n",
       "23605     23606  charg transfer effect import compon physic des...   \n",
       "1318       1319  smooth schubert varieti ration homogen manifol...   \n",
       "25299     25300  prove number iter weisfeiler-leman algorithm c...   \n",
       "27439     27440  studi relat ground-stat energi quantum graph h...   \n",
       "\n",
       "                  label  \n",
       "5291     cond-mat.other  \n",
       "10329           stat.ML  \n",
       "26654           stat.ML  \n",
       "27856  physics.atm-clus  \n",
       "11894           math.AC  \n",
       "...                 ...  \n",
       "27852       astro-ph.HE  \n",
       "23605   cond-mat.dis-nn  \n",
       "1318            math.DG  \n",
       "25299           math.CO  \n",
       "27439           math.MP  \n",
       "\n",
       "[26674 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23746</th>\n",
       "      <td>23747</td>\n",
       "      <td>cluster data physic subset requir assumpt rega...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23385</th>\n",
       "      <td>23386</td>\n",
       "      <td>propos possibl high-temperatur superconduct sc...</td>\n",
       "      <td>cond-mat.supr-con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16207</th>\n",
       "      <td>16208</td>\n",
       "      <td>prove kn orrer period type equival deriv facto...</td>\n",
       "      <td>math.AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17276</th>\n",
       "      <td>17277</td>\n",
       "      <td>simul probabilist algorithm statist test gener...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16994</th>\n",
       "      <td>16995</td>\n",
       "      <td>boij- oderberg theori focus properti dualiti r...</td>\n",
       "      <td>math.AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14385</th>\n",
       "      <td>14386</td>\n",
       "      <td>consid group comput unit tri cooper solv distr...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15603</th>\n",
       "      <td>15604</td>\n",
       "      <td>denot binari form order complex number divisor...</td>\n",
       "      <td>math.RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12003</th>\n",
       "      <td>12004</td>\n",
       "      <td>thermodynam argument construct physic motiv ly...</td>\n",
       "      <td>cond-mat.stat-mech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21984</th>\n",
       "      <td>21985</td>\n",
       "      <td>thi paper consid problem decentr goal assign t...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16736</th>\n",
       "      <td>16737</td>\n",
       "      <td>deep neural network exhibit state-of-th art re...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2964 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_id                                           abstract  \\\n",
       "23746    23747  cluster data physic subset requir assumpt rega...   \n",
       "23385    23386  propos possibl high-temperatur superconduct sc...   \n",
       "16207    16208  prove kn orrer period type equival deriv facto...   \n",
       "17276    17277  simul probabilist algorithm statist test gener...   \n",
       "16994    16995  boij- oderberg theori focus properti dualiti r...   \n",
       "...        ...                                                ...   \n",
       "14385    14386  consid group comput unit tri cooper solv distr...   \n",
       "15603    15604  denot binari form order complex number divisor...   \n",
       "12003    12004  thermodynam argument construct physic motiv ly...   \n",
       "21984    21985  thi paper consid problem decentr goal assign t...   \n",
       "16736    16737  deep neural network exhibit state-of-th art re...   \n",
       "\n",
       "                    label  \n",
       "23746                  cs  \n",
       "23385   cond-mat.supr-con  \n",
       "16207             math.AG  \n",
       "17276                  cs  \n",
       "16994             math.AC  \n",
       "...                   ...  \n",
       "14385                  cs  \n",
       "15603             math.RT  \n",
       "12003  cond-mat.stat-mech  \n",
       "21984                  cs  \n",
       "16736                  cs  \n",
       "\n",
       "[2964 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test = _test.rename(columns={'train_id': 'test_id'})\n",
    "\n",
    "\n",
    "_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = _train['abstract']\n",
    "test_x = _test['abstract']\n",
    "train_y = _train['label']\n",
    "test_y = _test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=50000)\n",
    "tf_vect = TfidfVectorizer(analyzer='word', max_features=50000)\n",
    "tf_vect.fit(train_x)\n",
    "#tf_vect.fit(merged_text)\n",
    "\n",
    "# transform train_x and test_x to tf-idf vectors\n",
    "#tf_vect.fit(train_x)\n",
    "train_tf =  tf_vect.transform(train_x)\n",
    "#tf_vect.fit(test_x)\n",
    "test_tf =  tf_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create count Vector method\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(train_x)\n",
    "\n",
    "train_count =  count_vect.transform(train_x)\n",
    "valid_count =  count_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticR = LogisticRegression(max_iter=1000,random_state=1234).fit(train_tf, train_y)\n",
    "#logisticR = LogisticRegression().fit(train_count, train_y)\n",
    "\n",
    "#Let's predict the test labels\n",
    "predictions_lr = logisticR.predict(test_tf)\n",
    "#predictions_lr = logisticR.predict(valid_count)\n",
    "\n",
    "#let's check the accuracy score of the Logistic Regression model on the test set\n",
    "accuracy_score(test_y,predictions_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create first pipeline for base without reducing features.\n",
    "# #pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "\n",
    "# # create the grid of different parameters\n",
    "# parameters =  { 'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "#              'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "#              'solver' : ['sag','saga','lbfgs','newton-cg','liblinear']}\n",
    "\n",
    "# # Create the model for the Grid Search\n",
    "\n",
    "# GSlr = GridSearchCV(LogisticRegression(max_iter=1000), param_grid = parameters, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# # Let's fit the model on the train dataset\n",
    "# best_lr = GSlr.fit(train_tf, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisino tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision_tree = DecisionTreeClassifier(random_state=1234).fit(train_tf, train_y)\n",
    "\n",
    "# predictions_dt = decision_tree.predict(test_tf)\n",
    "\n",
    "# accuracy_score(test_y,predictions_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest = RandomForestClassifier(random_state=1234).fit(train_tf, train_y)\n",
    "\n",
    "# predictions_rf = random_forest.predict(test_tf)\n",
    "\n",
    "# accuracy_score(test_y,predictions_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use SVC model from sklearn.svm  \n",
    "svcModel = SVC(random_state=1234).fit(train_tf, train_y)\n",
    "\n",
    "#Find the prediction\n",
    "predictions_svc = svcModel.predict(test_tf)\n",
    "\n",
    "#Get the accuracy\n",
    "accuracy_score(test_y,predictions_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbModel = xgboost.XGBClassifier(random_state=1234).fit(train_count,train_y)\n",
    "\n",
    "predictions_xgb = xgbModel.predict(valid_count)\n",
    "\n",
    "accuracy_score(test_y,predictions_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set different parameters of the xgboost classifier\n",
    "# params ={\n",
    "#  \"learning_rate\"    : [0.01,0.05, 0.10, 0.15] ,\n",
    "#   \"min_child_weight\" : [ 1, 2,3,4 ,5, 6,7 ],\n",
    "#  \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "#  \"max_depth\"        : [ 3, 4, 5, 6,7, 8, 9,10],\n",
    "#  \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.6,0.7,0.8 ]   \n",
    "# }\n",
    "\n",
    "# #Let's do RandomizedSearchCv to find the best parameters\n",
    "# RCVxgb=RandomizedSearchCV(xgboost.XGBClassifier(),params,scoring='accuracy',n_jobs=-1,cv=5,verbose=3)\n",
    "\n",
    "# xgb = RCVxgb.fit(train_count, train_y)\n",
    "\n",
    "# #Let's check the best score\n",
    "# xgb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(train_count, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.best_params_\n",
    "\n",
    "pred = xgb.predict(valid_count)\n",
    "\n",
    "accuracy_score(test_y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>2 days 12 hours 6 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Australia/Sydney</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.1.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 14 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_ClockworK_t73w0k</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>860 Mb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         2 days 12 hours 6 mins\n",
       "H2O_cluster_timezone:       Australia/Sydney\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.1.3\n",
       "H2O_cluster_version_age:    1 month and 14 days\n",
       "H2O_cluster_name:           H2O_from_python_ClockworK_t73w0k\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    860 Mb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.6 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init(nthreads=-1)\n",
    "from h2o.estimators import  H2OWord2vecEstimator,H2OGradientBoostingEstimator\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator,H2OAutoEncoderEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "h20_train_df = h2o.H2OFrame(_train)\n",
    "h20_test_df = h2o.H2OFrame(_test)\n",
    "# train_x = h20_train_df['Data']\n",
    "# test_x = h20_test_df['Data']\n",
    "# train_y = h20_train_df['gender']\n",
    "# test_y = h20_test_df['gender']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "h20_train_df['abstract'] = h20_train_df['abstract'].ascharacter()\n",
    "h20_test_df['abstract'] = h20_test_df['abstract'].ascharacter()\n",
    "\n",
    "def tokenize(sentences):\n",
    "    tokenized = sentences.tokenize(\"\\\\W+\")\n",
    "    tokenized_lower = tokenized.tolower()\n",
    "    tokenized_filtered = tokenized_lower[(tokenized_lower.nchar() >= 2) | (tokenized_lower.isna()),:]\n",
    "    tokenized_words = tokenized_filtered[tokenized_filtered.grep(\"[0-9]\",invert=True,output_logical=True),:]\n",
    "    #tokenized_words = tokenized_words[(tokenized_words.isna()),:]\n",
    "    return tokenized_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec Model Build progress: |██████████████████████████████████████████ (cancelled) 100%\n"
     ]
    },
    {
     "ename": "H2OJobCancelled",
     "evalue": "Job<$03017f00000132d4ffffffff$_a92f914ddd1e66863fc094621820445f> was cancelled by the user.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OJobCancelled\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-1441ad47ccbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Call the word to Vector model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mw2v_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mH2OWord2vecEstimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1800\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mw2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwords\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtrain_vecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggregate_method\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"AVERAGE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h2o\\estimators\\estimator_base.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, max_runtime_secs, ignored_columns, model_id, verbose)\u001b[0m\n\u001b[0;32m    113\u001b[0m                                  \u001b[0mvalidation_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_runtime_secs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_runtime_secs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                                  ignored_columns=ignored_columns, model_id=model_id, verbose=verbose)\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     def train_segments(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h2o\\estimators\\estimator_base.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, parms, verbose)\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoll_updates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_print_model_scoring_history\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m         \u001b[0mmodel_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GET /%d/Models/%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrest_ver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"models\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resolve_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h2o\\job.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, poll_updates)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# check if failed... and politely print relevant message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"CANCELLED\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mH2OJobCancelled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Job<%s> was cancelled by the user.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"FAILED\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"stacktrace\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mH2OJobCancelled\u001b[0m: Job<$03017f00000132d4ffffffff$_a92f914ddd1e66863fc094621820445f> was cancelled by the user."
     ]
    }
   ],
   "source": [
    "words = tokenize(h20_train_df['abstract']) #Tokenize the training data\n",
    "\n",
    "words_test=tokenize(h20_test_df['abstract'])#Tokenize the testing data\n",
    "\n",
    "#Call the word to Vector model\n",
    "w2v_model = H2OWord2vecEstimator(vec_size = 1800)\n",
    "w2v_model.train(training_frame=words )\n",
    "\n",
    "train_vecs = w2v_model.transform(words, aggregate_method = \"AVERAGE\")\n",
    "test_vecs = w2v_model.transform(words_test, aggregate_method = \"AVERAGE\")\n",
    "\n",
    "h20_train_df_vec=h20_train_df.cbind(train_vecs) #Bind the Train Vec to the Train Frame\n",
    "h20_test_df_vec=h20_test_df.cbind(test_vecs) #Bind the Test Vec to the Test Frame\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the output as factor \n",
    "h20_train_df_vec['label']=h20_train_df_vec['label'].asfactor()\n",
    "h20_test_df_vec['label']=h20_test_df_vec['label'].asfactor()\n",
    "\n",
    "x=train_vecs.names\n",
    "y = 'label'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "model1 = H2ODeepLearningEstimator(\n",
    "    hidden=[32,32,32],l1=1e-5,epochs=10,seed=1234)\n",
    "\n",
    "model1.train( x=x, y=y,training_frame=h20_train_df_vec)\n",
    "\n",
    "prediction=model1.predict(h20_test_df_vec).as_data_frame()['predict']\n",
    "prediction\n",
    "\n",
    "# h2o = prediction.tolist()\n",
    "\n",
    "# k = test_data\n",
    "# k['label'] = h2o\n",
    "# k = k.drop(columns=['abstract'])\n",
    "# k.to_csv(r'h2o_test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, json, gc, re, random\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch, transformers, tokenizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from simpletransformers.seq2seq import Seq2SeqModel\n",
    "\n",
    "# eval_df = papers.sample(frac=0.1, random_state=42)\n",
    "# train_df = papers.drop(eval_df.index)\n",
    "\n",
    "model_args = {\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"save_model_every_epoch\": False,\n",
    "    \"save_eval_checkpoints\": False,\n",
    "    \"max_seq_length\": 512,\n",
    "    \"train_batch_size\": 4,\n",
    "    \"num_train_epochs\": 4\n",
    "#     \"use_cuda\" : False\n",
    "}\n",
    "\n",
    "# Create a Bart-base model\n",
    "model = Seq2SeqModel(encoder_decoder_type=\"bart\",\n",
    "                    encoder_decoder_name=\"facebook/bart-base\",\n",
    "                    args=model_args,use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train.columns = ['train_id','input_text', 'target_text']\n",
    "_test.columns = ['train_id','input_text', 'target_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Train the model\n",
    "model.train_model(_train)\n",
    "\n",
    "# Evaluate the model\n",
    "result = model.eval_model(_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
